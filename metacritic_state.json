{
  "best_metric": 1.1635738611221313,
  "best_model_checkpoint": "./results_meta\\checkpoint-32124",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 48186,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 8.469182968139648,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 2.589,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.858822822570801,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.4673,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 13.392696380615234,
      "learning_rate": 3e-06,
      "loss": 2.3638,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.866711616516113,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.1158,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.602809429168701,
      "learning_rate": 5e-06,
      "loss": 2.0528,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.590128898620605,
      "learning_rate": 6e-06,
      "loss": 1.9999,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.8484110832214355,
      "learning_rate": 7.000000000000001e-06,
      "loss": 1.8542,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.925279140472412,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.875,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.113082885742188,
      "learning_rate": 9e-06,
      "loss": 1.8166,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.176511764526367,
      "learning_rate": 1e-05,
      "loss": 1.8393,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.162261962890625,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.8466,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.696991920471191,
      "learning_rate": 1.2e-05,
      "loss": 1.747,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.288877010345459,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.8427,
      "step": 130
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.50139856338501,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.7639,
      "step": 140
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.735785961151123,
      "learning_rate": 1.5e-05,
      "loss": 1.7055,
      "step": 150
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.1353654861450195,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.6885,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.574619770050049,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.7182,
      "step": 170
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.972448348999023,
      "learning_rate": 1.8e-05,
      "loss": 1.7772,
      "step": 180
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.3782477378845215,
      "learning_rate": 1.9e-05,
      "loss": 1.7217,
      "step": 190
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.274188041687012,
      "learning_rate": 2e-05,
      "loss": 1.7412,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 6.048167705535889,
      "learning_rate": 2.1e-05,
      "loss": 1.6626,
      "step": 210
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.477436542510986,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.638,
      "step": 220
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.351593971252441,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.6645,
      "step": 230
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.13907527923584,
      "learning_rate": 2.4e-05,
      "loss": 1.6246,
      "step": 240
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.269869327545166,
      "learning_rate": 2.5e-05,
      "loss": 1.6826,
      "step": 250
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.598234176635742,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.6048,
      "step": 260
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.653109550476074,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.4793,
      "step": 270
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.951671600341797,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.5599,
      "step": 280
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.263845920562744,
      "learning_rate": 2.9e-05,
      "loss": 1.5492,
      "step": 290
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.569410800933838,
      "learning_rate": 3e-05,
      "loss": 1.5271,
      "step": 300
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.383042812347412,
      "learning_rate": 3.1e-05,
      "loss": 1.4305,
      "step": 310
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.384608268737793,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.5335,
      "step": 320
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.863066673278809,
      "learning_rate": 3.3e-05,
      "loss": 1.5794,
      "step": 330
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.71060848236084,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.5362,
      "step": 340
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.101305961608887,
      "learning_rate": 3.5e-05,
      "loss": 1.561,
      "step": 350
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.494704246520996,
      "learning_rate": 3.6e-05,
      "loss": 1.5973,
      "step": 360
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.943214416503906,
      "learning_rate": 3.7e-05,
      "loss": 1.5002,
      "step": 370
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.665684700012207,
      "learning_rate": 3.8e-05,
      "loss": 1.5037,
      "step": 380
    },
    {
      "epoch": 0.02,
      "grad_norm": 5.816043376922607,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.4134,
      "step": 390
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.073604583740234,
      "learning_rate": 4e-05,
      "loss": 1.5146,
      "step": 400
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.495013236999512,
      "learning_rate": 4.1e-05,
      "loss": 1.451,
      "step": 410
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.281500816345215,
      "learning_rate": 4.2e-05,
      "loss": 1.4504,
      "step": 420
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.872162818908691,
      "learning_rate": 4.3e-05,
      "loss": 1.5835,
      "step": 430
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.15291690826416,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.5652,
      "step": 440
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.138010025024414,
      "learning_rate": 4.5e-05,
      "loss": 1.5618,
      "step": 450
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.083184242248535,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.4823,
      "step": 460
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.287960052490234,
      "learning_rate": 4.7e-05,
      "loss": 1.4052,
      "step": 470
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.324625015258789,
      "learning_rate": 4.8e-05,
      "loss": 1.4961,
      "step": 480
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.981504440307617,
      "learning_rate": 4.9e-05,
      "loss": 1.4316,
      "step": 490
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.655495643615723,
      "learning_rate": 5e-05,
      "loss": 1.4752,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.775706768035889,
      "learning_rate": 4.998951474227237e-05,
      "loss": 1.5931,
      "step": 510
    },
    {
      "epoch": 0.03,
      "grad_norm": 14.831883430480957,
      "learning_rate": 4.997902948454473e-05,
      "loss": 1.3928,
      "step": 520
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.987264633178711,
      "learning_rate": 4.99685442268171e-05,
      "loss": 1.569,
      "step": 530
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.534892559051514,
      "learning_rate": 4.9958058969089464e-05,
      "loss": 1.4784,
      "step": 540
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.774346351623535,
      "learning_rate": 4.9947573711361826e-05,
      "loss": 1.4412,
      "step": 550
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.227514266967773,
      "learning_rate": 4.9937088453634194e-05,
      "loss": 1.4404,
      "step": 560
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.083699703216553,
      "learning_rate": 4.9926603195906556e-05,
      "loss": 1.4432,
      "step": 570
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.67879581451416,
      "learning_rate": 4.9916117938178925e-05,
      "loss": 1.4569,
      "step": 580
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.636619567871094,
      "learning_rate": 4.990563268045129e-05,
      "loss": 1.3376,
      "step": 590
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.2285919189453125,
      "learning_rate": 4.9895147422723655e-05,
      "loss": 1.4219,
      "step": 600
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.918747901916504,
      "learning_rate": 4.988466216499602e-05,
      "loss": 1.3863,
      "step": 610
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.872854232788086,
      "learning_rate": 4.9874176907268386e-05,
      "loss": 1.4607,
      "step": 620
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.612919807434082,
      "learning_rate": 4.986369164954075e-05,
      "loss": 1.4392,
      "step": 630
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.245354652404785,
      "learning_rate": 4.985320639181311e-05,
      "loss": 1.2473,
      "step": 640
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.934012413024902,
      "learning_rate": 4.984272113408548e-05,
      "loss": 1.4767,
      "step": 650
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.388402938842773,
      "learning_rate": 4.983223587635784e-05,
      "loss": 1.3328,
      "step": 660
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.259807586669922,
      "learning_rate": 4.982175061863021e-05,
      "loss": 1.3953,
      "step": 670
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.027029991149902,
      "learning_rate": 4.981126536090258e-05,
      "loss": 1.3722,
      "step": 680
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.973475456237793,
      "learning_rate": 4.980078010317494e-05,
      "loss": 1.3524,
      "step": 690
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.724264144897461,
      "learning_rate": 4.97902948454473e-05,
      "loss": 1.4629,
      "step": 700
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.961821556091309,
      "learning_rate": 4.9779809587719664e-05,
      "loss": 1.31,
      "step": 710
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.466880798339844,
      "learning_rate": 4.976932432999203e-05,
      "loss": 1.4379,
      "step": 720
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.585747718811035,
      "learning_rate": 4.9758839072264394e-05,
      "loss": 1.4333,
      "step": 730
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.694342613220215,
      "learning_rate": 4.974835381453676e-05,
      "loss": 1.411,
      "step": 740
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.951031684875488,
      "learning_rate": 4.973786855680913e-05,
      "loss": 1.459,
      "step": 750
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.213020324707031,
      "learning_rate": 4.9727383299081494e-05,
      "loss": 1.5258,
      "step": 760
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.953762531280518,
      "learning_rate": 4.971689804135386e-05,
      "loss": 1.4537,
      "step": 770
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.080827236175537,
      "learning_rate": 4.9706412783626224e-05,
      "loss": 1.3631,
      "step": 780
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.05146598815918,
      "learning_rate": 4.9695927525898586e-05,
      "loss": 1.2718,
      "step": 790
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.237475872039795,
      "learning_rate": 4.9685442268170955e-05,
      "loss": 1.533,
      "step": 800
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.490145683288574,
      "learning_rate": 4.967495701044332e-05,
      "loss": 1.4097,
      "step": 810
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.714345932006836,
      "learning_rate": 4.9664471752715686e-05,
      "loss": 1.5042,
      "step": 820
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.085797309875488,
      "learning_rate": 4.965398649498805e-05,
      "loss": 1.3927,
      "step": 830
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.673666477203369,
      "learning_rate": 4.9643501237260416e-05,
      "loss": 1.3648,
      "step": 840
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.850601196289062,
      "learning_rate": 4.9633015979532785e-05,
      "loss": 1.4831,
      "step": 850
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.497176170349121,
      "learning_rate": 4.962253072180515e-05,
      "loss": 1.451,
      "step": 860
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.1005859375,
      "learning_rate": 4.961204546407751e-05,
      "loss": 1.3819,
      "step": 870
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.026671409606934,
      "learning_rate": 4.960156020634987e-05,
      "loss": 1.3555,
      "step": 880
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.78378963470459,
      "learning_rate": 4.959107494862224e-05,
      "loss": 1.3962,
      "step": 890
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.220786094665527,
      "learning_rate": 4.95805896908946e-05,
      "loss": 1.3474,
      "step": 900
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.191887855529785,
      "learning_rate": 4.957010443316697e-05,
      "loss": 1.3226,
      "step": 910
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.863104820251465,
      "learning_rate": 4.955961917543934e-05,
      "loss": 1.3543,
      "step": 920
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.672807693481445,
      "learning_rate": 4.95491339177117e-05,
      "loss": 1.4111,
      "step": 930
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.625632286071777,
      "learning_rate": 4.953864865998407e-05,
      "loss": 1.3622,
      "step": 940
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.021369934082031,
      "learning_rate": 4.952816340225643e-05,
      "loss": 1.3879,
      "step": 950
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.2026543617248535,
      "learning_rate": 4.951767814452879e-05,
      "loss": 1.3938,
      "step": 960
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.636778354644775,
      "learning_rate": 4.950719288680116e-05,
      "loss": 1.3628,
      "step": 970
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.049491882324219,
      "learning_rate": 4.9496707629073524e-05,
      "loss": 1.3483,
      "step": 980
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.124091625213623,
      "learning_rate": 4.948622237134589e-05,
      "loss": 1.352,
      "step": 990
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.653192520141602,
      "learning_rate": 4.9475737113618254e-05,
      "loss": 1.3784,
      "step": 1000
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.832566261291504,
      "learning_rate": 4.946525185589062e-05,
      "loss": 1.406,
      "step": 1010
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.571727752685547,
      "learning_rate": 4.9454766598162985e-05,
      "loss": 1.3008,
      "step": 1020
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.239964962005615,
      "learning_rate": 4.944428134043535e-05,
      "loss": 1.2698,
      "step": 1030
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.530020713806152,
      "learning_rate": 4.9433796082707716e-05,
      "loss": 1.3311,
      "step": 1040
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.2511568069458,
      "learning_rate": 4.942331082498008e-05,
      "loss": 1.4294,
      "step": 1050
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.419126033782959,
      "learning_rate": 4.9412825567252446e-05,
      "loss": 1.3616,
      "step": 1060
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.587875366210938,
      "learning_rate": 4.940234030952481e-05,
      "loss": 1.4459,
      "step": 1070
    },
    {
      "epoch": 0.07,
      "grad_norm": 5.878350734710693,
      "learning_rate": 4.939185505179718e-05,
      "loss": 1.3837,
      "step": 1080
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.402450561523438,
      "learning_rate": 4.9381369794069546e-05,
      "loss": 1.3703,
      "step": 1090
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.425090789794922,
      "learning_rate": 4.937088453634191e-05,
      "loss": 1.3627,
      "step": 1100
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.804685115814209,
      "learning_rate": 4.936039927861427e-05,
      "loss": 1.2914,
      "step": 1110
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.511937141418457,
      "learning_rate": 4.934991402088663e-05,
      "loss": 1.2635,
      "step": 1120
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.698888301849365,
      "learning_rate": 4.9339428763159e-05,
      "loss": 1.4414,
      "step": 1130
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.31287670135498,
      "learning_rate": 4.932894350543136e-05,
      "loss": 1.2951,
      "step": 1140
    },
    {
      "epoch": 0.07,
      "grad_norm": 5.683271408081055,
      "learning_rate": 4.931845824770373e-05,
      "loss": 1.3425,
      "step": 1150
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.644371509552002,
      "learning_rate": 4.93079729899761e-05,
      "loss": 1.4135,
      "step": 1160
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.22986364364624,
      "learning_rate": 4.929748773224846e-05,
      "loss": 1.3815,
      "step": 1170
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.000761985778809,
      "learning_rate": 4.928700247452083e-05,
      "loss": 1.3408,
      "step": 1180
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.023138046264648,
      "learning_rate": 4.927651721679319e-05,
      "loss": 1.3337,
      "step": 1190
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.959197044372559,
      "learning_rate": 4.9266031959065554e-05,
      "loss": 1.3441,
      "step": 1200
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.318507194519043,
      "learning_rate": 4.925554670133792e-05,
      "loss": 1.3265,
      "step": 1210
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.828346252441406,
      "learning_rate": 4.9245061443610284e-05,
      "loss": 1.3165,
      "step": 1220
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.435018062591553,
      "learning_rate": 4.923457618588265e-05,
      "loss": 1.2372,
      "step": 1230
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.796036720275879,
      "learning_rate": 4.9224090928155015e-05,
      "loss": 1.4103,
      "step": 1240
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.389603137969971,
      "learning_rate": 4.9213605670427384e-05,
      "loss": 1.3546,
      "step": 1250
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.763497352600098,
      "learning_rate": 4.920312041269975e-05,
      "loss": 1.4184,
      "step": 1260
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.512279510498047,
      "learning_rate": 4.9192635154972114e-05,
      "loss": 1.3061,
      "step": 1270
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.58513355255127,
      "learning_rate": 4.9182149897244476e-05,
      "loss": 1.3723,
      "step": 1280
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.111693382263184,
      "learning_rate": 4.917166463951684e-05,
      "loss": 1.3826,
      "step": 1290
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.977409839630127,
      "learning_rate": 4.916117938178921e-05,
      "loss": 1.3792,
      "step": 1300
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.783984184265137,
      "learning_rate": 4.915069412406157e-05,
      "loss": 1.3467,
      "step": 1310
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.818686008453369,
      "learning_rate": 4.914020886633394e-05,
      "loss": 1.3629,
      "step": 1320
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.848398208618164,
      "learning_rate": 4.9129723608606306e-05,
      "loss": 1.4424,
      "step": 1330
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.185088157653809,
      "learning_rate": 4.911923835087867e-05,
      "loss": 1.4083,
      "step": 1340
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.616438865661621,
      "learning_rate": 4.910875309315103e-05,
      "loss": 1.427,
      "step": 1350
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.794845581054688,
      "learning_rate": 4.909826783542339e-05,
      "loss": 1.2391,
      "step": 1360
    },
    {
      "epoch": 0.09,
      "grad_norm": 6.062673568725586,
      "learning_rate": 4.908778257769576e-05,
      "loss": 1.3731,
      "step": 1370
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.2641191482543945,
      "learning_rate": 4.907729731996813e-05,
      "loss": 1.3307,
      "step": 1380
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.440840721130371,
      "learning_rate": 4.906681206224049e-05,
      "loss": 1.3152,
      "step": 1390
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.269869804382324,
      "learning_rate": 4.905632680451286e-05,
      "loss": 1.3063,
      "step": 1400
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.998580455780029,
      "learning_rate": 4.904584154678522e-05,
      "loss": 1.3381,
      "step": 1410
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.624431133270264,
      "learning_rate": 4.903535628905759e-05,
      "loss": 1.3634,
      "step": 1420
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.870723724365234,
      "learning_rate": 4.902487103132995e-05,
      "loss": 1.3816,
      "step": 1430
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.839621543884277,
      "learning_rate": 4.9014385773602314e-05,
      "loss": 1.4096,
      "step": 1440
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.131036758422852,
      "learning_rate": 4.900390051587468e-05,
      "loss": 1.394,
      "step": 1450
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.067509651184082,
      "learning_rate": 4.8993415258147045e-05,
      "loss": 1.2763,
      "step": 1460
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.560574531555176,
      "learning_rate": 4.8982930000419414e-05,
      "loss": 1.3628,
      "step": 1470
    },
    {
      "epoch": 0.09,
      "grad_norm": 13.47542953491211,
      "learning_rate": 4.8972444742691776e-05,
      "loss": 1.315,
      "step": 1480
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.737232208251953,
      "learning_rate": 4.8961959484964144e-05,
      "loss": 1.2984,
      "step": 1490
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.267544746398926,
      "learning_rate": 4.895147422723651e-05,
      "loss": 1.2986,
      "step": 1500
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.800694465637207,
      "learning_rate": 4.8940988969508875e-05,
      "loss": 1.2764,
      "step": 1510
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.420547485351562,
      "learning_rate": 4.893050371178124e-05,
      "loss": 1.3894,
      "step": 1520
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.602132797241211,
      "learning_rate": 4.89200184540536e-05,
      "loss": 1.3601,
      "step": 1530
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.318822860717773,
      "learning_rate": 4.890953319632597e-05,
      "loss": 1.2014,
      "step": 1540
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.624969482421875,
      "learning_rate": 4.8899047938598336e-05,
      "loss": 1.3176,
      "step": 1550
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.696367263793945,
      "learning_rate": 4.88885626808707e-05,
      "loss": 1.3633,
      "step": 1560
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.532200813293457,
      "learning_rate": 4.887807742314307e-05,
      "loss": 1.4441,
      "step": 1570
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.740318298339844,
      "learning_rate": 4.886759216541543e-05,
      "loss": 1.329,
      "step": 1580
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.260868072509766,
      "learning_rate": 4.88571069076878e-05,
      "loss": 1.4838,
      "step": 1590
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.326056957244873,
      "learning_rate": 4.884662164996015e-05,
      "loss": 1.2378,
      "step": 1600
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.536566734313965,
      "learning_rate": 4.883613639223252e-05,
      "loss": 1.4616,
      "step": 1610
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.7450852394104,
      "learning_rate": 4.882565113450489e-05,
      "loss": 1.292,
      "step": 1620
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.230020046234131,
      "learning_rate": 4.881516587677725e-05,
      "loss": 1.2194,
      "step": 1630
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.86026668548584,
      "learning_rate": 4.880468061904962e-05,
      "loss": 1.4685,
      "step": 1640
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.94555950164795,
      "learning_rate": 4.879419536132198e-05,
      "loss": 1.4344,
      "step": 1650
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.474843978881836,
      "learning_rate": 4.878371010359435e-05,
      "loss": 1.3406,
      "step": 1660
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.399116039276123,
      "learning_rate": 4.877322484586671e-05,
      "loss": 1.4161,
      "step": 1670
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.127807140350342,
      "learning_rate": 4.8762739588139075e-05,
      "loss": 1.3819,
      "step": 1680
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.155791282653809,
      "learning_rate": 4.8752254330411444e-05,
      "loss": 1.1202,
      "step": 1690
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.111885070800781,
      "learning_rate": 4.8741769072683806e-05,
      "loss": 1.3207,
      "step": 1700
    },
    {
      "epoch": 0.11,
      "grad_norm": 12.419290542602539,
      "learning_rate": 4.8731283814956174e-05,
      "loss": 1.4179,
      "step": 1710
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.857842922210693,
      "learning_rate": 4.8720798557228536e-05,
      "loss": 1.3857,
      "step": 1720
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.25147533416748,
      "learning_rate": 4.8710313299500905e-05,
      "loss": 1.3913,
      "step": 1730
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.481999397277832,
      "learning_rate": 4.8699828041773274e-05,
      "loss": 1.472,
      "step": 1740
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.811723709106445,
      "learning_rate": 4.8689342784045636e-05,
      "loss": 1.2915,
      "step": 1750
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.089920043945312,
      "learning_rate": 4.8678857526318e-05,
      "loss": 1.4141,
      "step": 1760
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.424367427825928,
      "learning_rate": 4.866837226859036e-05,
      "loss": 1.3373,
      "step": 1770
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.556323051452637,
      "learning_rate": 4.865788701086273e-05,
      "loss": 1.4424,
      "step": 1780
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.034502983093262,
      "learning_rate": 4.86474017531351e-05,
      "loss": 1.2632,
      "step": 1790
    },
    {
      "epoch": 0.11,
      "grad_norm": 15.567963600158691,
      "learning_rate": 4.863691649540746e-05,
      "loss": 1.2919,
      "step": 1800
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.82471227645874,
      "learning_rate": 4.862643123767983e-05,
      "loss": 1.3682,
      "step": 1810
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.309836387634277,
      "learning_rate": 4.861594597995219e-05,
      "loss": 1.4769,
      "step": 1820
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.345871925354004,
      "learning_rate": 4.860546072222456e-05,
      "loss": 1.3392,
      "step": 1830
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.305202007293701,
      "learning_rate": 4.859497546449692e-05,
      "loss": 1.3583,
      "step": 1840
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.062461853027344,
      "learning_rate": 4.858449020676928e-05,
      "loss": 1.2966,
      "step": 1850
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.9946417808532715,
      "learning_rate": 4.857400494904165e-05,
      "loss": 1.3006,
      "step": 1860
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.505829811096191,
      "learning_rate": 4.856351969131401e-05,
      "loss": 1.3029,
      "step": 1870
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.515876293182373,
      "learning_rate": 4.855303443358638e-05,
      "loss": 1.3012,
      "step": 1880
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.586292743682861,
      "learning_rate": 4.854254917585874e-05,
      "loss": 1.3258,
      "step": 1890
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.655548095703125,
      "learning_rate": 4.853206391813111e-05,
      "loss": 1.2313,
      "step": 1900
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.294937133789062,
      "learning_rate": 4.852157866040348e-05,
      "loss": 1.2231,
      "step": 1910
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.397704124450684,
      "learning_rate": 4.8511093402675836e-05,
      "loss": 1.4077,
      "step": 1920
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.816697120666504,
      "learning_rate": 4.8500608144948204e-05,
      "loss": 1.4173,
      "step": 1930
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.144529342651367,
      "learning_rate": 4.8490122887220566e-05,
      "loss": 1.2723,
      "step": 1940
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.347396850585938,
      "learning_rate": 4.8479637629492935e-05,
      "loss": 1.3035,
      "step": 1950
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.8616623878479,
      "learning_rate": 4.8469152371765304e-05,
      "loss": 1.2761,
      "step": 1960
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.97694206237793,
      "learning_rate": 4.8458667114037666e-05,
      "loss": 1.306,
      "step": 1970
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.103466987609863,
      "learning_rate": 4.8448181856310034e-05,
      "loss": 1.3315,
      "step": 1980
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.280417442321777,
      "learning_rate": 4.8437696598582396e-05,
      "loss": 1.4182,
      "step": 1990
    },
    {
      "epoch": 0.12,
      "grad_norm": 14.338430404663086,
      "learning_rate": 4.842721134085476e-05,
      "loss": 1.3383,
      "step": 2000
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.9849348068237305,
      "learning_rate": 4.841672608312712e-05,
      "loss": 1.3958,
      "step": 2010
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.623894691467285,
      "learning_rate": 4.840624082539949e-05,
      "loss": 1.3151,
      "step": 2020
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.898085117340088,
      "learning_rate": 4.839575556767186e-05,
      "loss": 1.3437,
      "step": 2030
    },
    {
      "epoch": 0.13,
      "grad_norm": 8.27596664428711,
      "learning_rate": 4.838527030994422e-05,
      "loss": 1.279,
      "step": 2040
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.249792575836182,
      "learning_rate": 4.837478505221659e-05,
      "loss": 1.1804,
      "step": 2050
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.16873025894165,
      "learning_rate": 4.836429979448895e-05,
      "loss": 1.3737,
      "step": 2060
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.741728782653809,
      "learning_rate": 4.835381453676132e-05,
      "loss": 1.3436,
      "step": 2070
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.98932409286499,
      "learning_rate": 4.834332927903368e-05,
      "loss": 1.3115,
      "step": 2080
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.431316375732422,
      "learning_rate": 4.833284402130604e-05,
      "loss": 1.3063,
      "step": 2090
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.953734874725342,
      "learning_rate": 4.832235876357841e-05,
      "loss": 1.4798,
      "step": 2100
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.10084867477417,
      "learning_rate": 4.831187350585077e-05,
      "loss": 1.3036,
      "step": 2110
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.736168384552002,
      "learning_rate": 4.830138824812314e-05,
      "loss": 1.237,
      "step": 2120
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.11341667175293,
      "learning_rate": 4.8290902990395504e-05,
      "loss": 1.3456,
      "step": 2130
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.82614517211914,
      "learning_rate": 4.828041773266787e-05,
      "loss": 1.323,
      "step": 2140
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.502386093139648,
      "learning_rate": 4.826993247494024e-05,
      "loss": 1.2612,
      "step": 2150
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.105184078216553,
      "learning_rate": 4.82594472172126e-05,
      "loss": 1.2511,
      "step": 2160
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.778310775756836,
      "learning_rate": 4.8248961959484965e-05,
      "loss": 1.3366,
      "step": 2170
    },
    {
      "epoch": 0.14,
      "grad_norm": 6.82811975479126,
      "learning_rate": 4.823847670175733e-05,
      "loss": 1.3566,
      "step": 2180
    },
    {
      "epoch": 0.14,
      "grad_norm": 6.164840221405029,
      "learning_rate": 4.8227991444029696e-05,
      "loss": 1.3635,
      "step": 2190
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.498619556427002,
      "learning_rate": 4.8217506186302064e-05,
      "loss": 1.3167,
      "step": 2200
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.018167972564697,
      "learning_rate": 4.8207020928574426e-05,
      "loss": 1.2446,
      "step": 2210
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.14592170715332,
      "learning_rate": 4.8196535670846795e-05,
      "loss": 1.2898,
      "step": 2220
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.6974515914917,
      "learning_rate": 4.818605041311916e-05,
      "loss": 1.3726,
      "step": 2230
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.579829216003418,
      "learning_rate": 4.817556515539152e-05,
      "loss": 1.4052,
      "step": 2240
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.427550315856934,
      "learning_rate": 4.816507989766389e-05,
      "loss": 1.285,
      "step": 2250
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.57585334777832,
      "learning_rate": 4.815459463993625e-05,
      "loss": 1.4926,
      "step": 2260
    },
    {
      "epoch": 0.14,
      "grad_norm": 8.800249099731445,
      "learning_rate": 4.814410938220862e-05,
      "loss": 1.3987,
      "step": 2270
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.757595539093018,
      "learning_rate": 4.813362412448098e-05,
      "loss": 1.3792,
      "step": 2280
    },
    {
      "epoch": 0.14,
      "grad_norm": 6.225831031799316,
      "learning_rate": 4.812313886675335e-05,
      "loss": 1.259,
      "step": 2290
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.007201671600342,
      "learning_rate": 4.811265360902571e-05,
      "loss": 1.3052,
      "step": 2300
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.381310939788818,
      "learning_rate": 4.810216835129808e-05,
      "loss": 1.2897,
      "step": 2310
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.905447959899902,
      "learning_rate": 4.809168309357044e-05,
      "loss": 1.2941,
      "step": 2320
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.211112976074219,
      "learning_rate": 4.80811978358428e-05,
      "loss": 1.2776,
      "step": 2330
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.671963691711426,
      "learning_rate": 4.807071257811517e-05,
      "loss": 1.3802,
      "step": 2340
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.136290550231934,
      "learning_rate": 4.8060227320387534e-05,
      "loss": 1.4314,
      "step": 2350
    },
    {
      "epoch": 0.15,
      "grad_norm": 12.733674049377441,
      "learning_rate": 4.80497420626599e-05,
      "loss": 1.3173,
      "step": 2360
    },
    {
      "epoch": 0.15,
      "grad_norm": 10.398337364196777,
      "learning_rate": 4.803925680493227e-05,
      "loss": 1.2142,
      "step": 2370
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.187377452850342,
      "learning_rate": 4.802877154720463e-05,
      "loss": 1.3468,
      "step": 2380
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.350114822387695,
      "learning_rate": 4.8018286289477e-05,
      "loss": 1.2381,
      "step": 2390
    },
    {
      "epoch": 0.15,
      "grad_norm": 10.682117462158203,
      "learning_rate": 4.8007801031749364e-05,
      "loss": 1.3546,
      "step": 2400
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.948037147521973,
      "learning_rate": 4.7997315774021726e-05,
      "loss": 1.3728,
      "step": 2410
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.635486125946045,
      "learning_rate": 4.798683051629409e-05,
      "loss": 1.357,
      "step": 2420
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.553727149963379,
      "learning_rate": 4.7976345258566456e-05,
      "loss": 1.2658,
      "step": 2430
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.108007907867432,
      "learning_rate": 4.7965860000838825e-05,
      "loss": 1.3607,
      "step": 2440
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.38413667678833,
      "learning_rate": 4.795537474311119e-05,
      "loss": 1.2722,
      "step": 2450
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.839029312133789,
      "learning_rate": 4.7944889485383556e-05,
      "loss": 1.289,
      "step": 2460
    },
    {
      "epoch": 0.15,
      "grad_norm": 8.638872146606445,
      "learning_rate": 4.793440422765592e-05,
      "loss": 1.3355,
      "step": 2470
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.754429340362549,
      "learning_rate": 4.7923918969928286e-05,
      "loss": 1.2869,
      "step": 2480
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.429826736450195,
      "learning_rate": 4.791343371220065e-05,
      "loss": 1.3099,
      "step": 2490
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.746499061584473,
      "learning_rate": 4.790294845447301e-05,
      "loss": 1.3906,
      "step": 2500
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.463802337646484,
      "learning_rate": 4.789246319674538e-05,
      "loss": 1.3463,
      "step": 2510
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.630061626434326,
      "learning_rate": 4.788197793901774e-05,
      "loss": 1.3302,
      "step": 2520
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.987747192382812,
      "learning_rate": 4.787149268129011e-05,
      "loss": 1.2867,
      "step": 2530
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.267746925354004,
      "learning_rate": 4.786100742356248e-05,
      "loss": 1.3015,
      "step": 2540
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.572073459625244,
      "learning_rate": 4.785052216583484e-05,
      "loss": 1.3086,
      "step": 2550
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.076662540435791,
      "learning_rate": 4.78400369081072e-05,
      "loss": 1.3714,
      "step": 2560
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.136102676391602,
      "learning_rate": 4.7829551650379564e-05,
      "loss": 1.427,
      "step": 2570
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.713535308837891,
      "learning_rate": 4.781906639265193e-05,
      "loss": 1.2589,
      "step": 2580
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.316356658935547,
      "learning_rate": 4.7808581134924295e-05,
      "loss": 1.3313,
      "step": 2590
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.154989242553711,
      "learning_rate": 4.779809587719666e-05,
      "loss": 1.2517,
      "step": 2600
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.683775901794434,
      "learning_rate": 4.778761061946903e-05,
      "loss": 1.3103,
      "step": 2610
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.565043449401855,
      "learning_rate": 4.7777125361741394e-05,
      "loss": 1.3942,
      "step": 2620
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.277379512786865,
      "learning_rate": 4.776664010401376e-05,
      "loss": 1.3242,
      "step": 2630
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.373891353607178,
      "learning_rate": 4.7756154846286124e-05,
      "loss": 1.3303,
      "step": 2640
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.130147457122803,
      "learning_rate": 4.7745669588558486e-05,
      "loss": 1.414,
      "step": 2650
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.806342601776123,
      "learning_rate": 4.7735184330830855e-05,
      "loss": 1.3363,
      "step": 2660
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.657948970794678,
      "learning_rate": 4.772469907310322e-05,
      "loss": 1.3862,
      "step": 2670
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.716289043426514,
      "learning_rate": 4.7714213815375586e-05,
      "loss": 1.3479,
      "step": 2680
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.090693473815918,
      "learning_rate": 4.770372855764795e-05,
      "loss": 1.2876,
      "step": 2690
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.433560371398926,
      "learning_rate": 4.7693243299920316e-05,
      "loss": 1.2496,
      "step": 2700
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.348114967346191,
      "learning_rate": 4.768275804219268e-05,
      "loss": 1.3886,
      "step": 2710
    },
    {
      "epoch": 0.17,
      "grad_norm": 11.17847728729248,
      "learning_rate": 4.767227278446505e-05,
      "loss": 1.3949,
      "step": 2720
    },
    {
      "epoch": 0.17,
      "grad_norm": 11.170734405517578,
      "learning_rate": 4.766178752673741e-05,
      "loss": 1.3692,
      "step": 2730
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.275269985198975,
      "learning_rate": 4.765130226900977e-05,
      "loss": 1.3357,
      "step": 2740
    },
    {
      "epoch": 0.17,
      "grad_norm": 5.779294490814209,
      "learning_rate": 4.764081701128214e-05,
      "loss": 1.3321,
      "step": 2750
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.784387588500977,
      "learning_rate": 4.76303317535545e-05,
      "loss": 1.232,
      "step": 2760
    },
    {
      "epoch": 0.17,
      "grad_norm": 13.618284225463867,
      "learning_rate": 4.761984649582687e-05,
      "loss": 1.3956,
      "step": 2770
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.698172569274902,
      "learning_rate": 4.760936123809924e-05,
      "loss": 1.2128,
      "step": 2780
    },
    {
      "epoch": 0.17,
      "grad_norm": 5.671521186828613,
      "learning_rate": 4.75988759803716e-05,
      "loss": 1.2644,
      "step": 2790
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.979593276977539,
      "learning_rate": 4.758839072264397e-05,
      "loss": 1.3415,
      "step": 2800
    },
    {
      "epoch": 0.17,
      "grad_norm": 6.489789962768555,
      "learning_rate": 4.757790546491633e-05,
      "loss": 1.3672,
      "step": 2810
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.990167617797852,
      "learning_rate": 4.756742020718869e-05,
      "loss": 1.2768,
      "step": 2820
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.7915940284729,
      "learning_rate": 4.755693494946106e-05,
      "loss": 1.2249,
      "step": 2830
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.802742958068848,
      "learning_rate": 4.7546449691733424e-05,
      "loss": 1.2519,
      "step": 2840
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.220394134521484,
      "learning_rate": 4.753596443400579e-05,
      "loss": 1.3878,
      "step": 2850
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.099983215332031,
      "learning_rate": 4.7525479176278155e-05,
      "loss": 1.3517,
      "step": 2860
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.690405368804932,
      "learning_rate": 4.751499391855052e-05,
      "loss": 1.3172,
      "step": 2870
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.429581642150879,
      "learning_rate": 4.7504508660822885e-05,
      "loss": 1.2601,
      "step": 2880
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.691526412963867,
      "learning_rate": 4.749402340309525e-05,
      "loss": 1.2919,
      "step": 2890
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.613527297973633,
      "learning_rate": 4.7483538145367616e-05,
      "loss": 1.2649,
      "step": 2900
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.0815935134887695,
      "learning_rate": 4.747305288763998e-05,
      "loss": 1.2325,
      "step": 2910
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.937342166900635,
      "learning_rate": 4.7462567629912346e-05,
      "loss": 1.2639,
      "step": 2920
    },
    {
      "epoch": 0.18,
      "grad_norm": 8.191259384155273,
      "learning_rate": 4.745208237218471e-05,
      "loss": 1.3517,
      "step": 2930
    },
    {
      "epoch": 0.18,
      "grad_norm": 13.491455078125,
      "learning_rate": 4.744159711445708e-05,
      "loss": 1.3389,
      "step": 2940
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.386490821838379,
      "learning_rate": 4.7431111856729446e-05,
      "loss": 1.3715,
      "step": 2950
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.30735445022583,
      "learning_rate": 4.742062659900181e-05,
      "loss": 1.1658,
      "step": 2960
    },
    {
      "epoch": 0.18,
      "grad_norm": 7.638795852661133,
      "learning_rate": 4.741014134127417e-05,
      "loss": 1.3577,
      "step": 2970
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.296430587768555,
      "learning_rate": 4.739965608354653e-05,
      "loss": 1.3864,
      "step": 2980
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.889550685882568,
      "learning_rate": 4.73891708258189e-05,
      "loss": 1.3545,
      "step": 2990
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.668995380401611,
      "learning_rate": 4.737868556809126e-05,
      "loss": 1.2916,
      "step": 3000
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.657049179077148,
      "learning_rate": 4.736820031036363e-05,
      "loss": 1.2679,
      "step": 3010
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.683868408203125,
      "learning_rate": 4.7357715052636e-05,
      "loss": 1.3205,
      "step": 3020
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.387764930725098,
      "learning_rate": 4.734722979490836e-05,
      "loss": 1.2932,
      "step": 3030
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.992687702178955,
      "learning_rate": 4.733674453718073e-05,
      "loss": 1.2534,
      "step": 3040
    },
    {
      "epoch": 0.19,
      "grad_norm": 10.408773422241211,
      "learning_rate": 4.732625927945309e-05,
      "loss": 1.3222,
      "step": 3050
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.699676513671875,
      "learning_rate": 4.7315774021725454e-05,
      "loss": 1.2426,
      "step": 3060
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.554471969604492,
      "learning_rate": 4.730528876399782e-05,
      "loss": 1.1827,
      "step": 3070
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.124337196350098,
      "learning_rate": 4.7294803506270185e-05,
      "loss": 1.3545,
      "step": 3080
    },
    {
      "epoch": 0.19,
      "grad_norm": 5.482713222503662,
      "learning_rate": 4.728431824854255e-05,
      "loss": 1.2627,
      "step": 3090
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.454373359680176,
      "learning_rate": 4.7273832990814915e-05,
      "loss": 1.2806,
      "step": 3100
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.908191204071045,
      "learning_rate": 4.7263347733087284e-05,
      "loss": 1.2439,
      "step": 3110
    },
    {
      "epoch": 0.19,
      "grad_norm": 11.25659465789795,
      "learning_rate": 4.7252862475359646e-05,
      "loss": 1.1898,
      "step": 3120
    },
    {
      "epoch": 0.19,
      "grad_norm": 12.51167106628418,
      "learning_rate": 4.7242377217632015e-05,
      "loss": 1.3956,
      "step": 3130
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.69847297668457,
      "learning_rate": 4.7231891959904376e-05,
      "loss": 1.2161,
      "step": 3140
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.552735328674316,
      "learning_rate": 4.722140670217674e-05,
      "loss": 1.2337,
      "step": 3150
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.005889892578125,
      "learning_rate": 4.721092144444911e-05,
      "loss": 1.1909,
      "step": 3160
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.9045329093933105,
      "learning_rate": 4.720043618672147e-05,
      "loss": 1.3043,
      "step": 3170
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.06499719619751,
      "learning_rate": 4.718995092899384e-05,
      "loss": 1.3596,
      "step": 3180
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.031306743621826,
      "learning_rate": 4.7179465671266206e-05,
      "loss": 1.3342,
      "step": 3190
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.947153568267822,
      "learning_rate": 4.716898041353857e-05,
      "loss": 1.2777,
      "step": 3200
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.693741321563721,
      "learning_rate": 4.715849515581093e-05,
      "loss": 1.3364,
      "step": 3210
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.648002624511719,
      "learning_rate": 4.714800989808329e-05,
      "loss": 1.339,
      "step": 3220
    },
    {
      "epoch": 0.2,
      "grad_norm": 11.319924354553223,
      "learning_rate": 4.713752464035566e-05,
      "loss": 1.2516,
      "step": 3230
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.100990295410156,
      "learning_rate": 4.712703938262803e-05,
      "loss": 1.1952,
      "step": 3240
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.235577583312988,
      "learning_rate": 4.711655412490039e-05,
      "loss": 1.331,
      "step": 3250
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.7722954750061035,
      "learning_rate": 4.710606886717276e-05,
      "loss": 1.2596,
      "step": 3260
    },
    {
      "epoch": 0.2,
      "grad_norm": 8.9963960647583,
      "learning_rate": 4.709558360944512e-05,
      "loss": 1.4158,
      "step": 3270
    },
    {
      "epoch": 0.2,
      "grad_norm": 10.6542329788208,
      "learning_rate": 4.708509835171749e-05,
      "loss": 1.2731,
      "step": 3280
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.276786804199219,
      "learning_rate": 4.707461309398985e-05,
      "loss": 1.1879,
      "step": 3290
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.206620216369629,
      "learning_rate": 4.7064127836262215e-05,
      "loss": 1.1922,
      "step": 3300
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.752740859985352,
      "learning_rate": 4.705364257853458e-05,
      "loss": 1.1948,
      "step": 3310
    },
    {
      "epoch": 0.21,
      "grad_norm": 9.76884651184082,
      "learning_rate": 4.7043157320806945e-05,
      "loss": 1.1992,
      "step": 3320
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.052890777587891,
      "learning_rate": 4.7032672063079314e-05,
      "loss": 1.3055,
      "step": 3330
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.751008033752441,
      "learning_rate": 4.7022186805351676e-05,
      "loss": 1.4844,
      "step": 3340
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.873988151550293,
      "learning_rate": 4.7011701547624045e-05,
      "loss": 1.3271,
      "step": 3350
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.624088287353516,
      "learning_rate": 4.700121628989641e-05,
      "loss": 1.3334,
      "step": 3360
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.374638557434082,
      "learning_rate": 4.6990731032168775e-05,
      "loss": 1.3001,
      "step": 3370
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.292694091796875,
      "learning_rate": 4.698024577444114e-05,
      "loss": 1.3087,
      "step": 3380
    },
    {
      "epoch": 0.21,
      "grad_norm": 11.152791976928711,
      "learning_rate": 4.69697605167135e-05,
      "loss": 1.2972,
      "step": 3390
    },
    {
      "epoch": 0.21,
      "grad_norm": 10.329894065856934,
      "learning_rate": 4.695927525898587e-05,
      "loss": 1.2918,
      "step": 3400
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.918336868286133,
      "learning_rate": 4.694879000125823e-05,
      "loss": 1.3007,
      "step": 3410
    },
    {
      "epoch": 0.21,
      "grad_norm": 10.25504207611084,
      "learning_rate": 4.69383047435306e-05,
      "loss": 1.2354,
      "step": 3420
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.591331958770752,
      "learning_rate": 4.692781948580297e-05,
      "loss": 1.3158,
      "step": 3430
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.501064300537109,
      "learning_rate": 4.691733422807533e-05,
      "loss": 1.1717,
      "step": 3440
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.157527446746826,
      "learning_rate": 4.69068489703477e-05,
      "loss": 1.1642,
      "step": 3450
    },
    {
      "epoch": 0.22,
      "grad_norm": 13.434246063232422,
      "learning_rate": 4.689636371262005e-05,
      "loss": 1.3355,
      "step": 3460
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.44151782989502,
      "learning_rate": 4.688587845489242e-05,
      "loss": 1.3958,
      "step": 3470
    },
    {
      "epoch": 0.22,
      "grad_norm": 5.416346073150635,
      "learning_rate": 4.687539319716479e-05,
      "loss": 1.3213,
      "step": 3480
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.68328857421875,
      "learning_rate": 4.686490793943715e-05,
      "loss": 1.2582,
      "step": 3490
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.046189308166504,
      "learning_rate": 4.685442268170952e-05,
      "loss": 1.197,
      "step": 3500
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.395223140716553,
      "learning_rate": 4.684393742398188e-05,
      "loss": 1.2346,
      "step": 3510
    },
    {
      "epoch": 0.22,
      "grad_norm": 13.392107009887695,
      "learning_rate": 4.683345216625425e-05,
      "loss": 1.3921,
      "step": 3520
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.250112533569336,
      "learning_rate": 4.682296690852661e-05,
      "loss": 1.4463,
      "step": 3530
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.59549331665039,
      "learning_rate": 4.6812481650798975e-05,
      "loss": 1.3551,
      "step": 3540
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.886410713195801,
      "learning_rate": 4.6801996393071344e-05,
      "loss": 1.2559,
      "step": 3550
    },
    {
      "epoch": 0.22,
      "grad_norm": 5.8027753829956055,
      "learning_rate": 4.6791511135343706e-05,
      "loss": 1.2675,
      "step": 3560
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.136465549468994,
      "learning_rate": 4.6781025877616075e-05,
      "loss": 1.2038,
      "step": 3570
    },
    {
      "epoch": 0.22,
      "grad_norm": 15.563440322875977,
      "learning_rate": 4.6770540619888437e-05,
      "loss": 1.3767,
      "step": 3580
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.521543502807617,
      "learning_rate": 4.6760055362160805e-05,
      "loss": 1.3701,
      "step": 3590
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.456585884094238,
      "learning_rate": 4.6749570104433174e-05,
      "loss": 1.3357,
      "step": 3600
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.751743316650391,
      "learning_rate": 4.6739084846705536e-05,
      "loss": 1.2064,
      "step": 3610
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.198685169219971,
      "learning_rate": 4.67285995889779e-05,
      "loss": 1.2751,
      "step": 3620
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.054638385772705,
      "learning_rate": 4.671811433125026e-05,
      "loss": 1.2918,
      "step": 3630
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.416199207305908,
      "learning_rate": 4.670762907352263e-05,
      "loss": 1.3852,
      "step": 3640
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.587446212768555,
      "learning_rate": 4.6697143815795e-05,
      "loss": 1.376,
      "step": 3650
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.122711658477783,
      "learning_rate": 4.668665855806736e-05,
      "loss": 1.2846,
      "step": 3660
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.404738903045654,
      "learning_rate": 4.667617330033973e-05,
      "loss": 1.2644,
      "step": 3670
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.034308433532715,
      "learning_rate": 4.666568804261209e-05,
      "loss": 1.3479,
      "step": 3680
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.298285961151123,
      "learning_rate": 4.665520278488446e-05,
      "loss": 1.309,
      "step": 3690
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.361581325531006,
      "learning_rate": 4.664471752715682e-05,
      "loss": 1.4054,
      "step": 3700
    },
    {
      "epoch": 0.23,
      "grad_norm": 9.217581748962402,
      "learning_rate": 4.663423226942918e-05,
      "loss": 1.2879,
      "step": 3710
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.621367931365967,
      "learning_rate": 4.662374701170155e-05,
      "loss": 1.2744,
      "step": 3720
    },
    {
      "epoch": 0.23,
      "grad_norm": 6.99155330657959,
      "learning_rate": 4.661326175397391e-05,
      "loss": 1.2998,
      "step": 3730
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.33266019821167,
      "learning_rate": 4.660277649624628e-05,
      "loss": 1.4134,
      "step": 3740
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.504049301147461,
      "learning_rate": 4.6592291238518643e-05,
      "loss": 1.2859,
      "step": 3750
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.843130588531494,
      "learning_rate": 4.658180598079101e-05,
      "loss": 1.2903,
      "step": 3760
    },
    {
      "epoch": 0.23,
      "grad_norm": 11.37264347076416,
      "learning_rate": 4.657132072306338e-05,
      "loss": 1.328,
      "step": 3770
    },
    {
      "epoch": 0.24,
      "grad_norm": 11.180176734924316,
      "learning_rate": 4.6560835465335736e-05,
      "loss": 1.2972,
      "step": 3780
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.176261901855469,
      "learning_rate": 4.6550350207608105e-05,
      "loss": 1.3202,
      "step": 3790
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.8919782638549805,
      "learning_rate": 4.6539864949880467e-05,
      "loss": 1.3402,
      "step": 3800
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.250986099243164,
      "learning_rate": 4.6529379692152835e-05,
      "loss": 1.2041,
      "step": 3810
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.626007556915283,
      "learning_rate": 4.6518894434425204e-05,
      "loss": 1.2726,
      "step": 3820
    },
    {
      "epoch": 0.24,
      "grad_norm": 10.014012336730957,
      "learning_rate": 4.6508409176697566e-05,
      "loss": 1.346,
      "step": 3830
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.306204795837402,
      "learning_rate": 4.6497923918969935e-05,
      "loss": 1.243,
      "step": 3840
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.7009382247924805,
      "learning_rate": 4.6487438661242296e-05,
      "loss": 1.2494,
      "step": 3850
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.299267768859863,
      "learning_rate": 4.647695340351466e-05,
      "loss": 1.1338,
      "step": 3860
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.122408390045166,
      "learning_rate": 4.646646814578702e-05,
      "loss": 1.3618,
      "step": 3870
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.818813800811768,
      "learning_rate": 4.645598288805939e-05,
      "loss": 1.4199,
      "step": 3880
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.908540725708008,
      "learning_rate": 4.644549763033176e-05,
      "loss": 1.2539,
      "step": 3890
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.292463302612305,
      "learning_rate": 4.643501237260412e-05,
      "loss": 1.2067,
      "step": 3900
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.342558860778809,
      "learning_rate": 4.642452711487649e-05,
      "loss": 1.2877,
      "step": 3910
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.034559726715088,
      "learning_rate": 4.641404185714885e-05,
      "loss": 1.2786,
      "step": 3920
    },
    {
      "epoch": 0.24,
      "grad_norm": 8.746565818786621,
      "learning_rate": 4.640355659942122e-05,
      "loss": 1.2923,
      "step": 3930
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.320035457611084,
      "learning_rate": 4.639307134169358e-05,
      "loss": 1.2308,
      "step": 3940
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.480830192565918,
      "learning_rate": 4.638258608396594e-05,
      "loss": 1.2455,
      "step": 3950
    },
    {
      "epoch": 0.25,
      "grad_norm": 9.909451484680176,
      "learning_rate": 4.637210082623831e-05,
      "loss": 1.2639,
      "step": 3960
    },
    {
      "epoch": 0.25,
      "grad_norm": 10.468669891357422,
      "learning_rate": 4.6361615568510673e-05,
      "loss": 1.2106,
      "step": 3970
    },
    {
      "epoch": 0.25,
      "grad_norm": 9.770596504211426,
      "learning_rate": 4.635113031078304e-05,
      "loss": 1.2391,
      "step": 3980
    },
    {
      "epoch": 0.25,
      "grad_norm": 9.295339584350586,
      "learning_rate": 4.6340645053055404e-05,
      "loss": 1.2358,
      "step": 3990
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.46225643157959,
      "learning_rate": 4.633015979532777e-05,
      "loss": 1.2342,
      "step": 4000
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.353362560272217,
      "learning_rate": 4.631967453760014e-05,
      "loss": 1.2159,
      "step": 4010
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.735199451446533,
      "learning_rate": 4.63091892798725e-05,
      "loss": 1.3278,
      "step": 4020
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.805098533630371,
      "learning_rate": 4.6298704022144865e-05,
      "loss": 1.2383,
      "step": 4030
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.405623912811279,
      "learning_rate": 4.628821876441723e-05,
      "loss": 1.2313,
      "step": 4040
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.282982349395752,
      "learning_rate": 4.6277733506689596e-05,
      "loss": 1.2797,
      "step": 4050
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.63578462600708,
      "learning_rate": 4.6267248248961965e-05,
      "loss": 1.4915,
      "step": 4060
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.730922698974609,
      "learning_rate": 4.6256762991234327e-05,
      "loss": 1.3444,
      "step": 4070
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.845748901367188,
      "learning_rate": 4.6246277733506695e-05,
      "loss": 1.33,
      "step": 4080
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.71276569366455,
      "learning_rate": 4.623579247577906e-05,
      "loss": 1.2142,
      "step": 4090
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.167181491851807,
      "learning_rate": 4.622530721805142e-05,
      "loss": 1.279,
      "step": 4100
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.020007133483887,
      "learning_rate": 4.621482196032379e-05,
      "loss": 1.3534,
      "step": 4110
    },
    {
      "epoch": 0.26,
      "grad_norm": 5.576249599456787,
      "learning_rate": 4.620433670259615e-05,
      "loss": 1.2955,
      "step": 4120
    },
    {
      "epoch": 0.26,
      "grad_norm": 9.056892395019531,
      "learning_rate": 4.619385144486852e-05,
      "loss": 1.239,
      "step": 4130
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.261054515838623,
      "learning_rate": 4.618336618714088e-05,
      "loss": 1.2682,
      "step": 4140
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.934804916381836,
      "learning_rate": 4.617288092941325e-05,
      "loss": 1.3096,
      "step": 4150
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.299190044403076,
      "learning_rate": 4.616239567168561e-05,
      "loss": 1.2394,
      "step": 4160
    },
    {
      "epoch": 0.26,
      "grad_norm": 9.186671257019043,
      "learning_rate": 4.615191041395798e-05,
      "loss": 1.258,
      "step": 4170
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.539327621459961,
      "learning_rate": 4.614142515623034e-05,
      "loss": 1.2153,
      "step": 4180
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.306940078735352,
      "learning_rate": 4.6130939898502703e-05,
      "loss": 1.2042,
      "step": 4190
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.160695552825928,
      "learning_rate": 4.612045464077507e-05,
      "loss": 1.2215,
      "step": 4200
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.712730407714844,
      "learning_rate": 4.6109969383047434e-05,
      "loss": 1.2076,
      "step": 4210
    },
    {
      "epoch": 0.26,
      "grad_norm": 7.314571857452393,
      "learning_rate": 4.60994841253198e-05,
      "loss": 1.1998,
      "step": 4220
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.356145858764648,
      "learning_rate": 4.608899886759217e-05,
      "loss": 1.3879,
      "step": 4230
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.063400745391846,
      "learning_rate": 4.6078513609864533e-05,
      "loss": 1.2882,
      "step": 4240
    },
    {
      "epoch": 0.26,
      "grad_norm": 10.096597671508789,
      "learning_rate": 4.60680283521369e-05,
      "loss": 1.2867,
      "step": 4250
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.106571197509766,
      "learning_rate": 4.6057543094409264e-05,
      "loss": 1.3809,
      "step": 4260
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.583966255187988,
      "learning_rate": 4.6047057836681626e-05,
      "loss": 1.2691,
      "step": 4270
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.057568073272705,
      "learning_rate": 4.603657257895399e-05,
      "loss": 1.3078,
      "step": 4280
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.814077377319336,
      "learning_rate": 4.6026087321226357e-05,
      "loss": 1.3136,
      "step": 4290
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.336838722229004,
      "learning_rate": 4.6015602063498725e-05,
      "loss": 1.0748,
      "step": 4300
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.798096179962158,
      "learning_rate": 4.600511680577109e-05,
      "loss": 1.301,
      "step": 4310
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.943196296691895,
      "learning_rate": 4.5994631548043456e-05,
      "loss": 1.236,
      "step": 4320
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.105981826782227,
      "learning_rate": 4.598414629031582e-05,
      "loss": 1.2369,
      "step": 4330
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.466947555541992,
      "learning_rate": 4.5973661032588187e-05,
      "loss": 1.211,
      "step": 4340
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.44320011138916,
      "learning_rate": 4.596317577486055e-05,
      "loss": 1.1916,
      "step": 4350
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.38048791885376,
      "learning_rate": 4.595269051713291e-05,
      "loss": 1.1641,
      "step": 4360
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.96786880493164,
      "learning_rate": 4.594220525940528e-05,
      "loss": 1.3587,
      "step": 4370
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.94035530090332,
      "learning_rate": 4.593172000167764e-05,
      "loss": 1.3006,
      "step": 4380
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.050298690795898,
      "learning_rate": 4.592123474395001e-05,
      "loss": 1.253,
      "step": 4390
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.147692680358887,
      "learning_rate": 4.591074948622237e-05,
      "loss": 1.2835,
      "step": 4400
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.909215927124023,
      "learning_rate": 4.590026422849474e-05,
      "loss": 1.2552,
      "step": 4410
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.178583145141602,
      "learning_rate": 4.58897789707671e-05,
      "loss": 1.2446,
      "step": 4420
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.571780681610107,
      "learning_rate": 4.5879293713039464e-05,
      "loss": 1.2068,
      "step": 4430
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.352252006530762,
      "learning_rate": 4.586880845531183e-05,
      "loss": 1.3705,
      "step": 4440
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.057154655456543,
      "learning_rate": 4.5858323197584195e-05,
      "loss": 1.3221,
      "step": 4450
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.114856719970703,
      "learning_rate": 4.5847837939856563e-05,
      "loss": 1.227,
      "step": 4460
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.688512325286865,
      "learning_rate": 4.583735268212893e-05,
      "loss": 1.24,
      "step": 4470
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.602441787719727,
      "learning_rate": 4.5826867424401294e-05,
      "loss": 1.2773,
      "step": 4480
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.174093246459961,
      "learning_rate": 4.581638216667366e-05,
      "loss": 1.3089,
      "step": 4490
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.643342971801758,
      "learning_rate": 4.5805896908946025e-05,
      "loss": 1.3448,
      "step": 4500
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.271567344665527,
      "learning_rate": 4.579541165121839e-05,
      "loss": 1.2027,
      "step": 4510
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.464147567749023,
      "learning_rate": 4.5784926393490755e-05,
      "loss": 1.1818,
      "step": 4520
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.0080246925354,
      "learning_rate": 4.577444113576312e-05,
      "loss": 1.2441,
      "step": 4530
    },
    {
      "epoch": 0.28,
      "grad_norm": 11.897246360778809,
      "learning_rate": 4.5763955878035486e-05,
      "loss": 1.2915,
      "step": 4540
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.197120189666748,
      "learning_rate": 4.575347062030785e-05,
      "loss": 1.2675,
      "step": 4550
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.103429794311523,
      "learning_rate": 4.5742985362580217e-05,
      "loss": 1.2956,
      "step": 4560
    },
    {
      "epoch": 0.28,
      "grad_norm": 11.780292510986328,
      "learning_rate": 4.573250010485258e-05,
      "loss": 1.1884,
      "step": 4570
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.459150791168213,
      "learning_rate": 4.572201484712495e-05,
      "loss": 1.239,
      "step": 4580
    },
    {
      "epoch": 0.29,
      "grad_norm": 11.038143157958984,
      "learning_rate": 4.571152958939731e-05,
      "loss": 1.4046,
      "step": 4590
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.0693888664245605,
      "learning_rate": 4.570104433166967e-05,
      "loss": 1.2344,
      "step": 4600
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.2292866706848145,
      "learning_rate": 4.569055907394204e-05,
      "loss": 1.2238,
      "step": 4610
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.952488422393799,
      "learning_rate": 4.56800738162144e-05,
      "loss": 1.3508,
      "step": 4620
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.202384948730469,
      "learning_rate": 4.566958855848677e-05,
      "loss": 1.3585,
      "step": 4630
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.874476432800293,
      "learning_rate": 4.565910330075914e-05,
      "loss": 1.2185,
      "step": 4640
    },
    {
      "epoch": 0.29,
      "grad_norm": 6.2511091232299805,
      "learning_rate": 4.56486180430315e-05,
      "loss": 1.2808,
      "step": 4650
    },
    {
      "epoch": 0.29,
      "grad_norm": 6.458112716674805,
      "learning_rate": 4.563813278530387e-05,
      "loss": 1.1575,
      "step": 4660
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.358083724975586,
      "learning_rate": 4.562764752757623e-05,
      "loss": 1.2555,
      "step": 4670
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.175286293029785,
      "learning_rate": 4.5617162269848594e-05,
      "loss": 1.1785,
      "step": 4680
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.5186076164245605,
      "learning_rate": 4.5606677012120955e-05,
      "loss": 1.2699,
      "step": 4690
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.742922306060791,
      "learning_rate": 4.5596191754393324e-05,
      "loss": 1.3017,
      "step": 4700
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.814525127410889,
      "learning_rate": 4.558570649666569e-05,
      "loss": 1.333,
      "step": 4710
    },
    {
      "epoch": 0.29,
      "grad_norm": 6.416224002838135,
      "learning_rate": 4.5575221238938055e-05,
      "loss": 1.3911,
      "step": 4720
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.663360595703125,
      "learning_rate": 4.5564735981210423e-05,
      "loss": 1.2076,
      "step": 4730
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.002895355224609,
      "learning_rate": 4.5554250723482785e-05,
      "loss": 1.2322,
      "step": 4740
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.216015815734863,
      "learning_rate": 4.554376546575515e-05,
      "loss": 1.1771,
      "step": 4750
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.421425819396973,
      "learning_rate": 4.5533280208027516e-05,
      "loss": 1.3638,
      "step": 4760
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.706550121307373,
      "learning_rate": 4.552279495029988e-05,
      "loss": 1.2468,
      "step": 4770
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.415036201477051,
      "learning_rate": 4.5512309692572247e-05,
      "loss": 1.241,
      "step": 4780
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.190930366516113,
      "learning_rate": 4.550182443484461e-05,
      "loss": 1.2347,
      "step": 4790
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.863883972167969,
      "learning_rate": 4.549133917711698e-05,
      "loss": 1.1771,
      "step": 4800
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.812771797180176,
      "learning_rate": 4.5480853919389346e-05,
      "loss": 1.312,
      "step": 4810
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.5982027053833,
      "learning_rate": 4.547036866166171e-05,
      "loss": 1.1571,
      "step": 4820
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.101144313812256,
      "learning_rate": 4.545988340393407e-05,
      "loss": 1.2132,
      "step": 4830
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.650268077850342,
      "learning_rate": 4.544939814620643e-05,
      "loss": 1.3017,
      "step": 4840
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.196481704711914,
      "learning_rate": 4.54389128884788e-05,
      "loss": 1.3539,
      "step": 4850
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.830870628356934,
      "learning_rate": 4.542842763075116e-05,
      "loss": 1.3474,
      "step": 4860
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.39406156539917,
      "learning_rate": 4.541794237302353e-05,
      "loss": 1.22,
      "step": 4870
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.805408000946045,
      "learning_rate": 4.54074571152959e-05,
      "loss": 1.3627,
      "step": 4880
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.4025726318359375,
      "learning_rate": 4.539697185756826e-05,
      "loss": 1.2552,
      "step": 4890
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.775434494018555,
      "learning_rate": 4.538648659984063e-05,
      "loss": 1.4463,
      "step": 4900
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.936172962188721,
      "learning_rate": 4.537600134211299e-05,
      "loss": 1.2472,
      "step": 4910
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.8873138427734375,
      "learning_rate": 4.5365516084385354e-05,
      "loss": 1.1779,
      "step": 4920
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.276447772979736,
      "learning_rate": 4.535503082665772e-05,
      "loss": 1.3953,
      "step": 4930
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.399540901184082,
      "learning_rate": 4.5344545568930085e-05,
      "loss": 1.2374,
      "step": 4940
    },
    {
      "epoch": 0.31,
      "grad_norm": 11.027240753173828,
      "learning_rate": 4.5334060311202453e-05,
      "loss": 1.2831,
      "step": 4950
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.124894142150879,
      "learning_rate": 4.5323575053474815e-05,
      "loss": 1.4114,
      "step": 4960
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.045180320739746,
      "learning_rate": 4.5313089795747184e-05,
      "loss": 1.2003,
      "step": 4970
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.922944068908691,
      "learning_rate": 4.5302604538019546e-05,
      "loss": 1.2369,
      "step": 4980
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.354431629180908,
      "learning_rate": 4.5292119280291915e-05,
      "loss": 1.2757,
      "step": 4990
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.179332733154297,
      "learning_rate": 4.528163402256428e-05,
      "loss": 1.3317,
      "step": 5000
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.614409446716309,
      "learning_rate": 4.527114876483664e-05,
      "loss": 1.2141,
      "step": 5010
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.068038463592529,
      "learning_rate": 4.526066350710901e-05,
      "loss": 1.3027,
      "step": 5020
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.803020000457764,
      "learning_rate": 4.525017824938137e-05,
      "loss": 1.2555,
      "step": 5030
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.083355903625488,
      "learning_rate": 4.523969299165374e-05,
      "loss": 1.2499,
      "step": 5040
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.207450866699219,
      "learning_rate": 4.5229207733926107e-05,
      "loss": 1.3003,
      "step": 5050
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.213085651397705,
      "learning_rate": 4.521872247619847e-05,
      "loss": 1.2291,
      "step": 5060
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.998129367828369,
      "learning_rate": 4.520823721847083e-05,
      "loss": 1.3081,
      "step": 5070
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.56144905090332,
      "learning_rate": 4.519775196074319e-05,
      "loss": 1.2961,
      "step": 5080
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.09407901763916,
      "learning_rate": 4.518726670301556e-05,
      "loss": 1.2453,
      "step": 5090
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.878949165344238,
      "learning_rate": 4.517678144528793e-05,
      "loss": 1.3353,
      "step": 5100
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.8078203201293945,
      "learning_rate": 4.516629618756029e-05,
      "loss": 1.2719,
      "step": 5110
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.742350578308105,
      "learning_rate": 4.515581092983266e-05,
      "loss": 1.3615,
      "step": 5120
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.009683609008789,
      "learning_rate": 4.514532567210502e-05,
      "loss": 1.367,
      "step": 5130
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.577735424041748,
      "learning_rate": 4.513484041437739e-05,
      "loss": 1.2696,
      "step": 5140
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.55863094329834,
      "learning_rate": 4.512435515664975e-05,
      "loss": 1.2,
      "step": 5150
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.834120750427246,
      "learning_rate": 4.5113869898922115e-05,
      "loss": 1.2157,
      "step": 5160
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.805868625640869,
      "learning_rate": 4.5103384641194484e-05,
      "loss": 1.2374,
      "step": 5170
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.42000675201416,
      "learning_rate": 4.5092899383466845e-05,
      "loss": 1.2032,
      "step": 5180
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.393702507019043,
      "learning_rate": 4.5082414125739214e-05,
      "loss": 1.198,
      "step": 5190
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.6397385597229,
      "learning_rate": 4.5071928868011576e-05,
      "loss": 1.2651,
      "step": 5200
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.70853328704834,
      "learning_rate": 4.5061443610283945e-05,
      "loss": 1.332,
      "step": 5210
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.768548011779785,
      "learning_rate": 4.5050958352556313e-05,
      "loss": 1.2339,
      "step": 5220
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.4508867263793945,
      "learning_rate": 4.5040473094828675e-05,
      "loss": 1.1572,
      "step": 5230
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.674648761749268,
      "learning_rate": 4.502998783710104e-05,
      "loss": 1.247,
      "step": 5240
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.288237571716309,
      "learning_rate": 4.50195025793734e-05,
      "loss": 1.2237,
      "step": 5250
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.156660079956055,
      "learning_rate": 4.500901732164577e-05,
      "loss": 1.3231,
      "step": 5260
    },
    {
      "epoch": 0.33,
      "grad_norm": 7.038421154022217,
      "learning_rate": 4.499853206391813e-05,
      "loss": 1.2794,
      "step": 5270
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.772799491882324,
      "learning_rate": 4.49880468061905e-05,
      "loss": 1.3107,
      "step": 5280
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.64815092086792,
      "learning_rate": 4.497756154846287e-05,
      "loss": 1.3627,
      "step": 5290
    },
    {
      "epoch": 0.33,
      "grad_norm": 7.9910173416137695,
      "learning_rate": 4.496707629073523e-05,
      "loss": 1.4543,
      "step": 5300
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.557522296905518,
      "learning_rate": 4.49565910330076e-05,
      "loss": 1.3582,
      "step": 5310
    },
    {
      "epoch": 0.33,
      "grad_norm": 7.54089879989624,
      "learning_rate": 4.494610577527995e-05,
      "loss": 1.2402,
      "step": 5320
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.739617347717285,
      "learning_rate": 4.493562051755232e-05,
      "loss": 1.2184,
      "step": 5330
    },
    {
      "epoch": 0.33,
      "grad_norm": 11.986181259155273,
      "learning_rate": 4.492513525982469e-05,
      "loss": 1.216,
      "step": 5340
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.5601019859313965,
      "learning_rate": 4.491465000209705e-05,
      "loss": 1.3974,
      "step": 5350
    },
    {
      "epoch": 0.33,
      "grad_norm": 7.410431861877441,
      "learning_rate": 4.490416474436942e-05,
      "loss": 1.2516,
      "step": 5360
    },
    {
      "epoch": 0.33,
      "grad_norm": 7.105477809906006,
      "learning_rate": 4.489367948664178e-05,
      "loss": 1.2579,
      "step": 5370
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.397697448730469,
      "learning_rate": 4.488319422891415e-05,
      "loss": 1.3864,
      "step": 5380
    },
    {
      "epoch": 0.34,
      "grad_norm": 12.727319717407227,
      "learning_rate": 4.4872708971186514e-05,
      "loss": 1.2453,
      "step": 5390
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.178332805633545,
      "learning_rate": 4.4862223713458875e-05,
      "loss": 1.2585,
      "step": 5400
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.779654502868652,
      "learning_rate": 4.4851738455731244e-05,
      "loss": 1.3338,
      "step": 5410
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.660012245178223,
      "learning_rate": 4.4841253198003606e-05,
      "loss": 1.2637,
      "step": 5420
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.752951145172119,
      "learning_rate": 4.4830767940275975e-05,
      "loss": 1.2907,
      "step": 5430
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.646975994110107,
      "learning_rate": 4.482028268254834e-05,
      "loss": 1.2182,
      "step": 5440
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.8618745803833,
      "learning_rate": 4.4809797424820705e-05,
      "loss": 1.2228,
      "step": 5450
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.207174301147461,
      "learning_rate": 4.4799312167093074e-05,
      "loss": 1.2398,
      "step": 5460
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.244636535644531,
      "learning_rate": 4.4788826909365436e-05,
      "loss": 1.2409,
      "step": 5470
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.362756252288818,
      "learning_rate": 4.47783416516378e-05,
      "loss": 1.2813,
      "step": 5480
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.813365936279297,
      "learning_rate": 4.476785639391016e-05,
      "loss": 1.3186,
      "step": 5490
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.246523857116699,
      "learning_rate": 4.475737113618253e-05,
      "loss": 1.3337,
      "step": 5500
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.153685569763184,
      "learning_rate": 4.47468858784549e-05,
      "loss": 1.255,
      "step": 5510
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.24577522277832,
      "learning_rate": 4.473640062072726e-05,
      "loss": 1.2874,
      "step": 5520
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.57575511932373,
      "learning_rate": 4.472591536299963e-05,
      "loss": 1.3467,
      "step": 5530
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.346353054046631,
      "learning_rate": 4.471543010527199e-05,
      "loss": 1.3237,
      "step": 5540
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.098326683044434,
      "learning_rate": 4.470494484754436e-05,
      "loss": 1.3006,
      "step": 5550
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.465571403503418,
      "learning_rate": 4.469445958981672e-05,
      "loss": 1.3213,
      "step": 5560
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.03587532043457,
      "learning_rate": 4.468397433208908e-05,
      "loss": 1.2412,
      "step": 5570
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.7463579177856445,
      "learning_rate": 4.467348907436145e-05,
      "loss": 1.2409,
      "step": 5580
    },
    {
      "epoch": 0.35,
      "grad_norm": 10.982913970947266,
      "learning_rate": 4.466300381663381e-05,
      "loss": 1.2217,
      "step": 5590
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.562558174133301,
      "learning_rate": 4.465251855890618e-05,
      "loss": 1.1406,
      "step": 5600
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.507223129272461,
      "learning_rate": 4.4642033301178544e-05,
      "loss": 1.2604,
      "step": 5610
    },
    {
      "epoch": 0.35,
      "grad_norm": 9.269028663635254,
      "learning_rate": 4.463154804345091e-05,
      "loss": 1.2925,
      "step": 5620
    },
    {
      "epoch": 0.35,
      "grad_norm": 10.105732917785645,
      "learning_rate": 4.462106278572328e-05,
      "loss": 1.1461,
      "step": 5630
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.676517963409424,
      "learning_rate": 4.4610577527995636e-05,
      "loss": 1.3403,
      "step": 5640
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.347627639770508,
      "learning_rate": 4.4600092270268005e-05,
      "loss": 1.1953,
      "step": 5650
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.144907474517822,
      "learning_rate": 4.458960701254037e-05,
      "loss": 1.2865,
      "step": 5660
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.233316421508789,
      "learning_rate": 4.4579121754812735e-05,
      "loss": 1.0949,
      "step": 5670
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.501070022583008,
      "learning_rate": 4.45686364970851e-05,
      "loss": 1.1839,
      "step": 5680
    },
    {
      "epoch": 0.35,
      "grad_norm": 8.455964088439941,
      "learning_rate": 4.4558151239357466e-05,
      "loss": 1.3417,
      "step": 5690
    },
    {
      "epoch": 0.35,
      "grad_norm": 7.8924946784973145,
      "learning_rate": 4.4547665981629835e-05,
      "loss": 1.2178,
      "step": 5700
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.347917556762695,
      "learning_rate": 4.45371807239022e-05,
      "loss": 1.1813,
      "step": 5710
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.879951477050781,
      "learning_rate": 4.452669546617456e-05,
      "loss": 1.2007,
      "step": 5720
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.004047393798828,
      "learning_rate": 4.451621020844692e-05,
      "loss": 1.2772,
      "step": 5730
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.848206520080566,
      "learning_rate": 4.450572495071929e-05,
      "loss": 1.2248,
      "step": 5740
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.700590133666992,
      "learning_rate": 4.449523969299166e-05,
      "loss": 1.2256,
      "step": 5750
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.896075248718262,
      "learning_rate": 4.448475443526402e-05,
      "loss": 1.1815,
      "step": 5760
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.126965522766113,
      "learning_rate": 4.447426917753639e-05,
      "loss": 1.1901,
      "step": 5770
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.498141288757324,
      "learning_rate": 4.446378391980875e-05,
      "loss": 1.3295,
      "step": 5780
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.652939319610596,
      "learning_rate": 4.445329866208112e-05,
      "loss": 1.191,
      "step": 5790
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.443501949310303,
      "learning_rate": 4.444281340435348e-05,
      "loss": 1.26,
      "step": 5800
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.17090129852295,
      "learning_rate": 4.443232814662584e-05,
      "loss": 1.2715,
      "step": 5810
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.147409439086914,
      "learning_rate": 4.442184288889821e-05,
      "loss": 1.1553,
      "step": 5820
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.2936577796936035,
      "learning_rate": 4.4411357631170574e-05,
      "loss": 1.3748,
      "step": 5830
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.642927169799805,
      "learning_rate": 4.440087237344294e-05,
      "loss": 1.2137,
      "step": 5840
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.301651954650879,
      "learning_rate": 4.4390387115715304e-05,
      "loss": 1.2153,
      "step": 5850
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.874971389770508,
      "learning_rate": 4.437990185798767e-05,
      "loss": 1.3623,
      "step": 5860
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.819589614868164,
      "learning_rate": 4.436941660026004e-05,
      "loss": 1.3216,
      "step": 5870
    },
    {
      "epoch": 0.37,
      "grad_norm": 8.815643310546875,
      "learning_rate": 4.4358931342532404e-05,
      "loss": 1.2997,
      "step": 5880
    },
    {
      "epoch": 0.37,
      "grad_norm": 9.27664852142334,
      "learning_rate": 4.4348446084804766e-05,
      "loss": 1.2958,
      "step": 5890
    },
    {
      "epoch": 0.37,
      "grad_norm": 10.687651634216309,
      "learning_rate": 4.433796082707713e-05,
      "loss": 1.2615,
      "step": 5900
    },
    {
      "epoch": 0.37,
      "grad_norm": 8.18842887878418,
      "learning_rate": 4.4327475569349496e-05,
      "loss": 1.2755,
      "step": 5910
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.202277183532715,
      "learning_rate": 4.4316990311621865e-05,
      "loss": 1.2972,
      "step": 5920
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.8497161865234375,
      "learning_rate": 4.430650505389423e-05,
      "loss": 1.2854,
      "step": 5930
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.12615442276001,
      "learning_rate": 4.4296019796166595e-05,
      "loss": 1.3255,
      "step": 5940
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.387741565704346,
      "learning_rate": 4.428553453843896e-05,
      "loss": 1.1811,
      "step": 5950
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.0362629890441895,
      "learning_rate": 4.427504928071132e-05,
      "loss": 1.2211,
      "step": 5960
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.500118255615234,
      "learning_rate": 4.426456402298368e-05,
      "loss": 1.2237,
      "step": 5970
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.4963884353637695,
      "learning_rate": 4.425407876525605e-05,
      "loss": 1.2745,
      "step": 5980
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.643404483795166,
      "learning_rate": 4.424359350752842e-05,
      "loss": 1.2254,
      "step": 5990
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.839029312133789,
      "learning_rate": 4.423310824980078e-05,
      "loss": 1.2137,
      "step": 6000
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.5846171379089355,
      "learning_rate": 4.422262299207315e-05,
      "loss": 1.3073,
      "step": 6010
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.009519577026367,
      "learning_rate": 4.421213773434551e-05,
      "loss": 1.2898,
      "step": 6020
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.780195236206055,
      "learning_rate": 4.420165247661788e-05,
      "loss": 1.2827,
      "step": 6030
    },
    {
      "epoch": 0.38,
      "grad_norm": 8.520402908325195,
      "learning_rate": 4.419116721889024e-05,
      "loss": 1.3159,
      "step": 6040
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.74214506149292,
      "learning_rate": 4.4180681961162604e-05,
      "loss": 1.367,
      "step": 6050
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.981525421142578,
      "learning_rate": 4.417019670343497e-05,
      "loss": 1.2274,
      "step": 6060
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.3453779220581055,
      "learning_rate": 4.4159711445707334e-05,
      "loss": 1.2331,
      "step": 6070
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.279958724975586,
      "learning_rate": 4.41492261879797e-05,
      "loss": 1.2351,
      "step": 6080
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.592041015625,
      "learning_rate": 4.413874093025207e-05,
      "loss": 1.192,
      "step": 6090
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.520990371704102,
      "learning_rate": 4.4128255672524434e-05,
      "loss": 1.1758,
      "step": 6100
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.732944488525391,
      "learning_rate": 4.41177704147968e-05,
      "loss": 1.2036,
      "step": 6110
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.6871747970581055,
      "learning_rate": 4.4107285157069164e-05,
      "loss": 1.1636,
      "step": 6120
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.952512741088867,
      "learning_rate": 4.4096799899341526e-05,
      "loss": 1.219,
      "step": 6130
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.507272720336914,
      "learning_rate": 4.408631464161389e-05,
      "loss": 1.2795,
      "step": 6140
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.559981346130371,
      "learning_rate": 4.407582938388626e-05,
      "loss": 1.1475,
      "step": 6150
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.883564472198486,
      "learning_rate": 4.4065344126158625e-05,
      "loss": 1.3164,
      "step": 6160
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.917120456695557,
      "learning_rate": 4.405485886843099e-05,
      "loss": 1.2661,
      "step": 6170
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.459980964660645,
      "learning_rate": 4.4044373610703356e-05,
      "loss": 1.162,
      "step": 6180
    },
    {
      "epoch": 0.39,
      "grad_norm": 7.427047252655029,
      "learning_rate": 4.403388835297572e-05,
      "loss": 1.249,
      "step": 6190
    },
    {
      "epoch": 0.39,
      "grad_norm": 9.027228355407715,
      "learning_rate": 4.402340309524809e-05,
      "loss": 1.2512,
      "step": 6200
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.315953254699707,
      "learning_rate": 4.401291783752045e-05,
      "loss": 1.169,
      "step": 6210
    },
    {
      "epoch": 0.39,
      "grad_norm": 14.894264221191406,
      "learning_rate": 4.400243257979281e-05,
      "loss": 1.2726,
      "step": 6220
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.621131896972656,
      "learning_rate": 4.399194732206518e-05,
      "loss": 1.2476,
      "step": 6230
    },
    {
      "epoch": 0.39,
      "grad_norm": 7.777199745178223,
      "learning_rate": 4.398146206433754e-05,
      "loss": 1.3121,
      "step": 6240
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.038359642028809,
      "learning_rate": 4.397097680660991e-05,
      "loss": 1.3974,
      "step": 6250
    },
    {
      "epoch": 0.39,
      "grad_norm": 8.62693977355957,
      "learning_rate": 4.396049154888227e-05,
      "loss": 1.2845,
      "step": 6260
    },
    {
      "epoch": 0.39,
      "grad_norm": 7.376511096954346,
      "learning_rate": 4.395000629115464e-05,
      "loss": 1.321,
      "step": 6270
    },
    {
      "epoch": 0.39,
      "grad_norm": 9.003816604614258,
      "learning_rate": 4.3939521033427e-05,
      "loss": 1.2972,
      "step": 6280
    },
    {
      "epoch": 0.39,
      "grad_norm": 7.184131622314453,
      "learning_rate": 4.3929035775699364e-05,
      "loss": 1.3423,
      "step": 6290
    },
    {
      "epoch": 0.39,
      "grad_norm": 7.380613327026367,
      "learning_rate": 4.391855051797173e-05,
      "loss": 1.2193,
      "step": 6300
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.921579360961914,
      "learning_rate": 4.3908065260244095e-05,
      "loss": 1.3215,
      "step": 6310
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.936898231506348,
      "learning_rate": 4.3897580002516464e-05,
      "loss": 1.2908,
      "step": 6320
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.8522210121154785,
      "learning_rate": 4.388709474478883e-05,
      "loss": 1.2441,
      "step": 6330
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.243868350982666,
      "learning_rate": 4.3876609487061194e-05,
      "loss": 1.1523,
      "step": 6340
    },
    {
      "epoch": 0.4,
      "grad_norm": 14.021193504333496,
      "learning_rate": 4.386612422933356e-05,
      "loss": 1.2128,
      "step": 6350
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.322928428649902,
      "learning_rate": 4.3855638971605925e-05,
      "loss": 1.2431,
      "step": 6360
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.0673298835754395,
      "learning_rate": 4.384515371387829e-05,
      "loss": 1.3037,
      "step": 6370
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.208996772766113,
      "learning_rate": 4.383466845615065e-05,
      "loss": 1.156,
      "step": 6380
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.383192539215088,
      "learning_rate": 4.382418319842302e-05,
      "loss": 1.2757,
      "step": 6390
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.765215873718262,
      "learning_rate": 4.3813697940695386e-05,
      "loss": 1.1479,
      "step": 6400
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.322721004486084,
      "learning_rate": 4.380321268296775e-05,
      "loss": 1.309,
      "step": 6410
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.222217559814453,
      "learning_rate": 4.379272742524012e-05,
      "loss": 1.2859,
      "step": 6420
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.366397857666016,
      "learning_rate": 4.378224216751248e-05,
      "loss": 1.1833,
      "step": 6430
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.513817310333252,
      "learning_rate": 4.377175690978485e-05,
      "loss": 1.1246,
      "step": 6440
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.558846473693848,
      "learning_rate": 4.376127165205721e-05,
      "loss": 1.2438,
      "step": 6450
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.217658042907715,
      "learning_rate": 4.375078639432957e-05,
      "loss": 1.2733,
      "step": 6460
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.08054780960083,
      "learning_rate": 4.374030113660194e-05,
      "loss": 1.1819,
      "step": 6470
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.218887805938721,
      "learning_rate": 4.37298158788743e-05,
      "loss": 1.28,
      "step": 6480
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.444204330444336,
      "learning_rate": 4.371933062114667e-05,
      "loss": 1.2343,
      "step": 6490
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.848219871520996,
      "learning_rate": 4.370884536341904e-05,
      "loss": 1.2057,
      "step": 6500
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.2316789627075195,
      "learning_rate": 4.36983601056914e-05,
      "loss": 1.2319,
      "step": 6510
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.133213043212891,
      "learning_rate": 4.368787484796377e-05,
      "loss": 1.1738,
      "step": 6520
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.454687595367432,
      "learning_rate": 4.367738959023613e-05,
      "loss": 1.2056,
      "step": 6530
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.9875383377075195,
      "learning_rate": 4.3666904332508494e-05,
      "loss": 1.2722,
      "step": 6540
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.172795295715332,
      "learning_rate": 4.3656419074780856e-05,
      "loss": 1.2693,
      "step": 6550
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.008907794952393,
      "learning_rate": 4.3645933817053224e-05,
      "loss": 1.2049,
      "step": 6560
    },
    {
      "epoch": 0.41,
      "grad_norm": 18.478134155273438,
      "learning_rate": 4.363544855932559e-05,
      "loss": 1.3715,
      "step": 6570
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.688271522521973,
      "learning_rate": 4.3624963301597955e-05,
      "loss": 1.147,
      "step": 6580
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.452163219451904,
      "learning_rate": 4.3614478043870324e-05,
      "loss": 1.2933,
      "step": 6590
    },
    {
      "epoch": 0.41,
      "grad_norm": 9.055519104003906,
      "learning_rate": 4.3603992786142686e-05,
      "loss": 1.3039,
      "step": 6600
    },
    {
      "epoch": 0.41,
      "grad_norm": 8.670219421386719,
      "learning_rate": 4.359350752841505e-05,
      "loss": 1.1228,
      "step": 6610
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.567760467529297,
      "learning_rate": 4.3583022270687416e-05,
      "loss": 1.2377,
      "step": 6620
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.410305976867676,
      "learning_rate": 4.357253701295978e-05,
      "loss": 1.2825,
      "step": 6630
    },
    {
      "epoch": 0.41,
      "grad_norm": 8.264208793640137,
      "learning_rate": 4.356205175523215e-05,
      "loss": 1.2505,
      "step": 6640
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.5816755294799805,
      "learning_rate": 4.355156649750451e-05,
      "loss": 1.3736,
      "step": 6650
    },
    {
      "epoch": 0.41,
      "grad_norm": 14.130797386169434,
      "learning_rate": 4.354108123977688e-05,
      "loss": 1.2387,
      "step": 6660
    },
    {
      "epoch": 0.42,
      "grad_norm": 8.343127250671387,
      "learning_rate": 4.353059598204924e-05,
      "loss": 1.2365,
      "step": 6670
    },
    {
      "epoch": 0.42,
      "grad_norm": 7.993491172790527,
      "learning_rate": 4.352011072432161e-05,
      "loss": 1.2437,
      "step": 6680
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.973606586456299,
      "learning_rate": 4.350962546659397e-05,
      "loss": 1.2945,
      "step": 6690
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.482931613922119,
      "learning_rate": 4.349914020886633e-05,
      "loss": 1.2633,
      "step": 6700
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.651607513427734,
      "learning_rate": 4.34886549511387e-05,
      "loss": 1.3149,
      "step": 6710
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.539613246917725,
      "learning_rate": 4.347816969341106e-05,
      "loss": 1.3068,
      "step": 6720
    },
    {
      "epoch": 0.42,
      "grad_norm": 7.237940788269043,
      "learning_rate": 4.346768443568343e-05,
      "loss": 1.2702,
      "step": 6730
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.678887367248535,
      "learning_rate": 4.34571991779558e-05,
      "loss": 1.2135,
      "step": 6740
    },
    {
      "epoch": 0.42,
      "grad_norm": 8.049528121948242,
      "learning_rate": 4.344671392022816e-05,
      "loss": 1.1941,
      "step": 6750
    },
    {
      "epoch": 0.42,
      "grad_norm": 10.00314712524414,
      "learning_rate": 4.343622866250053e-05,
      "loss": 1.344,
      "step": 6760
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.526694297790527,
      "learning_rate": 4.342574340477289e-05,
      "loss": 1.2485,
      "step": 6770
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.2827656269073486,
      "learning_rate": 4.3415258147045254e-05,
      "loss": 1.1956,
      "step": 6780
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.2461652755737305,
      "learning_rate": 4.340477288931762e-05,
      "loss": 1.3689,
      "step": 6790
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.152334213256836,
      "learning_rate": 4.3394287631589985e-05,
      "loss": 1.3509,
      "step": 6800
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.387037754058838,
      "learning_rate": 4.3383802373862354e-05,
      "loss": 1.26,
      "step": 6810
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.590432643890381,
      "learning_rate": 4.3373317116134716e-05,
      "loss": 1.1982,
      "step": 6820
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.129953861236572,
      "learning_rate": 4.3362831858407084e-05,
      "loss": 1.3677,
      "step": 6830
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.363886833190918,
      "learning_rate": 4.3352346600679446e-05,
      "loss": 1.2582,
      "step": 6840
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.204916000366211,
      "learning_rate": 4.3341861342951815e-05,
      "loss": 1.2098,
      "step": 6850
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.62095308303833,
      "learning_rate": 4.333137608522418e-05,
      "loss": 1.2445,
      "step": 6860
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.136648654937744,
      "learning_rate": 4.332089082749654e-05,
      "loss": 1.146,
      "step": 6870
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.074688911437988,
      "learning_rate": 4.331040556976891e-05,
      "loss": 1.1989,
      "step": 6880
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.09612512588501,
      "learning_rate": 4.329992031204127e-05,
      "loss": 1.1327,
      "step": 6890
    },
    {
      "epoch": 0.43,
      "grad_norm": 12.820887565612793,
      "learning_rate": 4.328943505431364e-05,
      "loss": 1.2417,
      "step": 6900
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.917165279388428,
      "learning_rate": 4.327894979658601e-05,
      "loss": 1.2627,
      "step": 6910
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.50516939163208,
      "learning_rate": 4.326846453885837e-05,
      "loss": 1.2532,
      "step": 6920
    },
    {
      "epoch": 0.43,
      "grad_norm": 8.396788597106934,
      "learning_rate": 4.325797928113073e-05,
      "loss": 1.3157,
      "step": 6930
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.073029518127441,
      "learning_rate": 4.324749402340309e-05,
      "loss": 1.297,
      "step": 6940
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.762195587158203,
      "learning_rate": 4.323700876567546e-05,
      "loss": 1.2804,
      "step": 6950
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.38204288482666,
      "learning_rate": 4.322652350794782e-05,
      "loss": 1.2633,
      "step": 6960
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.2710442543029785,
      "learning_rate": 4.321603825022019e-05,
      "loss": 1.1393,
      "step": 6970
    },
    {
      "epoch": 0.43,
      "grad_norm": 10.348431587219238,
      "learning_rate": 4.320555299249256e-05,
      "loss": 1.3429,
      "step": 6980
    },
    {
      "epoch": 0.44,
      "grad_norm": 7.095753192901611,
      "learning_rate": 4.319506773476492e-05,
      "loss": 1.331,
      "step": 6990
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.962082862854004,
      "learning_rate": 4.318458247703729e-05,
      "loss": 1.3323,
      "step": 7000
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.482572555541992,
      "learning_rate": 4.317409721930965e-05,
      "loss": 1.2644,
      "step": 7010
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.547246932983398,
      "learning_rate": 4.3163611961582015e-05,
      "loss": 1.3995,
      "step": 7020
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.178160190582275,
      "learning_rate": 4.3153126703854384e-05,
      "loss": 1.3301,
      "step": 7030
    },
    {
      "epoch": 0.44,
      "grad_norm": 7.482104301452637,
      "learning_rate": 4.3142641446126746e-05,
      "loss": 1.3021,
      "step": 7040
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.1714448928833,
      "learning_rate": 4.3132156188399114e-05,
      "loss": 1.2413,
      "step": 7050
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.734713077545166,
      "learning_rate": 4.3121670930671476e-05,
      "loss": 1.1916,
      "step": 7060
    },
    {
      "epoch": 0.44,
      "grad_norm": 7.383593559265137,
      "learning_rate": 4.3111185672943845e-05,
      "loss": 1.3228,
      "step": 7070
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.345829010009766,
      "learning_rate": 4.3100700415216214e-05,
      "loss": 1.3349,
      "step": 7080
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.230643272399902,
      "learning_rate": 4.3090215157488576e-05,
      "loss": 1.2791,
      "step": 7090
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.678452014923096,
      "learning_rate": 4.307972989976094e-05,
      "loss": 1.2753,
      "step": 7100
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.693495750427246,
      "learning_rate": 4.30692446420333e-05,
      "loss": 1.318,
      "step": 7110
    },
    {
      "epoch": 0.44,
      "grad_norm": 7.332608222961426,
      "learning_rate": 4.305875938430567e-05,
      "loss": 1.2823,
      "step": 7120
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.84039306640625,
      "learning_rate": 4.304827412657803e-05,
      "loss": 1.252,
      "step": 7130
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.386504650115967,
      "learning_rate": 4.30377888688504e-05,
      "loss": 1.1722,
      "step": 7140
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.7306389808654785,
      "learning_rate": 4.302730361112277e-05,
      "loss": 1.3032,
      "step": 7150
    },
    {
      "epoch": 0.45,
      "grad_norm": 4.424070358276367,
      "learning_rate": 4.301681835339513e-05,
      "loss": 1.231,
      "step": 7160
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.010562896728516,
      "learning_rate": 4.30063330956675e-05,
      "loss": 1.3023,
      "step": 7170
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.446901321411133,
      "learning_rate": 4.299584783793986e-05,
      "loss": 1.2378,
      "step": 7180
    },
    {
      "epoch": 0.45,
      "grad_norm": 6.6220383644104,
      "learning_rate": 4.298536258021222e-05,
      "loss": 1.2388,
      "step": 7190
    },
    {
      "epoch": 0.45,
      "grad_norm": 6.246888637542725,
      "learning_rate": 4.297487732248459e-05,
      "loss": 1.2776,
      "step": 7200
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.885646343231201,
      "learning_rate": 4.296439206475695e-05,
      "loss": 1.2271,
      "step": 7210
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.099562168121338,
      "learning_rate": 4.295390680702932e-05,
      "loss": 1.2195,
      "step": 7220
    },
    {
      "epoch": 0.45,
      "grad_norm": 6.74810266494751,
      "learning_rate": 4.294342154930168e-05,
      "loss": 1.325,
      "step": 7230
    },
    {
      "epoch": 0.45,
      "grad_norm": 8.237627983093262,
      "learning_rate": 4.293293629157405e-05,
      "loss": 1.2537,
      "step": 7240
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.2101826667785645,
      "learning_rate": 4.2922451033846414e-05,
      "loss": 1.2232,
      "step": 7250
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.721643447875977,
      "learning_rate": 4.2911965776118776e-05,
      "loss": 1.2306,
      "step": 7260
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.903097152709961,
      "learning_rate": 4.2901480518391144e-05,
      "loss": 1.1298,
      "step": 7270
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.713736057281494,
      "learning_rate": 4.2890995260663506e-05,
      "loss": 1.4332,
      "step": 7280
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.338423728942871,
      "learning_rate": 4.2880510002935875e-05,
      "loss": 1.4487,
      "step": 7290
    },
    {
      "epoch": 0.45,
      "grad_norm": 9.245451927185059,
      "learning_rate": 4.287002474520824e-05,
      "loss": 1.2563,
      "step": 7300
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.041772842407227,
      "learning_rate": 4.2859539487480606e-05,
      "loss": 1.2157,
      "step": 7310
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.03789758682251,
      "learning_rate": 4.2849054229752974e-05,
      "loss": 1.1604,
      "step": 7320
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.800678730010986,
      "learning_rate": 4.2838568972025336e-05,
      "loss": 1.2119,
      "step": 7330
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.149117469787598,
      "learning_rate": 4.28280837142977e-05,
      "loss": 1.1789,
      "step": 7340
    },
    {
      "epoch": 0.46,
      "grad_norm": 9.76168155670166,
      "learning_rate": 4.281759845657006e-05,
      "loss": 1.2335,
      "step": 7350
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.844419479370117,
      "learning_rate": 4.280711319884243e-05,
      "loss": 1.1267,
      "step": 7360
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.986804962158203,
      "learning_rate": 4.279662794111479e-05,
      "loss": 1.3506,
      "step": 7370
    },
    {
      "epoch": 0.46,
      "grad_norm": 7.572991847991943,
      "learning_rate": 4.278614268338716e-05,
      "loss": 1.1528,
      "step": 7380
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.245160102844238,
      "learning_rate": 4.277565742565953e-05,
      "loss": 1.1348,
      "step": 7390
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.634883880615234,
      "learning_rate": 4.276517216793189e-05,
      "loss": 1.2418,
      "step": 7400
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.428635597229004,
      "learning_rate": 4.275468691020426e-05,
      "loss": 1.2899,
      "step": 7410
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.626823902130127,
      "learning_rate": 4.274420165247662e-05,
      "loss": 1.1978,
      "step": 7420
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.369339942932129,
      "learning_rate": 4.273371639474898e-05,
      "loss": 1.2351,
      "step": 7430
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.599380016326904,
      "learning_rate": 4.272323113702135e-05,
      "loss": 1.2964,
      "step": 7440
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.879663944244385,
      "learning_rate": 4.271274587929371e-05,
      "loss": 1.3378,
      "step": 7450
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.875179290771484,
      "learning_rate": 4.270226062156608e-05,
      "loss": 1.2034,
      "step": 7460
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.39303970336914,
      "learning_rate": 4.2691775363838444e-05,
      "loss": 1.3006,
      "step": 7470
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.941564083099365,
      "learning_rate": 4.268129010611081e-05,
      "loss": 1.1992,
      "step": 7480
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.215399742126465,
      "learning_rate": 4.267080484838318e-05,
      "loss": 1.1844,
      "step": 7490
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.44510555267334,
      "learning_rate": 4.266031959065554e-05,
      "loss": 1.2744,
      "step": 7500
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.101744651794434,
      "learning_rate": 4.2649834332927905e-05,
      "loss": 1.2331,
      "step": 7510
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.692442417144775,
      "learning_rate": 4.263934907520027e-05,
      "loss": 1.1856,
      "step": 7520
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.951776027679443,
      "learning_rate": 4.2628863817472636e-05,
      "loss": 1.3716,
      "step": 7530
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.049376487731934,
      "learning_rate": 4.2618378559745e-05,
      "loss": 1.2655,
      "step": 7540
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.2976789474487305,
      "learning_rate": 4.2607893302017366e-05,
      "loss": 1.2807,
      "step": 7550
    },
    {
      "epoch": 0.47,
      "grad_norm": 9.83621597290039,
      "learning_rate": 4.2597408044289735e-05,
      "loss": 1.1935,
      "step": 7560
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.73150634765625,
      "learning_rate": 4.25869227865621e-05,
      "loss": 1.192,
      "step": 7570
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.567293643951416,
      "learning_rate": 4.257643752883446e-05,
      "loss": 1.2363,
      "step": 7580
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.346660614013672,
      "learning_rate": 4.256595227110682e-05,
      "loss": 1.3011,
      "step": 7590
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.055039405822754,
      "learning_rate": 4.255546701337919e-05,
      "loss": 1.3601,
      "step": 7600
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.1710686683654785,
      "learning_rate": 4.254498175565156e-05,
      "loss": 1.2272,
      "step": 7610
    },
    {
      "epoch": 0.47,
      "grad_norm": 9.909560203552246,
      "learning_rate": 4.253449649792392e-05,
      "loss": 1.2927,
      "step": 7620
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.817371845245361,
      "learning_rate": 4.252401124019629e-05,
      "loss": 1.2203,
      "step": 7630
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.357769966125488,
      "learning_rate": 4.251352598246865e-05,
      "loss": 1.2845,
      "step": 7640
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.988606929779053,
      "learning_rate": 4.250304072474102e-05,
      "loss": 1.2096,
      "step": 7650
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.891457557678223,
      "learning_rate": 4.249255546701338e-05,
      "loss": 1.1604,
      "step": 7660
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.140687942504883,
      "learning_rate": 4.248207020928574e-05,
      "loss": 1.2077,
      "step": 7670
    },
    {
      "epoch": 0.48,
      "grad_norm": 8.156875610351562,
      "learning_rate": 4.247158495155811e-05,
      "loss": 1.2193,
      "step": 7680
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.665264129638672,
      "learning_rate": 4.2461099693830474e-05,
      "loss": 1.2521,
      "step": 7690
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.723058223724365,
      "learning_rate": 4.245061443610284e-05,
      "loss": 1.2649,
      "step": 7700
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.666225910186768,
      "learning_rate": 4.2440129178375204e-05,
      "loss": 1.2207,
      "step": 7710
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.869630336761475,
      "learning_rate": 4.242964392064757e-05,
      "loss": 1.2417,
      "step": 7720
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.746458053588867,
      "learning_rate": 4.241915866291994e-05,
      "loss": 1.2298,
      "step": 7730
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.502732753753662,
      "learning_rate": 4.2408673405192304e-05,
      "loss": 1.271,
      "step": 7740
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.527369499206543,
      "learning_rate": 4.2398188147464666e-05,
      "loss": 1.2633,
      "step": 7750
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.26948356628418,
      "learning_rate": 4.238770288973703e-05,
      "loss": 1.2588,
      "step": 7760
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.650784969329834,
      "learning_rate": 4.2377217632009396e-05,
      "loss": 1.2004,
      "step": 7770
    },
    {
      "epoch": 0.48,
      "grad_norm": 8.775077819824219,
      "learning_rate": 4.2366732374281765e-05,
      "loss": 1.1906,
      "step": 7780
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.37117338180542,
      "learning_rate": 4.235624711655413e-05,
      "loss": 1.246,
      "step": 7790
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.942294120788574,
      "learning_rate": 4.2345761858826496e-05,
      "loss": 1.192,
      "step": 7800
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.9342803955078125,
      "learning_rate": 4.233527660109886e-05,
      "loss": 1.2531,
      "step": 7810
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.138007640838623,
      "learning_rate": 4.232479134337122e-05,
      "loss": 1.2269,
      "step": 7820
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.288691520690918,
      "learning_rate": 4.231430608564358e-05,
      "loss": 1.1251,
      "step": 7830
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.882040977478027,
      "learning_rate": 4.230382082791595e-05,
      "loss": 1.2405,
      "step": 7840
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.127681732177734,
      "learning_rate": 4.229333557018832e-05,
      "loss": 1.3589,
      "step": 7850
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.217344760894775,
      "learning_rate": 4.228285031246068e-05,
      "loss": 1.2792,
      "step": 7860
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.336069583892822,
      "learning_rate": 4.227236505473305e-05,
      "loss": 1.1047,
      "step": 7870
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.184375762939453,
      "learning_rate": 4.226187979700541e-05,
      "loss": 1.1541,
      "step": 7880
    },
    {
      "epoch": 0.49,
      "grad_norm": 9.074004173278809,
      "learning_rate": 4.225139453927778e-05,
      "loss": 1.2264,
      "step": 7890
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.748942852020264,
      "learning_rate": 4.224090928155014e-05,
      "loss": 1.1504,
      "step": 7900
    },
    {
      "epoch": 0.49,
      "grad_norm": 7.415609359741211,
      "learning_rate": 4.2230424023822504e-05,
      "loss": 1.1335,
      "step": 7910
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.510218620300293,
      "learning_rate": 4.221993876609487e-05,
      "loss": 1.3254,
      "step": 7920
    },
    {
      "epoch": 0.49,
      "grad_norm": 8.017752647399902,
      "learning_rate": 4.2209453508367235e-05,
      "loss": 1.2637,
      "step": 7930
    },
    {
      "epoch": 0.49,
      "grad_norm": 7.646674633026123,
      "learning_rate": 4.21989682506396e-05,
      "loss": 1.1366,
      "step": 7940
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.106017112731934,
      "learning_rate": 4.2188482992911965e-05,
      "loss": 1.2598,
      "step": 7950
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.275796413421631,
      "learning_rate": 4.2177997735184334e-05,
      "loss": 1.2676,
      "step": 7960
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.190306663513184,
      "learning_rate": 4.21675124774567e-05,
      "loss": 1.1799,
      "step": 7970
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.110151290893555,
      "learning_rate": 4.2157027219729064e-05,
      "loss": 1.2788,
      "step": 7980
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.382070541381836,
      "learning_rate": 4.2146541962001426e-05,
      "loss": 1.2063,
      "step": 7990
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.814923286437988,
      "learning_rate": 4.213605670427379e-05,
      "loss": 1.2112,
      "step": 8000
    },
    {
      "epoch": 0.5,
      "grad_norm": 10.655498504638672,
      "learning_rate": 4.212557144654616e-05,
      "loss": 1.1822,
      "step": 8010
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.778674125671387,
      "learning_rate": 4.2115086188818526e-05,
      "loss": 1.1548,
      "step": 8020
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.9335408210754395,
      "learning_rate": 4.210460093109089e-05,
      "loss": 1.33,
      "step": 8030
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.909700870513916,
      "learning_rate": 4.2094115673363256e-05,
      "loss": 1.2625,
      "step": 8040
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.229581356048584,
      "learning_rate": 4.208363041563562e-05,
      "loss": 1.1816,
      "step": 8050
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.787467956542969,
      "learning_rate": 4.207314515790799e-05,
      "loss": 1.2429,
      "step": 8060
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.355060577392578,
      "learning_rate": 4.206265990018035e-05,
      "loss": 1.2279,
      "step": 8070
    },
    {
      "epoch": 0.5,
      "grad_norm": 10.370932579040527,
      "learning_rate": 4.205217464245271e-05,
      "loss": 1.3005,
      "step": 8080
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.638935565948486,
      "learning_rate": 4.204168938472508e-05,
      "loss": 1.378,
      "step": 8090
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.960005283355713,
      "learning_rate": 4.203120412699744e-05,
      "loss": 1.2778,
      "step": 8100
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.491668701171875,
      "learning_rate": 4.202071886926981e-05,
      "loss": 1.1889,
      "step": 8110
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.963016510009766,
      "learning_rate": 4.201023361154217e-05,
      "loss": 1.2799,
      "step": 8120
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.466312408447266,
      "learning_rate": 4.199974835381454e-05,
      "loss": 1.2125,
      "step": 8130
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.332237243652344,
      "learning_rate": 4.19892630960869e-05,
      "loss": 1.2263,
      "step": 8140
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.787980556488037,
      "learning_rate": 4.1978777838359265e-05,
      "loss": 1.2747,
      "step": 8150
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.224703311920166,
      "learning_rate": 4.196829258063163e-05,
      "loss": 1.3538,
      "step": 8160
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.343761444091797,
      "learning_rate": 4.1957807322903995e-05,
      "loss": 1.1985,
      "step": 8170
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.536331653594971,
      "learning_rate": 4.1947322065176364e-05,
      "loss": 1.2843,
      "step": 8180
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.936882019042969,
      "learning_rate": 4.193683680744873e-05,
      "loss": 1.3381,
      "step": 8190
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.02268123626709,
      "learning_rate": 4.1926351549721094e-05,
      "loss": 1.2699,
      "step": 8200
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.9647746086120605,
      "learning_rate": 4.191586629199346e-05,
      "loss": 1.3093,
      "step": 8210
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.814393520355225,
      "learning_rate": 4.1905381034265825e-05,
      "loss": 1.2318,
      "step": 8220
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.755425930023193,
      "learning_rate": 4.189489577653819e-05,
      "loss": 1.278,
      "step": 8230
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.195737838745117,
      "learning_rate": 4.188441051881055e-05,
      "loss": 1.244,
      "step": 8240
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.149825096130371,
      "learning_rate": 4.187392526108292e-05,
      "loss": 1.0405,
      "step": 8250
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.428438663482666,
      "learning_rate": 4.1863440003355286e-05,
      "loss": 1.2268,
      "step": 8260
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.3771467208862305,
      "learning_rate": 4.185295474562765e-05,
      "loss": 1.2226,
      "step": 8270
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.275520324707031,
      "learning_rate": 4.184246948790002e-05,
      "loss": 1.3185,
      "step": 8280
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.503861427307129,
      "learning_rate": 4.183198423017238e-05,
      "loss": 1.3148,
      "step": 8290
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.988795280456543,
      "learning_rate": 4.182149897244475e-05,
      "loss": 1.2376,
      "step": 8300
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.434551239013672,
      "learning_rate": 4.181101371471711e-05,
      "loss": 1.2463,
      "step": 8310
    },
    {
      "epoch": 0.52,
      "grad_norm": 7.721006393432617,
      "learning_rate": 4.180052845698947e-05,
      "loss": 1.184,
      "step": 8320
    },
    {
      "epoch": 0.52,
      "grad_norm": 12.652405738830566,
      "learning_rate": 4.179004319926184e-05,
      "loss": 1.2635,
      "step": 8330
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.901418685913086,
      "learning_rate": 4.17795579415342e-05,
      "loss": 1.1164,
      "step": 8340
    },
    {
      "epoch": 0.52,
      "grad_norm": 11.091765403747559,
      "learning_rate": 4.176907268380657e-05,
      "loss": 1.2998,
      "step": 8350
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.129443168640137,
      "learning_rate": 4.175858742607893e-05,
      "loss": 1.2695,
      "step": 8360
    },
    {
      "epoch": 0.52,
      "grad_norm": 7.820600509643555,
      "learning_rate": 4.17481021683513e-05,
      "loss": 1.1865,
      "step": 8370
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.251229286193848,
      "learning_rate": 4.173761691062367e-05,
      "loss": 1.1943,
      "step": 8380
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.587681293487549,
      "learning_rate": 4.172713165289603e-05,
      "loss": 1.2052,
      "step": 8390
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.51783561706543,
      "learning_rate": 4.1716646395168394e-05,
      "loss": 1.1623,
      "step": 8400
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.175009250640869,
      "learning_rate": 4.1706161137440756e-05,
      "loss": 1.2666,
      "step": 8410
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.063385963439941,
      "learning_rate": 4.1695675879713125e-05,
      "loss": 1.2141,
      "step": 8420
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.123259544372559,
      "learning_rate": 4.168519062198549e-05,
      "loss": 1.1757,
      "step": 8430
    },
    {
      "epoch": 0.53,
      "grad_norm": 8.525566101074219,
      "learning_rate": 4.1674705364257855e-05,
      "loss": 1.2731,
      "step": 8440
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.5913848876953125,
      "learning_rate": 4.1664220106530224e-05,
      "loss": 1.2384,
      "step": 8450
    },
    {
      "epoch": 0.53,
      "grad_norm": 8.38670825958252,
      "learning_rate": 4.1653734848802586e-05,
      "loss": 1.4128,
      "step": 8460
    },
    {
      "epoch": 0.53,
      "grad_norm": 9.114448547363281,
      "learning_rate": 4.164324959107495e-05,
      "loss": 1.3729,
      "step": 8470
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.083201885223389,
      "learning_rate": 4.1632764333347316e-05,
      "loss": 1.3185,
      "step": 8480
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.982762813568115,
      "learning_rate": 4.162227907561968e-05,
      "loss": 1.2209,
      "step": 8490
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.9882164001464844,
      "learning_rate": 4.161179381789205e-05,
      "loss": 1.2785,
      "step": 8500
    },
    {
      "epoch": 0.53,
      "grad_norm": 7.760572910308838,
      "learning_rate": 4.160130856016441e-05,
      "loss": 1.2989,
      "step": 8510
    },
    {
      "epoch": 0.53,
      "grad_norm": 7.238683223724365,
      "learning_rate": 4.159082330243678e-05,
      "loss": 1.3373,
      "step": 8520
    },
    {
      "epoch": 0.53,
      "grad_norm": 7.154861927032471,
      "learning_rate": 4.158033804470914e-05,
      "loss": 1.2386,
      "step": 8530
    },
    {
      "epoch": 0.53,
      "grad_norm": 7.688846588134766,
      "learning_rate": 4.156985278698151e-05,
      "loss": 1.1124,
      "step": 8540
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.183588981628418,
      "learning_rate": 4.155936752925387e-05,
      "loss": 1.2141,
      "step": 8550
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.951358318328857,
      "learning_rate": 4.154888227152623e-05,
      "loss": 1.2905,
      "step": 8560
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.94281005859375,
      "learning_rate": 4.15383970137986e-05,
      "loss": 1.1201,
      "step": 8570
    },
    {
      "epoch": 0.53,
      "grad_norm": 9.20659065246582,
      "learning_rate": 4.152791175607096e-05,
      "loss": 1.2024,
      "step": 8580
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.445746898651123,
      "learning_rate": 4.151742649834333e-05,
      "loss": 1.2285,
      "step": 8590
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.683903694152832,
      "learning_rate": 4.15069412406157e-05,
      "loss": 1.2942,
      "step": 8600
    },
    {
      "epoch": 0.54,
      "grad_norm": 6.564249038696289,
      "learning_rate": 4.149645598288806e-05,
      "loss": 1.256,
      "step": 8610
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.663363933563232,
      "learning_rate": 4.148597072516043e-05,
      "loss": 1.1249,
      "step": 8620
    },
    {
      "epoch": 0.54,
      "grad_norm": 9.719562530517578,
      "learning_rate": 4.147548546743279e-05,
      "loss": 1.2563,
      "step": 8630
    },
    {
      "epoch": 0.54,
      "grad_norm": 6.519103050231934,
      "learning_rate": 4.1465000209705155e-05,
      "loss": 1.1943,
      "step": 8640
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.17466402053833,
      "learning_rate": 4.1454514951977516e-05,
      "loss": 1.1286,
      "step": 8650
    },
    {
      "epoch": 0.54,
      "grad_norm": 6.270907402038574,
      "learning_rate": 4.1444029694249885e-05,
      "loss": 1.1795,
      "step": 8660
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.639396667480469,
      "learning_rate": 4.1433544436522254e-05,
      "loss": 1.1826,
      "step": 8670
    },
    {
      "epoch": 0.54,
      "grad_norm": 6.023970127105713,
      "learning_rate": 4.1423059178794616e-05,
      "loss": 1.2354,
      "step": 8680
    },
    {
      "epoch": 0.54,
      "grad_norm": 9.328097343444824,
      "learning_rate": 4.1412573921066985e-05,
      "loss": 1.2729,
      "step": 8690
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.075382232666016,
      "learning_rate": 4.1402088663339346e-05,
      "loss": 1.2087,
      "step": 8700
    },
    {
      "epoch": 0.54,
      "grad_norm": 11.796067237854004,
      "learning_rate": 4.1391603405611715e-05,
      "loss": 1.2337,
      "step": 8710
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.198922157287598,
      "learning_rate": 4.138111814788408e-05,
      "loss": 1.2426,
      "step": 8720
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.619849681854248,
      "learning_rate": 4.137063289015644e-05,
      "loss": 1.2355,
      "step": 8730
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.889461040496826,
      "learning_rate": 4.136014763242881e-05,
      "loss": 1.2253,
      "step": 8740
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.259093761444092,
      "learning_rate": 4.134966237470117e-05,
      "loss": 1.3223,
      "step": 8750
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.9702582359313965,
      "learning_rate": 4.133917711697354e-05,
      "loss": 1.1901,
      "step": 8760
    },
    {
      "epoch": 0.55,
      "grad_norm": 5.408617973327637,
      "learning_rate": 4.132869185924591e-05,
      "loss": 1.2287,
      "step": 8770
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.024077415466309,
      "learning_rate": 4.131820660151827e-05,
      "loss": 1.2287,
      "step": 8780
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.020929336547852,
      "learning_rate": 4.130772134379063e-05,
      "loss": 1.1836,
      "step": 8790
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.64354133605957,
      "learning_rate": 4.129723608606299e-05,
      "loss": 1.2647,
      "step": 8800
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.328986167907715,
      "learning_rate": 4.128675082833536e-05,
      "loss": 1.2669,
      "step": 8810
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.207437515258789,
      "learning_rate": 4.127626557060772e-05,
      "loss": 1.2823,
      "step": 8820
    },
    {
      "epoch": 0.55,
      "grad_norm": 5.761965274810791,
      "learning_rate": 4.126578031288009e-05,
      "loss": 1.2391,
      "step": 8830
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.231862545013428,
      "learning_rate": 4.125529505515246e-05,
      "loss": 1.3655,
      "step": 8840
    },
    {
      "epoch": 0.55,
      "grad_norm": 14.297351837158203,
      "learning_rate": 4.124480979742482e-05,
      "loss": 1.1614,
      "step": 8850
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.873493194580078,
      "learning_rate": 4.123432453969719e-05,
      "loss": 1.3128,
      "step": 8860
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.393592834472656,
      "learning_rate": 4.122383928196955e-05,
      "loss": 1.2063,
      "step": 8870
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.058637619018555,
      "learning_rate": 4.1213354024241915e-05,
      "loss": 1.2998,
      "step": 8880
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.175205707550049,
      "learning_rate": 4.1202868766514284e-05,
      "loss": 1.2892,
      "step": 8890
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.072979927062988,
      "learning_rate": 4.1192383508786646e-05,
      "loss": 1.2329,
      "step": 8900
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.191502571105957,
      "learning_rate": 4.1181898251059015e-05,
      "loss": 1.2447,
      "step": 8910
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.848597526550293,
      "learning_rate": 4.1171412993331376e-05,
      "loss": 1.2544,
      "step": 8920
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.291153430938721,
      "learning_rate": 4.1160927735603745e-05,
      "loss": 1.165,
      "step": 8930
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.1036200523376465,
      "learning_rate": 4.115044247787611e-05,
      "loss": 1.2098,
      "step": 8940
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.546769142150879,
      "learning_rate": 4.1139957220148476e-05,
      "loss": 1.073,
      "step": 8950
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.121529579162598,
      "learning_rate": 4.112947196242084e-05,
      "loss": 1.094,
      "step": 8960
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.886005878448486,
      "learning_rate": 4.11189867046932e-05,
      "loss": 1.3481,
      "step": 8970
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.920540809631348,
      "learning_rate": 4.110850144696557e-05,
      "loss": 1.2753,
      "step": 8980
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.6621246337890625,
      "learning_rate": 4.109801618923793e-05,
      "loss": 1.2241,
      "step": 8990
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.860572338104248,
      "learning_rate": 4.10875309315103e-05,
      "loss": 1.3786,
      "step": 9000
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.905975341796875,
      "learning_rate": 4.107704567378267e-05,
      "loss": 1.2257,
      "step": 9010
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.035347938537598,
      "learning_rate": 4.106656041605503e-05,
      "loss": 1.2734,
      "step": 9020
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.575937271118164,
      "learning_rate": 4.10560751583274e-05,
      "loss": 1.3302,
      "step": 9030
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.94252872467041,
      "learning_rate": 4.104558990059976e-05,
      "loss": 1.2342,
      "step": 9040
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.074854850769043,
      "learning_rate": 4.103510464287212e-05,
      "loss": 1.2339,
      "step": 9050
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.051939964294434,
      "learning_rate": 4.102461938514449e-05,
      "loss": 1.2119,
      "step": 9060
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.883438587188721,
      "learning_rate": 4.101413412741685e-05,
      "loss": 1.3162,
      "step": 9070
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.55427885055542,
      "learning_rate": 4.100364886968922e-05,
      "loss": 1.2276,
      "step": 9080
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.48794412612915,
      "learning_rate": 4.099316361196158e-05,
      "loss": 1.2611,
      "step": 9090
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.088462829589844,
      "learning_rate": 4.098267835423395e-05,
      "loss": 1.3152,
      "step": 9100
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.306323528289795,
      "learning_rate": 4.0972193096506314e-05,
      "loss": 1.1931,
      "step": 9110
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.175740718841553,
      "learning_rate": 4.0961707838778676e-05,
      "loss": 1.3144,
      "step": 9120
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.3263750076293945,
      "learning_rate": 4.0951222581051045e-05,
      "loss": 1.2608,
      "step": 9130
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.905640125274658,
      "learning_rate": 4.0940737323323407e-05,
      "loss": 1.3833,
      "step": 9140
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.430655002593994,
      "learning_rate": 4.0930252065595775e-05,
      "loss": 1.2152,
      "step": 9150
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.309417724609375,
      "learning_rate": 4.091976680786814e-05,
      "loss": 1.2194,
      "step": 9160
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.746792793273926,
      "learning_rate": 4.0909281550140506e-05,
      "loss": 1.2057,
      "step": 9170
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.398555755615234,
      "learning_rate": 4.0898796292412875e-05,
      "loss": 1.302,
      "step": 9180
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.222529888153076,
      "learning_rate": 4.0888311034685236e-05,
      "loss": 1.2194,
      "step": 9190
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.0847392082214355,
      "learning_rate": 4.08778257769576e-05,
      "loss": 1.1639,
      "step": 9200
    },
    {
      "epoch": 0.57,
      "grad_norm": 9.303414344787598,
      "learning_rate": 4.086734051922996e-05,
      "loss": 1.2353,
      "step": 9210
    },
    {
      "epoch": 0.57,
      "grad_norm": 9.348384857177734,
      "learning_rate": 4.085685526150233e-05,
      "loss": 1.1438,
      "step": 9220
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.56846809387207,
      "learning_rate": 4.084637000377469e-05,
      "loss": 1.1808,
      "step": 9230
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.623902797698975,
      "learning_rate": 4.083588474604706e-05,
      "loss": 1.2138,
      "step": 9240
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.931869029998779,
      "learning_rate": 4.082539948831943e-05,
      "loss": 1.1884,
      "step": 9250
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.612858772277832,
      "learning_rate": 4.081491423059179e-05,
      "loss": 1.1626,
      "step": 9260
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.356039524078369,
      "learning_rate": 4.080442897286416e-05,
      "loss": 1.141,
      "step": 9270
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.85486364364624,
      "learning_rate": 4.079394371513652e-05,
      "loss": 1.3173,
      "step": 9280
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.539464950561523,
      "learning_rate": 4.078345845740888e-05,
      "loss": 1.2506,
      "step": 9290
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.992740154266357,
      "learning_rate": 4.077297319968125e-05,
      "loss": 1.2479,
      "step": 9300
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.138391494750977,
      "learning_rate": 4.0762487941953613e-05,
      "loss": 1.2617,
      "step": 9310
    },
    {
      "epoch": 0.58,
      "grad_norm": 8.163254737854004,
      "learning_rate": 4.075200268422598e-05,
      "loss": 1.3341,
      "step": 9320
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.88913631439209,
      "learning_rate": 4.0741517426498344e-05,
      "loss": 1.3349,
      "step": 9330
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.754305839538574,
      "learning_rate": 4.073103216877071e-05,
      "loss": 1.2349,
      "step": 9340
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.2920732498168945,
      "learning_rate": 4.0720546911043075e-05,
      "loss": 1.3319,
      "step": 9350
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.111064910888672,
      "learning_rate": 4.071006165331544e-05,
      "loss": 1.1182,
      "step": 9360
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.787283897399902,
      "learning_rate": 4.0699576395587805e-05,
      "loss": 1.2136,
      "step": 9370
    },
    {
      "epoch": 0.58,
      "grad_norm": 7.6253180503845215,
      "learning_rate": 4.068909113786017e-05,
      "loss": 1.1419,
      "step": 9380
    },
    {
      "epoch": 0.58,
      "grad_norm": 7.039575576782227,
      "learning_rate": 4.0678605880132536e-05,
      "loss": 1.2845,
      "step": 9390
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.034352779388428,
      "learning_rate": 4.06681206224049e-05,
      "loss": 1.3591,
      "step": 9400
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.249933242797852,
      "learning_rate": 4.0657635364677266e-05,
      "loss": 1.2079,
      "step": 9410
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.403224945068359,
      "learning_rate": 4.0647150106949635e-05,
      "loss": 1.2338,
      "step": 9420
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.184531211853027,
      "learning_rate": 4.0636664849222e-05,
      "loss": 1.2055,
      "step": 9430
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.804067134857178,
      "learning_rate": 4.062617959149436e-05,
      "loss": 1.2805,
      "step": 9440
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.852691650390625,
      "learning_rate": 4.061569433376672e-05,
      "loss": 1.2304,
      "step": 9450
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.43335485458374,
      "learning_rate": 4.060520907603909e-05,
      "loss": 1.1881,
      "step": 9460
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.311201095581055,
      "learning_rate": 4.059472381831146e-05,
      "loss": 1.1994,
      "step": 9470
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.795119762420654,
      "learning_rate": 4.058423856058382e-05,
      "loss": 1.1159,
      "step": 9480
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.173561096191406,
      "learning_rate": 4.057375330285619e-05,
      "loss": 1.315,
      "step": 9490
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.909858226776123,
      "learning_rate": 4.056326804512855e-05,
      "loss": 1.2142,
      "step": 9500
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.466339111328125,
      "learning_rate": 4.055278278740092e-05,
      "loss": 1.1578,
      "step": 9510
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.216501712799072,
      "learning_rate": 4.054229752967328e-05,
      "loss": 1.1316,
      "step": 9520
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.31330680847168,
      "learning_rate": 4.0531812271945643e-05,
      "loss": 1.305,
      "step": 9530
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.472279071807861,
      "learning_rate": 4.052132701421801e-05,
      "loss": 1.2972,
      "step": 9540
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.753093242645264,
      "learning_rate": 4.0510841756490374e-05,
      "loss": 1.1808,
      "step": 9550
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.197982788085938,
      "learning_rate": 4.050035649876274e-05,
      "loss": 1.2368,
      "step": 9560
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.190513610839844,
      "learning_rate": 4.0489871241035105e-05,
      "loss": 1.2321,
      "step": 9570
    },
    {
      "epoch": 0.6,
      "grad_norm": 5.342239856719971,
      "learning_rate": 4.047938598330747e-05,
      "loss": 1.3008,
      "step": 9580
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.2076334953308105,
      "learning_rate": 4.046890072557984e-05,
      "loss": 1.225,
      "step": 9590
    },
    {
      "epoch": 0.6,
      "grad_norm": 8.455307960510254,
      "learning_rate": 4.0458415467852204e-05,
      "loss": 1.1508,
      "step": 9600
    },
    {
      "epoch": 0.6,
      "grad_norm": 8.808746337890625,
      "learning_rate": 4.0447930210124566e-05,
      "loss": 1.1601,
      "step": 9610
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.35434627532959,
      "learning_rate": 4.043744495239693e-05,
      "loss": 1.3694,
      "step": 9620
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.581455230712891,
      "learning_rate": 4.0426959694669297e-05,
      "loss": 1.2846,
      "step": 9630
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.937744617462158,
      "learning_rate": 4.041647443694166e-05,
      "loss": 1.0799,
      "step": 9640
    },
    {
      "epoch": 0.6,
      "grad_norm": 5.778326988220215,
      "learning_rate": 4.040598917921403e-05,
      "loss": 1.1894,
      "step": 9650
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.914163112640381,
      "learning_rate": 4.0395503921486396e-05,
      "loss": 1.2332,
      "step": 9660
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.667871952056885,
      "learning_rate": 4.038501866375876e-05,
      "loss": 1.2895,
      "step": 9670
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.205900192260742,
      "learning_rate": 4.0374533406031126e-05,
      "loss": 1.2348,
      "step": 9680
    },
    {
      "epoch": 0.6,
      "grad_norm": 7.221764087677002,
      "learning_rate": 4.036404814830348e-05,
      "loss": 1.2759,
      "step": 9690
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.654659271240234,
      "learning_rate": 4.035356289057585e-05,
      "loss": 1.3465,
      "step": 9700
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.717447757720947,
      "learning_rate": 4.034307763284822e-05,
      "loss": 1.2551,
      "step": 9710
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.808844566345215,
      "learning_rate": 4.033259237512058e-05,
      "loss": 1.2368,
      "step": 9720
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.545357704162598,
      "learning_rate": 4.032210711739295e-05,
      "loss": 1.1199,
      "step": 9730
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.1988935470581055,
      "learning_rate": 4.031162185966531e-05,
      "loss": 1.1071,
      "step": 9740
    },
    {
      "epoch": 0.61,
      "grad_norm": 11.634197235107422,
      "learning_rate": 4.030113660193768e-05,
      "loss": 1.1833,
      "step": 9750
    },
    {
      "epoch": 0.61,
      "grad_norm": 7.34067440032959,
      "learning_rate": 4.029065134421004e-05,
      "loss": 1.2564,
      "step": 9760
    },
    {
      "epoch": 0.61,
      "grad_norm": 6.674195289611816,
      "learning_rate": 4.0280166086482404e-05,
      "loss": 1.2769,
      "step": 9770
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.39510726928711,
      "learning_rate": 4.026968082875477e-05,
      "loss": 1.2741,
      "step": 9780
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.7445068359375,
      "learning_rate": 4.0259195571027135e-05,
      "loss": 1.2009,
      "step": 9790
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.620500564575195,
      "learning_rate": 4.0248710313299503e-05,
      "loss": 1.2417,
      "step": 9800
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.318880081176758,
      "learning_rate": 4.0238225055571865e-05,
      "loss": 1.1931,
      "step": 9810
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.982964992523193,
      "learning_rate": 4.0227739797844234e-05,
      "loss": 1.2909,
      "step": 9820
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.072124481201172,
      "learning_rate": 4.02172545401166e-05,
      "loss": 1.2109,
      "step": 9830
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.564198970794678,
      "learning_rate": 4.0206769282388965e-05,
      "loss": 1.0782,
      "step": 9840
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.113980293273926,
      "learning_rate": 4.0196284024661327e-05,
      "loss": 1.3296,
      "step": 9850
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.511878967285156,
      "learning_rate": 4.018579876693369e-05,
      "loss": 1.2836,
      "step": 9860
    },
    {
      "epoch": 0.61,
      "grad_norm": 7.350090026855469,
      "learning_rate": 4.017531350920606e-05,
      "loss": 1.2757,
      "step": 9870
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.843078136444092,
      "learning_rate": 4.0164828251478426e-05,
      "loss": 1.2264,
      "step": 9880
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.9220478534698486,
      "learning_rate": 4.015434299375079e-05,
      "loss": 1.1729,
      "step": 9890
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.292466163635254,
      "learning_rate": 4.0143857736023157e-05,
      "loss": 1.1919,
      "step": 9900
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.6586384773254395,
      "learning_rate": 4.013337247829552e-05,
      "loss": 1.1662,
      "step": 9910
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.2106242179870605,
      "learning_rate": 4.012288722056789e-05,
      "loss": 1.1906,
      "step": 9920
    },
    {
      "epoch": 0.62,
      "grad_norm": 6.60089111328125,
      "learning_rate": 4.011240196284025e-05,
      "loss": 1.1475,
      "step": 9930
    },
    {
      "epoch": 0.62,
      "grad_norm": 10.989190101623535,
      "learning_rate": 4.010191670511261e-05,
      "loss": 1.2078,
      "step": 9940
    },
    {
      "epoch": 0.62,
      "grad_norm": 10.094673156738281,
      "learning_rate": 4.009143144738498e-05,
      "loss": 1.2215,
      "step": 9950
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.620920181274414,
      "learning_rate": 4.008094618965734e-05,
      "loss": 1.2245,
      "step": 9960
    },
    {
      "epoch": 0.62,
      "grad_norm": 7.4559197425842285,
      "learning_rate": 4.007046093192971e-05,
      "loss": 1.2087,
      "step": 9970
    },
    {
      "epoch": 0.62,
      "grad_norm": 6.669946670532227,
      "learning_rate": 4.005997567420207e-05,
      "loss": 1.2539,
      "step": 9980
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.109416961669922,
      "learning_rate": 4.004949041647444e-05,
      "loss": 1.152,
      "step": 9990
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.393707752227783,
      "learning_rate": 4.003900515874681e-05,
      "loss": 1.2507,
      "step": 10000
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.769119262695312,
      "learning_rate": 4.0028519901019165e-05,
      "loss": 1.1417,
      "step": 10010
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.398693561553955,
      "learning_rate": 4.0018034643291533e-05,
      "loss": 1.0838,
      "step": 10020
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.592317581176758,
      "learning_rate": 4.0007549385563895e-05,
      "loss": 1.2155,
      "step": 10030
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.960604667663574,
      "learning_rate": 3.9997064127836264e-05,
      "loss": 1.2314,
      "step": 10040
    },
    {
      "epoch": 0.63,
      "grad_norm": 8.876235008239746,
      "learning_rate": 3.998657887010863e-05,
      "loss": 1.2748,
      "step": 10050
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.153533458709717,
      "learning_rate": 3.9976093612380995e-05,
      "loss": 1.3834,
      "step": 10060
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.953001022338867,
      "learning_rate": 3.996560835465336e-05,
      "loss": 1.194,
      "step": 10070
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.806504249572754,
      "learning_rate": 3.9955123096925725e-05,
      "loss": 1.313,
      "step": 10080
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.238848686218262,
      "learning_rate": 3.994463783919809e-05,
      "loss": 1.2274,
      "step": 10090
    },
    {
      "epoch": 0.63,
      "grad_norm": 10.453452110290527,
      "learning_rate": 3.993415258147045e-05,
      "loss": 1.2586,
      "step": 10100
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.923430442810059,
      "learning_rate": 3.992366732374282e-05,
      "loss": 1.145,
      "step": 10110
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.8049116134643555,
      "learning_rate": 3.9913182066015187e-05,
      "loss": 1.1661,
      "step": 10120
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.599449634552002,
      "learning_rate": 3.990269680828755e-05,
      "loss": 1.0604,
      "step": 10130
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.680298328399658,
      "learning_rate": 3.989221155055992e-05,
      "loss": 1.2411,
      "step": 10140
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.836885452270508,
      "learning_rate": 3.988172629283228e-05,
      "loss": 1.2836,
      "step": 10150
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.735195159912109,
      "learning_rate": 3.987124103510465e-05,
      "loss": 1.1992,
      "step": 10160
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.855599880218506,
      "learning_rate": 3.986075577737701e-05,
      "loss": 1.1884,
      "step": 10170
    },
    {
      "epoch": 0.63,
      "grad_norm": 16.319860458374023,
      "learning_rate": 3.985027051964937e-05,
      "loss": 1.2522,
      "step": 10180
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.3552751541137695,
      "learning_rate": 3.983978526192174e-05,
      "loss": 1.1819,
      "step": 10190
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.511277675628662,
      "learning_rate": 3.98293000041941e-05,
      "loss": 1.3178,
      "step": 10200
    },
    {
      "epoch": 0.64,
      "grad_norm": 11.73778247833252,
      "learning_rate": 3.981881474646647e-05,
      "loss": 1.3914,
      "step": 10210
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.547294616699219,
      "learning_rate": 3.980832948873883e-05,
      "loss": 1.2339,
      "step": 10220
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.552374839782715,
      "learning_rate": 3.97978442310112e-05,
      "loss": 1.1352,
      "step": 10230
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.224151611328125,
      "learning_rate": 3.978735897328357e-05,
      "loss": 1.2141,
      "step": 10240
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.091440677642822,
      "learning_rate": 3.977687371555593e-05,
      "loss": 1.2168,
      "step": 10250
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.40355920791626,
      "learning_rate": 3.9766388457828294e-05,
      "loss": 1.246,
      "step": 10260
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.6707377433776855,
      "learning_rate": 3.9755903200100656e-05,
      "loss": 1.2333,
      "step": 10270
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.688541889190674,
      "learning_rate": 3.9745417942373025e-05,
      "loss": 1.2643,
      "step": 10280
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.97804594039917,
      "learning_rate": 3.9734932684645393e-05,
      "loss": 1.3044,
      "step": 10290
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.269071578979492,
      "learning_rate": 3.9724447426917755e-05,
      "loss": 1.2074,
      "step": 10300
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.471572399139404,
      "learning_rate": 3.9713962169190124e-05,
      "loss": 1.1383,
      "step": 10310
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.693787097930908,
      "learning_rate": 3.9703476911462486e-05,
      "loss": 1.2089,
      "step": 10320
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.671183109283447,
      "learning_rate": 3.969299165373485e-05,
      "loss": 1.2648,
      "step": 10330
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.935407638549805,
      "learning_rate": 3.9682506396007217e-05,
      "loss": 1.2852,
      "step": 10340
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.021276473999023,
      "learning_rate": 3.967202113827958e-05,
      "loss": 1.1904,
      "step": 10350
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.211833953857422,
      "learning_rate": 3.966153588055195e-05,
      "loss": 1.0519,
      "step": 10360
    },
    {
      "epoch": 0.65,
      "grad_norm": 7.412272930145264,
      "learning_rate": 3.965105062282431e-05,
      "loss": 1.0705,
      "step": 10370
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.90171480178833,
      "learning_rate": 3.964056536509668e-05,
      "loss": 1.1603,
      "step": 10380
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.432994365692139,
      "learning_rate": 3.963008010736904e-05,
      "loss": 1.1113,
      "step": 10390
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.36054801940918,
      "learning_rate": 3.961959484964141e-05,
      "loss": 1.3476,
      "step": 10400
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.308536529541016,
      "learning_rate": 3.960910959191377e-05,
      "loss": 1.1457,
      "step": 10410
    },
    {
      "epoch": 0.65,
      "grad_norm": 8.365723609924316,
      "learning_rate": 3.959862433418613e-05,
      "loss": 1.1627,
      "step": 10420
    },
    {
      "epoch": 0.65,
      "grad_norm": 11.951929092407227,
      "learning_rate": 3.95881390764585e-05,
      "loss": 1.2026,
      "step": 10430
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.965930938720703,
      "learning_rate": 3.957765381873086e-05,
      "loss": 1.2941,
      "step": 10440
    },
    {
      "epoch": 0.65,
      "grad_norm": 10.743439674377441,
      "learning_rate": 3.956716856100323e-05,
      "loss": 1.0489,
      "step": 10450
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.434172630310059,
      "learning_rate": 3.95566833032756e-05,
      "loss": 1.3796,
      "step": 10460
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.81375789642334,
      "learning_rate": 3.954619804554796e-05,
      "loss": 1.2524,
      "step": 10470
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.586210250854492,
      "learning_rate": 3.953571278782033e-05,
      "loss": 1.2515,
      "step": 10480
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.421380043029785,
      "learning_rate": 3.952522753009269e-05,
      "loss": 1.2599,
      "step": 10490
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.395471096038818,
      "learning_rate": 3.9514742272365055e-05,
      "loss": 1.1245,
      "step": 10500
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.8850836753845215,
      "learning_rate": 3.950425701463742e-05,
      "loss": 1.2156,
      "step": 10510
    },
    {
      "epoch": 0.65,
      "grad_norm": 7.918096542358398,
      "learning_rate": 3.9493771756909785e-05,
      "loss": 1.1278,
      "step": 10520
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.2498698234558105,
      "learning_rate": 3.9483286499182154e-05,
      "loss": 1.1607,
      "step": 10530
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.12432861328125,
      "learning_rate": 3.9472801241454516e-05,
      "loss": 1.258,
      "step": 10540
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.94333553314209,
      "learning_rate": 3.9462315983726885e-05,
      "loss": 1.4526,
      "step": 10550
    },
    {
      "epoch": 0.66,
      "grad_norm": 6.19261360168457,
      "learning_rate": 3.945183072599925e-05,
      "loss": 1.1298,
      "step": 10560
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.66767692565918,
      "learning_rate": 3.9441345468271615e-05,
      "loss": 1.296,
      "step": 10570
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.012317657470703,
      "learning_rate": 3.943086021054398e-05,
      "loss": 1.3453,
      "step": 10580
    },
    {
      "epoch": 0.66,
      "grad_norm": 5.968450546264648,
      "learning_rate": 3.942037495281634e-05,
      "loss": 1.1997,
      "step": 10590
    },
    {
      "epoch": 0.66,
      "grad_norm": 6.234242916107178,
      "learning_rate": 3.940988969508871e-05,
      "loss": 1.2142,
      "step": 10600
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.632697105407715,
      "learning_rate": 3.939940443736107e-05,
      "loss": 1.2679,
      "step": 10610
    },
    {
      "epoch": 0.66,
      "grad_norm": 5.877838134765625,
      "learning_rate": 3.938891917963344e-05,
      "loss": 1.2141,
      "step": 10620
    },
    {
      "epoch": 0.66,
      "grad_norm": 8.5329008102417,
      "learning_rate": 3.93784339219058e-05,
      "loss": 1.2251,
      "step": 10630
    },
    {
      "epoch": 0.66,
      "grad_norm": 5.3242340087890625,
      "learning_rate": 3.936794866417817e-05,
      "loss": 1.2695,
      "step": 10640
    },
    {
      "epoch": 0.66,
      "grad_norm": 9.299759864807129,
      "learning_rate": 3.935746340645053e-05,
      "loss": 1.2919,
      "step": 10650
    },
    {
      "epoch": 0.66,
      "grad_norm": 6.840683460235596,
      "learning_rate": 3.934697814872289e-05,
      "loss": 1.1739,
      "step": 10660
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.697790145874023,
      "learning_rate": 3.933649289099526e-05,
      "loss": 1.2527,
      "step": 10670
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.337970733642578,
      "learning_rate": 3.9326007633267624e-05,
      "loss": 1.2655,
      "step": 10680
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.940001487731934,
      "learning_rate": 3.931552237553999e-05,
      "loss": 1.2442,
      "step": 10690
    },
    {
      "epoch": 0.67,
      "grad_norm": 8.516496658325195,
      "learning_rate": 3.930503711781236e-05,
      "loss": 1.1167,
      "step": 10700
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.547966003417969,
      "learning_rate": 3.929455186008472e-05,
      "loss": 1.2129,
      "step": 10710
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.105772018432617,
      "learning_rate": 3.928406660235709e-05,
      "loss": 1.3319,
      "step": 10720
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.42451286315918,
      "learning_rate": 3.9273581344629454e-05,
      "loss": 1.1998,
      "step": 10730
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.505777359008789,
      "learning_rate": 3.9263096086901815e-05,
      "loss": 1.2402,
      "step": 10740
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.970582962036133,
      "learning_rate": 3.9252610829174184e-05,
      "loss": 1.213,
      "step": 10750
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.33696174621582,
      "learning_rate": 3.9242125571446546e-05,
      "loss": 1.2868,
      "step": 10760
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.481840133666992,
      "learning_rate": 3.9231640313718915e-05,
      "loss": 1.1654,
      "step": 10770
    },
    {
      "epoch": 0.67,
      "grad_norm": 8.59241771697998,
      "learning_rate": 3.922115505599128e-05,
      "loss": 1.1941,
      "step": 10780
    },
    {
      "epoch": 0.67,
      "grad_norm": 8.528604507446289,
      "learning_rate": 3.9210669798263645e-05,
      "loss": 1.2451,
      "step": 10790
    },
    {
      "epoch": 0.67,
      "grad_norm": 8.972319602966309,
      "learning_rate": 3.920018454053601e-05,
      "loss": 1.2811,
      "step": 10800
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.9232177734375,
      "learning_rate": 3.9189699282808376e-05,
      "loss": 1.2772,
      "step": 10810
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.624723434448242,
      "learning_rate": 3.917921402508074e-05,
      "loss": 1.2946,
      "step": 10820
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.556432247161865,
      "learning_rate": 3.91687287673531e-05,
      "loss": 1.2172,
      "step": 10830
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.466549873352051,
      "learning_rate": 3.915824350962547e-05,
      "loss": 1.1969,
      "step": 10840
    },
    {
      "epoch": 0.68,
      "grad_norm": 9.425698280334473,
      "learning_rate": 3.914775825189783e-05,
      "loss": 1.1669,
      "step": 10850
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.694372653961182,
      "learning_rate": 3.91372729941702e-05,
      "loss": 1.2764,
      "step": 10860
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.400458335876465,
      "learning_rate": 3.912678773644257e-05,
      "loss": 1.2785,
      "step": 10870
    },
    {
      "epoch": 0.68,
      "grad_norm": 6.911975860595703,
      "learning_rate": 3.911630247871493e-05,
      "loss": 1.199,
      "step": 10880
    },
    {
      "epoch": 0.68,
      "grad_norm": 6.31969690322876,
      "learning_rate": 3.91058172209873e-05,
      "loss": 1.1142,
      "step": 10890
    },
    {
      "epoch": 0.68,
      "grad_norm": 7.052864074707031,
      "learning_rate": 3.909533196325966e-05,
      "loss": 1.2675,
      "step": 10900
    },
    {
      "epoch": 0.68,
      "grad_norm": 10.72843074798584,
      "learning_rate": 3.908484670553202e-05,
      "loss": 1.192,
      "step": 10910
    },
    {
      "epoch": 0.68,
      "grad_norm": 10.766225814819336,
      "learning_rate": 3.9074361447804384e-05,
      "loss": 1.2341,
      "step": 10920
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.595016479492188,
      "learning_rate": 3.906387619007675e-05,
      "loss": 1.2324,
      "step": 10930
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.803175926208496,
      "learning_rate": 3.905339093234912e-05,
      "loss": 1.2961,
      "step": 10940
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.037227153778076,
      "learning_rate": 3.9042905674621484e-05,
      "loss": 1.2768,
      "step": 10950
    },
    {
      "epoch": 0.68,
      "grad_norm": 6.2715606689453125,
      "learning_rate": 3.903242041689385e-05,
      "loss": 1.2638,
      "step": 10960
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.809979438781738,
      "learning_rate": 3.9021935159166214e-05,
      "loss": 1.0163,
      "step": 10970
    },
    {
      "epoch": 0.68,
      "grad_norm": 7.04006290435791,
      "learning_rate": 3.9011449901438576e-05,
      "loss": 1.194,
      "step": 10980
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.845227241516113,
      "learning_rate": 3.9000964643710945e-05,
      "loss": 1.2159,
      "step": 10990
    },
    {
      "epoch": 0.68,
      "grad_norm": 6.6800456047058105,
      "learning_rate": 3.899047938598331e-05,
      "loss": 1.2833,
      "step": 11000
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.979365825653076,
      "learning_rate": 3.8979994128255675e-05,
      "loss": 1.2128,
      "step": 11010
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.653379440307617,
      "learning_rate": 3.896950887052804e-05,
      "loss": 1.1192,
      "step": 11020
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.608545780181885,
      "learning_rate": 3.8959023612800406e-05,
      "loss": 1.1106,
      "step": 11030
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.264032363891602,
      "learning_rate": 3.8948538355072775e-05,
      "loss": 1.278,
      "step": 11040
    },
    {
      "epoch": 0.69,
      "grad_norm": 7.608108997344971,
      "learning_rate": 3.893805309734514e-05,
      "loss": 1.2464,
      "step": 11050
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.1702704429626465,
      "learning_rate": 3.89275678396175e-05,
      "loss": 1.2173,
      "step": 11060
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.406673431396484,
      "learning_rate": 3.891708258188986e-05,
      "loss": 1.2856,
      "step": 11070
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.39709997177124,
      "learning_rate": 3.890659732416223e-05,
      "loss": 1.1175,
      "step": 11080
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.915368556976318,
      "learning_rate": 3.889611206643459e-05,
      "loss": 1.211,
      "step": 11090
    },
    {
      "epoch": 0.69,
      "grad_norm": 10.306562423706055,
      "learning_rate": 3.888562680870696e-05,
      "loss": 1.2288,
      "step": 11100
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.31486177444458,
      "learning_rate": 3.887514155097933e-05,
      "loss": 1.138,
      "step": 11110
    },
    {
      "epoch": 0.69,
      "grad_norm": 10.127577781677246,
      "learning_rate": 3.886465629325169e-05,
      "loss": 1.203,
      "step": 11120
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.533917427062988,
      "learning_rate": 3.885417103552406e-05,
      "loss": 1.2726,
      "step": 11130
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.185493469238281,
      "learning_rate": 3.884368577779642e-05,
      "loss": 1.1267,
      "step": 11140
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.196214199066162,
      "learning_rate": 3.883320052006878e-05,
      "loss": 1.1356,
      "step": 11150
    },
    {
      "epoch": 0.69,
      "grad_norm": 10.189507484436035,
      "learning_rate": 3.882271526234115e-05,
      "loss": 1.124,
      "step": 11160
    },
    {
      "epoch": 0.7,
      "grad_norm": 9.45086669921875,
      "learning_rate": 3.8812230004613514e-05,
      "loss": 1.3265,
      "step": 11170
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.35888147354126,
      "learning_rate": 3.880174474688588e-05,
      "loss": 1.2065,
      "step": 11180
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.307147979736328,
      "learning_rate": 3.8791259489158244e-05,
      "loss": 1.2742,
      "step": 11190
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.031215667724609,
      "learning_rate": 3.878077423143061e-05,
      "loss": 1.166,
      "step": 11200
    },
    {
      "epoch": 0.7,
      "grad_norm": 8.676584243774414,
      "learning_rate": 3.8770288973702975e-05,
      "loss": 1.1493,
      "step": 11210
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.373592376708984,
      "learning_rate": 3.8759803715975344e-05,
      "loss": 1.2232,
      "step": 11220
    },
    {
      "epoch": 0.7,
      "grad_norm": 10.642333030700684,
      "learning_rate": 3.8749318458247705e-05,
      "loss": 1.1701,
      "step": 11230
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.014537334442139,
      "learning_rate": 3.873883320052007e-05,
      "loss": 1.2343,
      "step": 11240
    },
    {
      "epoch": 0.7,
      "grad_norm": 8.609658241271973,
      "learning_rate": 3.8728347942792436e-05,
      "loss": 1.2536,
      "step": 11250
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.2341437339782715,
      "learning_rate": 3.87178626850648e-05,
      "loss": 1.2411,
      "step": 11260
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.537283897399902,
      "learning_rate": 3.870737742733717e-05,
      "loss": 1.1819,
      "step": 11270
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.790101528167725,
      "learning_rate": 3.8696892169609535e-05,
      "loss": 1.2101,
      "step": 11280
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.24119234085083,
      "learning_rate": 3.86864069118819e-05,
      "loss": 1.2166,
      "step": 11290
    },
    {
      "epoch": 0.7,
      "grad_norm": 10.33139705657959,
      "learning_rate": 3.867592165415426e-05,
      "loss": 1.2447,
      "step": 11300
    },
    {
      "epoch": 0.7,
      "grad_norm": 9.027348518371582,
      "learning_rate": 3.866543639642662e-05,
      "loss": 1.2096,
      "step": 11310
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.1122355461120605,
      "learning_rate": 3.865495113869899e-05,
      "loss": 1.068,
      "step": 11320
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.384284496307373,
      "learning_rate": 3.864446588097136e-05,
      "loss": 1.1479,
      "step": 11330
    },
    {
      "epoch": 0.71,
      "grad_norm": 6.887837886810303,
      "learning_rate": 3.863398062324372e-05,
      "loss": 1.2297,
      "step": 11340
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.433706283569336,
      "learning_rate": 3.862349536551609e-05,
      "loss": 1.2128,
      "step": 11350
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.208083152770996,
      "learning_rate": 3.861301010778845e-05,
      "loss": 1.1393,
      "step": 11360
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.277081489562988,
      "learning_rate": 3.860252485006082e-05,
      "loss": 1.2201,
      "step": 11370
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.364853858947754,
      "learning_rate": 3.859203959233318e-05,
      "loss": 1.1642,
      "step": 11380
    },
    {
      "epoch": 0.71,
      "grad_norm": 11.412992477416992,
      "learning_rate": 3.8581554334605544e-05,
      "loss": 1.3689,
      "step": 11390
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.914818286895752,
      "learning_rate": 3.857106907687791e-05,
      "loss": 1.2738,
      "step": 11400
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.131455898284912,
      "learning_rate": 3.8560583819150274e-05,
      "loss": 1.199,
      "step": 11410
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.773273944854736,
      "learning_rate": 3.855009856142264e-05,
      "loss": 1.2752,
      "step": 11420
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.01894474029541,
      "learning_rate": 3.8539613303695005e-05,
      "loss": 1.2708,
      "step": 11430
    },
    {
      "epoch": 0.71,
      "grad_norm": 6.653820991516113,
      "learning_rate": 3.8529128045967374e-05,
      "loss": 1.201,
      "step": 11440
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.400414943695068,
      "learning_rate": 3.851864278823974e-05,
      "loss": 1.2224,
      "step": 11450
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.765809535980225,
      "learning_rate": 3.8508157530512104e-05,
      "loss": 1.0584,
      "step": 11460
    },
    {
      "epoch": 0.71,
      "grad_norm": 11.147821426391602,
      "learning_rate": 3.8497672272784466e-05,
      "loss": 1.257,
      "step": 11470
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.892952919006348,
      "learning_rate": 3.848718701505683e-05,
      "loss": 1.2664,
      "step": 11480
    },
    {
      "epoch": 0.72,
      "grad_norm": 7.168953895568848,
      "learning_rate": 3.84767017573292e-05,
      "loss": 1.1212,
      "step": 11490
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.569741725921631,
      "learning_rate": 3.846621649960156e-05,
      "loss": 1.1809,
      "step": 11500
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.203007698059082,
      "learning_rate": 3.845573124187393e-05,
      "loss": 1.1512,
      "step": 11510
    },
    {
      "epoch": 0.72,
      "grad_norm": 10.33597183227539,
      "learning_rate": 3.8445245984146296e-05,
      "loss": 1.2687,
      "step": 11520
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.382002830505371,
      "learning_rate": 3.843476072641866e-05,
      "loss": 1.1222,
      "step": 11530
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.665946960449219,
      "learning_rate": 3.842427546869103e-05,
      "loss": 1.16,
      "step": 11540
    },
    {
      "epoch": 0.72,
      "grad_norm": 11.268169403076172,
      "learning_rate": 3.841379021096338e-05,
      "loss": 1.2387,
      "step": 11550
    },
    {
      "epoch": 0.72,
      "grad_norm": 7.362945079803467,
      "learning_rate": 3.840330495323575e-05,
      "loss": 1.1586,
      "step": 11560
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.791496276855469,
      "learning_rate": 3.839281969550812e-05,
      "loss": 1.2386,
      "step": 11570
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.443615913391113,
      "learning_rate": 3.838233443778048e-05,
      "loss": 1.1585,
      "step": 11580
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.104905128479004,
      "learning_rate": 3.837184918005285e-05,
      "loss": 1.2016,
      "step": 11590
    },
    {
      "epoch": 0.72,
      "grad_norm": 7.898041248321533,
      "learning_rate": 3.836136392232521e-05,
      "loss": 1.2253,
      "step": 11600
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.2042107582092285,
      "learning_rate": 3.835087866459758e-05,
      "loss": 1.1494,
      "step": 11610
    },
    {
      "epoch": 0.72,
      "grad_norm": 9.52989673614502,
      "learning_rate": 3.834039340686994e-05,
      "loss": 1.2106,
      "step": 11620
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.511276245117188,
      "learning_rate": 3.8329908149142304e-05,
      "loss": 1.1675,
      "step": 11630
    },
    {
      "epoch": 0.72,
      "grad_norm": 10.182945251464844,
      "learning_rate": 3.831942289141467e-05,
      "loss": 1.4458,
      "step": 11640
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.893006801605225,
      "learning_rate": 3.8308937633687035e-05,
      "loss": 1.307,
      "step": 11650
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.414016246795654,
      "learning_rate": 3.8298452375959404e-05,
      "loss": 1.2887,
      "step": 11660
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.763182163238525,
      "learning_rate": 3.8287967118231766e-05,
      "loss": 1.2372,
      "step": 11670
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.25076675415039,
      "learning_rate": 3.8277481860504134e-05,
      "loss": 1.2394,
      "step": 11680
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.900445461273193,
      "learning_rate": 3.82669966027765e-05,
      "loss": 1.331,
      "step": 11690
    },
    {
      "epoch": 0.73,
      "grad_norm": 7.312790393829346,
      "learning_rate": 3.8256511345048865e-05,
      "loss": 1.1996,
      "step": 11700
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.907854080200195,
      "learning_rate": 3.824602608732123e-05,
      "loss": 1.184,
      "step": 11710
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.921719074249268,
      "learning_rate": 3.823554082959359e-05,
      "loss": 1.2744,
      "step": 11720
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.030117034912109,
      "learning_rate": 3.822505557186596e-05,
      "loss": 1.2185,
      "step": 11730
    },
    {
      "epoch": 0.73,
      "grad_norm": 7.547507286071777,
      "learning_rate": 3.8214570314138326e-05,
      "loss": 1.2651,
      "step": 11740
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.354312419891357,
      "learning_rate": 3.820408505641069e-05,
      "loss": 1.1925,
      "step": 11750
    },
    {
      "epoch": 0.73,
      "grad_norm": 7.194250106811523,
      "learning_rate": 3.819359979868306e-05,
      "loss": 1.3269,
      "step": 11760
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.84740686416626,
      "learning_rate": 3.818311454095542e-05,
      "loss": 1.2318,
      "step": 11770
    },
    {
      "epoch": 0.73,
      "grad_norm": 5.925888538360596,
      "learning_rate": 3.817262928322779e-05,
      "loss": 1.1819,
      "step": 11780
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.6477861404418945,
      "learning_rate": 3.816214402550015e-05,
      "loss": 1.2725,
      "step": 11790
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.497521877288818,
      "learning_rate": 3.815165876777251e-05,
      "loss": 1.1207,
      "step": 11800
    },
    {
      "epoch": 0.74,
      "grad_norm": 7.869458198547363,
      "learning_rate": 3.814117351004488e-05,
      "loss": 1.2587,
      "step": 11810
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.824814796447754,
      "learning_rate": 3.813068825231724e-05,
      "loss": 1.152,
      "step": 11820
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.902814865112305,
      "learning_rate": 3.812020299458961e-05,
      "loss": 1.0948,
      "step": 11830
    },
    {
      "epoch": 0.74,
      "grad_norm": 7.100574970245361,
      "learning_rate": 3.810971773686197e-05,
      "loss": 1.2662,
      "step": 11840
    },
    {
      "epoch": 0.74,
      "grad_norm": 9.040985107421875,
      "learning_rate": 3.809923247913434e-05,
      "loss": 1.1162,
      "step": 11850
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.059424877166748,
      "learning_rate": 3.808874722140671e-05,
      "loss": 1.1577,
      "step": 11860
    },
    {
      "epoch": 0.74,
      "grad_norm": 10.19552230834961,
      "learning_rate": 3.8078261963679065e-05,
      "loss": 1.2535,
      "step": 11870
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.006462097167969,
      "learning_rate": 3.8067776705951434e-05,
      "loss": 1.2863,
      "step": 11880
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.612601280212402,
      "learning_rate": 3.8057291448223796e-05,
      "loss": 1.2498,
      "step": 11890
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.098066329956055,
      "learning_rate": 3.8046806190496164e-05,
      "loss": 1.1529,
      "step": 11900
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.714346885681152,
      "learning_rate": 3.8036320932768526e-05,
      "loss": 1.244,
      "step": 11910
    },
    {
      "epoch": 0.74,
      "grad_norm": 8.049717903137207,
      "learning_rate": 3.8025835675040895e-05,
      "loss": 1.1828,
      "step": 11920
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.980234622955322,
      "learning_rate": 3.8015350417313264e-05,
      "loss": 1.1205,
      "step": 11930
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.5818352699279785,
      "learning_rate": 3.8004865159585626e-05,
      "loss": 1.3676,
      "step": 11940
    },
    {
      "epoch": 0.74,
      "grad_norm": 7.122072219848633,
      "learning_rate": 3.799437990185799e-05,
      "loss": 1.2729,
      "step": 11950
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.942152976989746,
      "learning_rate": 3.798389464413035e-05,
      "loss": 1.2486,
      "step": 11960
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.977005481719971,
      "learning_rate": 3.797340938640272e-05,
      "loss": 1.2225,
      "step": 11970
    },
    {
      "epoch": 0.75,
      "grad_norm": 8.398838996887207,
      "learning_rate": 3.796292412867509e-05,
      "loss": 1.1733,
      "step": 11980
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.809576988220215,
      "learning_rate": 3.795243887094745e-05,
      "loss": 1.1151,
      "step": 11990
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.386726379394531,
      "learning_rate": 3.794195361321982e-05,
      "loss": 1.3196,
      "step": 12000
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.280423164367676,
      "learning_rate": 3.793146835549218e-05,
      "loss": 1.2183,
      "step": 12010
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.555665493011475,
      "learning_rate": 3.792098309776455e-05,
      "loss": 1.3852,
      "step": 12020
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.163621425628662,
      "learning_rate": 3.791049784003691e-05,
      "loss": 1.2037,
      "step": 12030
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.665976047515869,
      "learning_rate": 3.790001258230927e-05,
      "loss": 1.2414,
      "step": 12040
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.23773193359375,
      "learning_rate": 3.788952732458164e-05,
      "loss": 1.2049,
      "step": 12050
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.880600929260254,
      "learning_rate": 3.7879042066854e-05,
      "loss": 1.2376,
      "step": 12060
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.733328342437744,
      "learning_rate": 3.786855680912637e-05,
      "loss": 1.309,
      "step": 12070
    },
    {
      "epoch": 0.75,
      "grad_norm": 9.854850769042969,
      "learning_rate": 3.785807155139873e-05,
      "loss": 1.2995,
      "step": 12080
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.832361698150635,
      "learning_rate": 3.78475862936711e-05,
      "loss": 1.2332,
      "step": 12090
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.250936031341553,
      "learning_rate": 3.783710103594347e-05,
      "loss": 1.2329,
      "step": 12100
    },
    {
      "epoch": 0.75,
      "grad_norm": 8.389954566955566,
      "learning_rate": 3.782661577821583e-05,
      "loss": 1.2711,
      "step": 12110
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.373176574707031,
      "learning_rate": 3.7816130520488194e-05,
      "loss": 1.3652,
      "step": 12120
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.77280330657959,
      "learning_rate": 3.7805645262760556e-05,
      "loss": 1.1792,
      "step": 12130
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.43203067779541,
      "learning_rate": 3.7795160005032925e-05,
      "loss": 1.2649,
      "step": 12140
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.714259147644043,
      "learning_rate": 3.7784674747305294e-05,
      "loss": 1.2907,
      "step": 12150
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.611886978149414,
      "learning_rate": 3.7774189489577656e-05,
      "loss": 1.2019,
      "step": 12160
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.626004695892334,
      "learning_rate": 3.7763704231850024e-05,
      "loss": 1.1508,
      "step": 12170
    },
    {
      "epoch": 0.76,
      "grad_norm": 7.591307163238525,
      "learning_rate": 3.7753218974122386e-05,
      "loss": 1.2144,
      "step": 12180
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.166524410247803,
      "learning_rate": 3.774273371639475e-05,
      "loss": 1.2213,
      "step": 12190
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.759570121765137,
      "learning_rate": 3.773224845866711e-05,
      "loss": 1.0584,
      "step": 12200
    },
    {
      "epoch": 0.76,
      "grad_norm": 7.369185447692871,
      "learning_rate": 3.772176320093948e-05,
      "loss": 1.1613,
      "step": 12210
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.820440292358398,
      "learning_rate": 3.771127794321185e-05,
      "loss": 1.0905,
      "step": 12220
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.053057670593262,
      "learning_rate": 3.770079268548421e-05,
      "loss": 1.1968,
      "step": 12230
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.783081531524658,
      "learning_rate": 3.769030742775658e-05,
      "loss": 1.2364,
      "step": 12240
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.175708770751953,
      "learning_rate": 3.767982217002894e-05,
      "loss": 1.2043,
      "step": 12250
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.396054267883301,
      "learning_rate": 3.766933691230131e-05,
      "loss": 1.0941,
      "step": 12260
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.800412654876709,
      "learning_rate": 3.765885165457367e-05,
      "loss": 1.1759,
      "step": 12270
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.382279396057129,
      "learning_rate": 3.764836639684603e-05,
      "loss": 1.2259,
      "step": 12280
    },
    {
      "epoch": 0.77,
      "grad_norm": 7.9697442054748535,
      "learning_rate": 3.76378811391184e-05,
      "loss": 1.2637,
      "step": 12290
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.164172649383545,
      "learning_rate": 3.762739588139076e-05,
      "loss": 1.1604,
      "step": 12300
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.914102554321289,
      "learning_rate": 3.761691062366313e-05,
      "loss": 1.2847,
      "step": 12310
    },
    {
      "epoch": 0.77,
      "grad_norm": 7.231095790863037,
      "learning_rate": 3.76064253659355e-05,
      "loss": 1.2417,
      "step": 12320
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.529478549957275,
      "learning_rate": 3.759594010820786e-05,
      "loss": 1.2271,
      "step": 12330
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.981958866119385,
      "learning_rate": 3.758545485048023e-05,
      "loss": 1.2452,
      "step": 12340
    },
    {
      "epoch": 0.77,
      "grad_norm": 7.046581745147705,
      "learning_rate": 3.757496959275259e-05,
      "loss": 1.1352,
      "step": 12350
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.399695873260498,
      "learning_rate": 3.7564484335024955e-05,
      "loss": 1.2291,
      "step": 12360
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.190853118896484,
      "learning_rate": 3.755399907729732e-05,
      "loss": 1.23,
      "step": 12370
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.410244941711426,
      "learning_rate": 3.7543513819569686e-05,
      "loss": 1.2953,
      "step": 12380
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.902554988861084,
      "learning_rate": 3.7533028561842054e-05,
      "loss": 1.2262,
      "step": 12390
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.860834121704102,
      "learning_rate": 3.7522543304114416e-05,
      "loss": 1.2094,
      "step": 12400
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.999259948730469,
      "learning_rate": 3.7512058046386785e-05,
      "loss": 1.1454,
      "step": 12410
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.326605796813965,
      "learning_rate": 3.750157278865915e-05,
      "loss": 1.2222,
      "step": 12420
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.228029251098633,
      "learning_rate": 3.7491087530931516e-05,
      "loss": 1.1942,
      "step": 12430
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.982431411743164,
      "learning_rate": 3.748060227320388e-05,
      "loss": 1.1687,
      "step": 12440
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.354591369628906,
      "learning_rate": 3.747011701547624e-05,
      "loss": 1.1915,
      "step": 12450
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.554742813110352,
      "learning_rate": 3.745963175774861e-05,
      "loss": 1.2921,
      "step": 12460
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.734926700592041,
      "learning_rate": 3.744914650002097e-05,
      "loss": 1.179,
      "step": 12470
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.811237335205078,
      "learning_rate": 3.743866124229334e-05,
      "loss": 1.2849,
      "step": 12480
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.40980339050293,
      "learning_rate": 3.74281759845657e-05,
      "loss": 1.1906,
      "step": 12490
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.486739635467529,
      "learning_rate": 3.741769072683807e-05,
      "loss": 1.1051,
      "step": 12500
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.3058648109436035,
      "learning_rate": 3.740720546911043e-05,
      "loss": 1.1685,
      "step": 12510
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.80418586730957,
      "learning_rate": 3.739672021138279e-05,
      "loss": 1.2453,
      "step": 12520
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.509804725646973,
      "learning_rate": 3.738623495365516e-05,
      "loss": 1.0896,
      "step": 12530
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.951535224914551,
      "learning_rate": 3.7375749695927524e-05,
      "loss": 1.1392,
      "step": 12540
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.959402561187744,
      "learning_rate": 3.736526443819989e-05,
      "loss": 1.1458,
      "step": 12550
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.678692817687988,
      "learning_rate": 3.735477918047226e-05,
      "loss": 1.3256,
      "step": 12560
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.567325115203857,
      "learning_rate": 3.734429392274462e-05,
      "loss": 1.2245,
      "step": 12570
    },
    {
      "epoch": 0.78,
      "grad_norm": 7.682524681091309,
      "learning_rate": 3.733380866501699e-05,
      "loss": 1.2503,
      "step": 12580
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.132293224334717,
      "learning_rate": 3.7323323407289354e-05,
      "loss": 1.1955,
      "step": 12590
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.780538558959961,
      "learning_rate": 3.7312838149561716e-05,
      "loss": 1.2095,
      "step": 12600
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.314235687255859,
      "learning_rate": 3.730235289183408e-05,
      "loss": 1.1204,
      "step": 12610
    },
    {
      "epoch": 0.79,
      "grad_norm": 7.97739839553833,
      "learning_rate": 3.7291867634106446e-05,
      "loss": 1.229,
      "step": 12620
    },
    {
      "epoch": 0.79,
      "grad_norm": 7.2712082862854,
      "learning_rate": 3.7281382376378815e-05,
      "loss": 1.0982,
      "step": 12630
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.527453422546387,
      "learning_rate": 3.727089711865118e-05,
      "loss": 1.2921,
      "step": 12640
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.215119361877441,
      "learning_rate": 3.7260411860923546e-05,
      "loss": 1.2376,
      "step": 12650
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.515829563140869,
      "learning_rate": 3.724992660319591e-05,
      "loss": 1.22,
      "step": 12660
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.970255374908447,
      "learning_rate": 3.7239441345468276e-05,
      "loss": 1.2284,
      "step": 12670
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.049549102783203,
      "learning_rate": 3.722895608774064e-05,
      "loss": 1.2253,
      "step": 12680
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.258280277252197,
      "learning_rate": 3.7218470830013e-05,
      "loss": 1.275,
      "step": 12690
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.604413986206055,
      "learning_rate": 3.720798557228537e-05,
      "loss": 1.1986,
      "step": 12700
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.662376403808594,
      "learning_rate": 3.719750031455773e-05,
      "loss": 1.2465,
      "step": 12710
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.5406084060668945,
      "learning_rate": 3.71870150568301e-05,
      "loss": 1.2576,
      "step": 12720
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.916417598724365,
      "learning_rate": 3.717652979910247e-05,
      "loss": 1.1952,
      "step": 12730
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.797162055969238,
      "learning_rate": 3.716604454137483e-05,
      "loss": 1.2059,
      "step": 12740
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.971907138824463,
      "learning_rate": 3.71555592836472e-05,
      "loss": 1.2169,
      "step": 12750
    },
    {
      "epoch": 0.79,
      "grad_norm": 11.605907440185547,
      "learning_rate": 3.714507402591956e-05,
      "loss": 1.2863,
      "step": 12760
    },
    {
      "epoch": 0.8,
      "grad_norm": 11.938848495483398,
      "learning_rate": 3.713458876819192e-05,
      "loss": 1.2517,
      "step": 12770
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.404280662536621,
      "learning_rate": 3.7124103510464284e-05,
      "loss": 0.9999,
      "step": 12780
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.640260219573975,
      "learning_rate": 3.711361825273665e-05,
      "loss": 1.2964,
      "step": 12790
    },
    {
      "epoch": 0.8,
      "grad_norm": 6.117669582366943,
      "learning_rate": 3.710313299500902e-05,
      "loss": 1.3653,
      "step": 12800
    },
    {
      "epoch": 0.8,
      "grad_norm": 6.632314205169678,
      "learning_rate": 3.7092647737281384e-05,
      "loss": 1.2943,
      "step": 12810
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.187979698181152,
      "learning_rate": 3.708216247955375e-05,
      "loss": 1.2117,
      "step": 12820
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.792582988739014,
      "learning_rate": 3.7071677221826114e-05,
      "loss": 1.0667,
      "step": 12830
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.210463523864746,
      "learning_rate": 3.7061191964098476e-05,
      "loss": 1.0894,
      "step": 12840
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.678984642028809,
      "learning_rate": 3.7050706706370845e-05,
      "loss": 1.1602,
      "step": 12850
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.199769496917725,
      "learning_rate": 3.704022144864321e-05,
      "loss": 1.3217,
      "step": 12860
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.3705668449401855,
      "learning_rate": 3.7029736190915576e-05,
      "loss": 1.1527,
      "step": 12870
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.935514450073242,
      "learning_rate": 3.701925093318794e-05,
      "loss": 1.1866,
      "step": 12880
    },
    {
      "epoch": 0.8,
      "grad_norm": 6.621828079223633,
      "learning_rate": 3.7008765675460306e-05,
      "loss": 1.1647,
      "step": 12890
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.815356254577637,
      "learning_rate": 3.699828041773267e-05,
      "loss": 1.2201,
      "step": 12900
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.200817108154297,
      "learning_rate": 3.698779516000504e-05,
      "loss": 1.2941,
      "step": 12910
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.137331008911133,
      "learning_rate": 3.69773099022774e-05,
      "loss": 1.2039,
      "step": 12920
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.746501922607422,
      "learning_rate": 3.696682464454976e-05,
      "loss": 1.3239,
      "step": 12930
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.638944625854492,
      "learning_rate": 3.695633938682213e-05,
      "loss": 1.2896,
      "step": 12940
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.4967339038848877,
      "learning_rate": 3.694585412909449e-05,
      "loss": 1.2109,
      "step": 12950
    },
    {
      "epoch": 0.81,
      "grad_norm": 7.353958606719971,
      "learning_rate": 3.693536887136686e-05,
      "loss": 1.1602,
      "step": 12960
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.521396160125732,
      "learning_rate": 3.692488361363923e-05,
      "loss": 1.1551,
      "step": 12970
    },
    {
      "epoch": 0.81,
      "grad_norm": 7.557132244110107,
      "learning_rate": 3.691439835591159e-05,
      "loss": 1.1896,
      "step": 12980
    },
    {
      "epoch": 0.81,
      "grad_norm": 7.4745941162109375,
      "learning_rate": 3.690391309818396e-05,
      "loss": 1.1938,
      "step": 12990
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.908163547515869,
      "learning_rate": 3.689342784045632e-05,
      "loss": 1.1221,
      "step": 13000
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.64525032043457,
      "learning_rate": 3.688294258272868e-05,
      "loss": 1.1491,
      "step": 13010
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.595352172851562,
      "learning_rate": 3.687245732500105e-05,
      "loss": 1.2466,
      "step": 13020
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.729598045349121,
      "learning_rate": 3.6861972067273414e-05,
      "loss": 1.1973,
      "step": 13030
    },
    {
      "epoch": 0.81,
      "grad_norm": 7.168338775634766,
      "learning_rate": 3.685148680954578e-05,
      "loss": 1.3605,
      "step": 13040
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.198069095611572,
      "learning_rate": 3.6841001551818144e-05,
      "loss": 1.2305,
      "step": 13050
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.514075756072998,
      "learning_rate": 3.683051629409051e-05,
      "loss": 1.1634,
      "step": 13060
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.60239315032959,
      "learning_rate": 3.6820031036362875e-05,
      "loss": 1.2894,
      "step": 13070
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.298709392547607,
      "learning_rate": 3.6809545778635244e-05,
      "loss": 1.0378,
      "step": 13080
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.831862449645996,
      "learning_rate": 3.6799060520907606e-05,
      "loss": 1.207,
      "step": 13090
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.217358112335205,
      "learning_rate": 3.678857526317997e-05,
      "loss": 1.1733,
      "step": 13100
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.128124237060547,
      "learning_rate": 3.6778090005452336e-05,
      "loss": 1.2648,
      "step": 13110
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.117301940917969,
      "learning_rate": 3.67676047477247e-05,
      "loss": 1.2798,
      "step": 13120
    },
    {
      "epoch": 0.82,
      "grad_norm": 10.602744102478027,
      "learning_rate": 3.675711948999707e-05,
      "loss": 1.1797,
      "step": 13130
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.002469062805176,
      "learning_rate": 3.6746634232269436e-05,
      "loss": 1.3296,
      "step": 13140
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.260281562805176,
      "learning_rate": 3.67361489745418e-05,
      "loss": 1.215,
      "step": 13150
    },
    {
      "epoch": 0.82,
      "grad_norm": 9.476567268371582,
      "learning_rate": 3.672566371681416e-05,
      "loss": 1.1865,
      "step": 13160
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.474278450012207,
      "learning_rate": 3.671517845908652e-05,
      "loss": 1.257,
      "step": 13170
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.1554365158081055,
      "learning_rate": 3.670469320135889e-05,
      "loss": 1.2112,
      "step": 13180
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.599531173706055,
      "learning_rate": 3.669420794363125e-05,
      "loss": 1.1883,
      "step": 13190
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.645124435424805,
      "learning_rate": 3.668372268590362e-05,
      "loss": 1.112,
      "step": 13200
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.321415901184082,
      "learning_rate": 3.667323742817599e-05,
      "loss": 1.3345,
      "step": 13210
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.843386173248291,
      "learning_rate": 3.666275217044835e-05,
      "loss": 1.3138,
      "step": 13220
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.994235992431641,
      "learning_rate": 3.665226691272072e-05,
      "loss": 1.1617,
      "step": 13230
    },
    {
      "epoch": 0.82,
      "grad_norm": 8.165733337402344,
      "learning_rate": 3.664178165499308e-05,
      "loss": 1.1706,
      "step": 13240
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.01142692565918,
      "learning_rate": 3.6631296397265444e-05,
      "loss": 1.1222,
      "step": 13250
    },
    {
      "epoch": 0.83,
      "grad_norm": 5.144011497497559,
      "learning_rate": 3.662081113953781e-05,
      "loss": 1.0645,
      "step": 13260
    },
    {
      "epoch": 0.83,
      "grad_norm": 6.875010013580322,
      "learning_rate": 3.6610325881810174e-05,
      "loss": 1.3152,
      "step": 13270
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.932580947875977,
      "learning_rate": 3.659984062408254e-05,
      "loss": 1.3697,
      "step": 13280
    },
    {
      "epoch": 0.83,
      "grad_norm": 5.999797344207764,
      "learning_rate": 3.6589355366354905e-05,
      "loss": 1.2564,
      "step": 13290
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.056081295013428,
      "learning_rate": 3.6578870108627274e-05,
      "loss": 1.1509,
      "step": 13300
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.298516273498535,
      "learning_rate": 3.656838485089964e-05,
      "loss": 1.2268,
      "step": 13310
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.31196117401123,
      "learning_rate": 3.6557899593172004e-05,
      "loss": 1.1863,
      "step": 13320
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.449881553649902,
      "learning_rate": 3.6547414335444366e-05,
      "loss": 1.359,
      "step": 13330
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.447546005249023,
      "learning_rate": 3.653692907771673e-05,
      "loss": 1.2351,
      "step": 13340
    },
    {
      "epoch": 0.83,
      "grad_norm": 6.2639312744140625,
      "learning_rate": 3.65264438199891e-05,
      "loss": 1.2112,
      "step": 13350
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.554360389709473,
      "learning_rate": 3.651595856226146e-05,
      "loss": 1.2825,
      "step": 13360
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.31447982788086,
      "learning_rate": 3.650547330453383e-05,
      "loss": 1.2067,
      "step": 13370
    },
    {
      "epoch": 0.83,
      "grad_norm": 10.038509368896484,
      "learning_rate": 3.6494988046806196e-05,
      "loss": 1.26,
      "step": 13380
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.756375312805176,
      "learning_rate": 3.648450278907856e-05,
      "loss": 1.2491,
      "step": 13390
    },
    {
      "epoch": 0.83,
      "grad_norm": 7.5017852783203125,
      "learning_rate": 3.647401753135093e-05,
      "loss": 1.2177,
      "step": 13400
    },
    {
      "epoch": 0.83,
      "grad_norm": 5.723767280578613,
      "learning_rate": 3.646353227362328e-05,
      "loss": 1.2184,
      "step": 13410
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.785774230957031,
      "learning_rate": 3.645304701589565e-05,
      "loss": 1.1165,
      "step": 13420
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.380936622619629,
      "learning_rate": 3.644256175816802e-05,
      "loss": 1.1704,
      "step": 13430
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.105066299438477,
      "learning_rate": 3.643207650044038e-05,
      "loss": 1.2814,
      "step": 13440
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.175697326660156,
      "learning_rate": 3.642159124271275e-05,
      "loss": 1.2032,
      "step": 13450
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.00003719329834,
      "learning_rate": 3.641110598498511e-05,
      "loss": 1.2627,
      "step": 13460
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.190874099731445,
      "learning_rate": 3.640062072725748e-05,
      "loss": 1.136,
      "step": 13470
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.254480838775635,
      "learning_rate": 3.639013546952984e-05,
      "loss": 1.1047,
      "step": 13480
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.6204094886779785,
      "learning_rate": 3.6379650211802204e-05,
      "loss": 1.1674,
      "step": 13490
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.370838642120361,
      "learning_rate": 3.636916495407457e-05,
      "loss": 1.264,
      "step": 13500
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.725723266601562,
      "learning_rate": 3.6358679696346935e-05,
      "loss": 1.2024,
      "step": 13510
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.496249198913574,
      "learning_rate": 3.6348194438619304e-05,
      "loss": 1.1703,
      "step": 13520
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.560890197753906,
      "learning_rate": 3.6337709180891666e-05,
      "loss": 1.1223,
      "step": 13530
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.646495819091797,
      "learning_rate": 3.6327223923164034e-05,
      "loss": 1.2004,
      "step": 13540
    },
    {
      "epoch": 0.84,
      "grad_norm": 9.888511657714844,
      "learning_rate": 3.63167386654364e-05,
      "loss": 1.3011,
      "step": 13550
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.881038188934326,
      "learning_rate": 3.6306253407708765e-05,
      "loss": 1.2098,
      "step": 13560
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.14039945602417,
      "learning_rate": 3.629576814998113e-05,
      "loss": 1.2547,
      "step": 13570
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.285548686981201,
      "learning_rate": 3.628528289225349e-05,
      "loss": 1.1199,
      "step": 13580
    },
    {
      "epoch": 0.85,
      "grad_norm": 9.83082103729248,
      "learning_rate": 3.627479763452586e-05,
      "loss": 1.2533,
      "step": 13590
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.213178634643555,
      "learning_rate": 3.626431237679822e-05,
      "loss": 1.2501,
      "step": 13600
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.982595682144165,
      "learning_rate": 3.625382711907059e-05,
      "loss": 1.1189,
      "step": 13610
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.625151634216309,
      "learning_rate": 3.624334186134296e-05,
      "loss": 1.0966,
      "step": 13620
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.908088684082031,
      "learning_rate": 3.623285660361532e-05,
      "loss": 1.2771,
      "step": 13630
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.581604957580566,
      "learning_rate": 3.622237134588769e-05,
      "loss": 1.2782,
      "step": 13640
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.122424602508545,
      "learning_rate": 3.621188608816005e-05,
      "loss": 1.0748,
      "step": 13650
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.522891521453857,
      "learning_rate": 3.620140083043241e-05,
      "loss": 1.2041,
      "step": 13660
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.599699974060059,
      "learning_rate": 3.619091557270478e-05,
      "loss": 1.2103,
      "step": 13670
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.3465895652771,
      "learning_rate": 3.618043031497714e-05,
      "loss": 1.1046,
      "step": 13680
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.536592960357666,
      "learning_rate": 3.616994505724951e-05,
      "loss": 1.0771,
      "step": 13690
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.714148998260498,
      "learning_rate": 3.615945979952187e-05,
      "loss": 1.3568,
      "step": 13700
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.143260478973389,
      "learning_rate": 3.614897454179424e-05,
      "loss": 1.2515,
      "step": 13710
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.818492889404297,
      "learning_rate": 3.613848928406661e-05,
      "loss": 1.2713,
      "step": 13720
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.498969554901123,
      "learning_rate": 3.6128004026338965e-05,
      "loss": 1.2,
      "step": 13730
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.2384161949157715,
      "learning_rate": 3.6117518768611334e-05,
      "loss": 1.2127,
      "step": 13740
    },
    {
      "epoch": 0.86,
      "grad_norm": 6.128571510314941,
      "learning_rate": 3.6107033510883696e-05,
      "loss": 1.3003,
      "step": 13750
    },
    {
      "epoch": 0.86,
      "grad_norm": 11.45952320098877,
      "learning_rate": 3.6096548253156064e-05,
      "loss": 1.1527,
      "step": 13760
    },
    {
      "epoch": 0.86,
      "grad_norm": 10.22456169128418,
      "learning_rate": 3.6086062995428426e-05,
      "loss": 1.2031,
      "step": 13770
    },
    {
      "epoch": 0.86,
      "grad_norm": 6.8082733154296875,
      "learning_rate": 3.6075577737700795e-05,
      "loss": 1.2091,
      "step": 13780
    },
    {
      "epoch": 0.86,
      "grad_norm": 9.19279670715332,
      "learning_rate": 3.6065092479973164e-05,
      "loss": 1.2834,
      "step": 13790
    },
    {
      "epoch": 0.86,
      "grad_norm": 7.116140365600586,
      "learning_rate": 3.6054607222245526e-05,
      "loss": 1.2835,
      "step": 13800
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.9117231369018555,
      "learning_rate": 3.604412196451789e-05,
      "loss": 1.1874,
      "step": 13810
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.3965349197387695,
      "learning_rate": 3.603363670679025e-05,
      "loss": 1.2627,
      "step": 13820
    },
    {
      "epoch": 0.86,
      "grad_norm": 7.968774318695068,
      "learning_rate": 3.602315144906262e-05,
      "loss": 1.1706,
      "step": 13830
    },
    {
      "epoch": 0.86,
      "grad_norm": 7.547743797302246,
      "learning_rate": 3.601266619133499e-05,
      "loss": 1.2275,
      "step": 13840
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.849809169769287,
      "learning_rate": 3.600218093360735e-05,
      "loss": 1.1853,
      "step": 13850
    },
    {
      "epoch": 0.86,
      "grad_norm": 10.238068580627441,
      "learning_rate": 3.599169567587972e-05,
      "loss": 1.1278,
      "step": 13860
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.728204727172852,
      "learning_rate": 3.598121041815208e-05,
      "loss": 1.3136,
      "step": 13870
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.567470550537109,
      "learning_rate": 3.597072516042445e-05,
      "loss": 1.0807,
      "step": 13880
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.339237689971924,
      "learning_rate": 3.596023990269681e-05,
      "loss": 1.2137,
      "step": 13890
    },
    {
      "epoch": 0.87,
      "grad_norm": 9.05423355102539,
      "learning_rate": 3.594975464496917e-05,
      "loss": 1.1629,
      "step": 13900
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.998348712921143,
      "learning_rate": 3.593926938724154e-05,
      "loss": 1.1867,
      "step": 13910
    },
    {
      "epoch": 0.87,
      "grad_norm": 6.8360748291015625,
      "learning_rate": 3.59287841295139e-05,
      "loss": 1.2129,
      "step": 13920
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.115180969238281,
      "learning_rate": 3.591829887178627e-05,
      "loss": 1.1624,
      "step": 13930
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.2694597244262695,
      "learning_rate": 3.590781361405863e-05,
      "loss": 1.1347,
      "step": 13940
    },
    {
      "epoch": 0.87,
      "grad_norm": 6.152957439422607,
      "learning_rate": 3.5897328356331e-05,
      "loss": 1.2799,
      "step": 13950
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.205924987792969,
      "learning_rate": 3.588684309860337e-05,
      "loss": 1.161,
      "step": 13960
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.908827781677246,
      "learning_rate": 3.587635784087573e-05,
      "loss": 1.1007,
      "step": 13970
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.712251663208008,
      "learning_rate": 3.5865872583148095e-05,
      "loss": 1.2625,
      "step": 13980
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.620097637176514,
      "learning_rate": 3.5855387325420456e-05,
      "loss": 1.2695,
      "step": 13990
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.3849449157714844,
      "learning_rate": 3.5844902067692825e-05,
      "loss": 1.2174,
      "step": 14000
    },
    {
      "epoch": 0.87,
      "grad_norm": 6.642581939697266,
      "learning_rate": 3.5834416809965194e-05,
      "loss": 1.3222,
      "step": 14010
    },
    {
      "epoch": 0.87,
      "grad_norm": 8.075063705444336,
      "learning_rate": 3.5823931552237556e-05,
      "loss": 1.1095,
      "step": 14020
    },
    {
      "epoch": 0.87,
      "grad_norm": 9.334060668945312,
      "learning_rate": 3.5813446294509924e-05,
      "loss": 1.1069,
      "step": 14030
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.82154655456543,
      "learning_rate": 3.5802961036782286e-05,
      "loss": 1.1971,
      "step": 14040
    },
    {
      "epoch": 0.87,
      "grad_norm": 6.564092636108398,
      "learning_rate": 3.579247577905465e-05,
      "loss": 1.0842,
      "step": 14050
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.441165447235107,
      "learning_rate": 3.578199052132701e-05,
      "loss": 1.3449,
      "step": 14060
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.615884304046631,
      "learning_rate": 3.577150526359938e-05,
      "loss": 1.0924,
      "step": 14070
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.21668529510498,
      "learning_rate": 3.576102000587175e-05,
      "loss": 1.1161,
      "step": 14080
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.756313800811768,
      "learning_rate": 3.575053474814411e-05,
      "loss": 1.2803,
      "step": 14090
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.808201789855957,
      "learning_rate": 3.574004949041648e-05,
      "loss": 1.1902,
      "step": 14100
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.663960933685303,
      "learning_rate": 3.572956423268884e-05,
      "loss": 1.2623,
      "step": 14110
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.160257816314697,
      "learning_rate": 3.571907897496121e-05,
      "loss": 1.186,
      "step": 14120
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.808865070343018,
      "learning_rate": 3.570859371723357e-05,
      "loss": 1.252,
      "step": 14130
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.9063520431518555,
      "learning_rate": 3.569810845950593e-05,
      "loss": 1.2098,
      "step": 14140
    },
    {
      "epoch": 0.88,
      "grad_norm": 9.80055046081543,
      "learning_rate": 3.56876232017783e-05,
      "loss": 1.1832,
      "step": 14150
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.80525016784668,
      "learning_rate": 3.567713794405066e-05,
      "loss": 1.1492,
      "step": 14160
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.334286689758301,
      "learning_rate": 3.566665268632303e-05,
      "loss": 1.1952,
      "step": 14170
    },
    {
      "epoch": 0.88,
      "grad_norm": 10.828243255615234,
      "learning_rate": 3.5656167428595394e-05,
      "loss": 1.1552,
      "step": 14180
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.700626373291016,
      "learning_rate": 3.564568217086776e-05,
      "loss": 1.1964,
      "step": 14190
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.3401103019714355,
      "learning_rate": 3.563519691314013e-05,
      "loss": 1.2034,
      "step": 14200
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.285804748535156,
      "learning_rate": 3.562471165541249e-05,
      "loss": 1.2079,
      "step": 14210
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.261348724365234,
      "learning_rate": 3.5614226397684855e-05,
      "loss": 1.0878,
      "step": 14220
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.652991771697998,
      "learning_rate": 3.560374113995722e-05,
      "loss": 1.1792,
      "step": 14230
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.704028606414795,
      "learning_rate": 3.5593255882229586e-05,
      "loss": 1.1825,
      "step": 14240
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.908239364624023,
      "learning_rate": 3.5582770624501954e-05,
      "loss": 1.308,
      "step": 14250
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.534590244293213,
      "learning_rate": 3.5572285366774316e-05,
      "loss": 1.2208,
      "step": 14260
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.767207622528076,
      "learning_rate": 3.5561800109046685e-05,
      "loss": 1.0766,
      "step": 14270
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.864370822906494,
      "learning_rate": 3.555131485131905e-05,
      "loss": 1.09,
      "step": 14280
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.457365989685059,
      "learning_rate": 3.5540829593591416e-05,
      "loss": 1.1341,
      "step": 14290
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.704491138458252,
      "learning_rate": 3.553034433586378e-05,
      "loss": 1.0825,
      "step": 14300
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.273233413696289,
      "learning_rate": 3.551985907813614e-05,
      "loss": 1.1926,
      "step": 14310
    },
    {
      "epoch": 0.89,
      "grad_norm": 10.430269241333008,
      "learning_rate": 3.550937382040851e-05,
      "loss": 1.1222,
      "step": 14320
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.528746128082275,
      "learning_rate": 3.549888856268087e-05,
      "loss": 1.1181,
      "step": 14330
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.983343124389648,
      "learning_rate": 3.548840330495324e-05,
      "loss": 1.2746,
      "step": 14340
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.138426780700684,
      "learning_rate": 3.54779180472256e-05,
      "loss": 1.1207,
      "step": 14350
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.253283977508545,
      "learning_rate": 3.546743278949797e-05,
      "loss": 1.0404,
      "step": 14360
    },
    {
      "epoch": 0.89,
      "grad_norm": 11.29161548614502,
      "learning_rate": 3.545694753177033e-05,
      "loss": 1.1041,
      "step": 14370
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.792520999908447,
      "learning_rate": 3.544646227404269e-05,
      "loss": 1.163,
      "step": 14380
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.268386840820312,
      "learning_rate": 3.543597701631506e-05,
      "loss": 1.261,
      "step": 14390
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.964437484741211,
      "learning_rate": 3.5425491758587424e-05,
      "loss": 1.2769,
      "step": 14400
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.918702125549316,
      "learning_rate": 3.541500650085979e-05,
      "loss": 1.2229,
      "step": 14410
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.812651634216309,
      "learning_rate": 3.540452124313216e-05,
      "loss": 1.1761,
      "step": 14420
    },
    {
      "epoch": 0.9,
      "grad_norm": 11.161182403564453,
      "learning_rate": 3.539403598540452e-05,
      "loss": 1.3008,
      "step": 14430
    },
    {
      "epoch": 0.9,
      "grad_norm": 10.755060195922852,
      "learning_rate": 3.538355072767689e-05,
      "loss": 1.4045,
      "step": 14440
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.599088191986084,
      "learning_rate": 3.5373065469949254e-05,
      "loss": 1.0989,
      "step": 14450
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.020363807678223,
      "learning_rate": 3.5362580212221616e-05,
      "loss": 1.2072,
      "step": 14460
    },
    {
      "epoch": 0.9,
      "grad_norm": 5.018000602722168,
      "learning_rate": 3.535209495449398e-05,
      "loss": 1.2043,
      "step": 14470
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.276115894317627,
      "learning_rate": 3.5341609696766346e-05,
      "loss": 1.2273,
      "step": 14480
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.427033424377441,
      "learning_rate": 3.5331124439038715e-05,
      "loss": 1.2577,
      "step": 14490
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.5774712562561035,
      "learning_rate": 3.532063918131108e-05,
      "loss": 1.1311,
      "step": 14500
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.023862838745117,
      "learning_rate": 3.5310153923583446e-05,
      "loss": 1.2572,
      "step": 14510
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.828904151916504,
      "learning_rate": 3.529966866585581e-05,
      "loss": 1.3042,
      "step": 14520
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.466042518615723,
      "learning_rate": 3.5289183408128176e-05,
      "loss": 1.0671,
      "step": 14530
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.614252090454102,
      "learning_rate": 3.527869815040054e-05,
      "loss": 1.1229,
      "step": 14540
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.779110431671143,
      "learning_rate": 3.52682128926729e-05,
      "loss": 1.2069,
      "step": 14550
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.1983137130737305,
      "learning_rate": 3.525772763494527e-05,
      "loss": 1.1951,
      "step": 14560
    },
    {
      "epoch": 0.91,
      "grad_norm": 10.414155960083008,
      "learning_rate": 3.524724237721763e-05,
      "loss": 1.1901,
      "step": 14570
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.041927814483643,
      "learning_rate": 3.523675711949e-05,
      "loss": 1.1296,
      "step": 14580
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.611238479614258,
      "learning_rate": 3.522627186176236e-05,
      "loss": 1.1436,
      "step": 14590
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.825335502624512,
      "learning_rate": 3.521578660403473e-05,
      "loss": 1.2337,
      "step": 14600
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.570518970489502,
      "learning_rate": 3.52053013463071e-05,
      "loss": 1.2828,
      "step": 14610
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.555035591125488,
      "learning_rate": 3.519481608857946e-05,
      "loss": 1.2059,
      "step": 14620
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.40723180770874,
      "learning_rate": 3.518433083085182e-05,
      "loss": 1.1863,
      "step": 14630
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.114649772644043,
      "learning_rate": 3.5173845573124185e-05,
      "loss": 1.2058,
      "step": 14640
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.6348772048950195,
      "learning_rate": 3.516336031539655e-05,
      "loss": 1.155,
      "step": 14650
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.666322708129883,
      "learning_rate": 3.515287505766892e-05,
      "loss": 1.1394,
      "step": 14660
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.702744483947754,
      "learning_rate": 3.5142389799941284e-05,
      "loss": 1.108,
      "step": 14670
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.134222507476807,
      "learning_rate": 3.513190454221365e-05,
      "loss": 1.1472,
      "step": 14680
    },
    {
      "epoch": 0.91,
      "grad_norm": 8.420159339904785,
      "learning_rate": 3.5121419284486015e-05,
      "loss": 1.1787,
      "step": 14690
    },
    {
      "epoch": 0.92,
      "grad_norm": 10.830496788024902,
      "learning_rate": 3.5110934026758376e-05,
      "loss": 1.0902,
      "step": 14700
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.926572799682617,
      "learning_rate": 3.5100448769030745e-05,
      "loss": 1.2982,
      "step": 14710
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.578683376312256,
      "learning_rate": 3.508996351130311e-05,
      "loss": 1.1398,
      "step": 14720
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.480127334594727,
      "learning_rate": 3.5079478253575476e-05,
      "loss": 1.111,
      "step": 14730
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.080769538879395,
      "learning_rate": 3.506899299584784e-05,
      "loss": 1.2514,
      "step": 14740
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.382648468017578,
      "learning_rate": 3.5058507738120206e-05,
      "loss": 1.1428,
      "step": 14750
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.572939872741699,
      "learning_rate": 3.504802248039257e-05,
      "loss": 1.1937,
      "step": 14760
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.2758097648620605,
      "learning_rate": 3.503753722266494e-05,
      "loss": 1.25,
      "step": 14770
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.053431510925293,
      "learning_rate": 3.50270519649373e-05,
      "loss": 1.2553,
      "step": 14780
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.72987174987793,
      "learning_rate": 3.501656670720966e-05,
      "loss": 1.1416,
      "step": 14790
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.67987060546875,
      "learning_rate": 3.500608144948203e-05,
      "loss": 1.237,
      "step": 14800
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.805753231048584,
      "learning_rate": 3.499559619175439e-05,
      "loss": 1.1985,
      "step": 14810
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.371903419494629,
      "learning_rate": 3.498511093402676e-05,
      "loss": 1.3078,
      "step": 14820
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.406980991363525,
      "learning_rate": 3.497462567629913e-05,
      "loss": 1.2486,
      "step": 14830
    },
    {
      "epoch": 0.92,
      "grad_norm": 5.975705146789551,
      "learning_rate": 3.496414041857149e-05,
      "loss": 1.207,
      "step": 14840
    },
    {
      "epoch": 0.92,
      "grad_norm": 6.178966045379639,
      "learning_rate": 3.495365516084386e-05,
      "loss": 1.1859,
      "step": 14850
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.922703742980957,
      "learning_rate": 3.494316990311622e-05,
      "loss": 1.0942,
      "step": 14860
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.8016557693481445,
      "learning_rate": 3.493268464538858e-05,
      "loss": 1.1951,
      "step": 14870
    },
    {
      "epoch": 0.93,
      "grad_norm": 9.674574851989746,
      "learning_rate": 3.4922199387660945e-05,
      "loss": 1.2194,
      "step": 14880
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.545114040374756,
      "learning_rate": 3.4911714129933314e-05,
      "loss": 1.152,
      "step": 14890
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.963586330413818,
      "learning_rate": 3.490122887220568e-05,
      "loss": 1.264,
      "step": 14900
    },
    {
      "epoch": 0.93,
      "grad_norm": 8.281128883361816,
      "learning_rate": 3.4890743614478045e-05,
      "loss": 1.1309,
      "step": 14910
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.1580281257629395,
      "learning_rate": 3.488025835675041e-05,
      "loss": 1.1527,
      "step": 14920
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.25430154800415,
      "learning_rate": 3.4869773099022775e-05,
      "loss": 1.1554,
      "step": 14930
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.996318340301514,
      "learning_rate": 3.4859287841295144e-05,
      "loss": 1.2697,
      "step": 14940
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.301501750946045,
      "learning_rate": 3.4848802583567506e-05,
      "loss": 1.1566,
      "step": 14950
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.282461166381836,
      "learning_rate": 3.483831732583987e-05,
      "loss": 1.1397,
      "step": 14960
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.578718662261963,
      "learning_rate": 3.4827832068112236e-05,
      "loss": 1.2195,
      "step": 14970
    },
    {
      "epoch": 0.93,
      "grad_norm": 8.866780281066895,
      "learning_rate": 3.48173468103846e-05,
      "loss": 1.2088,
      "step": 14980
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.743738651275635,
      "learning_rate": 3.480686155265697e-05,
      "loss": 1.2023,
      "step": 14990
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.006371021270752,
      "learning_rate": 3.4796376294929336e-05,
      "loss": 1.3432,
      "step": 15000
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.643337726593018,
      "learning_rate": 3.47858910372017e-05,
      "loss": 1.2474,
      "step": 15010
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.937164783477783,
      "learning_rate": 3.477540577947406e-05,
      "loss": 1.2555,
      "step": 15020
    },
    {
      "epoch": 0.94,
      "grad_norm": 6.107532978057861,
      "learning_rate": 3.476492052174642e-05,
      "loss": 1.1628,
      "step": 15030
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.343460559844971,
      "learning_rate": 3.475443526401879e-05,
      "loss": 1.179,
      "step": 15040
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.221560001373291,
      "learning_rate": 3.474395000629115e-05,
      "loss": 1.198,
      "step": 15050
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.537960529327393,
      "learning_rate": 3.473346474856352e-05,
      "loss": 1.3264,
      "step": 15060
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.699415683746338,
      "learning_rate": 3.472297949083589e-05,
      "loss": 1.2692,
      "step": 15070
    },
    {
      "epoch": 0.94,
      "grad_norm": 9.134142875671387,
      "learning_rate": 3.471249423310825e-05,
      "loss": 1.2641,
      "step": 15080
    },
    {
      "epoch": 0.94,
      "grad_norm": 6.023922443389893,
      "learning_rate": 3.470200897538062e-05,
      "loss": 1.2316,
      "step": 15090
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.058534145355225,
      "learning_rate": 3.469152371765298e-05,
      "loss": 1.4315,
      "step": 15100
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.197196960449219,
      "learning_rate": 3.4681038459925344e-05,
      "loss": 1.2105,
      "step": 15110
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.037914276123047,
      "learning_rate": 3.467055320219771e-05,
      "loss": 1.152,
      "step": 15120
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.022621154785156,
      "learning_rate": 3.4660067944470075e-05,
      "loss": 1.2116,
      "step": 15130
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.841832637786865,
      "learning_rate": 3.464958268674244e-05,
      "loss": 1.1959,
      "step": 15140
    },
    {
      "epoch": 0.94,
      "grad_norm": 6.288004398345947,
      "learning_rate": 3.4639097429014805e-05,
      "loss": 1.1521,
      "step": 15150
    },
    {
      "epoch": 0.94,
      "grad_norm": 6.434401512145996,
      "learning_rate": 3.4628612171287174e-05,
      "loss": 1.3086,
      "step": 15160
    },
    {
      "epoch": 0.94,
      "grad_norm": 9.468442916870117,
      "learning_rate": 3.4618126913559536e-05,
      "loss": 1.2459,
      "step": 15170
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.125278949737549,
      "learning_rate": 3.4607641655831905e-05,
      "loss": 1.2671,
      "step": 15180
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.651887893676758,
      "learning_rate": 3.4597156398104267e-05,
      "loss": 1.2359,
      "step": 15190
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.622888088226318,
      "learning_rate": 3.458667114037663e-05,
      "loss": 1.1146,
      "step": 15200
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.469431400299072,
      "learning_rate": 3.4576185882649e-05,
      "loss": 1.1861,
      "step": 15210
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.452152729034424,
      "learning_rate": 3.456570062492136e-05,
      "loss": 1.2988,
      "step": 15220
    },
    {
      "epoch": 0.95,
      "grad_norm": 8.058236122131348,
      "learning_rate": 3.455521536719373e-05,
      "loss": 1.0724,
      "step": 15230
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.537621974945068,
      "learning_rate": 3.4544730109466096e-05,
      "loss": 1.1876,
      "step": 15240
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.547466278076172,
      "learning_rate": 3.453424485173846e-05,
      "loss": 1.2273,
      "step": 15250
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.222774982452393,
      "learning_rate": 3.452375959401083e-05,
      "loss": 1.1492,
      "step": 15260
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.709663391113281,
      "learning_rate": 3.451327433628319e-05,
      "loss": 1.0453,
      "step": 15270
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.483319282531738,
      "learning_rate": 3.450278907855555e-05,
      "loss": 1.1238,
      "step": 15280
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.917930603027344,
      "learning_rate": 3.449230382082792e-05,
      "loss": 1.2249,
      "step": 15290
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.0372700691223145,
      "learning_rate": 3.448181856310028e-05,
      "loss": 1.2535,
      "step": 15300
    },
    {
      "epoch": 0.95,
      "grad_norm": 8.738913536071777,
      "learning_rate": 3.447133330537265e-05,
      "loss": 1.269,
      "step": 15310
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.230238914489746,
      "learning_rate": 3.446084804764501e-05,
      "loss": 1.2057,
      "step": 15320
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.133463382720947,
      "learning_rate": 3.445036278991738e-05,
      "loss": 1.2312,
      "step": 15330
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.621626853942871,
      "learning_rate": 3.443987753218974e-05,
      "loss": 1.0788,
      "step": 15340
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.4241533279418945,
      "learning_rate": 3.4429392274462105e-05,
      "loss": 1.1655,
      "step": 15350
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.930092811584473,
      "learning_rate": 3.4418907016734473e-05,
      "loss": 1.1605,
      "step": 15360
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.704848289489746,
      "learning_rate": 3.4408421759006835e-05,
      "loss": 1.2837,
      "step": 15370
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.844725608825684,
      "learning_rate": 3.4397936501279204e-05,
      "loss": 1.0888,
      "step": 15380
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.757408618927002,
      "learning_rate": 3.4387451243551566e-05,
      "loss": 1.1601,
      "step": 15390
    },
    {
      "epoch": 0.96,
      "grad_norm": 9.356593132019043,
      "learning_rate": 3.4376965985823935e-05,
      "loss": 1.1551,
      "step": 15400
    },
    {
      "epoch": 0.96,
      "grad_norm": 8.772355079650879,
      "learning_rate": 3.43664807280963e-05,
      "loss": 1.2882,
      "step": 15410
    },
    {
      "epoch": 0.96,
      "grad_norm": 8.101360321044922,
      "learning_rate": 3.4355995470368665e-05,
      "loss": 1.2773,
      "step": 15420
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.544970989227295,
      "learning_rate": 3.434551021264103e-05,
      "loss": 1.2399,
      "step": 15430
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.949776649475098,
      "learning_rate": 3.433502495491339e-05,
      "loss": 1.1094,
      "step": 15440
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.077976703643799,
      "learning_rate": 3.432453969718576e-05,
      "loss": 1.2833,
      "step": 15450
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.343242645263672,
      "learning_rate": 3.431405443945812e-05,
      "loss": 1.2253,
      "step": 15460
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.020005702972412,
      "learning_rate": 3.430356918173049e-05,
      "loss": 1.2859,
      "step": 15470
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.904320240020752,
      "learning_rate": 3.429308392400286e-05,
      "loss": 1.1046,
      "step": 15480
    },
    {
      "epoch": 0.96,
      "grad_norm": 9.58374309539795,
      "learning_rate": 3.428259866627522e-05,
      "loss": 1.2847,
      "step": 15490
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.962008953094482,
      "learning_rate": 3.427211340854759e-05,
      "loss": 1.0861,
      "step": 15500
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.894813060760498,
      "learning_rate": 3.426162815081995e-05,
      "loss": 1.184,
      "step": 15510
    },
    {
      "epoch": 0.97,
      "grad_norm": 8.338390350341797,
      "learning_rate": 3.425114289309231e-05,
      "loss": 1.0731,
      "step": 15520
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.104860782623291,
      "learning_rate": 3.424065763536468e-05,
      "loss": 1.1751,
      "step": 15530
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.823063850402832,
      "learning_rate": 3.423017237763704e-05,
      "loss": 1.3344,
      "step": 15540
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.553560256958008,
      "learning_rate": 3.421968711990941e-05,
      "loss": 1.1593,
      "step": 15550
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.558135986328125,
      "learning_rate": 3.420920186218177e-05,
      "loss": 1.2343,
      "step": 15560
    },
    {
      "epoch": 0.97,
      "grad_norm": 8.161065101623535,
      "learning_rate": 3.419871660445414e-05,
      "loss": 1.289,
      "step": 15570
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.865231513977051,
      "learning_rate": 3.4188231346726503e-05,
      "loss": 1.2076,
      "step": 15580
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.808683395385742,
      "learning_rate": 3.417774608899887e-05,
      "loss": 1.2328,
      "step": 15590
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.211822986602783,
      "learning_rate": 3.4167260831271234e-05,
      "loss": 1.1422,
      "step": 15600
    },
    {
      "epoch": 0.97,
      "grad_norm": 8.539963722229004,
      "learning_rate": 3.4156775573543596e-05,
      "loss": 1.3804,
      "step": 15610
    },
    {
      "epoch": 0.97,
      "grad_norm": 8.903831481933594,
      "learning_rate": 3.4146290315815965e-05,
      "loss": 1.2071,
      "step": 15620
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.104044437408447,
      "learning_rate": 3.4135805058088327e-05,
      "loss": 1.3052,
      "step": 15630
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.407948970794678,
      "learning_rate": 3.4125319800360695e-05,
      "loss": 1.2386,
      "step": 15640
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.868248462677002,
      "learning_rate": 3.4114834542633064e-05,
      "loss": 1.1264,
      "step": 15650
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.042967319488525,
      "learning_rate": 3.4104349284905426e-05,
      "loss": 1.2989,
      "step": 15660
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.113519191741943,
      "learning_rate": 3.409386402717779e-05,
      "loss": 1.136,
      "step": 15670
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.924476146697998,
      "learning_rate": 3.408337876945015e-05,
      "loss": 1.2444,
      "step": 15680
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.529005527496338,
      "learning_rate": 3.407289351172252e-05,
      "loss": 1.261,
      "step": 15690
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.647102355957031,
      "learning_rate": 3.406240825399489e-05,
      "loss": 1.275,
      "step": 15700
    },
    {
      "epoch": 0.98,
      "grad_norm": 7.941451072692871,
      "learning_rate": 3.405192299626725e-05,
      "loss": 1.1479,
      "step": 15710
    },
    {
      "epoch": 0.98,
      "grad_norm": 7.140366077423096,
      "learning_rate": 3.404143773853962e-05,
      "loss": 1.1689,
      "step": 15720
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.186062812805176,
      "learning_rate": 3.403095248081198e-05,
      "loss": 1.1845,
      "step": 15730
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.58701753616333,
      "learning_rate": 3.402046722308435e-05,
      "loss": 1.2425,
      "step": 15740
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.179197311401367,
      "learning_rate": 3.400998196535671e-05,
      "loss": 1.2996,
      "step": 15750
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.811618804931641,
      "learning_rate": 3.399949670762907e-05,
      "loss": 1.2027,
      "step": 15760
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.262796878814697,
      "learning_rate": 3.398901144990144e-05,
      "loss": 1.1894,
      "step": 15770
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.620218753814697,
      "learning_rate": 3.39785261921738e-05,
      "loss": 1.3097,
      "step": 15780
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.3086652755737305,
      "learning_rate": 3.396804093444617e-05,
      "loss": 1.1186,
      "step": 15790
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.218355655670166,
      "learning_rate": 3.3957555676718533e-05,
      "loss": 1.247,
      "step": 15800
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.6156721115112305,
      "learning_rate": 3.39470704189909e-05,
      "loss": 1.1291,
      "step": 15810
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.129868030548096,
      "learning_rate": 3.393658516126327e-05,
      "loss": 1.1956,
      "step": 15820
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.827242374420166,
      "learning_rate": 3.392609990353563e-05,
      "loss": 1.2369,
      "step": 15830
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.78145980834961,
      "learning_rate": 3.3915614645807995e-05,
      "loss": 1.2856,
      "step": 15840
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.803567409515381,
      "learning_rate": 3.390512938808036e-05,
      "loss": 1.2394,
      "step": 15850
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.61558198928833,
      "learning_rate": 3.3894644130352725e-05,
      "loss": 1.2965,
      "step": 15860
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.658143043518066,
      "learning_rate": 3.388415887262509e-05,
      "loss": 1.2781,
      "step": 15870
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.0815510749816895,
      "learning_rate": 3.3873673614897456e-05,
      "loss": 1.1116,
      "step": 15880
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.419018268585205,
      "learning_rate": 3.3863188357169825e-05,
      "loss": 1.2525,
      "step": 15890
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.826335430145264,
      "learning_rate": 3.3852703099442187e-05,
      "loss": 1.2782,
      "step": 15900
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.025515556335449,
      "learning_rate": 3.3842217841714555e-05,
      "loss": 1.1638,
      "step": 15910
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.823746681213379,
      "learning_rate": 3.383173258398691e-05,
      "loss": 1.167,
      "step": 15920
    },
    {
      "epoch": 0.99,
      "grad_norm": 13.447212219238281,
      "learning_rate": 3.382124732625928e-05,
      "loss": 1.2438,
      "step": 15930
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.890616416931152,
      "learning_rate": 3.381076206853165e-05,
      "loss": 1.1585,
      "step": 15940
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.292662620544434,
      "learning_rate": 3.380027681080401e-05,
      "loss": 1.223,
      "step": 15950
    },
    {
      "epoch": 0.99,
      "grad_norm": 10.094844818115234,
      "learning_rate": 3.378979155307638e-05,
      "loss": 1.1821,
      "step": 15960
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.614622116088867,
      "learning_rate": 3.377930629534874e-05,
      "loss": 1.2232,
      "step": 15970
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.739048480987549,
      "learning_rate": 3.376882103762111e-05,
      "loss": 1.1614,
      "step": 15980
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.560805320739746,
      "learning_rate": 3.375833577989347e-05,
      "loss": 1.258,
      "step": 15990
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.369814872741699,
      "learning_rate": 3.374785052216583e-05,
      "loss": 1.1278,
      "step": 16000
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.005844116210938,
      "learning_rate": 3.37373652644382e-05,
      "loss": 1.1789,
      "step": 16010
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.804520606994629,
      "learning_rate": 3.3726880006710564e-05,
      "loss": 1.1834,
      "step": 16020
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.630050182342529,
      "learning_rate": 3.371639474898293e-05,
      "loss": 1.2768,
      "step": 16030
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.349335670471191,
      "learning_rate": 3.3705909491255294e-05,
      "loss": 1.2541,
      "step": 16040
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.738166809082031,
      "learning_rate": 3.369542423352766e-05,
      "loss": 1.1583,
      "step": 16050
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.750617980957031,
      "learning_rate": 3.368493897580003e-05,
      "loss": 1.2724,
      "step": 16060
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1695427894592285,
      "eval_runtime": 178.6587,
      "eval_samples_per_second": 359.602,
      "eval_steps_per_second": 5.62,
      "step": 16062
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.028835296630859,
      "learning_rate": 3.3674453718072393e-05,
      "loss": 1.08,
      "step": 16070
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.063310623168945,
      "learning_rate": 3.3663968460344755e-05,
      "loss": 1.1165,
      "step": 16080
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.018867492675781,
      "learning_rate": 3.365348320261712e-05,
      "loss": 0.9307,
      "step": 16090
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.726211547851562,
      "learning_rate": 3.3642997944889486e-05,
      "loss": 0.9829,
      "step": 16100
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.605155944824219,
      "learning_rate": 3.3632512687161855e-05,
      "loss": 1.0132,
      "step": 16110
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.443756103515625,
      "learning_rate": 3.362202742943422e-05,
      "loss": 1.1704,
      "step": 16120
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.537439823150635,
      "learning_rate": 3.3611542171706585e-05,
      "loss": 0.9695,
      "step": 16130
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.193106174468994,
      "learning_rate": 3.360105691397895e-05,
      "loss": 1.0693,
      "step": 16140
    },
    {
      "epoch": 1.01,
      "grad_norm": 7.404323101043701,
      "learning_rate": 3.3590571656251316e-05,
      "loss": 1.0717,
      "step": 16150
    },
    {
      "epoch": 1.01,
      "grad_norm": 8.514906883239746,
      "learning_rate": 3.358008639852368e-05,
      "loss": 1.1604,
      "step": 16160
    },
    {
      "epoch": 1.01,
      "grad_norm": 7.425852298736572,
      "learning_rate": 3.356960114079604e-05,
      "loss": 1.0661,
      "step": 16170
    },
    {
      "epoch": 1.01,
      "grad_norm": 8.147581100463867,
      "learning_rate": 3.355911588306841e-05,
      "loss": 1.2128,
      "step": 16180
    },
    {
      "epoch": 1.01,
      "grad_norm": 5.777187824249268,
      "learning_rate": 3.354863062534077e-05,
      "loss": 1.0766,
      "step": 16190
    },
    {
      "epoch": 1.01,
      "grad_norm": 5.896486759185791,
      "learning_rate": 3.353814536761314e-05,
      "loss": 1.0193,
      "step": 16200
    },
    {
      "epoch": 1.01,
      "grad_norm": 9.202098846435547,
      "learning_rate": 3.35276601098855e-05,
      "loss": 1.1677,
      "step": 16210
    },
    {
      "epoch": 1.01,
      "grad_norm": 4.573115348815918,
      "learning_rate": 3.351717485215787e-05,
      "loss": 1.0636,
      "step": 16220
    },
    {
      "epoch": 1.01,
      "grad_norm": 7.045571804046631,
      "learning_rate": 3.350668959443024e-05,
      "loss": 0.9684,
      "step": 16230
    },
    {
      "epoch": 1.01,
      "grad_norm": 9.17708969116211,
      "learning_rate": 3.3496204336702594e-05,
      "loss": 1.1463,
      "step": 16240
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.453042984008789,
      "learning_rate": 3.348571907897496e-05,
      "loss": 1.0839,
      "step": 16250
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.336167335510254,
      "learning_rate": 3.3475233821247324e-05,
      "loss": 1.0157,
      "step": 16260
    },
    {
      "epoch": 1.01,
      "grad_norm": 8.568124771118164,
      "learning_rate": 3.346474856351969e-05,
      "loss": 1.1005,
      "step": 16270
    },
    {
      "epoch": 1.01,
      "grad_norm": 13.437471389770508,
      "learning_rate": 3.345426330579206e-05,
      "loss": 1.1195,
      "step": 16280
    },
    {
      "epoch": 1.01,
      "grad_norm": 10.090980529785156,
      "learning_rate": 3.3443778048064423e-05,
      "loss": 1.1188,
      "step": 16290
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.898037910461426,
      "learning_rate": 3.343329279033679e-05,
      "loss": 1.0998,
      "step": 16300
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.619057655334473,
      "learning_rate": 3.3422807532609154e-05,
      "loss": 1.1067,
      "step": 16310
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.109599590301514,
      "learning_rate": 3.3412322274881516e-05,
      "loss": 0.9808,
      "step": 16320
    },
    {
      "epoch": 1.02,
      "grad_norm": 9.330581665039062,
      "learning_rate": 3.340183701715388e-05,
      "loss": 1.0309,
      "step": 16330
    },
    {
      "epoch": 1.02,
      "grad_norm": 8.178810119628906,
      "learning_rate": 3.339135175942625e-05,
      "loss": 1.1532,
      "step": 16340
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.114184856414795,
      "learning_rate": 3.3380866501698615e-05,
      "loss": 1.1536,
      "step": 16350
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.779275417327881,
      "learning_rate": 3.337038124397098e-05,
      "loss": 1.0052,
      "step": 16360
    },
    {
      "epoch": 1.02,
      "grad_norm": 13.807796478271484,
      "learning_rate": 3.3359895986243346e-05,
      "loss": 1.1371,
      "step": 16370
    },
    {
      "epoch": 1.02,
      "grad_norm": 9.948543548583984,
      "learning_rate": 3.334941072851571e-05,
      "loss": 1.036,
      "step": 16380
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.107884407043457,
      "learning_rate": 3.3338925470788077e-05,
      "loss": 1.1435,
      "step": 16390
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.3979902267456055,
      "learning_rate": 3.332844021306044e-05,
      "loss": 1.0727,
      "step": 16400
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.875667572021484,
      "learning_rate": 3.33179549553328e-05,
      "loss": 1.0749,
      "step": 16410
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.554752826690674,
      "learning_rate": 3.330746969760517e-05,
      "loss": 1.1037,
      "step": 16420
    },
    {
      "epoch": 1.02,
      "grad_norm": 9.88509464263916,
      "learning_rate": 3.329698443987753e-05,
      "loss": 1.1714,
      "step": 16430
    },
    {
      "epoch": 1.02,
      "grad_norm": 8.86730670928955,
      "learning_rate": 3.32864991821499e-05,
      "loss": 1.17,
      "step": 16440
    },
    {
      "epoch": 1.02,
      "grad_norm": 8.271427154541016,
      "learning_rate": 3.327601392442226e-05,
      "loss": 1.0372,
      "step": 16450
    },
    {
      "epoch": 1.02,
      "grad_norm": 9.222085952758789,
      "learning_rate": 3.326552866669463e-05,
      "loss": 1.1385,
      "step": 16460
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.363452434539795,
      "learning_rate": 3.3255043408967e-05,
      "loss": 1.0479,
      "step": 16470
    },
    {
      "epoch": 1.03,
      "grad_norm": 4.426189422607422,
      "learning_rate": 3.324455815123936e-05,
      "loss": 0.981,
      "step": 16480
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.355166435241699,
      "learning_rate": 3.323407289351172e-05,
      "loss": 1.1002,
      "step": 16490
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.951235294342041,
      "learning_rate": 3.3223587635784085e-05,
      "loss": 1.0359,
      "step": 16500
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.8912935256958,
      "learning_rate": 3.3213102378056454e-05,
      "loss": 1.1027,
      "step": 16510
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.998889923095703,
      "learning_rate": 3.320261712032882e-05,
      "loss": 1.1742,
      "step": 16520
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.609341621398926,
      "learning_rate": 3.3192131862601184e-05,
      "loss": 1.1694,
      "step": 16530
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.0073041915893555,
      "learning_rate": 3.318164660487355e-05,
      "loss": 1.077,
      "step": 16540
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.34000301361084,
      "learning_rate": 3.3171161347145915e-05,
      "loss": 1.0903,
      "step": 16550
    },
    {
      "epoch": 1.03,
      "grad_norm": 5.048593521118164,
      "learning_rate": 3.316067608941828e-05,
      "loss": 1.0107,
      "step": 16560
    },
    {
      "epoch": 1.03,
      "grad_norm": 8.313033103942871,
      "learning_rate": 3.315019083169064e-05,
      "loss": 1.1649,
      "step": 16570
    },
    {
      "epoch": 1.03,
      "grad_norm": 12.783821105957031,
      "learning_rate": 3.313970557396301e-05,
      "loss": 1.1424,
      "step": 16580
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.847766876220703,
      "learning_rate": 3.3129220316235376e-05,
      "loss": 1.0591,
      "step": 16590
    },
    {
      "epoch": 1.03,
      "grad_norm": 8.37460994720459,
      "learning_rate": 3.311873505850774e-05,
      "loss": 1.1296,
      "step": 16600
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.188480854034424,
      "learning_rate": 3.310824980078011e-05,
      "loss": 1.1148,
      "step": 16610
    },
    {
      "epoch": 1.03,
      "grad_norm": 5.74699592590332,
      "learning_rate": 3.309776454305247e-05,
      "loss": 1.009,
      "step": 16620
    },
    {
      "epoch": 1.04,
      "grad_norm": 8.736990928649902,
      "learning_rate": 3.308727928532484e-05,
      "loss": 1.1091,
      "step": 16630
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.988076686859131,
      "learning_rate": 3.30767940275972e-05,
      "loss": 1.1496,
      "step": 16640
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.007096767425537,
      "learning_rate": 3.306630876986956e-05,
      "loss": 1.1695,
      "step": 16650
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.221536159515381,
      "learning_rate": 3.305582351214193e-05,
      "loss": 1.0284,
      "step": 16660
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.598593711853027,
      "learning_rate": 3.304533825441429e-05,
      "loss": 0.9948,
      "step": 16670
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.6230669021606445,
      "learning_rate": 3.303485299668666e-05,
      "loss": 1.1794,
      "step": 16680
    },
    {
      "epoch": 1.04,
      "grad_norm": 8.571832656860352,
      "learning_rate": 3.302436773895903e-05,
      "loss": 1.0475,
      "step": 16690
    },
    {
      "epoch": 1.04,
      "grad_norm": 12.822223663330078,
      "learning_rate": 3.301388248123139e-05,
      "loss": 0.9648,
      "step": 16700
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.724775314331055,
      "learning_rate": 3.300339722350376e-05,
      "loss": 1.1755,
      "step": 16710
    },
    {
      "epoch": 1.04,
      "grad_norm": 11.06268310546875,
      "learning_rate": 3.299291196577612e-05,
      "loss": 1.2063,
      "step": 16720
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.507647514343262,
      "learning_rate": 3.2982426708048484e-05,
      "loss": 0.9283,
      "step": 16730
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.636525630950928,
      "learning_rate": 3.2971941450320845e-05,
      "loss": 1.1544,
      "step": 16740
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.078064918518066,
      "learning_rate": 3.2961456192593214e-05,
      "loss": 1.0702,
      "step": 16750
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.384737014770508,
      "learning_rate": 3.295097093486558e-05,
      "loss": 1.0405,
      "step": 16760
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.157174587249756,
      "learning_rate": 3.2940485677137945e-05,
      "loss": 1.1011,
      "step": 16770
    },
    {
      "epoch": 1.04,
      "grad_norm": 5.105712890625,
      "learning_rate": 3.2930000419410314e-05,
      "loss": 1.098,
      "step": 16780
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.566189765930176,
      "learning_rate": 3.2919515161682675e-05,
      "loss": 1.1676,
      "step": 16790
    },
    {
      "epoch": 1.05,
      "grad_norm": 10.384931564331055,
      "learning_rate": 3.2909029903955044e-05,
      "loss": 1.1222,
      "step": 16800
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.003183841705322,
      "learning_rate": 3.2898544646227406e-05,
      "loss": 1.0209,
      "step": 16810
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.323095321655273,
      "learning_rate": 3.288805938849977e-05,
      "loss": 0.9794,
      "step": 16820
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.243768215179443,
      "learning_rate": 3.287757413077214e-05,
      "loss": 1.0644,
      "step": 16830
    },
    {
      "epoch": 1.05,
      "grad_norm": 10.352668762207031,
      "learning_rate": 3.28670888730445e-05,
      "loss": 0.9772,
      "step": 16840
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.1473822593688965,
      "learning_rate": 3.285660361531687e-05,
      "loss": 1.2535,
      "step": 16850
    },
    {
      "epoch": 1.05,
      "grad_norm": 9.35136890411377,
      "learning_rate": 3.284611835758923e-05,
      "loss": 0.9517,
      "step": 16860
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.98415756225586,
      "learning_rate": 3.28356330998616e-05,
      "loss": 1.2109,
      "step": 16870
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.1928071975708,
      "learning_rate": 3.282514784213396e-05,
      "loss": 1.1306,
      "step": 16880
    },
    {
      "epoch": 1.05,
      "grad_norm": 9.804091453552246,
      "learning_rate": 3.281466258440632e-05,
      "loss": 1.0647,
      "step": 16890
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.088051795959473,
      "learning_rate": 3.280417732667869e-05,
      "loss": 1.1843,
      "step": 16900
    },
    {
      "epoch": 1.05,
      "grad_norm": 9.238807678222656,
      "learning_rate": 3.279369206895105e-05,
      "loss": 1.0683,
      "step": 16910
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.125770568847656,
      "learning_rate": 3.278320681122342e-05,
      "loss": 0.8951,
      "step": 16920
    },
    {
      "epoch": 1.05,
      "grad_norm": 6.496309757232666,
      "learning_rate": 3.277272155349579e-05,
      "loss": 1.1255,
      "step": 16930
    },
    {
      "epoch": 1.05,
      "grad_norm": 4.588634490966797,
      "learning_rate": 3.276223629576815e-05,
      "loss": 1.0884,
      "step": 16940
    },
    {
      "epoch": 1.06,
      "grad_norm": 10.377473831176758,
      "learning_rate": 3.275175103804052e-05,
      "loss": 1.0123,
      "step": 16950
    },
    {
      "epoch": 1.06,
      "grad_norm": 10.50928783416748,
      "learning_rate": 3.274126578031288e-05,
      "loss": 1.0893,
      "step": 16960
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.887277126312256,
      "learning_rate": 3.2730780522585244e-05,
      "loss": 1.0086,
      "step": 16970
    },
    {
      "epoch": 1.06,
      "grad_norm": 10.650225639343262,
      "learning_rate": 3.272029526485761e-05,
      "loss": 1.1352,
      "step": 16980
    },
    {
      "epoch": 1.06,
      "grad_norm": 8.695733070373535,
      "learning_rate": 3.2709810007129975e-05,
      "loss": 1.0198,
      "step": 16990
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.88403844833374,
      "learning_rate": 3.2699324749402344e-05,
      "loss": 1.0319,
      "step": 17000
    },
    {
      "epoch": 1.06,
      "grad_norm": 9.542744636535645,
      "learning_rate": 3.2688839491674705e-05,
      "loss": 1.1241,
      "step": 17010
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.868980884552002,
      "learning_rate": 3.2678354233947074e-05,
      "loss": 1.005,
      "step": 17020
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.247218608856201,
      "learning_rate": 3.2667868976219436e-05,
      "loss": 1.1488,
      "step": 17030
    },
    {
      "epoch": 1.06,
      "grad_norm": 8.552227020263672,
      "learning_rate": 3.2657383718491805e-05,
      "loss": 1.1318,
      "step": 17040
    },
    {
      "epoch": 1.06,
      "grad_norm": 5.719292163848877,
      "learning_rate": 3.264689846076417e-05,
      "loss": 1.1838,
      "step": 17050
    },
    {
      "epoch": 1.06,
      "grad_norm": 5.918693542480469,
      "learning_rate": 3.263641320303653e-05,
      "loss": 1.0521,
      "step": 17060
    },
    {
      "epoch": 1.06,
      "grad_norm": 4.290600299835205,
      "learning_rate": 3.26259279453089e-05,
      "loss": 0.9473,
      "step": 17070
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.070716381072998,
      "learning_rate": 3.261544268758126e-05,
      "loss": 1.0215,
      "step": 17080
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.061617374420166,
      "learning_rate": 3.260495742985363e-05,
      "loss": 1.0382,
      "step": 17090
    },
    {
      "epoch": 1.06,
      "grad_norm": 9.585749626159668,
      "learning_rate": 3.2594472172126e-05,
      "loss": 1.1875,
      "step": 17100
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.067259788513184,
      "learning_rate": 3.258398691439836e-05,
      "loss": 1.1445,
      "step": 17110
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.173522472381592,
      "learning_rate": 3.257350165667073e-05,
      "loss": 1.1524,
      "step": 17120
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.919604778289795,
      "learning_rate": 3.256301639894309e-05,
      "loss": 1.1056,
      "step": 17130
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.718912124633789,
      "learning_rate": 3.255253114121545e-05,
      "loss": 1.1737,
      "step": 17140
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.323876857757568,
      "learning_rate": 3.254204588348781e-05,
      "loss": 1.0854,
      "step": 17150
    },
    {
      "epoch": 1.07,
      "grad_norm": 11.498656272888184,
      "learning_rate": 3.253156062576018e-05,
      "loss": 0.9487,
      "step": 17160
    },
    {
      "epoch": 1.07,
      "grad_norm": 8.334894180297852,
      "learning_rate": 3.252107536803255e-05,
      "loss": 1.0785,
      "step": 17170
    },
    {
      "epoch": 1.07,
      "grad_norm": 8.632915496826172,
      "learning_rate": 3.251059011030491e-05,
      "loss": 1.1289,
      "step": 17180
    },
    {
      "epoch": 1.07,
      "grad_norm": 10.615896224975586,
      "learning_rate": 3.250010485257728e-05,
      "loss": 1.1121,
      "step": 17190
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.9774956703186035,
      "learning_rate": 3.248961959484964e-05,
      "loss": 1.0597,
      "step": 17200
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.263401985168457,
      "learning_rate": 3.2479134337122005e-05,
      "loss": 1.1055,
      "step": 17210
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.25983190536499,
      "learning_rate": 3.2468649079394374e-05,
      "loss": 1.117,
      "step": 17220
    },
    {
      "epoch": 1.07,
      "grad_norm": 6.005645751953125,
      "learning_rate": 3.2458163821666736e-05,
      "loss": 1.1606,
      "step": 17230
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.103575706481934,
      "learning_rate": 3.2447678563939104e-05,
      "loss": 1.1689,
      "step": 17240
    },
    {
      "epoch": 1.07,
      "grad_norm": 9.24401569366455,
      "learning_rate": 3.2437193306211466e-05,
      "loss": 0.9429,
      "step": 17250
    },
    {
      "epoch": 1.07,
      "grad_norm": 7.2999267578125,
      "learning_rate": 3.2426708048483835e-05,
      "loss": 1.1149,
      "step": 17260
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.697235107421875,
      "learning_rate": 3.2416222790756204e-05,
      "loss": 1.0003,
      "step": 17270
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.185826301574707,
      "learning_rate": 3.2405737533028565e-05,
      "loss": 1.0812,
      "step": 17280
    },
    {
      "epoch": 1.08,
      "grad_norm": 10.00898551940918,
      "learning_rate": 3.239525227530093e-05,
      "loss": 1.1485,
      "step": 17290
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.088709831237793,
      "learning_rate": 3.238476701757329e-05,
      "loss": 1.0307,
      "step": 17300
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.458344459533691,
      "learning_rate": 3.237428175984566e-05,
      "loss": 1.0318,
      "step": 17310
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.979917049407959,
      "learning_rate": 3.236379650211802e-05,
      "loss": 0.9849,
      "step": 17320
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.489790916442871,
      "learning_rate": 3.235331124439039e-05,
      "loss": 1.1491,
      "step": 17330
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.059669494628906,
      "learning_rate": 3.234282598666276e-05,
      "loss": 1.1509,
      "step": 17340
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.072621822357178,
      "learning_rate": 3.233234072893512e-05,
      "loss": 1.0547,
      "step": 17350
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.128406524658203,
      "learning_rate": 3.232185547120749e-05,
      "loss": 1.1202,
      "step": 17360
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.962021350860596,
      "learning_rate": 3.231137021347985e-05,
      "loss": 1.1473,
      "step": 17370
    },
    {
      "epoch": 1.08,
      "grad_norm": 10.569283485412598,
      "learning_rate": 3.230088495575221e-05,
      "loss": 1.0737,
      "step": 17380
    },
    {
      "epoch": 1.08,
      "grad_norm": 6.847994804382324,
      "learning_rate": 3.229039969802458e-05,
      "loss": 1.0882,
      "step": 17390
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.450541019439697,
      "learning_rate": 3.227991444029694e-05,
      "loss": 1.2128,
      "step": 17400
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.241470813751221,
      "learning_rate": 3.226942918256931e-05,
      "loss": 1.0964,
      "step": 17410
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.931325435638428,
      "learning_rate": 3.225894392484167e-05,
      "loss": 1.1222,
      "step": 17420
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.508737564086914,
      "learning_rate": 3.224845866711404e-05,
      "loss": 1.0638,
      "step": 17430
    },
    {
      "epoch": 1.09,
      "grad_norm": 12.14413833618164,
      "learning_rate": 3.2237973409386404e-05,
      "loss": 1.1451,
      "step": 17440
    },
    {
      "epoch": 1.09,
      "grad_norm": 6.803997039794922,
      "learning_rate": 3.222748815165877e-05,
      "loss": 1.1224,
      "step": 17450
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.866640090942383,
      "learning_rate": 3.2217002893931134e-05,
      "loss": 1.0935,
      "step": 17460
    },
    {
      "epoch": 1.09,
      "grad_norm": 6.922023296356201,
      "learning_rate": 3.2206517636203496e-05,
      "loss": 1.0442,
      "step": 17470
    },
    {
      "epoch": 1.09,
      "grad_norm": 10.034459114074707,
      "learning_rate": 3.2196032378475865e-05,
      "loss": 1.0567,
      "step": 17480
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.521345615386963,
      "learning_rate": 3.218554712074823e-05,
      "loss": 1.1074,
      "step": 17490
    },
    {
      "epoch": 1.09,
      "grad_norm": 5.316235542297363,
      "learning_rate": 3.2175061863020595e-05,
      "loss": 1.0735,
      "step": 17500
    },
    {
      "epoch": 1.09,
      "grad_norm": 10.196229934692383,
      "learning_rate": 3.2164576605292964e-05,
      "loss": 0.987,
      "step": 17510
    },
    {
      "epoch": 1.09,
      "grad_norm": 9.01780891418457,
      "learning_rate": 3.2154091347565326e-05,
      "loss": 1.1505,
      "step": 17520
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.759514808654785,
      "learning_rate": 3.214360608983769e-05,
      "loss": 1.0862,
      "step": 17530
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.9936017990112305,
      "learning_rate": 3.213312083211005e-05,
      "loss": 1.1238,
      "step": 17540
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.961719989776611,
      "learning_rate": 3.212263557438242e-05,
      "loss": 1.106,
      "step": 17550
    },
    {
      "epoch": 1.09,
      "grad_norm": 9.857819557189941,
      "learning_rate": 3.211215031665479e-05,
      "loss": 1.1492,
      "step": 17560
    },
    {
      "epoch": 1.09,
      "grad_norm": 5.734844207763672,
      "learning_rate": 3.210166505892715e-05,
      "loss": 1.0968,
      "step": 17570
    },
    {
      "epoch": 1.09,
      "grad_norm": 8.714735984802246,
      "learning_rate": 3.209117980119952e-05,
      "loss": 1.0851,
      "step": 17580
    },
    {
      "epoch": 1.1,
      "grad_norm": 7.760268211364746,
      "learning_rate": 3.208069454347188e-05,
      "loss": 1.1519,
      "step": 17590
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.190440654754639,
      "learning_rate": 3.207020928574425e-05,
      "loss": 1.0758,
      "step": 17600
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.878423690795898,
      "learning_rate": 3.205972402801661e-05,
      "loss": 1.0401,
      "step": 17610
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.489858627319336,
      "learning_rate": 3.204923877028897e-05,
      "loss": 1.0394,
      "step": 17620
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.390598297119141,
      "learning_rate": 3.203875351256134e-05,
      "loss": 1.1712,
      "step": 17630
    },
    {
      "epoch": 1.1,
      "grad_norm": 7.669341087341309,
      "learning_rate": 3.20282682548337e-05,
      "loss": 1.1089,
      "step": 17640
    },
    {
      "epoch": 1.1,
      "grad_norm": 5.804437160491943,
      "learning_rate": 3.201778299710607e-05,
      "loss": 1.0715,
      "step": 17650
    },
    {
      "epoch": 1.1,
      "grad_norm": 15.374180793762207,
      "learning_rate": 3.2007297739378434e-05,
      "loss": 1.0456,
      "step": 17660
    },
    {
      "epoch": 1.1,
      "grad_norm": 14.386076927185059,
      "learning_rate": 3.19968124816508e-05,
      "loss": 1.3198,
      "step": 17670
    },
    {
      "epoch": 1.1,
      "grad_norm": 10.152235984802246,
      "learning_rate": 3.198632722392317e-05,
      "loss": 1.1881,
      "step": 17680
    },
    {
      "epoch": 1.1,
      "grad_norm": 8.71556282043457,
      "learning_rate": 3.197584196619553e-05,
      "loss": 1.0802,
      "step": 17690
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.618432521820068,
      "learning_rate": 3.1965356708467895e-05,
      "loss": 1.1076,
      "step": 17700
    },
    {
      "epoch": 1.1,
      "grad_norm": 8.386630058288574,
      "learning_rate": 3.195487145074026e-05,
      "loss": 0.9932,
      "step": 17710
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.727283477783203,
      "learning_rate": 3.1944386193012626e-05,
      "loss": 1.0489,
      "step": 17720
    },
    {
      "epoch": 1.1,
      "grad_norm": 11.153226852416992,
      "learning_rate": 3.193390093528499e-05,
      "loss": 0.9854,
      "step": 17730
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.805444717407227,
      "learning_rate": 3.1923415677557356e-05,
      "loss": 1.0279,
      "step": 17740
    },
    {
      "epoch": 1.11,
      "grad_norm": 6.652487754821777,
      "learning_rate": 3.1912930419829725e-05,
      "loss": 0.9783,
      "step": 17750
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.723291873931885,
      "learning_rate": 3.190244516210209e-05,
      "loss": 1.0671,
      "step": 17760
    },
    {
      "epoch": 1.11,
      "grad_norm": 12.689249992370605,
      "learning_rate": 3.1891959904374455e-05,
      "loss": 1.1827,
      "step": 17770
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.674291610717773,
      "learning_rate": 3.188147464664681e-05,
      "loss": 1.1734,
      "step": 17780
    },
    {
      "epoch": 1.11,
      "grad_norm": 5.754251480102539,
      "learning_rate": 3.187098938891918e-05,
      "loss": 1.1531,
      "step": 17790
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.225215911865234,
      "learning_rate": 3.186050413119155e-05,
      "loss": 1.0926,
      "step": 17800
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.292997360229492,
      "learning_rate": 3.185001887346391e-05,
      "loss": 1.0312,
      "step": 17810
    },
    {
      "epoch": 1.11,
      "grad_norm": 6.299965858459473,
      "learning_rate": 3.183953361573628e-05,
      "loss": 0.9809,
      "step": 17820
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.445987701416016,
      "learning_rate": 3.182904835800864e-05,
      "loss": 1.029,
      "step": 17830
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.120463848114014,
      "learning_rate": 3.181856310028101e-05,
      "loss": 0.9984,
      "step": 17840
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.760063171386719,
      "learning_rate": 3.180807784255337e-05,
      "loss": 0.9567,
      "step": 17850
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.531716346740723,
      "learning_rate": 3.179759258482573e-05,
      "loss": 1.0441,
      "step": 17860
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.743585586547852,
      "learning_rate": 3.17871073270981e-05,
      "loss": 1.1794,
      "step": 17870
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.777273178100586,
      "learning_rate": 3.1776622069370464e-05,
      "loss": 1.0411,
      "step": 17880
    },
    {
      "epoch": 1.11,
      "grad_norm": 10.517314910888672,
      "learning_rate": 3.176613681164283e-05,
      "loss": 1.1177,
      "step": 17890
    },
    {
      "epoch": 1.11,
      "grad_norm": 5.266123294830322,
      "learning_rate": 3.1755651553915194e-05,
      "loss": 1.0437,
      "step": 17900
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.481635093688965,
      "learning_rate": 3.174516629618756e-05,
      "loss": 1.0824,
      "step": 17910
    },
    {
      "epoch": 1.12,
      "grad_norm": 9.513946533203125,
      "learning_rate": 3.173468103845993e-05,
      "loss": 0.9155,
      "step": 17920
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.233355522155762,
      "learning_rate": 3.1724195780732294e-05,
      "loss": 1.0041,
      "step": 17930
    },
    {
      "epoch": 1.12,
      "grad_norm": 9.492542266845703,
      "learning_rate": 3.1713710523004656e-05,
      "loss": 1.0329,
      "step": 17940
    },
    {
      "epoch": 1.12,
      "grad_norm": 6.374032974243164,
      "learning_rate": 3.170322526527702e-05,
      "loss": 1.0593,
      "step": 17950
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.610987663269043,
      "learning_rate": 3.1692740007549386e-05,
      "loss": 0.9531,
      "step": 17960
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.94158935546875,
      "learning_rate": 3.1682254749821755e-05,
      "loss": 1.0861,
      "step": 17970
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.4936723709106445,
      "learning_rate": 3.167176949209412e-05,
      "loss": 1.1082,
      "step": 17980
    },
    {
      "epoch": 1.12,
      "grad_norm": 4.1030049324035645,
      "learning_rate": 3.1661284234366486e-05,
      "loss": 1.0825,
      "step": 17990
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.308335781097412,
      "learning_rate": 3.165079897663885e-05,
      "loss": 0.9842,
      "step": 18000
    },
    {
      "epoch": 1.12,
      "grad_norm": 12.195578575134277,
      "learning_rate": 3.1640313718911216e-05,
      "loss": 0.9883,
      "step": 18010
    },
    {
      "epoch": 1.12,
      "grad_norm": 11.314034461975098,
      "learning_rate": 3.162982846118358e-05,
      "loss": 1.043,
      "step": 18020
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.585980415344238,
      "learning_rate": 3.161934320345594e-05,
      "loss": 1.0311,
      "step": 18030
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.951333999633789,
      "learning_rate": 3.160885794572831e-05,
      "loss": 0.941,
      "step": 18040
    },
    {
      "epoch": 1.12,
      "grad_norm": 6.1404619216918945,
      "learning_rate": 3.159837268800067e-05,
      "loss": 0.9019,
      "step": 18050
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.487282752990723,
      "learning_rate": 3.158788743027304e-05,
      "loss": 1.3578,
      "step": 18060
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.045258522033691,
      "learning_rate": 3.15774021725454e-05,
      "loss": 1.092,
      "step": 18070
    },
    {
      "epoch": 1.13,
      "grad_norm": 6.401435375213623,
      "learning_rate": 3.156691691481777e-05,
      "loss": 0.9959,
      "step": 18080
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.579224586486816,
      "learning_rate": 3.155643165709014e-05,
      "loss": 1.0636,
      "step": 18090
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.372454643249512,
      "learning_rate": 3.1545946399362494e-05,
      "loss": 1.0937,
      "step": 18100
    },
    {
      "epoch": 1.13,
      "grad_norm": 6.610384464263916,
      "learning_rate": 3.153546114163486e-05,
      "loss": 1.0755,
      "step": 18110
    },
    {
      "epoch": 1.13,
      "grad_norm": 9.530494689941406,
      "learning_rate": 3.1524975883907224e-05,
      "loss": 1.0129,
      "step": 18120
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.522489547729492,
      "learning_rate": 3.151449062617959e-05,
      "loss": 1.0882,
      "step": 18130
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.852620601654053,
      "learning_rate": 3.1504005368451955e-05,
      "loss": 1.2262,
      "step": 18140
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.636178970336914,
      "learning_rate": 3.1493520110724324e-05,
      "loss": 1.1913,
      "step": 18150
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.262938499450684,
      "learning_rate": 3.148303485299669e-05,
      "loss": 1.0289,
      "step": 18160
    },
    {
      "epoch": 1.13,
      "grad_norm": 10.586525917053223,
      "learning_rate": 3.1472549595269054e-05,
      "loss": 1.0332,
      "step": 18170
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.469880104064941,
      "learning_rate": 3.1462064337541416e-05,
      "loss": 1.1067,
      "step": 18180
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.747053146362305,
      "learning_rate": 3.145157907981378e-05,
      "loss": 1.0818,
      "step": 18190
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.599137306213379,
      "learning_rate": 3.144109382208615e-05,
      "loss": 1.0767,
      "step": 18200
    },
    {
      "epoch": 1.13,
      "grad_norm": 6.9335808753967285,
      "learning_rate": 3.1430608564358516e-05,
      "loss": 1.0019,
      "step": 18210
    },
    {
      "epoch": 1.13,
      "grad_norm": 9.416367530822754,
      "learning_rate": 3.142012330663088e-05,
      "loss": 1.0924,
      "step": 18220
    },
    {
      "epoch": 1.13,
      "grad_norm": 9.539972305297852,
      "learning_rate": 3.1409638048903246e-05,
      "loss": 1.1135,
      "step": 18230
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.172532558441162,
      "learning_rate": 3.139915279117561e-05,
      "loss": 1.1017,
      "step": 18240
    },
    {
      "epoch": 1.14,
      "grad_norm": 8.726856231689453,
      "learning_rate": 3.138866753344798e-05,
      "loss": 1.0872,
      "step": 18250
    },
    {
      "epoch": 1.14,
      "grad_norm": 6.027561664581299,
      "learning_rate": 3.137818227572034e-05,
      "loss": 1.0379,
      "step": 18260
    },
    {
      "epoch": 1.14,
      "grad_norm": 9.212590217590332,
      "learning_rate": 3.13676970179927e-05,
      "loss": 1.1477,
      "step": 18270
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.513751983642578,
      "learning_rate": 3.135721176026507e-05,
      "loss": 1.0327,
      "step": 18280
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.00003719329834,
      "learning_rate": 3.134672650253743e-05,
      "loss": 1.1194,
      "step": 18290
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.8149027824401855,
      "learning_rate": 3.13362412448098e-05,
      "loss": 1.1027,
      "step": 18300
    },
    {
      "epoch": 1.14,
      "grad_norm": 12.472795486450195,
      "learning_rate": 3.132575598708216e-05,
      "loss": 1.1329,
      "step": 18310
    },
    {
      "epoch": 1.14,
      "grad_norm": 5.014872074127197,
      "learning_rate": 3.131527072935453e-05,
      "loss": 1.3128,
      "step": 18320
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.007395267486572,
      "learning_rate": 3.13047854716269e-05,
      "loss": 1.0995,
      "step": 18330
    },
    {
      "epoch": 1.14,
      "grad_norm": 10.904520034790039,
      "learning_rate": 3.129430021389926e-05,
      "loss": 1.0041,
      "step": 18340
    },
    {
      "epoch": 1.14,
      "grad_norm": 9.198100090026855,
      "learning_rate": 3.128381495617162e-05,
      "loss": 0.9861,
      "step": 18350
    },
    {
      "epoch": 1.14,
      "grad_norm": 5.925985813140869,
      "learning_rate": 3.1273329698443985e-05,
      "loss": 1.0696,
      "step": 18360
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.101980209350586,
      "learning_rate": 3.1262844440716354e-05,
      "loss": 1.0336,
      "step": 18370
    },
    {
      "epoch": 1.14,
      "grad_norm": 10.523828506469727,
      "learning_rate": 3.125235918298872e-05,
      "loss": 1.0651,
      "step": 18380
    },
    {
      "epoch": 1.14,
      "grad_norm": 6.168514728546143,
      "learning_rate": 3.1241873925261084e-05,
      "loss": 1.038,
      "step": 18390
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.488303184509277,
      "learning_rate": 3.123138866753345e-05,
      "loss": 1.0946,
      "step": 18400
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.229791641235352,
      "learning_rate": 3.1220903409805815e-05,
      "loss": 1.1357,
      "step": 18410
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.949825286865234,
      "learning_rate": 3.121041815207818e-05,
      "loss": 1.0119,
      "step": 18420
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.430552005767822,
      "learning_rate": 3.119993289435054e-05,
      "loss": 1.0235,
      "step": 18430
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.469118118286133,
      "learning_rate": 3.118944763662291e-05,
      "loss": 0.9606,
      "step": 18440
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.911021709442139,
      "learning_rate": 3.1178962378895276e-05,
      "loss": 1.0154,
      "step": 18450
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.141153335571289,
      "learning_rate": 3.116847712116764e-05,
      "loss": 1.0125,
      "step": 18460
    },
    {
      "epoch": 1.15,
      "grad_norm": 10.675647735595703,
      "learning_rate": 3.115799186344001e-05,
      "loss": 1.2635,
      "step": 18470
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.603605270385742,
      "learning_rate": 3.114750660571237e-05,
      "loss": 1.025,
      "step": 18480
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.405632972717285,
      "learning_rate": 3.113702134798474e-05,
      "loss": 1.0726,
      "step": 18490
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.1141886711120605,
      "learning_rate": 3.11265360902571e-05,
      "loss": 1.1254,
      "step": 18500
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.309383392333984,
      "learning_rate": 3.111605083252946e-05,
      "loss": 0.9924,
      "step": 18510
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.62236499786377,
      "learning_rate": 3.110556557480183e-05,
      "loss": 1.0317,
      "step": 18520
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.009599685668945,
      "learning_rate": 3.109508031707419e-05,
      "loss": 1.1068,
      "step": 18530
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.371243000030518,
      "learning_rate": 3.108459505934656e-05,
      "loss": 1.1396,
      "step": 18540
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.343042373657227,
      "learning_rate": 3.107410980161893e-05,
      "loss": 1.0125,
      "step": 18550
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.033670425415039,
      "learning_rate": 3.106362454389129e-05,
      "loss": 1.1462,
      "step": 18560
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.791370391845703,
      "learning_rate": 3.105313928616366e-05,
      "loss": 1.0102,
      "step": 18570
    },
    {
      "epoch": 1.16,
      "grad_norm": 6.486438274383545,
      "learning_rate": 3.104265402843602e-05,
      "loss": 1.0614,
      "step": 18580
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.027337074279785,
      "learning_rate": 3.1032168770708384e-05,
      "loss": 1.1045,
      "step": 18590
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.82921028137207,
      "learning_rate": 3.1021683512980746e-05,
      "loss": 1.0873,
      "step": 18600
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.620774269104004,
      "learning_rate": 3.1011198255253114e-05,
      "loss": 1.0726,
      "step": 18610
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.625311851501465,
      "learning_rate": 3.100071299752548e-05,
      "loss": 1.1185,
      "step": 18620
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.347471237182617,
      "learning_rate": 3.0990227739797845e-05,
      "loss": 1.0953,
      "step": 18630
    },
    {
      "epoch": 1.16,
      "grad_norm": 11.277334213256836,
      "learning_rate": 3.0979742482070214e-05,
      "loss": 1.1611,
      "step": 18640
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.089571952819824,
      "learning_rate": 3.0969257224342576e-05,
      "loss": 1.0445,
      "step": 18650
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.045759201049805,
      "learning_rate": 3.0958771966614944e-05,
      "loss": 0.9366,
      "step": 18660
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.512838363647461,
      "learning_rate": 3.0948286708887306e-05,
      "loss": 1.0113,
      "step": 18670
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.582632541656494,
      "learning_rate": 3.093780145115967e-05,
      "loss": 1.0339,
      "step": 18680
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.115928649902344,
      "learning_rate": 3.092731619343204e-05,
      "loss": 1.0146,
      "step": 18690
    },
    {
      "epoch": 1.16,
      "grad_norm": 8.096304893493652,
      "learning_rate": 3.09168309357044e-05,
      "loss": 1.0311,
      "step": 18700
    },
    {
      "epoch": 1.16,
      "grad_norm": 10.627020835876465,
      "learning_rate": 3.090634567797677e-05,
      "loss": 0.989,
      "step": 18710
    },
    {
      "epoch": 1.17,
      "grad_norm": 10.24086856842041,
      "learning_rate": 3.089586042024913e-05,
      "loss": 1.1321,
      "step": 18720
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.271451473236084,
      "learning_rate": 3.08853751625215e-05,
      "loss": 1.1305,
      "step": 18730
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.400112152099609,
      "learning_rate": 3.087488990479386e-05,
      "loss": 1.0362,
      "step": 18740
    },
    {
      "epoch": 1.17,
      "grad_norm": 20.509389877319336,
      "learning_rate": 3.086440464706622e-05,
      "loss": 1.0281,
      "step": 18750
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.805844306945801,
      "learning_rate": 3.085391938933859e-05,
      "loss": 1.1195,
      "step": 18760
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.802644729614258,
      "learning_rate": 3.084343413161095e-05,
      "loss": 1.1691,
      "step": 18770
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.727551460266113,
      "learning_rate": 3.083294887388332e-05,
      "loss": 0.9936,
      "step": 18780
    },
    {
      "epoch": 1.17,
      "grad_norm": 12.901955604553223,
      "learning_rate": 3.082246361615569e-05,
      "loss": 0.9277,
      "step": 18790
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.759091854095459,
      "learning_rate": 3.081197835842805e-05,
      "loss": 0.9829,
      "step": 18800
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.979412078857422,
      "learning_rate": 3.080149310070042e-05,
      "loss": 1.078,
      "step": 18810
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.980652332305908,
      "learning_rate": 3.079100784297278e-05,
      "loss": 1.106,
      "step": 18820
    },
    {
      "epoch": 1.17,
      "grad_norm": 9.048221588134766,
      "learning_rate": 3.0780522585245144e-05,
      "loss": 1.064,
      "step": 18830
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.464486122131348,
      "learning_rate": 3.0770037327517506e-05,
      "loss": 0.9542,
      "step": 18840
    },
    {
      "epoch": 1.17,
      "grad_norm": 12.350604057312012,
      "learning_rate": 3.0759552069789875e-05,
      "loss": 1.1293,
      "step": 18850
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.695967674255371,
      "learning_rate": 3.0749066812062244e-05,
      "loss": 1.1956,
      "step": 18860
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.617362976074219,
      "learning_rate": 3.0738581554334606e-05,
      "loss": 1.0817,
      "step": 18870
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.765721321105957,
      "learning_rate": 3.0728096296606974e-05,
      "loss": 1.05,
      "step": 18880
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.983193874359131,
      "learning_rate": 3.0717611038879336e-05,
      "loss": 1.0144,
      "step": 18890
    },
    {
      "epoch": 1.18,
      "grad_norm": 7.520135402679443,
      "learning_rate": 3.0707125781151705e-05,
      "loss": 1.0546,
      "step": 18900
    },
    {
      "epoch": 1.18,
      "grad_norm": 7.559196949005127,
      "learning_rate": 3.069664052342407e-05,
      "loss": 0.9844,
      "step": 18910
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.697897434234619,
      "learning_rate": 3.068615526569643e-05,
      "loss": 1.0318,
      "step": 18920
    },
    {
      "epoch": 1.18,
      "grad_norm": 10.61928653717041,
      "learning_rate": 3.06756700079688e-05,
      "loss": 1.1048,
      "step": 18930
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.538578987121582,
      "learning_rate": 3.066518475024116e-05,
      "loss": 1.0787,
      "step": 18940
    },
    {
      "epoch": 1.18,
      "grad_norm": 12.808629989624023,
      "learning_rate": 3.065469949251353e-05,
      "loss": 1.0188,
      "step": 18950
    },
    {
      "epoch": 1.18,
      "grad_norm": 10.79220199584961,
      "learning_rate": 3.06442142347859e-05,
      "loss": 1.0529,
      "step": 18960
    },
    {
      "epoch": 1.18,
      "grad_norm": 11.06640625,
      "learning_rate": 3.063372897705826e-05,
      "loss": 1.1393,
      "step": 18970
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.247892379760742,
      "learning_rate": 3.062324371933063e-05,
      "loss": 0.9104,
      "step": 18980
    },
    {
      "epoch": 1.18,
      "grad_norm": 7.92374324798584,
      "learning_rate": 3.061275846160299e-05,
      "loss": 1.059,
      "step": 18990
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.497944831848145,
      "learning_rate": 3.060227320387535e-05,
      "loss": 1.0733,
      "step": 19000
    },
    {
      "epoch": 1.18,
      "grad_norm": 9.393125534057617,
      "learning_rate": 3.059178794614771e-05,
      "loss": 1.1172,
      "step": 19010
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.972066879272461,
      "learning_rate": 3.058130268842008e-05,
      "loss": 1.0545,
      "step": 19020
    },
    {
      "epoch": 1.18,
      "grad_norm": 11.236618995666504,
      "learning_rate": 3.057081743069245e-05,
      "loss": 1.1189,
      "step": 19030
    },
    {
      "epoch": 1.19,
      "grad_norm": 5.425816535949707,
      "learning_rate": 3.056033217296481e-05,
      "loss": 0.9722,
      "step": 19040
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.257465362548828,
      "learning_rate": 3.054984691523718e-05,
      "loss": 1.0952,
      "step": 19050
    },
    {
      "epoch": 1.19,
      "grad_norm": 7.847402572631836,
      "learning_rate": 3.053936165750954e-05,
      "loss": 1.1552,
      "step": 19060
    },
    {
      "epoch": 1.19,
      "grad_norm": 8.515893936157227,
      "learning_rate": 3.0528876399781905e-05,
      "loss": 1.0385,
      "step": 19070
    },
    {
      "epoch": 1.19,
      "grad_norm": 4.93914270401001,
      "learning_rate": 3.0518391142054274e-05,
      "loss": 1.0426,
      "step": 19080
    },
    {
      "epoch": 1.19,
      "grad_norm": 8.840392112731934,
      "learning_rate": 3.050790588432664e-05,
      "loss": 1.0286,
      "step": 19090
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.9686567783355713,
      "learning_rate": 3.0497420626599004e-05,
      "loss": 1.0286,
      "step": 19100
    },
    {
      "epoch": 1.19,
      "grad_norm": 11.13158893585205,
      "learning_rate": 3.0486935368871366e-05,
      "loss": 1.1594,
      "step": 19110
    },
    {
      "epoch": 1.19,
      "grad_norm": 6.434063911437988,
      "learning_rate": 3.0476450111143735e-05,
      "loss": 1.036,
      "step": 19120
    },
    {
      "epoch": 1.19,
      "grad_norm": 7.501082420349121,
      "learning_rate": 3.0465964853416097e-05,
      "loss": 1.0135,
      "step": 19130
    },
    {
      "epoch": 1.19,
      "grad_norm": 6.395966529846191,
      "learning_rate": 3.0455479595688462e-05,
      "loss": 0.9946,
      "step": 19140
    },
    {
      "epoch": 1.19,
      "grad_norm": 10.21090316772461,
      "learning_rate": 3.044499433796083e-05,
      "loss": 1.1047,
      "step": 19150
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.26761531829834,
      "learning_rate": 3.0434509080233193e-05,
      "loss": 1.1332,
      "step": 19160
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.365979194641113,
      "learning_rate": 3.0424023822505558e-05,
      "loss": 1.1887,
      "step": 19170
    },
    {
      "epoch": 1.19,
      "grad_norm": 8.899529457092285,
      "learning_rate": 3.041353856477792e-05,
      "loss": 1.0119,
      "step": 19180
    },
    {
      "epoch": 1.19,
      "grad_norm": 11.083146095275879,
      "learning_rate": 3.040305330705029e-05,
      "loss": 1.0687,
      "step": 19190
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.058534622192383,
      "learning_rate": 3.0392568049322658e-05,
      "loss": 0.9695,
      "step": 19200
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.792601108551025,
      "learning_rate": 3.038208279159502e-05,
      "loss": 1.0944,
      "step": 19210
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.432967662811279,
      "learning_rate": 3.0371597533867385e-05,
      "loss": 1.0455,
      "step": 19220
    },
    {
      "epoch": 1.2,
      "grad_norm": 11.123918533325195,
      "learning_rate": 3.0361112276139747e-05,
      "loss": 1.1012,
      "step": 19230
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.3392157554626465,
      "learning_rate": 3.0350627018412115e-05,
      "loss": 1.0888,
      "step": 19240
    },
    {
      "epoch": 1.2,
      "grad_norm": 8.212361335754395,
      "learning_rate": 3.034014176068448e-05,
      "loss": 1.0781,
      "step": 19250
    },
    {
      "epoch": 1.2,
      "grad_norm": 10.367727279663086,
      "learning_rate": 3.0329656502956843e-05,
      "loss": 1.1783,
      "step": 19260
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.502713203430176,
      "learning_rate": 3.031917124522921e-05,
      "loss": 1.0542,
      "step": 19270
    },
    {
      "epoch": 1.2,
      "grad_norm": 9.097223281860352,
      "learning_rate": 3.0308685987501573e-05,
      "loss": 1.0249,
      "step": 19280
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.0013580322265625,
      "learning_rate": 3.029820072977394e-05,
      "loss": 1.0433,
      "step": 19290
    },
    {
      "epoch": 1.2,
      "grad_norm": 15.30837631225586,
      "learning_rate": 3.02877154720463e-05,
      "loss": 1.1628,
      "step": 19300
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.549173831939697,
      "learning_rate": 3.027723021431867e-05,
      "loss": 1.1485,
      "step": 19310
    },
    {
      "epoch": 1.2,
      "grad_norm": 8.696608543395996,
      "learning_rate": 3.0266744956591038e-05,
      "loss": 1.0963,
      "step": 19320
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.587620258331299,
      "learning_rate": 3.02562596988634e-05,
      "loss": 1.1528,
      "step": 19330
    },
    {
      "epoch": 1.2,
      "grad_norm": 4.3103461265563965,
      "learning_rate": 3.0245774441135765e-05,
      "loss": 0.8932,
      "step": 19340
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.558317184448242,
      "learning_rate": 3.0235289183408127e-05,
      "loss": 1.1204,
      "step": 19350
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.137868881225586,
      "learning_rate": 3.0224803925680496e-05,
      "loss": 0.9616,
      "step": 19360
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.799788475036621,
      "learning_rate": 3.021431866795286e-05,
      "loss": 1.1081,
      "step": 19370
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.668044090270996,
      "learning_rate": 3.0203833410225223e-05,
      "loss": 1.0215,
      "step": 19380
    },
    {
      "epoch": 1.21,
      "grad_norm": 10.518345832824707,
      "learning_rate": 3.019334815249759e-05,
      "loss": 1.2292,
      "step": 19390
    },
    {
      "epoch": 1.21,
      "grad_norm": 6.99127721786499,
      "learning_rate": 3.0182862894769954e-05,
      "loss": 1.0354,
      "step": 19400
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.147026062011719,
      "learning_rate": 3.0172377637042322e-05,
      "loss": 1.0235,
      "step": 19410
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.018089294433594,
      "learning_rate": 3.016189237931468e-05,
      "loss": 1.1908,
      "step": 19420
    },
    {
      "epoch": 1.21,
      "grad_norm": 6.963789463043213,
      "learning_rate": 3.015140712158705e-05,
      "loss": 1.0847,
      "step": 19430
    },
    {
      "epoch": 1.21,
      "grad_norm": 7.07631254196167,
      "learning_rate": 3.0140921863859418e-05,
      "loss": 1.1363,
      "step": 19440
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.73289966583252,
      "learning_rate": 3.013043660613178e-05,
      "loss": 1.1221,
      "step": 19450
    },
    {
      "epoch": 1.21,
      "grad_norm": 7.2235941886901855,
      "learning_rate": 3.0119951348404145e-05,
      "loss": 1.0624,
      "step": 19460
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.839225769042969,
      "learning_rate": 3.0109466090676507e-05,
      "loss": 0.9953,
      "step": 19470
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.383326530456543,
      "learning_rate": 3.0098980832948876e-05,
      "loss": 1.0091,
      "step": 19480
    },
    {
      "epoch": 1.21,
      "grad_norm": 10.748377799987793,
      "learning_rate": 3.008849557522124e-05,
      "loss": 1.1554,
      "step": 19490
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.561589241027832,
      "learning_rate": 3.0078010317493603e-05,
      "loss": 1.2036,
      "step": 19500
    },
    {
      "epoch": 1.21,
      "grad_norm": 8.771496772766113,
      "learning_rate": 3.0067525059765972e-05,
      "loss": 1.0274,
      "step": 19510
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.526981353759766,
      "learning_rate": 3.0057039802038334e-05,
      "loss": 1.1121,
      "step": 19520
    },
    {
      "epoch": 1.22,
      "grad_norm": 11.13880729675293,
      "learning_rate": 3.0046554544310703e-05,
      "loss": 1.0876,
      "step": 19530
    },
    {
      "epoch": 1.22,
      "grad_norm": 9.885482788085938,
      "learning_rate": 3.0036069286583068e-05,
      "loss": 1.0885,
      "step": 19540
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.673795700073242,
      "learning_rate": 3.002558402885543e-05,
      "loss": 1.0773,
      "step": 19550
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.335810661315918,
      "learning_rate": 3.00150987711278e-05,
      "loss": 1.0495,
      "step": 19560
    },
    {
      "epoch": 1.22,
      "grad_norm": 8.925398826599121,
      "learning_rate": 3.000461351340016e-05,
      "loss": 1.1522,
      "step": 19570
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.365360260009766,
      "learning_rate": 2.9994128255672526e-05,
      "loss": 1.0407,
      "step": 19580
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.574763774871826,
      "learning_rate": 2.9983642997944888e-05,
      "loss": 1.0962,
      "step": 19590
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.772655487060547,
      "learning_rate": 2.9973157740217256e-05,
      "loss": 0.9364,
      "step": 19600
    },
    {
      "epoch": 1.22,
      "grad_norm": 12.88363265991211,
      "learning_rate": 2.996267248248962e-05,
      "loss": 0.9857,
      "step": 19610
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.918586254119873,
      "learning_rate": 2.9952187224761984e-05,
      "loss": 1.0898,
      "step": 19620
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.757597923278809,
      "learning_rate": 2.9941701967034352e-05,
      "loss": 1.0771,
      "step": 19630
    },
    {
      "epoch": 1.22,
      "grad_norm": 9.755500793457031,
      "learning_rate": 2.9931216709306714e-05,
      "loss": 1.193,
      "step": 19640
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.07000207901001,
      "learning_rate": 2.9920731451579083e-05,
      "loss": 1.0699,
      "step": 19650
    },
    {
      "epoch": 1.22,
      "grad_norm": 8.939227104187012,
      "learning_rate": 2.9910246193851448e-05,
      "loss": 1.0422,
      "step": 19660
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.660642623901367,
      "learning_rate": 2.989976093612381e-05,
      "loss": 1.0412,
      "step": 19670
    },
    {
      "epoch": 1.23,
      "grad_norm": 9.629459381103516,
      "learning_rate": 2.988927567839618e-05,
      "loss": 1.0628,
      "step": 19680
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.959108352661133,
      "learning_rate": 2.987879042066854e-05,
      "loss": 1.0734,
      "step": 19690
    },
    {
      "epoch": 1.23,
      "grad_norm": 8.124529838562012,
      "learning_rate": 2.9868305162940906e-05,
      "loss": 1.0133,
      "step": 19700
    },
    {
      "epoch": 1.23,
      "grad_norm": 10.097282409667969,
      "learning_rate": 2.9857819905213268e-05,
      "loss": 1.0653,
      "step": 19710
    },
    {
      "epoch": 1.23,
      "grad_norm": 11.92242431640625,
      "learning_rate": 2.9847334647485637e-05,
      "loss": 1.0497,
      "step": 19720
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.952622413635254,
      "learning_rate": 2.9836849389758005e-05,
      "loss": 1.1914,
      "step": 19730
    },
    {
      "epoch": 1.23,
      "grad_norm": 6.504504680633545,
      "learning_rate": 2.9826364132030364e-05,
      "loss": 1.1092,
      "step": 19740
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.795921325683594,
      "learning_rate": 2.9815878874302733e-05,
      "loss": 0.9943,
      "step": 19750
    },
    {
      "epoch": 1.23,
      "grad_norm": 11.721819877624512,
      "learning_rate": 2.9805393616575095e-05,
      "loss": 1.0206,
      "step": 19760
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.906341552734375,
      "learning_rate": 2.9794908358847463e-05,
      "loss": 1.0591,
      "step": 19770
    },
    {
      "epoch": 1.23,
      "grad_norm": 10.228118896484375,
      "learning_rate": 2.978442310111983e-05,
      "loss": 1.0597,
      "step": 19780
    },
    {
      "epoch": 1.23,
      "grad_norm": 5.5288190841674805,
      "learning_rate": 2.977393784339219e-05,
      "loss": 1.013,
      "step": 19790
    },
    {
      "epoch": 1.23,
      "grad_norm": 9.29255485534668,
      "learning_rate": 2.976345258566456e-05,
      "loss": 1.0932,
      "step": 19800
    },
    {
      "epoch": 1.23,
      "grad_norm": 6.143655300140381,
      "learning_rate": 2.975296732793692e-05,
      "loss": 1.0703,
      "step": 19810
    },
    {
      "epoch": 1.23,
      "grad_norm": 8.509398460388184,
      "learning_rate": 2.9742482070209286e-05,
      "loss": 1.0038,
      "step": 19820
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.967399597167969,
      "learning_rate": 2.973199681248165e-05,
      "loss": 1.1645,
      "step": 19830
    },
    {
      "epoch": 1.24,
      "grad_norm": 10.830438613891602,
      "learning_rate": 2.9721511554754017e-05,
      "loss": 1.1633,
      "step": 19840
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.390645503997803,
      "learning_rate": 2.9711026297026386e-05,
      "loss": 1.0338,
      "step": 19850
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.574995994567871,
      "learning_rate": 2.9700541039298748e-05,
      "loss": 1.1851,
      "step": 19860
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.055264949798584,
      "learning_rate": 2.9690055781571113e-05,
      "loss": 1.0637,
      "step": 19870
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.693730354309082,
      "learning_rate": 2.9679570523843475e-05,
      "loss": 1.1511,
      "step": 19880
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.59221363067627,
      "learning_rate": 2.9669085266115844e-05,
      "loss": 1.0776,
      "step": 19890
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.815142631530762,
      "learning_rate": 2.965860000838821e-05,
      "loss": 1.1325,
      "step": 19900
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.088618755340576,
      "learning_rate": 2.964811475066057e-05,
      "loss": 1.0956,
      "step": 19910
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.568929195404053,
      "learning_rate": 2.963762949293294e-05,
      "loss": 1.071,
      "step": 19920
    },
    {
      "epoch": 1.24,
      "grad_norm": 10.801848411560059,
      "learning_rate": 2.96271442352053e-05,
      "loss": 1.1257,
      "step": 19930
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.557962894439697,
      "learning_rate": 2.9616658977477667e-05,
      "loss": 1.0639,
      "step": 19940
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.396078586578369,
      "learning_rate": 2.9606173719750035e-05,
      "loss": 1.057,
      "step": 19950
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.747735500335693,
      "learning_rate": 2.9595688462022397e-05,
      "loss": 1.1747,
      "step": 19960
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.938424587249756,
      "learning_rate": 2.9585203204294766e-05,
      "loss": 1.0412,
      "step": 19970
    },
    {
      "epoch": 1.24,
      "grad_norm": 12.374845504760742,
      "learning_rate": 2.9574717946567128e-05,
      "loss": 1.0531,
      "step": 19980
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.2397990226745605,
      "learning_rate": 2.9564232688839493e-05,
      "loss": 1.1322,
      "step": 19990
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.157623291015625,
      "learning_rate": 2.9553747431111855e-05,
      "loss": 1.031,
      "step": 20000
    },
    {
      "epoch": 1.25,
      "grad_norm": 9.343721389770508,
      "learning_rate": 2.9543262173384224e-05,
      "loss": 1.0253,
      "step": 20010
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.219465255737305,
      "learning_rate": 2.953277691565659e-05,
      "loss": 1.0925,
      "step": 20020
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.80947732925415,
      "learning_rate": 2.952229165792895e-05,
      "loss": 1.0198,
      "step": 20030
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.21784496307373,
      "learning_rate": 2.951180640020132e-05,
      "loss": 1.0563,
      "step": 20040
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.473552703857422,
      "learning_rate": 2.9501321142473682e-05,
      "loss": 1.1342,
      "step": 20050
    },
    {
      "epoch": 1.25,
      "grad_norm": 11.13673210144043,
      "learning_rate": 2.9490835884746047e-05,
      "loss": 1.1822,
      "step": 20060
    },
    {
      "epoch": 1.25,
      "grad_norm": 12.01889419555664,
      "learning_rate": 2.9480350627018416e-05,
      "loss": 1.0806,
      "step": 20070
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.603291034698486,
      "learning_rate": 2.9469865369290778e-05,
      "loss": 1.0275,
      "step": 20080
    },
    {
      "epoch": 1.25,
      "grad_norm": 9.631589889526367,
      "learning_rate": 2.9459380111563146e-05,
      "loss": 1.1439,
      "step": 20090
    },
    {
      "epoch": 1.25,
      "grad_norm": 11.420183181762695,
      "learning_rate": 2.9448894853835508e-05,
      "loss": 1.0187,
      "step": 20100
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.609827041625977,
      "learning_rate": 2.9438409596107874e-05,
      "loss": 1.1067,
      "step": 20110
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.773530006408691,
      "learning_rate": 2.9427924338380236e-05,
      "loss": 1.1218,
      "step": 20120
    },
    {
      "epoch": 1.25,
      "grad_norm": 9.814214706420898,
      "learning_rate": 2.9417439080652604e-05,
      "loss": 1.0477,
      "step": 20130
    },
    {
      "epoch": 1.25,
      "grad_norm": 9.067204475402832,
      "learning_rate": 2.940695382292497e-05,
      "loss": 1.1327,
      "step": 20140
    },
    {
      "epoch": 1.25,
      "grad_norm": 7.148306846618652,
      "learning_rate": 2.939646856519733e-05,
      "loss": 1.1314,
      "step": 20150
    },
    {
      "epoch": 1.26,
      "grad_norm": 10.408884048461914,
      "learning_rate": 2.93859833074697e-05,
      "loss": 1.2402,
      "step": 20160
    },
    {
      "epoch": 1.26,
      "grad_norm": 6.733534812927246,
      "learning_rate": 2.9375498049742062e-05,
      "loss": 1.0976,
      "step": 20170
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.5656256675720215,
      "learning_rate": 2.936501279201443e-05,
      "loss": 1.1222,
      "step": 20180
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.80931282043457,
      "learning_rate": 2.9354527534286796e-05,
      "loss": 1.041,
      "step": 20190
    },
    {
      "epoch": 1.26,
      "grad_norm": 9.260763168334961,
      "learning_rate": 2.9344042276559158e-05,
      "loss": 1.0258,
      "step": 20200
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.014377593994141,
      "learning_rate": 2.9333557018831527e-05,
      "loss": 1.0939,
      "step": 20210
    },
    {
      "epoch": 1.26,
      "grad_norm": 8.445892333984375,
      "learning_rate": 2.932307176110389e-05,
      "loss": 1.0067,
      "step": 20220
    },
    {
      "epoch": 1.26,
      "grad_norm": 9.010719299316406,
      "learning_rate": 2.9312586503376254e-05,
      "loss": 1.0413,
      "step": 20230
    },
    {
      "epoch": 1.26,
      "grad_norm": 8.75404167175293,
      "learning_rate": 2.9302101245648623e-05,
      "loss": 1.0507,
      "step": 20240
    },
    {
      "epoch": 1.26,
      "grad_norm": 8.806269645690918,
      "learning_rate": 2.9291615987920985e-05,
      "loss": 1.0179,
      "step": 20250
    },
    {
      "epoch": 1.26,
      "grad_norm": 8.519206047058105,
      "learning_rate": 2.928113073019335e-05,
      "loss": 1.0725,
      "step": 20260
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.966379642486572,
      "learning_rate": 2.9270645472465712e-05,
      "loss": 1.0014,
      "step": 20270
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.479089260101318,
      "learning_rate": 2.926016021473808e-05,
      "loss": 1.0195,
      "step": 20280
    },
    {
      "epoch": 1.26,
      "grad_norm": 9.528945922851562,
      "learning_rate": 2.9249674957010442e-05,
      "loss": 1.1078,
      "step": 20290
    },
    {
      "epoch": 1.26,
      "grad_norm": 10.717573165893555,
      "learning_rate": 2.923918969928281e-05,
      "loss": 1.0404,
      "step": 20300
    },
    {
      "epoch": 1.26,
      "grad_norm": 10.278535842895508,
      "learning_rate": 2.9228704441555176e-05,
      "loss": 0.991,
      "step": 20310
    },
    {
      "epoch": 1.27,
      "grad_norm": 9.60167407989502,
      "learning_rate": 2.921821918382754e-05,
      "loss": 0.9077,
      "step": 20320
    },
    {
      "epoch": 1.27,
      "grad_norm": 8.834551811218262,
      "learning_rate": 2.9207733926099907e-05,
      "loss": 1.1239,
      "step": 20330
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.691263675689697,
      "learning_rate": 2.919724866837227e-05,
      "loss": 0.9473,
      "step": 20340
    },
    {
      "epoch": 1.27,
      "grad_norm": 5.118223667144775,
      "learning_rate": 2.9186763410644634e-05,
      "loss": 1.0284,
      "step": 20350
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.489189624786377,
      "learning_rate": 2.9176278152917003e-05,
      "loss": 1.215,
      "step": 20360
    },
    {
      "epoch": 1.27,
      "grad_norm": 6.584977149963379,
      "learning_rate": 2.9165792895189365e-05,
      "loss": 1.0533,
      "step": 20370
    },
    {
      "epoch": 1.27,
      "grad_norm": 5.170478820800781,
      "learning_rate": 2.915530763746173e-05,
      "loss": 1.044,
      "step": 20380
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.991816997528076,
      "learning_rate": 2.9144822379734092e-05,
      "loss": 1.1567,
      "step": 20390
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.8429036140441895,
      "learning_rate": 2.913433712200646e-05,
      "loss": 1.1445,
      "step": 20400
    },
    {
      "epoch": 1.27,
      "grad_norm": 10.9638090133667,
      "learning_rate": 2.9123851864278823e-05,
      "loss": 1.0754,
      "step": 20410
    },
    {
      "epoch": 1.27,
      "grad_norm": 8.540763854980469,
      "learning_rate": 2.911336660655119e-05,
      "loss": 0.8953,
      "step": 20420
    },
    {
      "epoch": 1.27,
      "grad_norm": 9.724105834960938,
      "learning_rate": 2.9102881348823557e-05,
      "loss": 1.1366,
      "step": 20430
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.802448749542236,
      "learning_rate": 2.909239609109592e-05,
      "loss": 0.9919,
      "step": 20440
    },
    {
      "epoch": 1.27,
      "grad_norm": 6.8947577476501465,
      "learning_rate": 2.9081910833368287e-05,
      "loss": 1.0309,
      "step": 20450
    },
    {
      "epoch": 1.27,
      "grad_norm": 9.654067993164062,
      "learning_rate": 2.907142557564065e-05,
      "loss": 1.0474,
      "step": 20460
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.299890995025635,
      "learning_rate": 2.9060940317913015e-05,
      "loss": 0.9366,
      "step": 20470
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.529394149780273,
      "learning_rate": 2.9050455060185383e-05,
      "loss": 1.0515,
      "step": 20480
    },
    {
      "epoch": 1.28,
      "grad_norm": 11.925285339355469,
      "learning_rate": 2.9039969802457745e-05,
      "loss": 1.1032,
      "step": 20490
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.793611526489258,
      "learning_rate": 2.9029484544730114e-05,
      "loss": 1.0675,
      "step": 20500
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.567746639251709,
      "learning_rate": 2.9018999287002472e-05,
      "loss": 1.0547,
      "step": 20510
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.824830055236816,
      "learning_rate": 2.900851402927484e-05,
      "loss": 1.0271,
      "step": 20520
    },
    {
      "epoch": 1.28,
      "grad_norm": 9.634027481079102,
      "learning_rate": 2.899802877154721e-05,
      "loss": 1.0561,
      "step": 20530
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.685092926025391,
      "learning_rate": 2.8987543513819572e-05,
      "loss": 1.1754,
      "step": 20540
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.753783226013184,
      "learning_rate": 2.8977058256091937e-05,
      "loss": 1.1059,
      "step": 20550
    },
    {
      "epoch": 1.28,
      "grad_norm": 10.36639404296875,
      "learning_rate": 2.89665729983643e-05,
      "loss": 1.0757,
      "step": 20560
    },
    {
      "epoch": 1.28,
      "grad_norm": 9.501114845275879,
      "learning_rate": 2.8956087740636668e-05,
      "loss": 1.1021,
      "step": 20570
    },
    {
      "epoch": 1.28,
      "grad_norm": 10.361610412597656,
      "learning_rate": 2.894560248290903e-05,
      "loss": 1.0974,
      "step": 20580
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.525758743286133,
      "learning_rate": 2.8935117225181395e-05,
      "loss": 1.1088,
      "step": 20590
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.864447593688965,
      "learning_rate": 2.8924631967453764e-05,
      "loss": 0.9888,
      "step": 20600
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.307167053222656,
      "learning_rate": 2.8914146709726126e-05,
      "loss": 1.0664,
      "step": 20610
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.834287166595459,
      "learning_rate": 2.8903661451998494e-05,
      "loss": 0.9896,
      "step": 20620
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.292575836181641,
      "learning_rate": 2.8893176194270856e-05,
      "loss": 1.0122,
      "step": 20630
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.837017059326172,
      "learning_rate": 2.888269093654322e-05,
      "loss": 1.002,
      "step": 20640
    },
    {
      "epoch": 1.29,
      "grad_norm": 6.607808589935303,
      "learning_rate": 2.887220567881559e-05,
      "loss": 1.0908,
      "step": 20650
    },
    {
      "epoch": 1.29,
      "grad_norm": 10.693851470947266,
      "learning_rate": 2.8861720421087952e-05,
      "loss": 1.1809,
      "step": 20660
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.876513481140137,
      "learning_rate": 2.8851235163360317e-05,
      "loss": 1.0604,
      "step": 20670
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.04094409942627,
      "learning_rate": 2.884074990563268e-05,
      "loss": 1.0634,
      "step": 20680
    },
    {
      "epoch": 1.29,
      "grad_norm": 8.893064498901367,
      "learning_rate": 2.8830264647905048e-05,
      "loss": 1.0084,
      "step": 20690
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.066076755523682,
      "learning_rate": 2.881977939017741e-05,
      "loss": 0.982,
      "step": 20700
    },
    {
      "epoch": 1.29,
      "grad_norm": 8.935708999633789,
      "learning_rate": 2.8809294132449775e-05,
      "loss": 1.0167,
      "step": 20710
    },
    {
      "epoch": 1.29,
      "grad_norm": 10.174418449401855,
      "learning_rate": 2.8798808874722144e-05,
      "loss": 1.0607,
      "step": 20720
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.577498435974121,
      "learning_rate": 2.8788323616994506e-05,
      "loss": 1.1447,
      "step": 20730
    },
    {
      "epoch": 1.29,
      "grad_norm": 6.569254398345947,
      "learning_rate": 2.8777838359266875e-05,
      "loss": 1.1956,
      "step": 20740
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.809440612792969,
      "learning_rate": 2.8767353101539237e-05,
      "loss": 1.1074,
      "step": 20750
    },
    {
      "epoch": 1.29,
      "grad_norm": 8.623529434204102,
      "learning_rate": 2.8756867843811602e-05,
      "loss": 1.0204,
      "step": 20760
    },
    {
      "epoch": 1.29,
      "grad_norm": 10.08493709564209,
      "learning_rate": 2.874638258608397e-05,
      "loss": 1.0053,
      "step": 20770
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.652552127838135,
      "learning_rate": 2.8735897328356332e-05,
      "loss": 1.0073,
      "step": 20780
    },
    {
      "epoch": 1.29,
      "grad_norm": 14.152436256408691,
      "learning_rate": 2.8725412070628698e-05,
      "loss": 1.1149,
      "step": 20790
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.458731651306152,
      "learning_rate": 2.871492681290106e-05,
      "loss": 1.1864,
      "step": 20800
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.224536895751953,
      "learning_rate": 2.870444155517343e-05,
      "loss": 1.149,
      "step": 20810
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.876987457275391,
      "learning_rate": 2.869395629744579e-05,
      "loss": 1.0271,
      "step": 20820
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.609213829040527,
      "learning_rate": 2.8683471039718156e-05,
      "loss": 1.0277,
      "step": 20830
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.46662712097168,
      "learning_rate": 2.8672985781990524e-05,
      "loss": 1.1372,
      "step": 20840
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.2057523727417,
      "learning_rate": 2.8662500524262886e-05,
      "loss": 1.1541,
      "step": 20850
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.146598815917969,
      "learning_rate": 2.8652015266535255e-05,
      "loss": 1.1215,
      "step": 20860
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.404031753540039,
      "learning_rate": 2.8641530008807617e-05,
      "loss": 1.0118,
      "step": 20870
    },
    {
      "epoch": 1.3,
      "grad_norm": 5.897614479064941,
      "learning_rate": 2.8631044751079982e-05,
      "loss": 1.1701,
      "step": 20880
    },
    {
      "epoch": 1.3,
      "grad_norm": 9.023932456970215,
      "learning_rate": 2.862055949335235e-05,
      "loss": 0.9938,
      "step": 20890
    },
    {
      "epoch": 1.3,
      "grad_norm": 6.996375560760498,
      "learning_rate": 2.8610074235624713e-05,
      "loss": 1.0238,
      "step": 20900
    },
    {
      "epoch": 1.3,
      "grad_norm": 6.131298542022705,
      "learning_rate": 2.8599588977897078e-05,
      "loss": 0.987,
      "step": 20910
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.499235153198242,
      "learning_rate": 2.858910372016944e-05,
      "loss": 1.1201,
      "step": 20920
    },
    {
      "epoch": 1.3,
      "grad_norm": 11.32872486114502,
      "learning_rate": 2.857861846244181e-05,
      "loss": 1.1764,
      "step": 20930
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.432507514953613,
      "learning_rate": 2.8568133204714177e-05,
      "loss": 1.2519,
      "step": 20940
    },
    {
      "epoch": 1.3,
      "grad_norm": 8.529020309448242,
      "learning_rate": 2.855764794698654e-05,
      "loss": 1.0143,
      "step": 20950
    },
    {
      "epoch": 1.3,
      "grad_norm": 6.116822719573975,
      "learning_rate": 2.8547162689258905e-05,
      "loss": 1.1315,
      "step": 20960
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.278744220733643,
      "learning_rate": 2.8536677431531267e-05,
      "loss": 1.0536,
      "step": 20970
    },
    {
      "epoch": 1.31,
      "grad_norm": 11.272228240966797,
      "learning_rate": 2.8526192173803635e-05,
      "loss": 1.0726,
      "step": 20980
    },
    {
      "epoch": 1.31,
      "grad_norm": 13.036853790283203,
      "learning_rate": 2.8515706916075997e-05,
      "loss": 1.0593,
      "step": 20990
    },
    {
      "epoch": 1.31,
      "grad_norm": 8.052177429199219,
      "learning_rate": 2.8505221658348362e-05,
      "loss": 1.0498,
      "step": 21000
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.583621501922607,
      "learning_rate": 2.849473640062073e-05,
      "loss": 0.9191,
      "step": 21010
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.764366626739502,
      "learning_rate": 2.8484251142893093e-05,
      "loss": 1.0643,
      "step": 21020
    },
    {
      "epoch": 1.31,
      "grad_norm": 9.169537544250488,
      "learning_rate": 2.847376588516546e-05,
      "loss": 1.155,
      "step": 21030
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.965972900390625,
      "learning_rate": 2.846328062743782e-05,
      "loss": 1.1386,
      "step": 21040
    },
    {
      "epoch": 1.31,
      "grad_norm": 9.025809288024902,
      "learning_rate": 2.845279536971019e-05,
      "loss": 1.1532,
      "step": 21050
    },
    {
      "epoch": 1.31,
      "grad_norm": 13.922898292541504,
      "learning_rate": 2.8442310111982558e-05,
      "loss": 1.099,
      "step": 21060
    },
    {
      "epoch": 1.31,
      "grad_norm": 8.64453125,
      "learning_rate": 2.843182485425492e-05,
      "loss": 1.1367,
      "step": 21070
    },
    {
      "epoch": 1.31,
      "grad_norm": 10.922710418701172,
      "learning_rate": 2.8421339596527285e-05,
      "loss": 1.0975,
      "step": 21080
    },
    {
      "epoch": 1.31,
      "grad_norm": 11.539517402648926,
      "learning_rate": 2.8410854338799647e-05,
      "loss": 1.0614,
      "step": 21090
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.795598030090332,
      "learning_rate": 2.8400369081072016e-05,
      "loss": 1.042,
      "step": 21100
    },
    {
      "epoch": 1.31,
      "grad_norm": 8.899646759033203,
      "learning_rate": 2.8389883823344377e-05,
      "loss": 1.1864,
      "step": 21110
    },
    {
      "epoch": 1.31,
      "grad_norm": 9.919028282165527,
      "learning_rate": 2.8379398565616743e-05,
      "loss": 1.1302,
      "step": 21120
    },
    {
      "epoch": 1.32,
      "grad_norm": 10.683243751525879,
      "learning_rate": 2.836891330788911e-05,
      "loss": 1.1191,
      "step": 21130
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.945775032043457,
      "learning_rate": 2.8358428050161473e-05,
      "loss": 1.0942,
      "step": 21140
    },
    {
      "epoch": 1.32,
      "grad_norm": 8.11153793334961,
      "learning_rate": 2.834794279243384e-05,
      "loss": 1.0863,
      "step": 21150
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.052339553833008,
      "learning_rate": 2.83374575347062e-05,
      "loss": 0.9756,
      "step": 21160
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.879332542419434,
      "learning_rate": 2.832697227697857e-05,
      "loss": 1.0517,
      "step": 21170
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.611351013183594,
      "learning_rate": 2.8316487019250938e-05,
      "loss": 1.01,
      "step": 21180
    },
    {
      "epoch": 1.32,
      "grad_norm": 8.730006217956543,
      "learning_rate": 2.83060017615233e-05,
      "loss": 1.0897,
      "step": 21190
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.577938079833984,
      "learning_rate": 2.8295516503795665e-05,
      "loss": 0.9862,
      "step": 21200
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.6070556640625,
      "learning_rate": 2.8285031246068027e-05,
      "loss": 1.043,
      "step": 21210
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.11237907409668,
      "learning_rate": 2.8274545988340396e-05,
      "loss": 1.1557,
      "step": 21220
    },
    {
      "epoch": 1.32,
      "grad_norm": 8.175703048706055,
      "learning_rate": 2.826406073061276e-05,
      "loss": 1.2732,
      "step": 21230
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.093838691711426,
      "learning_rate": 2.8253575472885123e-05,
      "loss": 1.1494,
      "step": 21240
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.91074275970459,
      "learning_rate": 2.8243090215157492e-05,
      "loss": 1.0782,
      "step": 21250
    },
    {
      "epoch": 1.32,
      "grad_norm": 8.12039852142334,
      "learning_rate": 2.8232604957429854e-05,
      "loss": 0.9764,
      "step": 21260
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.36227560043335,
      "learning_rate": 2.8222119699702222e-05,
      "loss": 1.1179,
      "step": 21270
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.245569229125977,
      "learning_rate": 2.821163444197458e-05,
      "loss": 1.1541,
      "step": 21280
    },
    {
      "epoch": 1.33,
      "grad_norm": 10.657949447631836,
      "learning_rate": 2.820114918424695e-05,
      "loss": 1.0543,
      "step": 21290
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.265375137329102,
      "learning_rate": 2.819066392651932e-05,
      "loss": 1.2126,
      "step": 21300
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.772805213928223,
      "learning_rate": 2.818017866879168e-05,
      "loss": 0.9423,
      "step": 21310
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.586384773254395,
      "learning_rate": 2.8169693411064046e-05,
      "loss": 1.0849,
      "step": 21320
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.927781105041504,
      "learning_rate": 2.8159208153336408e-05,
      "loss": 0.9952,
      "step": 21330
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.583362102508545,
      "learning_rate": 2.8148722895608776e-05,
      "loss": 1.0851,
      "step": 21340
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.967491626739502,
      "learning_rate": 2.813823763788114e-05,
      "loss": 0.9786,
      "step": 21350
    },
    {
      "epoch": 1.33,
      "grad_norm": 13.370940208435059,
      "learning_rate": 2.8127752380153503e-05,
      "loss": 1.0661,
      "step": 21360
    },
    {
      "epoch": 1.33,
      "grad_norm": 9.880836486816406,
      "learning_rate": 2.8117267122425872e-05,
      "loss": 1.0697,
      "step": 21370
    },
    {
      "epoch": 1.33,
      "grad_norm": 10.803092956542969,
      "learning_rate": 2.8106781864698234e-05,
      "loss": 1.1533,
      "step": 21380
    },
    {
      "epoch": 1.33,
      "grad_norm": 9.952351570129395,
      "learning_rate": 2.8096296606970603e-05,
      "loss": 1.0873,
      "step": 21390
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.364868640899658,
      "learning_rate": 2.8085811349242965e-05,
      "loss": 1.0227,
      "step": 21400
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.86871337890625,
      "learning_rate": 2.807532609151533e-05,
      "loss": 1.0076,
      "step": 21410
    },
    {
      "epoch": 1.33,
      "grad_norm": 7.070889949798584,
      "learning_rate": 2.80648408337877e-05,
      "loss": 1.0686,
      "step": 21420
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.021263122558594,
      "learning_rate": 2.805435557606006e-05,
      "loss": 1.0056,
      "step": 21430
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.086273193359375,
      "learning_rate": 2.8043870318332426e-05,
      "loss": 1.1151,
      "step": 21440
    },
    {
      "epoch": 1.34,
      "grad_norm": 12.064885139465332,
      "learning_rate": 2.8033385060604788e-05,
      "loss": 1.1808,
      "step": 21450
    },
    {
      "epoch": 1.34,
      "grad_norm": 9.19523811340332,
      "learning_rate": 2.8022899802877157e-05,
      "loss": 1.0512,
      "step": 21460
    },
    {
      "epoch": 1.34,
      "grad_norm": 8.40627670288086,
      "learning_rate": 2.8012414545149522e-05,
      "loss": 1.038,
      "step": 21470
    },
    {
      "epoch": 1.34,
      "grad_norm": 5.9701433181762695,
      "learning_rate": 2.8001929287421884e-05,
      "loss": 1.0447,
      "step": 21480
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.437310218811035,
      "learning_rate": 2.7991444029694252e-05,
      "loss": 1.0939,
      "step": 21490
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.61925745010376,
      "learning_rate": 2.7980958771966614e-05,
      "loss": 1.1702,
      "step": 21500
    },
    {
      "epoch": 1.34,
      "grad_norm": 13.222803115844727,
      "learning_rate": 2.7970473514238983e-05,
      "loss": 1.0962,
      "step": 21510
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.256011486053467,
      "learning_rate": 2.795998825651135e-05,
      "loss": 1.0251,
      "step": 21520
    },
    {
      "epoch": 1.34,
      "grad_norm": 9.925783157348633,
      "learning_rate": 2.794950299878371e-05,
      "loss": 1.1023,
      "step": 21530
    },
    {
      "epoch": 1.34,
      "grad_norm": 5.343794345855713,
      "learning_rate": 2.793901774105608e-05,
      "loss": 1.0783,
      "step": 21540
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.352564811706543,
      "learning_rate": 2.792853248332844e-05,
      "loss": 1.0153,
      "step": 21550
    },
    {
      "epoch": 1.34,
      "grad_norm": 8.200241088867188,
      "learning_rate": 2.7918047225600806e-05,
      "loss": 1.0925,
      "step": 21560
    },
    {
      "epoch": 1.34,
      "grad_norm": 8.348105430603027,
      "learning_rate": 2.7907561967873168e-05,
      "loss": 1.1563,
      "step": 21570
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.103372097015381,
      "learning_rate": 2.7897076710145537e-05,
      "loss": 1.2519,
      "step": 21580
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.864941120147705,
      "learning_rate": 2.7886591452417906e-05,
      "loss": 1.0661,
      "step": 21590
    },
    {
      "epoch": 1.34,
      "grad_norm": 9.967818260192871,
      "learning_rate": 2.7876106194690264e-05,
      "loss": 1.0911,
      "step": 21600
    },
    {
      "epoch": 1.35,
      "grad_norm": 11.140654563903809,
      "learning_rate": 2.7865620936962633e-05,
      "loss": 1.1299,
      "step": 21610
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.005109786987305,
      "learning_rate": 2.7855135679234995e-05,
      "loss": 1.0213,
      "step": 21620
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.296653747558594,
      "learning_rate": 2.7844650421507363e-05,
      "loss": 0.9897,
      "step": 21630
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.99538516998291,
      "learning_rate": 2.783416516377973e-05,
      "loss": 1.0056,
      "step": 21640
    },
    {
      "epoch": 1.35,
      "grad_norm": 9.309890747070312,
      "learning_rate": 2.782367990605209e-05,
      "loss": 0.9973,
      "step": 21650
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.495670795440674,
      "learning_rate": 2.781319464832446e-05,
      "loss": 0.9863,
      "step": 21660
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.268576622009277,
      "learning_rate": 2.780270939059682e-05,
      "loss": 1.0293,
      "step": 21670
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.593349456787109,
      "learning_rate": 2.7792224132869187e-05,
      "loss": 1.0477,
      "step": 21680
    },
    {
      "epoch": 1.35,
      "grad_norm": 9.404111862182617,
      "learning_rate": 2.778173887514155e-05,
      "loss": 1.0139,
      "step": 21690
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.375672817230225,
      "learning_rate": 2.7771253617413917e-05,
      "loss": 1.0315,
      "step": 21700
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.926538467407227,
      "learning_rate": 2.7760768359686286e-05,
      "loss": 1.1442,
      "step": 21710
    },
    {
      "epoch": 1.35,
      "grad_norm": 8.027933120727539,
      "learning_rate": 2.7750283101958648e-05,
      "loss": 1.1596,
      "step": 21720
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.735569477081299,
      "learning_rate": 2.7739797844231013e-05,
      "loss": 1.0511,
      "step": 21730
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.450543403625488,
      "learning_rate": 2.7729312586503375e-05,
      "loss": 1.0946,
      "step": 21740
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.115671157836914,
      "learning_rate": 2.7718827328775744e-05,
      "loss": 1.0925,
      "step": 21750
    },
    {
      "epoch": 1.35,
      "grad_norm": 7.391927719116211,
      "learning_rate": 2.770834207104811e-05,
      "loss": 1.1421,
      "step": 21760
    },
    {
      "epoch": 1.36,
      "grad_norm": 8.972744941711426,
      "learning_rate": 2.769785681332047e-05,
      "loss": 1.2648,
      "step": 21770
    },
    {
      "epoch": 1.36,
      "grad_norm": 7.831534385681152,
      "learning_rate": 2.768737155559284e-05,
      "loss": 1.0183,
      "step": 21780
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.2714762687683105,
      "learning_rate": 2.76768862978652e-05,
      "loss": 1.0682,
      "step": 21790
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.2731828689575195,
      "learning_rate": 2.7666401040137567e-05,
      "loss": 1.0485,
      "step": 21800
    },
    {
      "epoch": 1.36,
      "grad_norm": 9.70999813079834,
      "learning_rate": 2.765591578240993e-05,
      "loss": 1.0949,
      "step": 21810
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.6994242668151855,
      "learning_rate": 2.7645430524682298e-05,
      "loss": 1.0249,
      "step": 21820
    },
    {
      "epoch": 1.36,
      "grad_norm": 5.238098621368408,
      "learning_rate": 2.7634945266954666e-05,
      "loss": 1.1018,
      "step": 21830
    },
    {
      "epoch": 1.36,
      "grad_norm": 8.260998725891113,
      "learning_rate": 2.7624460009227028e-05,
      "loss": 1.1235,
      "step": 21840
    },
    {
      "epoch": 1.36,
      "grad_norm": 12.73275089263916,
      "learning_rate": 2.7613974751499393e-05,
      "loss": 1.1756,
      "step": 21850
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.414995193481445,
      "learning_rate": 2.7603489493771755e-05,
      "loss": 0.9817,
      "step": 21860
    },
    {
      "epoch": 1.36,
      "grad_norm": 10.600454330444336,
      "learning_rate": 2.7593004236044124e-05,
      "loss": 1.0432,
      "step": 21870
    },
    {
      "epoch": 1.36,
      "grad_norm": 9.616048812866211,
      "learning_rate": 2.758251897831649e-05,
      "loss": 1.0677,
      "step": 21880
    },
    {
      "epoch": 1.36,
      "grad_norm": 7.288463592529297,
      "learning_rate": 2.757203372058885e-05,
      "loss": 1.087,
      "step": 21890
    },
    {
      "epoch": 1.36,
      "grad_norm": 12.991548538208008,
      "learning_rate": 2.756154846286122e-05,
      "loss": 1.0168,
      "step": 21900
    },
    {
      "epoch": 1.36,
      "grad_norm": 9.676295280456543,
      "learning_rate": 2.7551063205133582e-05,
      "loss": 1.031,
      "step": 21910
    },
    {
      "epoch": 1.36,
      "grad_norm": 13.475669860839844,
      "learning_rate": 2.7540577947405947e-05,
      "loss": 1.0205,
      "step": 21920
    },
    {
      "epoch": 1.37,
      "grad_norm": 6.9444427490234375,
      "learning_rate": 2.7530092689678316e-05,
      "loss": 1.0071,
      "step": 21930
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.5712890625,
      "learning_rate": 2.7519607431950678e-05,
      "loss": 1.0112,
      "step": 21940
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.873093128204346,
      "learning_rate": 2.7509122174223047e-05,
      "loss": 1.0244,
      "step": 21950
    },
    {
      "epoch": 1.37,
      "grad_norm": 10.822381973266602,
      "learning_rate": 2.749863691649541e-05,
      "loss": 1.1744,
      "step": 21960
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.313531398773193,
      "learning_rate": 2.7488151658767774e-05,
      "loss": 1.0362,
      "step": 21970
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.387580871582031,
      "learning_rate": 2.7477666401040136e-05,
      "loss": 1.0817,
      "step": 21980
    },
    {
      "epoch": 1.37,
      "grad_norm": 8.581122398376465,
      "learning_rate": 2.7467181143312504e-05,
      "loss": 1.1459,
      "step": 21990
    },
    {
      "epoch": 1.37,
      "grad_norm": 9.207457542419434,
      "learning_rate": 2.745669588558487e-05,
      "loss": 1.0102,
      "step": 22000
    },
    {
      "epoch": 1.37,
      "grad_norm": 10.309103965759277,
      "learning_rate": 2.744621062785723e-05,
      "loss": 1.1554,
      "step": 22010
    },
    {
      "epoch": 1.37,
      "grad_norm": 5.055502891540527,
      "learning_rate": 2.74357253701296e-05,
      "loss": 1.0132,
      "step": 22020
    },
    {
      "epoch": 1.37,
      "grad_norm": 6.951822757720947,
      "learning_rate": 2.7425240112401962e-05,
      "loss": 1.1391,
      "step": 22030
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.236708641052246,
      "learning_rate": 2.741475485467433e-05,
      "loss": 1.0294,
      "step": 22040
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.8387346267700195,
      "learning_rate": 2.7404269596946696e-05,
      "loss": 1.1649,
      "step": 22050
    },
    {
      "epoch": 1.37,
      "grad_norm": 10.602311134338379,
      "learning_rate": 2.7393784339219058e-05,
      "loss": 1.1496,
      "step": 22060
    },
    {
      "epoch": 1.37,
      "grad_norm": 7.951902389526367,
      "learning_rate": 2.7383299081491427e-05,
      "loss": 1.1249,
      "step": 22070
    },
    {
      "epoch": 1.37,
      "grad_norm": 6.981510639190674,
      "learning_rate": 2.737281382376379e-05,
      "loss": 1.0477,
      "step": 22080
    },
    {
      "epoch": 1.38,
      "grad_norm": 7.0805158615112305,
      "learning_rate": 2.7362328566036154e-05,
      "loss": 1.0967,
      "step": 22090
    },
    {
      "epoch": 1.38,
      "grad_norm": 4.474503993988037,
      "learning_rate": 2.7351843308308516e-05,
      "loss": 0.9475,
      "step": 22100
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.243046760559082,
      "learning_rate": 2.7341358050580885e-05,
      "loss": 1.0289,
      "step": 22110
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.801461219787598,
      "learning_rate": 2.733087279285325e-05,
      "loss": 1.073,
      "step": 22120
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.026809692382812,
      "learning_rate": 2.7320387535125612e-05,
      "loss": 1.0265,
      "step": 22130
    },
    {
      "epoch": 1.38,
      "grad_norm": 5.64516019821167,
      "learning_rate": 2.730990227739798e-05,
      "loss": 1.1427,
      "step": 22140
    },
    {
      "epoch": 1.38,
      "grad_norm": 8.400931358337402,
      "learning_rate": 2.7299417019670343e-05,
      "loss": 1.0356,
      "step": 22150
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.73874282836914,
      "learning_rate": 2.728893176194271e-05,
      "loss": 1.1919,
      "step": 22160
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.887283325195312,
      "learning_rate": 2.7278446504215077e-05,
      "loss": 1.0744,
      "step": 22170
    },
    {
      "epoch": 1.38,
      "grad_norm": 7.81602144241333,
      "learning_rate": 2.726796124648744e-05,
      "loss": 1.1167,
      "step": 22180
    },
    {
      "epoch": 1.38,
      "grad_norm": 8.334489822387695,
      "learning_rate": 2.7257475988759807e-05,
      "loss": 1.1675,
      "step": 22190
    },
    {
      "epoch": 1.38,
      "grad_norm": 5.908500671386719,
      "learning_rate": 2.724699073103217e-05,
      "loss": 1.0241,
      "step": 22200
    },
    {
      "epoch": 1.38,
      "grad_norm": 7.3678131103515625,
      "learning_rate": 2.7236505473304534e-05,
      "loss": 1.0254,
      "step": 22210
    },
    {
      "epoch": 1.38,
      "grad_norm": 8.703622817993164,
      "learning_rate": 2.7226020215576903e-05,
      "loss": 1.1267,
      "step": 22220
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.238885879516602,
      "learning_rate": 2.7215534957849265e-05,
      "loss": 1.1057,
      "step": 22230
    },
    {
      "epoch": 1.38,
      "grad_norm": 9.4513521194458,
      "learning_rate": 2.720504970012163e-05,
      "loss": 1.204,
      "step": 22240
    },
    {
      "epoch": 1.39,
      "grad_norm": 7.675823211669922,
      "learning_rate": 2.7194564442393992e-05,
      "loss": 1.0251,
      "step": 22250
    },
    {
      "epoch": 1.39,
      "grad_norm": 9.518019676208496,
      "learning_rate": 2.718407918466636e-05,
      "loss": 1.1155,
      "step": 22260
    },
    {
      "epoch": 1.39,
      "grad_norm": 5.613649368286133,
      "learning_rate": 2.7173593926938723e-05,
      "loss": 1.0083,
      "step": 22270
    },
    {
      "epoch": 1.39,
      "grad_norm": 9.621891975402832,
      "learning_rate": 2.716310866921109e-05,
      "loss": 1.1344,
      "step": 22280
    },
    {
      "epoch": 1.39,
      "grad_norm": 8.308338165283203,
      "learning_rate": 2.7152623411483457e-05,
      "loss": 1.0252,
      "step": 22290
    },
    {
      "epoch": 1.39,
      "grad_norm": 7.245183944702148,
      "learning_rate": 2.714213815375582e-05,
      "loss": 1.0444,
      "step": 22300
    },
    {
      "epoch": 1.39,
      "grad_norm": 8.050219535827637,
      "learning_rate": 2.7131652896028188e-05,
      "loss": 1.0178,
      "step": 22310
    },
    {
      "epoch": 1.39,
      "grad_norm": 12.675220489501953,
      "learning_rate": 2.712116763830055e-05,
      "loss": 1.1464,
      "step": 22320
    },
    {
      "epoch": 1.39,
      "grad_norm": 10.156700134277344,
      "learning_rate": 2.7110682380572915e-05,
      "loss": 1.2449,
      "step": 22330
    },
    {
      "epoch": 1.39,
      "grad_norm": 10.403313636779785,
      "learning_rate": 2.7100197122845284e-05,
      "loss": 0.9401,
      "step": 22340
    },
    {
      "epoch": 1.39,
      "grad_norm": 9.057748794555664,
      "learning_rate": 2.7089711865117645e-05,
      "loss": 1.0527,
      "step": 22350
    },
    {
      "epoch": 1.39,
      "grad_norm": 8.663418769836426,
      "learning_rate": 2.7079226607390014e-05,
      "loss": 1.0492,
      "step": 22360
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.844207763671875,
      "learning_rate": 2.7068741349662373e-05,
      "loss": 1.0903,
      "step": 22370
    },
    {
      "epoch": 1.39,
      "grad_norm": 9.776312828063965,
      "learning_rate": 2.705825609193474e-05,
      "loss": 1.1184,
      "step": 22380
    },
    {
      "epoch": 1.39,
      "grad_norm": 8.339829444885254,
      "learning_rate": 2.7047770834207103e-05,
      "loss": 1.0707,
      "step": 22390
    },
    {
      "epoch": 1.39,
      "grad_norm": 10.369294166564941,
      "learning_rate": 2.7037285576479472e-05,
      "loss": 1.0627,
      "step": 22400
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.913880348205566,
      "learning_rate": 2.7026800318751837e-05,
      "loss": 0.9963,
      "step": 22410
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.934924125671387,
      "learning_rate": 2.70163150610242e-05,
      "loss": 1.0209,
      "step": 22420
    },
    {
      "epoch": 1.4,
      "grad_norm": 5.9648661613464355,
      "learning_rate": 2.7005829803296568e-05,
      "loss": 0.9516,
      "step": 22430
    },
    {
      "epoch": 1.4,
      "grad_norm": 12.439798355102539,
      "learning_rate": 2.699534454556893e-05,
      "loss": 1.0438,
      "step": 22440
    },
    {
      "epoch": 1.4,
      "grad_norm": 8.426468849182129,
      "learning_rate": 2.6984859287841295e-05,
      "loss": 1.1611,
      "step": 22450
    },
    {
      "epoch": 1.4,
      "grad_norm": 8.248476028442383,
      "learning_rate": 2.6974374030113664e-05,
      "loss": 1.1239,
      "step": 22460
    },
    {
      "epoch": 1.4,
      "grad_norm": 8.46949577331543,
      "learning_rate": 2.6963888772386026e-05,
      "loss": 1.0621,
      "step": 22470
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.132061958312988,
      "learning_rate": 2.6953403514658394e-05,
      "loss": 1.0989,
      "step": 22480
    },
    {
      "epoch": 1.4,
      "grad_norm": 10.009913444519043,
      "learning_rate": 2.6942918256930756e-05,
      "loss": 1.1822,
      "step": 22490
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.068645477294922,
      "learning_rate": 2.693243299920312e-05,
      "loss": 1.0194,
      "step": 22500
    },
    {
      "epoch": 1.4,
      "grad_norm": 12.084712982177734,
      "learning_rate": 2.692194774147549e-05,
      "loss": 1.0818,
      "step": 22510
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.889519691467285,
      "learning_rate": 2.6911462483747852e-05,
      "loss": 1.0386,
      "step": 22520
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.790086269378662,
      "learning_rate": 2.6900977226020218e-05,
      "loss": 0.9976,
      "step": 22530
    },
    {
      "epoch": 1.4,
      "grad_norm": 15.44382095336914,
      "learning_rate": 2.689049196829258e-05,
      "loss": 1.0406,
      "step": 22540
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.6497673988342285,
      "learning_rate": 2.6880006710564948e-05,
      "loss": 1.0602,
      "step": 22550
    },
    {
      "epoch": 1.4,
      "grad_norm": 8.688474655151367,
      "learning_rate": 2.686952145283731e-05,
      "loss": 1.1029,
      "step": 22560
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.788314819335938,
      "learning_rate": 2.6859036195109675e-05,
      "loss": 1.0542,
      "step": 22570
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.795726776123047,
      "learning_rate": 2.6848550937382044e-05,
      "loss": 1.0605,
      "step": 22580
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.004490852355957,
      "learning_rate": 2.6838065679654406e-05,
      "loss": 1.0593,
      "step": 22590
    },
    {
      "epoch": 1.41,
      "grad_norm": 9.085416793823242,
      "learning_rate": 2.6827580421926775e-05,
      "loss": 1.0488,
      "step": 22600
    },
    {
      "epoch": 1.41,
      "grad_norm": 12.195107460021973,
      "learning_rate": 2.6817095164199137e-05,
      "loss": 0.9067,
      "step": 22610
    },
    {
      "epoch": 1.41,
      "grad_norm": 6.445322513580322,
      "learning_rate": 2.6806609906471502e-05,
      "loss": 1.0742,
      "step": 22620
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.019546508789062,
      "learning_rate": 2.679612464874387e-05,
      "loss": 0.9491,
      "step": 22630
    },
    {
      "epoch": 1.41,
      "grad_norm": 4.73325252532959,
      "learning_rate": 2.6785639391016233e-05,
      "loss": 1.1783,
      "step": 22640
    },
    {
      "epoch": 1.41,
      "grad_norm": 4.574208736419678,
      "learning_rate": 2.6775154133288598e-05,
      "loss": 0.9875,
      "step": 22650
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.458191871643066,
      "learning_rate": 2.676466887556096e-05,
      "loss": 1.0873,
      "step": 22660
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.460395812988281,
      "learning_rate": 2.675418361783333e-05,
      "loss": 1.0667,
      "step": 22670
    },
    {
      "epoch": 1.41,
      "grad_norm": 6.934764385223389,
      "learning_rate": 2.674369836010569e-05,
      "loss": 1.0792,
      "step": 22680
    },
    {
      "epoch": 1.41,
      "grad_norm": 7.115646839141846,
      "learning_rate": 2.6733213102378056e-05,
      "loss": 0.9554,
      "step": 22690
    },
    {
      "epoch": 1.41,
      "grad_norm": 6.494290828704834,
      "learning_rate": 2.6722727844650424e-05,
      "loss": 1.0806,
      "step": 22700
    },
    {
      "epoch": 1.41,
      "grad_norm": 5.384856700897217,
      "learning_rate": 2.6712242586922786e-05,
      "loss": 1.0548,
      "step": 22710
    },
    {
      "epoch": 1.41,
      "grad_norm": 8.965142250061035,
      "learning_rate": 2.6701757329195155e-05,
      "loss": 1.1678,
      "step": 22720
    },
    {
      "epoch": 1.42,
      "grad_norm": 8.643560409545898,
      "learning_rate": 2.6691272071467517e-05,
      "loss": 1.0949,
      "step": 22730
    },
    {
      "epoch": 1.42,
      "grad_norm": 11.49516487121582,
      "learning_rate": 2.6680786813739882e-05,
      "loss": 1.1403,
      "step": 22740
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.527820110321045,
      "learning_rate": 2.667030155601225e-05,
      "loss": 1.0415,
      "step": 22750
    },
    {
      "epoch": 1.42,
      "grad_norm": 7.4924821853637695,
      "learning_rate": 2.6659816298284613e-05,
      "loss": 1.0382,
      "step": 22760
    },
    {
      "epoch": 1.42,
      "grad_norm": 7.922881126403809,
      "learning_rate": 2.6649331040556978e-05,
      "loss": 1.2059,
      "step": 22770
    },
    {
      "epoch": 1.42,
      "grad_norm": 9.961960792541504,
      "learning_rate": 2.663884578282934e-05,
      "loss": 1.1192,
      "step": 22780
    },
    {
      "epoch": 1.42,
      "grad_norm": 10.171103477478027,
      "learning_rate": 2.662836052510171e-05,
      "loss": 1.1671,
      "step": 22790
    },
    {
      "epoch": 1.42,
      "grad_norm": 10.914670944213867,
      "learning_rate": 2.661787526737407e-05,
      "loss": 1.2039,
      "step": 22800
    },
    {
      "epoch": 1.42,
      "grad_norm": 8.644801139831543,
      "learning_rate": 2.660739000964644e-05,
      "loss": 1.0926,
      "step": 22810
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.93572473526001,
      "learning_rate": 2.6596904751918805e-05,
      "loss": 1.1542,
      "step": 22820
    },
    {
      "epoch": 1.42,
      "grad_norm": 7.0038580894470215,
      "learning_rate": 2.6586419494191167e-05,
      "loss": 1.0785,
      "step": 22830
    },
    {
      "epoch": 1.42,
      "grad_norm": 9.489587783813477,
      "learning_rate": 2.6575934236463535e-05,
      "loss": 1.0894,
      "step": 22840
    },
    {
      "epoch": 1.42,
      "grad_norm": 11.550583839416504,
      "learning_rate": 2.6565448978735897e-05,
      "loss": 1.0808,
      "step": 22850
    },
    {
      "epoch": 1.42,
      "grad_norm": 9.694167137145996,
      "learning_rate": 2.6554963721008263e-05,
      "loss": 1.0931,
      "step": 22860
    },
    {
      "epoch": 1.42,
      "grad_norm": 11.667370796203613,
      "learning_rate": 2.654447846328063e-05,
      "loss": 1.0926,
      "step": 22870
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.580325603485107,
      "learning_rate": 2.6533993205552993e-05,
      "loss": 1.0505,
      "step": 22880
    },
    {
      "epoch": 1.43,
      "grad_norm": 10.731718063354492,
      "learning_rate": 2.652350794782536e-05,
      "loss": 1.1363,
      "step": 22890
    },
    {
      "epoch": 1.43,
      "grad_norm": 13.272384643554688,
      "learning_rate": 2.651302269009772e-05,
      "loss": 1.1063,
      "step": 22900
    },
    {
      "epoch": 1.43,
      "grad_norm": 9.531120300292969,
      "learning_rate": 2.650253743237009e-05,
      "loss": 1.011,
      "step": 22910
    },
    {
      "epoch": 1.43,
      "grad_norm": 10.202492713928223,
      "learning_rate": 2.6492052174642458e-05,
      "loss": 1.1249,
      "step": 22920
    },
    {
      "epoch": 1.43,
      "grad_norm": 11.488146781921387,
      "learning_rate": 2.648156691691482e-05,
      "loss": 1.1143,
      "step": 22930
    },
    {
      "epoch": 1.43,
      "grad_norm": 8.347448348999023,
      "learning_rate": 2.6471081659187185e-05,
      "loss": 1.036,
      "step": 22940
    },
    {
      "epoch": 1.43,
      "grad_norm": 11.933629989624023,
      "learning_rate": 2.6460596401459547e-05,
      "loss": 1.1984,
      "step": 22950
    },
    {
      "epoch": 1.43,
      "grad_norm": 9.586078643798828,
      "learning_rate": 2.6450111143731916e-05,
      "loss": 1.1176,
      "step": 22960
    },
    {
      "epoch": 1.43,
      "grad_norm": 9.442691802978516,
      "learning_rate": 2.6439625886004278e-05,
      "loss": 1.0164,
      "step": 22970
    },
    {
      "epoch": 1.43,
      "grad_norm": 11.450005531311035,
      "learning_rate": 2.6429140628276643e-05,
      "loss": 1.0634,
      "step": 22980
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.1290788650512695,
      "learning_rate": 2.6418655370549012e-05,
      "loss": 1.0158,
      "step": 22990
    },
    {
      "epoch": 1.43,
      "grad_norm": 7.067276477813721,
      "learning_rate": 2.6408170112821374e-05,
      "loss": 0.9307,
      "step": 23000
    },
    {
      "epoch": 1.43,
      "grad_norm": 12.636492729187012,
      "learning_rate": 2.639768485509374e-05,
      "loss": 0.9802,
      "step": 23010
    },
    {
      "epoch": 1.43,
      "grad_norm": 8.764443397521973,
      "learning_rate": 2.63871995973661e-05,
      "loss": 0.9547,
      "step": 23020
    },
    {
      "epoch": 1.43,
      "grad_norm": 11.212894439697266,
      "learning_rate": 2.637671433963847e-05,
      "loss": 1.0325,
      "step": 23030
    },
    {
      "epoch": 1.43,
      "grad_norm": 10.605575561523438,
      "learning_rate": 2.6366229081910838e-05,
      "loss": 1.1617,
      "step": 23040
    },
    {
      "epoch": 1.44,
      "grad_norm": 8.172065734863281,
      "learning_rate": 2.63557438241832e-05,
      "loss": 1.0684,
      "step": 23050
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.895643711090088,
      "learning_rate": 2.6345258566455565e-05,
      "loss": 1.0745,
      "step": 23060
    },
    {
      "epoch": 1.44,
      "grad_norm": 10.204205513000488,
      "learning_rate": 2.6334773308727927e-05,
      "loss": 1.1016,
      "step": 23070
    },
    {
      "epoch": 1.44,
      "grad_norm": 10.632187843322754,
      "learning_rate": 2.6324288051000296e-05,
      "loss": 1.0958,
      "step": 23080
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.734440326690674,
      "learning_rate": 2.6313802793272658e-05,
      "loss": 1.0261,
      "step": 23090
    },
    {
      "epoch": 1.44,
      "grad_norm": 7.10153865814209,
      "learning_rate": 2.6303317535545023e-05,
      "loss": 0.9683,
      "step": 23100
    },
    {
      "epoch": 1.44,
      "grad_norm": 9.323265075683594,
      "learning_rate": 2.6292832277817392e-05,
      "loss": 0.9432,
      "step": 23110
    },
    {
      "epoch": 1.44,
      "grad_norm": 6.9621710777282715,
      "learning_rate": 2.6282347020089754e-05,
      "loss": 1.0263,
      "step": 23120
    },
    {
      "epoch": 1.44,
      "grad_norm": 12.486780166625977,
      "learning_rate": 2.6271861762362123e-05,
      "loss": 1.1324,
      "step": 23130
    },
    {
      "epoch": 1.44,
      "grad_norm": 6.897648811340332,
      "learning_rate": 2.626137650463448e-05,
      "loss": 1.0381,
      "step": 23140
    },
    {
      "epoch": 1.44,
      "grad_norm": 12.013060569763184,
      "learning_rate": 2.625089124690685e-05,
      "loss": 1.0263,
      "step": 23150
    },
    {
      "epoch": 1.44,
      "grad_norm": 6.189753532409668,
      "learning_rate": 2.624040598917922e-05,
      "loss": 1.0515,
      "step": 23160
    },
    {
      "epoch": 1.44,
      "grad_norm": 7.531571865081787,
      "learning_rate": 2.622992073145158e-05,
      "loss": 1.1313,
      "step": 23170
    },
    {
      "epoch": 1.44,
      "grad_norm": 8.799729347229004,
      "learning_rate": 2.6219435473723946e-05,
      "loss": 1.0612,
      "step": 23180
    },
    {
      "epoch": 1.44,
      "grad_norm": 9.661056518554688,
      "learning_rate": 2.6208950215996308e-05,
      "loss": 0.944,
      "step": 23190
    },
    {
      "epoch": 1.44,
      "grad_norm": 10.463241577148438,
      "learning_rate": 2.6198464958268676e-05,
      "loss": 1.0128,
      "step": 23200
    },
    {
      "epoch": 1.45,
      "grad_norm": 11.634364128112793,
      "learning_rate": 2.6187979700541042e-05,
      "loss": 1.2227,
      "step": 23210
    },
    {
      "epoch": 1.45,
      "grad_norm": 9.171661376953125,
      "learning_rate": 2.6177494442813404e-05,
      "loss": 1.0869,
      "step": 23220
    },
    {
      "epoch": 1.45,
      "grad_norm": 8.900223731994629,
      "learning_rate": 2.6167009185085772e-05,
      "loss": 1.0774,
      "step": 23230
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.948307037353516,
      "learning_rate": 2.6156523927358134e-05,
      "loss": 1.0411,
      "step": 23240
    },
    {
      "epoch": 1.45,
      "grad_norm": 8.951038360595703,
      "learning_rate": 2.6146038669630503e-05,
      "loss": 1.1003,
      "step": 23250
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.276451110839844,
      "learning_rate": 2.6135553411902865e-05,
      "loss": 1.0916,
      "step": 23260
    },
    {
      "epoch": 1.45,
      "grad_norm": 10.36899471282959,
      "learning_rate": 2.612506815417523e-05,
      "loss": 1.0311,
      "step": 23270
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.183573246002197,
      "learning_rate": 2.61145828964476e-05,
      "loss": 1.019,
      "step": 23280
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.786311626434326,
      "learning_rate": 2.610409763871996e-05,
      "loss": 1.0414,
      "step": 23290
    },
    {
      "epoch": 1.45,
      "grad_norm": 8.849084854125977,
      "learning_rate": 2.6093612380992326e-05,
      "loss": 1.098,
      "step": 23300
    },
    {
      "epoch": 1.45,
      "grad_norm": 8.617942810058594,
      "learning_rate": 2.6083127123264688e-05,
      "loss": 1.1902,
      "step": 23310
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.553107738494873,
      "learning_rate": 2.6072641865537057e-05,
      "loss": 1.0273,
      "step": 23320
    },
    {
      "epoch": 1.45,
      "grad_norm": 9.957671165466309,
      "learning_rate": 2.6062156607809422e-05,
      "loss": 1.0633,
      "step": 23330
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.328441143035889,
      "learning_rate": 2.6051671350081784e-05,
      "loss": 0.9835,
      "step": 23340
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.62420129776001,
      "learning_rate": 2.6041186092354153e-05,
      "loss": 1.0678,
      "step": 23350
    },
    {
      "epoch": 1.45,
      "grad_norm": 8.570371627807617,
      "learning_rate": 2.6030700834626515e-05,
      "loss": 1.0205,
      "step": 23360
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.881856441497803,
      "learning_rate": 2.6020215576898883e-05,
      "loss": 1.0511,
      "step": 23370
    },
    {
      "epoch": 1.46,
      "grad_norm": 5.920387268066406,
      "learning_rate": 2.6009730319171245e-05,
      "loss": 0.9979,
      "step": 23380
    },
    {
      "epoch": 1.46,
      "grad_norm": 10.424151420593262,
      "learning_rate": 2.599924506144361e-05,
      "loss": 1.0146,
      "step": 23390
    },
    {
      "epoch": 1.46,
      "grad_norm": 11.5210599899292,
      "learning_rate": 2.598875980371598e-05,
      "loss": 1.0188,
      "step": 23400
    },
    {
      "epoch": 1.46,
      "grad_norm": 9.483268737792969,
      "learning_rate": 2.597827454598834e-05,
      "loss": 1.1525,
      "step": 23410
    },
    {
      "epoch": 1.46,
      "grad_norm": 12.914365768432617,
      "learning_rate": 2.5967789288260706e-05,
      "loss": 1.0775,
      "step": 23420
    },
    {
      "epoch": 1.46,
      "grad_norm": 8.513907432556152,
      "learning_rate": 2.595730403053307e-05,
      "loss": 1.1162,
      "step": 23430
    },
    {
      "epoch": 1.46,
      "grad_norm": 6.418116092681885,
      "learning_rate": 2.5946818772805437e-05,
      "loss": 0.9791,
      "step": 23440
    },
    {
      "epoch": 1.46,
      "grad_norm": 10.885540962219238,
      "learning_rate": 2.5936333515077806e-05,
      "loss": 1.1493,
      "step": 23450
    },
    {
      "epoch": 1.46,
      "grad_norm": 11.473285675048828,
      "learning_rate": 2.5925848257350164e-05,
      "loss": 0.9387,
      "step": 23460
    },
    {
      "epoch": 1.46,
      "grad_norm": 9.012986183166504,
      "learning_rate": 2.5915362999622533e-05,
      "loss": 1.1274,
      "step": 23470
    },
    {
      "epoch": 1.46,
      "grad_norm": 9.41317081451416,
      "learning_rate": 2.5904877741894895e-05,
      "loss": 1.1252,
      "step": 23480
    },
    {
      "epoch": 1.46,
      "grad_norm": 9.501026153564453,
      "learning_rate": 2.5894392484167264e-05,
      "loss": 1.0116,
      "step": 23490
    },
    {
      "epoch": 1.46,
      "grad_norm": 8.092884063720703,
      "learning_rate": 2.588390722643963e-05,
      "loss": 1.0616,
      "step": 23500
    },
    {
      "epoch": 1.46,
      "grad_norm": 7.374660015106201,
      "learning_rate": 2.587342196871199e-05,
      "loss": 1.0577,
      "step": 23510
    },
    {
      "epoch": 1.46,
      "grad_norm": 5.698000907897949,
      "learning_rate": 2.586293671098436e-05,
      "loss": 1.0247,
      "step": 23520
    },
    {
      "epoch": 1.46,
      "grad_norm": 8.656087875366211,
      "learning_rate": 2.585245145325672e-05,
      "loss": 1.063,
      "step": 23530
    },
    {
      "epoch": 1.47,
      "grad_norm": 8.111257553100586,
      "learning_rate": 2.5841966195529087e-05,
      "loss": 1.0724,
      "step": 23540
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.578195095062256,
      "learning_rate": 2.583148093780145e-05,
      "loss": 1.1358,
      "step": 23550
    },
    {
      "epoch": 1.47,
      "grad_norm": 10.10391616821289,
      "learning_rate": 2.5820995680073817e-05,
      "loss": 1.088,
      "step": 23560
    },
    {
      "epoch": 1.47,
      "grad_norm": 10.442176818847656,
      "learning_rate": 2.5810510422346186e-05,
      "loss": 1.0336,
      "step": 23570
    },
    {
      "epoch": 1.47,
      "grad_norm": 6.94523811340332,
      "learning_rate": 2.5800025164618548e-05,
      "loss": 1.0083,
      "step": 23580
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.397453308105469,
      "learning_rate": 2.5789539906890913e-05,
      "loss": 1.0423,
      "step": 23590
    },
    {
      "epoch": 1.47,
      "grad_norm": 8.419109344482422,
      "learning_rate": 2.5779054649163275e-05,
      "loss": 1.0907,
      "step": 23600
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.553693771362305,
      "learning_rate": 2.5768569391435644e-05,
      "loss": 1.103,
      "step": 23610
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.084299087524414,
      "learning_rate": 2.575808413370801e-05,
      "loss": 0.9914,
      "step": 23620
    },
    {
      "epoch": 1.47,
      "grad_norm": 9.771693229675293,
      "learning_rate": 2.574759887598037e-05,
      "loss": 1.2495,
      "step": 23630
    },
    {
      "epoch": 1.47,
      "grad_norm": 11.936325073242188,
      "learning_rate": 2.573711361825274e-05,
      "loss": 0.9024,
      "step": 23640
    },
    {
      "epoch": 1.47,
      "grad_norm": 9.655234336853027,
      "learning_rate": 2.5726628360525102e-05,
      "loss": 1.114,
      "step": 23650
    },
    {
      "epoch": 1.47,
      "grad_norm": 9.343276023864746,
      "learning_rate": 2.5716143102797467e-05,
      "loss": 1.1913,
      "step": 23660
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.930848598480225,
      "learning_rate": 2.570565784506983e-05,
      "loss": 1.1607,
      "step": 23670
    },
    {
      "epoch": 1.47,
      "grad_norm": 5.129313945770264,
      "learning_rate": 2.5695172587342198e-05,
      "loss": 1.0752,
      "step": 23680
    },
    {
      "epoch": 1.47,
      "grad_norm": 6.186683177947998,
      "learning_rate": 2.5684687329614566e-05,
      "loss": 1.0554,
      "step": 23690
    },
    {
      "epoch": 1.48,
      "grad_norm": 11.583024024963379,
      "learning_rate": 2.567420207188693e-05,
      "loss": 1.106,
      "step": 23700
    },
    {
      "epoch": 1.48,
      "grad_norm": 11.247000694274902,
      "learning_rate": 2.5663716814159294e-05,
      "loss": 1.0566,
      "step": 23710
    },
    {
      "epoch": 1.48,
      "grad_norm": 14.19636344909668,
      "learning_rate": 2.5653231556431656e-05,
      "loss": 1.1077,
      "step": 23720
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.997668743133545,
      "learning_rate": 2.5642746298704024e-05,
      "loss": 1.0342,
      "step": 23730
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.728577613830566,
      "learning_rate": 2.563226104097639e-05,
      "loss": 0.9601,
      "step": 23740
    },
    {
      "epoch": 1.48,
      "grad_norm": 6.352768898010254,
      "learning_rate": 2.562177578324875e-05,
      "loss": 0.9518,
      "step": 23750
    },
    {
      "epoch": 1.48,
      "grad_norm": 10.122461318969727,
      "learning_rate": 2.561129052552112e-05,
      "loss": 1.0997,
      "step": 23760
    },
    {
      "epoch": 1.48,
      "grad_norm": 6.269838333129883,
      "learning_rate": 2.5600805267793482e-05,
      "loss": 1.1153,
      "step": 23770
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.099577903747559,
      "learning_rate": 2.5590320010065847e-05,
      "loss": 1.0287,
      "step": 23780
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.140016555786133,
      "learning_rate": 2.5579834752338216e-05,
      "loss": 1.138,
      "step": 23790
    },
    {
      "epoch": 1.48,
      "grad_norm": 8.686393737792969,
      "learning_rate": 2.5569349494610578e-05,
      "loss": 1.0031,
      "step": 23800
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.360033988952637,
      "learning_rate": 2.5558864236882947e-05,
      "loss": 1.0877,
      "step": 23810
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.424901008605957,
      "learning_rate": 2.554837897915531e-05,
      "loss": 1.0403,
      "step": 23820
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.477519989013672,
      "learning_rate": 2.5537893721427674e-05,
      "loss": 0.9922,
      "step": 23830
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.24329948425293,
      "learning_rate": 2.5527408463700036e-05,
      "loss": 1.0762,
      "step": 23840
    },
    {
      "epoch": 1.48,
      "grad_norm": 5.556432247161865,
      "learning_rate": 2.5516923205972405e-05,
      "loss": 1.0839,
      "step": 23850
    },
    {
      "epoch": 1.49,
      "grad_norm": 6.854065895080566,
      "learning_rate": 2.550643794824477e-05,
      "loss": 1.043,
      "step": 23860
    },
    {
      "epoch": 1.49,
      "grad_norm": 10.150147438049316,
      "learning_rate": 2.5495952690517132e-05,
      "loss": 1.0859,
      "step": 23870
    },
    {
      "epoch": 1.49,
      "grad_norm": 6.326250076293945,
      "learning_rate": 2.54854674327895e-05,
      "loss": 1.0267,
      "step": 23880
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.650108337402344,
      "learning_rate": 2.5474982175061862e-05,
      "loss": 0.9568,
      "step": 23890
    },
    {
      "epoch": 1.49,
      "grad_norm": 8.65787410736084,
      "learning_rate": 2.546449691733423e-05,
      "loss": 0.9704,
      "step": 23900
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.820597171783447,
      "learning_rate": 2.5454011659606596e-05,
      "loss": 1.0293,
      "step": 23910
    },
    {
      "epoch": 1.49,
      "grad_norm": 10.7633056640625,
      "learning_rate": 2.544352640187896e-05,
      "loss": 1.1698,
      "step": 23920
    },
    {
      "epoch": 1.49,
      "grad_norm": 8.532503128051758,
      "learning_rate": 2.5433041144151327e-05,
      "loss": 1.0425,
      "step": 23930
    },
    {
      "epoch": 1.49,
      "grad_norm": 14.549894332885742,
      "learning_rate": 2.542255588642369e-05,
      "loss": 1.0862,
      "step": 23940
    },
    {
      "epoch": 1.49,
      "grad_norm": 8.226507186889648,
      "learning_rate": 2.5412070628696054e-05,
      "loss": 1.0967,
      "step": 23950
    },
    {
      "epoch": 1.49,
      "grad_norm": 6.393721103668213,
      "learning_rate": 2.5401585370968416e-05,
      "loss": 1.0625,
      "step": 23960
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.631649494171143,
      "learning_rate": 2.5391100113240785e-05,
      "loss": 1.0724,
      "step": 23970
    },
    {
      "epoch": 1.49,
      "grad_norm": 11.703254699707031,
      "learning_rate": 2.538061485551315e-05,
      "loss": 1.1239,
      "step": 23980
    },
    {
      "epoch": 1.49,
      "grad_norm": 5.216193199157715,
      "learning_rate": 2.5370129597785512e-05,
      "loss": 1.0056,
      "step": 23990
    },
    {
      "epoch": 1.49,
      "grad_norm": 8.8447847366333,
      "learning_rate": 2.535964434005788e-05,
      "loss": 1.06,
      "step": 24000
    },
    {
      "epoch": 1.49,
      "grad_norm": 9.359358787536621,
      "learning_rate": 2.5349159082330243e-05,
      "loss": 1.0711,
      "step": 24010
    },
    {
      "epoch": 1.5,
      "grad_norm": 12.394634246826172,
      "learning_rate": 2.533867382460261e-05,
      "loss": 1.1776,
      "step": 24020
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.31385612487793,
      "learning_rate": 2.5328188566874977e-05,
      "loss": 1.066,
      "step": 24030
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.970296382904053,
      "learning_rate": 2.531770330914734e-05,
      "loss": 0.959,
      "step": 24040
    },
    {
      "epoch": 1.5,
      "grad_norm": 19.789735794067383,
      "learning_rate": 2.5307218051419707e-05,
      "loss": 1.1369,
      "step": 24050
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.852197647094727,
      "learning_rate": 2.529673279369207e-05,
      "loss": 0.9815,
      "step": 24060
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.553808212280273,
      "learning_rate": 2.5286247535964435e-05,
      "loss": 1.1157,
      "step": 24070
    },
    {
      "epoch": 1.5,
      "grad_norm": 9.134923934936523,
      "learning_rate": 2.5275762278236797e-05,
      "loss": 1.1169,
      "step": 24080
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.5397844314575195,
      "learning_rate": 2.5265277020509165e-05,
      "loss": 1.1369,
      "step": 24090
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.351284027099609,
      "learning_rate": 2.525479176278153e-05,
      "loss": 1.0718,
      "step": 24100
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.584417343139648,
      "learning_rate": 2.5244306505053893e-05,
      "loss": 0.9702,
      "step": 24110
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.67620849609375,
      "learning_rate": 2.523382124732626e-05,
      "loss": 1.1054,
      "step": 24120
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.167920112609863,
      "learning_rate": 2.5223335989598623e-05,
      "loss": 1.1008,
      "step": 24130
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.813255310058594,
      "learning_rate": 2.5212850731870992e-05,
      "loss": 1.1681,
      "step": 24140
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.569939613342285,
      "learning_rate": 2.5202365474143357e-05,
      "loss": 1.1093,
      "step": 24150
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.693820953369141,
      "learning_rate": 2.519188021641572e-05,
      "loss": 1.0635,
      "step": 24160
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.0673065185546875,
      "learning_rate": 2.5181394958688088e-05,
      "loss": 1.105,
      "step": 24170
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.527973651885986,
      "learning_rate": 2.517090970096045e-05,
      "loss": 1.1182,
      "step": 24180
    },
    {
      "epoch": 1.51,
      "grad_norm": 11.13884162902832,
      "learning_rate": 2.5160424443232815e-05,
      "loss": 1.068,
      "step": 24190
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.265529155731201,
      "learning_rate": 2.5149939185505184e-05,
      "loss": 1.0936,
      "step": 24200
    },
    {
      "epoch": 1.51,
      "grad_norm": 15.351224899291992,
      "learning_rate": 2.5139453927777546e-05,
      "loss": 1.2121,
      "step": 24210
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.218288898468018,
      "learning_rate": 2.5128968670049914e-05,
      "loss": 0.9804,
      "step": 24220
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.080352783203125,
      "learning_rate": 2.5118483412322273e-05,
      "loss": 1.1215,
      "step": 24230
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.766415596008301,
      "learning_rate": 2.510799815459464e-05,
      "loss": 1.0323,
      "step": 24240
    },
    {
      "epoch": 1.51,
      "grad_norm": 11.789002418518066,
      "learning_rate": 2.5097512896867003e-05,
      "loss": 1.0974,
      "step": 24250
    },
    {
      "epoch": 1.51,
      "grad_norm": 9.477568626403809,
      "learning_rate": 2.5087027639139372e-05,
      "loss": 1.0086,
      "step": 24260
    },
    {
      "epoch": 1.51,
      "grad_norm": 10.631631851196289,
      "learning_rate": 2.5076542381411737e-05,
      "loss": 1.1995,
      "step": 24270
    },
    {
      "epoch": 1.51,
      "grad_norm": 5.821063995361328,
      "learning_rate": 2.50660571236841e-05,
      "loss": 0.9839,
      "step": 24280
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.403595447540283,
      "learning_rate": 2.5055571865956468e-05,
      "loss": 0.9711,
      "step": 24290
    },
    {
      "epoch": 1.51,
      "grad_norm": 11.32466983795166,
      "learning_rate": 2.504508660822883e-05,
      "loss": 1.0603,
      "step": 24300
    },
    {
      "epoch": 1.51,
      "grad_norm": 7.418001651763916,
      "learning_rate": 2.5034601350501195e-05,
      "loss": 1.0681,
      "step": 24310
    },
    {
      "epoch": 1.51,
      "grad_norm": 9.240692138671875,
      "learning_rate": 2.5024116092773564e-05,
      "loss": 1.1031,
      "step": 24320
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.575525283813477,
      "learning_rate": 2.5013630835045926e-05,
      "loss": 1.1515,
      "step": 24330
    },
    {
      "epoch": 1.52,
      "grad_norm": 7.564629077911377,
      "learning_rate": 2.5003145577318295e-05,
      "loss": 1.1143,
      "step": 24340
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.045785903930664,
      "learning_rate": 2.4992660319590657e-05,
      "loss": 1.1398,
      "step": 24350
    },
    {
      "epoch": 1.52,
      "grad_norm": 11.341135025024414,
      "learning_rate": 2.4982175061863022e-05,
      "loss": 1.1896,
      "step": 24360
    },
    {
      "epoch": 1.52,
      "grad_norm": 7.988955974578857,
      "learning_rate": 2.4971689804135387e-05,
      "loss": 0.9945,
      "step": 24370
    },
    {
      "epoch": 1.52,
      "grad_norm": 9.033509254455566,
      "learning_rate": 2.4961204546407753e-05,
      "loss": 1.0177,
      "step": 24380
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.14627742767334,
      "learning_rate": 2.4950719288680114e-05,
      "loss": 1.1242,
      "step": 24390
    },
    {
      "epoch": 1.52,
      "grad_norm": 6.052164077758789,
      "learning_rate": 2.494023403095248e-05,
      "loss": 1.0854,
      "step": 24400
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.604471206665039,
      "learning_rate": 2.492974877322485e-05,
      "loss": 1.0274,
      "step": 24410
    },
    {
      "epoch": 1.52,
      "grad_norm": 5.657966613769531,
      "learning_rate": 2.4919263515497214e-05,
      "loss": 0.9563,
      "step": 24420
    },
    {
      "epoch": 1.52,
      "grad_norm": 9.73348331451416,
      "learning_rate": 2.4908778257769576e-05,
      "loss": 1.1302,
      "step": 24430
    },
    {
      "epoch": 1.52,
      "grad_norm": 11.274304389953613,
      "learning_rate": 2.489829300004194e-05,
      "loss": 1.1108,
      "step": 24440
    },
    {
      "epoch": 1.52,
      "grad_norm": 7.149227619171143,
      "learning_rate": 2.4887807742314306e-05,
      "loss": 1.101,
      "step": 24450
    },
    {
      "epoch": 1.52,
      "grad_norm": 7.865884304046631,
      "learning_rate": 2.4877322484586675e-05,
      "loss": 1.0905,
      "step": 24460
    },
    {
      "epoch": 1.52,
      "grad_norm": 7.193639278411865,
      "learning_rate": 2.4866837226859037e-05,
      "loss": 0.9905,
      "step": 24470
    },
    {
      "epoch": 1.52,
      "grad_norm": 6.841364860534668,
      "learning_rate": 2.4856351969131402e-05,
      "loss": 0.9452,
      "step": 24480
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.77130126953125,
      "learning_rate": 2.4845866711403768e-05,
      "loss": 1.1914,
      "step": 24490
    },
    {
      "epoch": 1.53,
      "grad_norm": 9.375227928161621,
      "learning_rate": 2.4835381453676133e-05,
      "loss": 1.0706,
      "step": 24500
    },
    {
      "epoch": 1.53,
      "grad_norm": 8.698578834533691,
      "learning_rate": 2.4824896195948498e-05,
      "loss": 1.0548,
      "step": 24510
    },
    {
      "epoch": 1.53,
      "grad_norm": 10.357809066772461,
      "learning_rate": 2.4814410938220863e-05,
      "loss": 1.2931,
      "step": 24520
    },
    {
      "epoch": 1.53,
      "grad_norm": 10.016578674316406,
      "learning_rate": 2.480392568049323e-05,
      "loss": 1.1377,
      "step": 24530
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.759520053863525,
      "learning_rate": 2.4793440422765594e-05,
      "loss": 1.1311,
      "step": 24540
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.5806660652160645,
      "learning_rate": 2.4782955165037956e-05,
      "loss": 1.0152,
      "step": 24550
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.951040267944336,
      "learning_rate": 2.477246990731032e-05,
      "loss": 1.016,
      "step": 24560
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.627972602844238,
      "learning_rate": 2.4761984649582687e-05,
      "loss": 0.9478,
      "step": 24570
    },
    {
      "epoch": 1.53,
      "grad_norm": 7.554823875427246,
      "learning_rate": 2.4751499391855055e-05,
      "loss": 1.0109,
      "step": 24580
    },
    {
      "epoch": 1.53,
      "grad_norm": 8.014609336853027,
      "learning_rate": 2.4741014134127417e-05,
      "loss": 1.1482,
      "step": 24590
    },
    {
      "epoch": 1.53,
      "grad_norm": 10.220820426940918,
      "learning_rate": 2.4730528876399783e-05,
      "loss": 1.0138,
      "step": 24600
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.6951093673706055,
      "learning_rate": 2.4720043618672148e-05,
      "loss": 1.0098,
      "step": 24610
    },
    {
      "epoch": 1.53,
      "grad_norm": 8.140619277954102,
      "learning_rate": 2.4709558360944513e-05,
      "loss": 1.0129,
      "step": 24620
    },
    {
      "epoch": 1.53,
      "grad_norm": 7.767806053161621,
      "learning_rate": 2.469907310321688e-05,
      "loss": 1.1265,
      "step": 24630
    },
    {
      "epoch": 1.53,
      "grad_norm": 8.289595603942871,
      "learning_rate": 2.4688587845489244e-05,
      "loss": 1.0017,
      "step": 24640
    },
    {
      "epoch": 1.53,
      "grad_norm": 7.8819756507873535,
      "learning_rate": 2.467810258776161e-05,
      "loss": 1.1205,
      "step": 24650
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.7832818031311035,
      "learning_rate": 2.4667617330033974e-05,
      "loss": 1.0168,
      "step": 24660
    },
    {
      "epoch": 1.54,
      "grad_norm": 9.703286170959473,
      "learning_rate": 2.465713207230634e-05,
      "loss": 1.1314,
      "step": 24670
    },
    {
      "epoch": 1.54,
      "grad_norm": 6.106429576873779,
      "learning_rate": 2.46466468145787e-05,
      "loss": 1.0668,
      "step": 24680
    },
    {
      "epoch": 1.54,
      "grad_norm": 10.93876838684082,
      "learning_rate": 2.4636161556851067e-05,
      "loss": 1.1748,
      "step": 24690
    },
    {
      "epoch": 1.54,
      "grad_norm": 11.513611793518066,
      "learning_rate": 2.4625676299123436e-05,
      "loss": 1.0802,
      "step": 24700
    },
    {
      "epoch": 1.54,
      "grad_norm": 10.332201957702637,
      "learning_rate": 2.4615191041395798e-05,
      "loss": 1.0119,
      "step": 24710
    },
    {
      "epoch": 1.54,
      "grad_norm": 6.41859245300293,
      "learning_rate": 2.4604705783668163e-05,
      "loss": 1.0686,
      "step": 24720
    },
    {
      "epoch": 1.54,
      "grad_norm": 10.1539306640625,
      "learning_rate": 2.4594220525940528e-05,
      "loss": 1.0952,
      "step": 24730
    },
    {
      "epoch": 1.54,
      "grad_norm": 9.974238395690918,
      "learning_rate": 2.4583735268212893e-05,
      "loss": 1.0357,
      "step": 24740
    },
    {
      "epoch": 1.54,
      "grad_norm": 7.873514175415039,
      "learning_rate": 2.457325001048526e-05,
      "loss": 1.0543,
      "step": 24750
    },
    {
      "epoch": 1.54,
      "grad_norm": 7.61716365814209,
      "learning_rate": 2.4562764752757624e-05,
      "loss": 1.0614,
      "step": 24760
    },
    {
      "epoch": 1.54,
      "grad_norm": 7.927176475524902,
      "learning_rate": 2.455227949502999e-05,
      "loss": 1.0258,
      "step": 24770
    },
    {
      "epoch": 1.54,
      "grad_norm": 8.191549301147461,
      "learning_rate": 2.4541794237302355e-05,
      "loss": 1.2137,
      "step": 24780
    },
    {
      "epoch": 1.54,
      "grad_norm": 10.762918472290039,
      "learning_rate": 2.453130897957472e-05,
      "loss": 1.0848,
      "step": 24790
    },
    {
      "epoch": 1.54,
      "grad_norm": 9.47587776184082,
      "learning_rate": 2.4520823721847082e-05,
      "loss": 1.114,
      "step": 24800
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.507174491882324,
      "learning_rate": 2.451033846411945e-05,
      "loss": 1.0539,
      "step": 24810
    },
    {
      "epoch": 1.55,
      "grad_norm": 7.157277584075928,
      "learning_rate": 2.4499853206391816e-05,
      "loss": 1.0633,
      "step": 24820
    },
    {
      "epoch": 1.55,
      "grad_norm": 9.794909477233887,
      "learning_rate": 2.448936794866418e-05,
      "loss": 1.1257,
      "step": 24830
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.607777118682861,
      "learning_rate": 2.4478882690936543e-05,
      "loss": 1.1299,
      "step": 24840
    },
    {
      "epoch": 1.55,
      "grad_norm": 9.125907897949219,
      "learning_rate": 2.446839743320891e-05,
      "loss": 1.0621,
      "step": 24850
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.4221367835998535,
      "learning_rate": 2.4457912175481274e-05,
      "loss": 1.0263,
      "step": 24860
    },
    {
      "epoch": 1.55,
      "grad_norm": 10.499309539794922,
      "learning_rate": 2.444742691775364e-05,
      "loss": 1.1439,
      "step": 24870
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.430949687957764,
      "learning_rate": 2.4436941660026004e-05,
      "loss": 1.0122,
      "step": 24880
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.795477390289307,
      "learning_rate": 2.442645640229837e-05,
      "loss": 1.0315,
      "step": 24890
    },
    {
      "epoch": 1.55,
      "grad_norm": 10.63422679901123,
      "learning_rate": 2.4415971144570735e-05,
      "loss": 1.0543,
      "step": 24900
    },
    {
      "epoch": 1.55,
      "grad_norm": 9.209434509277344,
      "learning_rate": 2.44054858868431e-05,
      "loss": 1.0809,
      "step": 24910
    },
    {
      "epoch": 1.55,
      "grad_norm": 8.25460147857666,
      "learning_rate": 2.4395000629115462e-05,
      "loss": 1.1125,
      "step": 24920
    },
    {
      "epoch": 1.55,
      "grad_norm": 7.8266096115112305,
      "learning_rate": 2.438451537138783e-05,
      "loss": 1.2296,
      "step": 24930
    },
    {
      "epoch": 1.55,
      "grad_norm": 9.566316604614258,
      "learning_rate": 2.4374030113660196e-05,
      "loss": 1.0634,
      "step": 24940
    },
    {
      "epoch": 1.55,
      "grad_norm": 7.251463413238525,
      "learning_rate": 2.436354485593256e-05,
      "loss": 1.0729,
      "step": 24950
    },
    {
      "epoch": 1.55,
      "grad_norm": 8.484651565551758,
      "learning_rate": 2.4353059598204924e-05,
      "loss": 0.9791,
      "step": 24960
    },
    {
      "epoch": 1.55,
      "grad_norm": 8.879393577575684,
      "learning_rate": 2.434257434047729e-05,
      "loss": 1.1423,
      "step": 24970
    },
    {
      "epoch": 1.56,
      "grad_norm": 8.09473991394043,
      "learning_rate": 2.4332089082749654e-05,
      "loss": 1.059,
      "step": 24980
    },
    {
      "epoch": 1.56,
      "grad_norm": 10.835864067077637,
      "learning_rate": 2.4321603825022023e-05,
      "loss": 1.0418,
      "step": 24990
    },
    {
      "epoch": 1.56,
      "grad_norm": 8.808576583862305,
      "learning_rate": 2.4311118567294385e-05,
      "loss": 1.1031,
      "step": 25000
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.806374549865723,
      "learning_rate": 2.430063330956675e-05,
      "loss": 1.1151,
      "step": 25010
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.362028121948242,
      "learning_rate": 2.4290148051839115e-05,
      "loss": 1.1092,
      "step": 25020
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.854612350463867,
      "learning_rate": 2.427966279411148e-05,
      "loss": 1.094,
      "step": 25030
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.339846134185791,
      "learning_rate": 2.4269177536383843e-05,
      "loss": 1.0499,
      "step": 25040
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.852802276611328,
      "learning_rate": 2.425869227865621e-05,
      "loss": 1.0852,
      "step": 25050
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.165902614593506,
      "learning_rate": 2.4248207020928577e-05,
      "loss": 1.1111,
      "step": 25060
    },
    {
      "epoch": 1.56,
      "grad_norm": 9.017302513122559,
      "learning_rate": 2.4237721763200942e-05,
      "loss": 1.068,
      "step": 25070
    },
    {
      "epoch": 1.56,
      "grad_norm": 5.400882720947266,
      "learning_rate": 2.4227236505473304e-05,
      "loss": 0.9952,
      "step": 25080
    },
    {
      "epoch": 1.56,
      "grad_norm": 9.654645919799805,
      "learning_rate": 2.421675124774567e-05,
      "loss": 0.981,
      "step": 25090
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.932102680206299,
      "learning_rate": 2.4206265990018038e-05,
      "loss": 0.9982,
      "step": 25100
    },
    {
      "epoch": 1.56,
      "grad_norm": 10.256122589111328,
      "learning_rate": 2.4195780732290403e-05,
      "loss": 1.1451,
      "step": 25110
    },
    {
      "epoch": 1.56,
      "grad_norm": 11.133868217468262,
      "learning_rate": 2.4185295474562765e-05,
      "loss": 1.0017,
      "step": 25120
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.467291831970215,
      "learning_rate": 2.417481021683513e-05,
      "loss": 1.0649,
      "step": 25130
    },
    {
      "epoch": 1.57,
      "grad_norm": 6.535257339477539,
      "learning_rate": 2.4164324959107496e-05,
      "loss": 1.1063,
      "step": 25140
    },
    {
      "epoch": 1.57,
      "grad_norm": 7.944176197052002,
      "learning_rate": 2.415383970137986e-05,
      "loss": 0.9889,
      "step": 25150
    },
    {
      "epoch": 1.57,
      "grad_norm": 5.014096260070801,
      "learning_rate": 2.4143354443652226e-05,
      "loss": 0.9509,
      "step": 25160
    },
    {
      "epoch": 1.57,
      "grad_norm": 8.65880012512207,
      "learning_rate": 2.413286918592459e-05,
      "loss": 1.0711,
      "step": 25170
    },
    {
      "epoch": 1.57,
      "grad_norm": 16.105728149414062,
      "learning_rate": 2.4122383928196957e-05,
      "loss": 1.0649,
      "step": 25180
    },
    {
      "epoch": 1.57,
      "grad_norm": 8.268630981445312,
      "learning_rate": 2.4111898670469322e-05,
      "loss": 0.9318,
      "step": 25190
    },
    {
      "epoch": 1.57,
      "grad_norm": 9.447092056274414,
      "learning_rate": 2.4101413412741684e-05,
      "loss": 1.0953,
      "step": 25200
    },
    {
      "epoch": 1.57,
      "grad_norm": 7.512475490570068,
      "learning_rate": 2.409092815501405e-05,
      "loss": 1.0453,
      "step": 25210
    },
    {
      "epoch": 1.57,
      "grad_norm": 7.412866115570068,
      "learning_rate": 2.4080442897286418e-05,
      "loss": 1.0412,
      "step": 25220
    },
    {
      "epoch": 1.57,
      "grad_norm": 12.69556713104248,
      "learning_rate": 2.4069957639558784e-05,
      "loss": 1.2348,
      "step": 25230
    },
    {
      "epoch": 1.57,
      "grad_norm": 8.413933753967285,
      "learning_rate": 2.4059472381831145e-05,
      "loss": 1.1519,
      "step": 25240
    },
    {
      "epoch": 1.57,
      "grad_norm": 6.658837795257568,
      "learning_rate": 2.404898712410351e-05,
      "loss": 0.9934,
      "step": 25250
    },
    {
      "epoch": 1.57,
      "grad_norm": 4.9025349617004395,
      "learning_rate": 2.4038501866375876e-05,
      "loss": 1.1453,
      "step": 25260
    },
    {
      "epoch": 1.57,
      "grad_norm": 9.91736125946045,
      "learning_rate": 2.402801660864824e-05,
      "loss": 1.1227,
      "step": 25270
    },
    {
      "epoch": 1.57,
      "grad_norm": 9.641510963439941,
      "learning_rate": 2.4017531350920607e-05,
      "loss": 1.0878,
      "step": 25280
    },
    {
      "epoch": 1.57,
      "grad_norm": 11.529784202575684,
      "learning_rate": 2.4007046093192972e-05,
      "loss": 1.0637,
      "step": 25290
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.29611587524414,
      "learning_rate": 2.3996560835465337e-05,
      "loss": 1.0936,
      "step": 25300
    },
    {
      "epoch": 1.58,
      "grad_norm": 7.287898540496826,
      "learning_rate": 2.3986075577737703e-05,
      "loss": 1.0903,
      "step": 25310
    },
    {
      "epoch": 1.58,
      "grad_norm": 10.404348373413086,
      "learning_rate": 2.3975590320010065e-05,
      "loss": 1.1918,
      "step": 25320
    },
    {
      "epoch": 1.58,
      "grad_norm": 7.820118427276611,
      "learning_rate": 2.396510506228243e-05,
      "loss": 1.124,
      "step": 25330
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.897073745727539,
      "learning_rate": 2.39546198045548e-05,
      "loss": 1.0313,
      "step": 25340
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.148712158203125,
      "learning_rate": 2.3944134546827164e-05,
      "loss": 1.0993,
      "step": 25350
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.4170966148376465,
      "learning_rate": 2.3933649289099526e-05,
      "loss": 1.164,
      "step": 25360
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.864772796630859,
      "learning_rate": 2.392316403137189e-05,
      "loss": 0.9833,
      "step": 25370
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.383008003234863,
      "learning_rate": 2.3912678773644256e-05,
      "loss": 1.1054,
      "step": 25380
    },
    {
      "epoch": 1.58,
      "grad_norm": 6.877187252044678,
      "learning_rate": 2.3902193515916622e-05,
      "loss": 1.0083,
      "step": 25390
    },
    {
      "epoch": 1.58,
      "grad_norm": 9.757780075073242,
      "learning_rate": 2.3891708258188987e-05,
      "loss": 0.9891,
      "step": 25400
    },
    {
      "epoch": 1.58,
      "grad_norm": 13.359872817993164,
      "learning_rate": 2.3881223000461352e-05,
      "loss": 0.8869,
      "step": 25410
    },
    {
      "epoch": 1.58,
      "grad_norm": 10.750271797180176,
      "learning_rate": 2.3870737742733718e-05,
      "loss": 1.1607,
      "step": 25420
    },
    {
      "epoch": 1.58,
      "grad_norm": 7.218995094299316,
      "learning_rate": 2.3860252485006083e-05,
      "loss": 1.1121,
      "step": 25430
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.209446907043457,
      "learning_rate": 2.3849767227278448e-05,
      "loss": 1.2389,
      "step": 25440
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.026551246643066,
      "learning_rate": 2.3839281969550814e-05,
      "loss": 0.9704,
      "step": 25450
    },
    {
      "epoch": 1.59,
      "grad_norm": 8.720918655395508,
      "learning_rate": 2.382879671182318e-05,
      "loss": 0.9026,
      "step": 25460
    },
    {
      "epoch": 1.59,
      "grad_norm": 7.337960720062256,
      "learning_rate": 2.3818311454095544e-05,
      "loss": 0.9636,
      "step": 25470
    },
    {
      "epoch": 1.59,
      "grad_norm": 9.539660453796387,
      "learning_rate": 2.3807826196367906e-05,
      "loss": 1.0342,
      "step": 25480
    },
    {
      "epoch": 1.59,
      "grad_norm": 11.102355003356934,
      "learning_rate": 2.379734093864027e-05,
      "loss": 1.1709,
      "step": 25490
    },
    {
      "epoch": 1.59,
      "grad_norm": 10.27038288116455,
      "learning_rate": 2.3786855680912637e-05,
      "loss": 1.0413,
      "step": 25500
    },
    {
      "epoch": 1.59,
      "grad_norm": 10.403371810913086,
      "learning_rate": 2.3776370423185005e-05,
      "loss": 1.1235,
      "step": 25510
    },
    {
      "epoch": 1.59,
      "grad_norm": 7.533613204956055,
      "learning_rate": 2.3765885165457367e-05,
      "loss": 1.059,
      "step": 25520
    },
    {
      "epoch": 1.59,
      "grad_norm": 7.7783732414245605,
      "learning_rate": 2.3755399907729733e-05,
      "loss": 1.2009,
      "step": 25530
    },
    {
      "epoch": 1.59,
      "grad_norm": 10.107688903808594,
      "learning_rate": 2.3744914650002098e-05,
      "loss": 1.1724,
      "step": 25540
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.958127021789551,
      "learning_rate": 2.3734429392274463e-05,
      "loss": 1.0738,
      "step": 25550
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.600353240966797,
      "learning_rate": 2.372394413454683e-05,
      "loss": 1.0176,
      "step": 25560
    },
    {
      "epoch": 1.59,
      "grad_norm": 7.69600248336792,
      "learning_rate": 2.3713458876819194e-05,
      "loss": 1.1542,
      "step": 25570
    },
    {
      "epoch": 1.59,
      "grad_norm": 11.17439079284668,
      "learning_rate": 2.370297361909156e-05,
      "loss": 1.1107,
      "step": 25580
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.462370872497559,
      "learning_rate": 2.3692488361363925e-05,
      "loss": 0.9956,
      "step": 25590
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.712876319885254,
      "learning_rate": 2.368200310363629e-05,
      "loss": 1.0077,
      "step": 25600
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.1044020652771,
      "learning_rate": 2.3671517845908652e-05,
      "loss": 1.0576,
      "step": 25610
    },
    {
      "epoch": 1.6,
      "grad_norm": 11.29599666595459,
      "learning_rate": 2.3661032588181017e-05,
      "loss": 1.1728,
      "step": 25620
    },
    {
      "epoch": 1.6,
      "grad_norm": 16.132808685302734,
      "learning_rate": 2.3650547330453386e-05,
      "loss": 1.0614,
      "step": 25630
    },
    {
      "epoch": 1.6,
      "grad_norm": 11.606321334838867,
      "learning_rate": 2.3640062072725748e-05,
      "loss": 1.1374,
      "step": 25640
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.048127174377441,
      "learning_rate": 2.3629576814998113e-05,
      "loss": 1.0934,
      "step": 25650
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.665626525878906,
      "learning_rate": 2.3619091557270478e-05,
      "loss": 1.0196,
      "step": 25660
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.166474342346191,
      "learning_rate": 2.3608606299542844e-05,
      "loss": 1.0966,
      "step": 25670
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.280580520629883,
      "learning_rate": 2.359812104181521e-05,
      "loss": 1.1459,
      "step": 25680
    },
    {
      "epoch": 1.6,
      "grad_norm": 9.225205421447754,
      "learning_rate": 2.3587635784087574e-05,
      "loss": 1.1062,
      "step": 25690
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.456197738647461,
      "learning_rate": 2.357715052635994e-05,
      "loss": 1.0669,
      "step": 25700
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.209054946899414,
      "learning_rate": 2.3566665268632305e-05,
      "loss": 1.0075,
      "step": 25710
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.537406921386719,
      "learning_rate": 2.355618001090467e-05,
      "loss": 1.0248,
      "step": 25720
    },
    {
      "epoch": 1.6,
      "grad_norm": 6.83131217956543,
      "learning_rate": 2.3545694753177032e-05,
      "loss": 1.0271,
      "step": 25730
    },
    {
      "epoch": 1.6,
      "grad_norm": 6.1259284019470215,
      "learning_rate": 2.3535209495449397e-05,
      "loss": 1.0566,
      "step": 25740
    },
    {
      "epoch": 1.6,
      "grad_norm": 5.5608367919921875,
      "learning_rate": 2.3524724237721766e-05,
      "loss": 1.143,
      "step": 25750
    },
    {
      "epoch": 1.6,
      "grad_norm": 12.411617279052734,
      "learning_rate": 2.351423897999413e-05,
      "loss": 1.1434,
      "step": 25760
    },
    {
      "epoch": 1.6,
      "grad_norm": 5.155183792114258,
      "learning_rate": 2.3503753722266493e-05,
      "loss": 0.9601,
      "step": 25770
    },
    {
      "epoch": 1.61,
      "grad_norm": 9.965703964233398,
      "learning_rate": 2.349326846453886e-05,
      "loss": 1.1076,
      "step": 25780
    },
    {
      "epoch": 1.61,
      "grad_norm": 10.12524700164795,
      "learning_rate": 2.3482783206811224e-05,
      "loss": 1.0445,
      "step": 25790
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.485877990722656,
      "learning_rate": 2.347229794908359e-05,
      "loss": 1.0426,
      "step": 25800
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.665715217590332,
      "learning_rate": 2.3461812691355955e-05,
      "loss": 1.1316,
      "step": 25810
    },
    {
      "epoch": 1.61,
      "grad_norm": 10.342679977416992,
      "learning_rate": 2.345132743362832e-05,
      "loss": 1.1442,
      "step": 25820
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.646844863891602,
      "learning_rate": 2.3440842175900685e-05,
      "loss": 1.0691,
      "step": 25830
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.933148384094238,
      "learning_rate": 2.343035691817305e-05,
      "loss": 1.0156,
      "step": 25840
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.437822341918945,
      "learning_rate": 2.3419871660445412e-05,
      "loss": 1.0946,
      "step": 25850
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.281590461730957,
      "learning_rate": 2.340938640271778e-05,
      "loss": 1.0673,
      "step": 25860
    },
    {
      "epoch": 1.61,
      "grad_norm": 5.53472900390625,
      "learning_rate": 2.3398901144990146e-05,
      "loss": 0.9721,
      "step": 25870
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.003471374511719,
      "learning_rate": 2.3388415887262512e-05,
      "loss": 1.0527,
      "step": 25880
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.060001850128174,
      "learning_rate": 2.3377930629534874e-05,
      "loss": 1.1282,
      "step": 25890
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.972853660583496,
      "learning_rate": 2.336744537180724e-05,
      "loss": 1.0894,
      "step": 25900
    },
    {
      "epoch": 1.61,
      "grad_norm": 6.700921058654785,
      "learning_rate": 2.3356960114079604e-05,
      "loss": 1.1096,
      "step": 25910
    },
    {
      "epoch": 1.61,
      "grad_norm": 8.225870132446289,
      "learning_rate": 2.3346474856351973e-05,
      "loss": 1.0685,
      "step": 25920
    },
    {
      "epoch": 1.61,
      "grad_norm": 5.42494010925293,
      "learning_rate": 2.3335989598624335e-05,
      "loss": 1.0169,
      "step": 25930
    },
    {
      "epoch": 1.61,
      "grad_norm": 11.715315818786621,
      "learning_rate": 2.33255043408967e-05,
      "loss": 0.8945,
      "step": 25940
    },
    {
      "epoch": 1.62,
      "grad_norm": 11.267034530639648,
      "learning_rate": 2.3315019083169065e-05,
      "loss": 1.1436,
      "step": 25950
    },
    {
      "epoch": 1.62,
      "grad_norm": 9.142889976501465,
      "learning_rate": 2.330453382544143e-05,
      "loss": 1.0816,
      "step": 25960
    },
    {
      "epoch": 1.62,
      "grad_norm": 7.166412353515625,
      "learning_rate": 2.3294048567713793e-05,
      "loss": 1.1319,
      "step": 25970
    },
    {
      "epoch": 1.62,
      "grad_norm": 6.822816848754883,
      "learning_rate": 2.328356330998616e-05,
      "loss": 1.1308,
      "step": 25980
    },
    {
      "epoch": 1.62,
      "grad_norm": 8.887660026550293,
      "learning_rate": 2.3273078052258527e-05,
      "loss": 1.1538,
      "step": 25990
    },
    {
      "epoch": 1.62,
      "grad_norm": 8.899762153625488,
      "learning_rate": 2.3262592794530892e-05,
      "loss": 1.0938,
      "step": 26000
    },
    {
      "epoch": 1.62,
      "grad_norm": 9.99366569519043,
      "learning_rate": 2.3252107536803254e-05,
      "loss": 1.0437,
      "step": 26010
    },
    {
      "epoch": 1.62,
      "grad_norm": 10.476101875305176,
      "learning_rate": 2.324162227907562e-05,
      "loss": 1.0456,
      "step": 26020
    },
    {
      "epoch": 1.62,
      "grad_norm": 8.563026428222656,
      "learning_rate": 2.3231137021347985e-05,
      "loss": 1.0795,
      "step": 26030
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.78564453125,
      "learning_rate": 2.3220651763620353e-05,
      "loss": 1.0087,
      "step": 26040
    },
    {
      "epoch": 1.62,
      "grad_norm": 10.327251434326172,
      "learning_rate": 2.3210166505892715e-05,
      "loss": 1.022,
      "step": 26050
    },
    {
      "epoch": 1.62,
      "grad_norm": 12.094246864318848,
      "learning_rate": 2.319968124816508e-05,
      "loss": 1.2014,
      "step": 26060
    },
    {
      "epoch": 1.62,
      "grad_norm": 10.401025772094727,
      "learning_rate": 2.3189195990437446e-05,
      "loss": 1.0493,
      "step": 26070
    },
    {
      "epoch": 1.62,
      "grad_norm": 9.881745338439941,
      "learning_rate": 2.317871073270981e-05,
      "loss": 1.1754,
      "step": 26080
    },
    {
      "epoch": 1.62,
      "grad_norm": 7.414830684661865,
      "learning_rate": 2.3168225474982176e-05,
      "loss": 1.1237,
      "step": 26090
    },
    {
      "epoch": 1.62,
      "grad_norm": 9.573813438415527,
      "learning_rate": 2.3157740217254542e-05,
      "loss": 1.0868,
      "step": 26100
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.11540699005127,
      "learning_rate": 2.3147254959526907e-05,
      "loss": 1.076,
      "step": 26110
    },
    {
      "epoch": 1.63,
      "grad_norm": 14.552440643310547,
      "learning_rate": 2.3136769701799272e-05,
      "loss": 1.2171,
      "step": 26120
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.028541564941406,
      "learning_rate": 2.3126284444071634e-05,
      "loss": 1.1027,
      "step": 26130
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.491023063659668,
      "learning_rate": 2.3115799186344e-05,
      "loss": 1.0448,
      "step": 26140
    },
    {
      "epoch": 1.63,
      "grad_norm": 11.389046669006348,
      "learning_rate": 2.310531392861637e-05,
      "loss": 1.1145,
      "step": 26150
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.998183250427246,
      "learning_rate": 2.3094828670888734e-05,
      "loss": 1.0956,
      "step": 26160
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.208030700683594,
      "learning_rate": 2.3084343413161096e-05,
      "loss": 1.023,
      "step": 26170
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.760485649108887,
      "learning_rate": 2.307385815543346e-05,
      "loss": 1.0795,
      "step": 26180
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.916561126708984,
      "learning_rate": 2.3063372897705826e-05,
      "loss": 1.0147,
      "step": 26190
    },
    {
      "epoch": 1.63,
      "grad_norm": 6.699584484100342,
      "learning_rate": 2.305288763997819e-05,
      "loss": 1.1237,
      "step": 26200
    },
    {
      "epoch": 1.63,
      "grad_norm": 6.5423173904418945,
      "learning_rate": 2.3042402382250557e-05,
      "loss": 1.0445,
      "step": 26210
    },
    {
      "epoch": 1.63,
      "grad_norm": 10.82598876953125,
      "learning_rate": 2.3031917124522922e-05,
      "loss": 1.0692,
      "step": 26220
    },
    {
      "epoch": 1.63,
      "grad_norm": 10.062834739685059,
      "learning_rate": 2.3021431866795287e-05,
      "loss": 0.9789,
      "step": 26230
    },
    {
      "epoch": 1.63,
      "grad_norm": 8.05401611328125,
      "learning_rate": 2.3010946609067653e-05,
      "loss": 1.004,
      "step": 26240
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.6762518882751465,
      "learning_rate": 2.3000461351340018e-05,
      "loss": 1.1627,
      "step": 26250
    },
    {
      "epoch": 1.63,
      "grad_norm": 7.380245685577393,
      "learning_rate": 2.298997609361238e-05,
      "loss": 1.0085,
      "step": 26260
    },
    {
      "epoch": 1.64,
      "grad_norm": 8.379406929016113,
      "learning_rate": 2.297949083588475e-05,
      "loss": 1.073,
      "step": 26270
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.935848236083984,
      "learning_rate": 2.2969005578157114e-05,
      "loss": 1.0461,
      "step": 26280
    },
    {
      "epoch": 1.64,
      "grad_norm": 8.803947448730469,
      "learning_rate": 2.2958520320429476e-05,
      "loss": 1.1387,
      "step": 26290
    },
    {
      "epoch": 1.64,
      "grad_norm": 10.80012321472168,
      "learning_rate": 2.294803506270184e-05,
      "loss": 1.0407,
      "step": 26300
    },
    {
      "epoch": 1.64,
      "grad_norm": 5.459575653076172,
      "learning_rate": 2.2937549804974206e-05,
      "loss": 1.1398,
      "step": 26310
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.711251735687256,
      "learning_rate": 2.2927064547246572e-05,
      "loss": 1.0411,
      "step": 26320
    },
    {
      "epoch": 1.64,
      "grad_norm": 5.133242607116699,
      "learning_rate": 2.2916579289518937e-05,
      "loss": 0.9296,
      "step": 26330
    },
    {
      "epoch": 1.64,
      "grad_norm": 7.181493282318115,
      "learning_rate": 2.2906094031791302e-05,
      "loss": 1.0035,
      "step": 26340
    },
    {
      "epoch": 1.64,
      "grad_norm": 7.816117286682129,
      "learning_rate": 2.2895608774063668e-05,
      "loss": 1.074,
      "step": 26350
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.614727973937988,
      "learning_rate": 2.2885123516336033e-05,
      "loss": 0.9698,
      "step": 26360
    },
    {
      "epoch": 1.64,
      "grad_norm": 7.705747127532959,
      "learning_rate": 2.28746382586084e-05,
      "loss": 1.1057,
      "step": 26370
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.654297351837158,
      "learning_rate": 2.286415300088076e-05,
      "loss": 0.9814,
      "step": 26380
    },
    {
      "epoch": 1.64,
      "grad_norm": 8.233785629272461,
      "learning_rate": 2.285366774315313e-05,
      "loss": 1.0454,
      "step": 26390
    },
    {
      "epoch": 1.64,
      "grad_norm": 8.356417655944824,
      "learning_rate": 2.2843182485425494e-05,
      "loss": 1.0987,
      "step": 26400
    },
    {
      "epoch": 1.64,
      "grad_norm": 7.875436782836914,
      "learning_rate": 2.283269722769786e-05,
      "loss": 1.0728,
      "step": 26410
    },
    {
      "epoch": 1.64,
      "grad_norm": 9.201026916503906,
      "learning_rate": 2.282221196997022e-05,
      "loss": 1.006,
      "step": 26420
    },
    {
      "epoch": 1.65,
      "grad_norm": 8.419748306274414,
      "learning_rate": 2.2811726712242587e-05,
      "loss": 1.1175,
      "step": 26430
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.5745673179626465,
      "learning_rate": 2.2801241454514956e-05,
      "loss": 1.0278,
      "step": 26440
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.140052795410156,
      "learning_rate": 2.2790756196787317e-05,
      "loss": 1.0974,
      "step": 26450
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.553968906402588,
      "learning_rate": 2.2780270939059683e-05,
      "loss": 1.1572,
      "step": 26460
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.469237327575684,
      "learning_rate": 2.2769785681332048e-05,
      "loss": 0.997,
      "step": 26470
    },
    {
      "epoch": 1.65,
      "grad_norm": 7.430567264556885,
      "learning_rate": 2.2759300423604413e-05,
      "loss": 1.0615,
      "step": 26480
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.86191987991333,
      "learning_rate": 2.274881516587678e-05,
      "loss": 0.9784,
      "step": 26490
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.310348510742188,
      "learning_rate": 2.2738329908149144e-05,
      "loss": 1.0175,
      "step": 26500
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.272089004516602,
      "learning_rate": 2.272784465042151e-05,
      "loss": 0.9694,
      "step": 26510
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.412130355834961,
      "learning_rate": 2.2717359392693875e-05,
      "loss": 1.0716,
      "step": 26520
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.507328510284424,
      "learning_rate": 2.270687413496624e-05,
      "loss": 1.105,
      "step": 26530
    },
    {
      "epoch": 1.65,
      "grad_norm": 11.026570320129395,
      "learning_rate": 2.2696388877238602e-05,
      "loss": 1.1265,
      "step": 26540
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.389677047729492,
      "learning_rate": 2.2685903619510967e-05,
      "loss": 1.1813,
      "step": 26550
    },
    {
      "epoch": 1.65,
      "grad_norm": 8.274693489074707,
      "learning_rate": 2.2675418361783336e-05,
      "loss": 1.1064,
      "step": 26560
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.768000602722168,
      "learning_rate": 2.26649331040557e-05,
      "loss": 0.9698,
      "step": 26570
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.141150951385498,
      "learning_rate": 2.2654447846328063e-05,
      "loss": 1.0965,
      "step": 26580
    },
    {
      "epoch": 1.66,
      "grad_norm": 11.415058135986328,
      "learning_rate": 2.264396258860043e-05,
      "loss": 1.1553,
      "step": 26590
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.45466423034668,
      "learning_rate": 2.2633477330872794e-05,
      "loss": 1.0798,
      "step": 26600
    },
    {
      "epoch": 1.66,
      "grad_norm": 5.750943183898926,
      "learning_rate": 2.262299207314516e-05,
      "loss": 1.0149,
      "step": 26610
    },
    {
      "epoch": 1.66,
      "grad_norm": 6.011809349060059,
      "learning_rate": 2.2612506815417524e-05,
      "loss": 1.1417,
      "step": 26620
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.610287189483643,
      "learning_rate": 2.260202155768989e-05,
      "loss": 1.1427,
      "step": 26630
    },
    {
      "epoch": 1.66,
      "grad_norm": 6.424483299255371,
      "learning_rate": 2.2591536299962255e-05,
      "loss": 1.0795,
      "step": 26640
    },
    {
      "epoch": 1.66,
      "grad_norm": 5.660188674926758,
      "learning_rate": 2.258105104223462e-05,
      "loss": 0.9843,
      "step": 26650
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.683391094207764,
      "learning_rate": 2.2570565784506982e-05,
      "loss": 1.0032,
      "step": 26660
    },
    {
      "epoch": 1.66,
      "grad_norm": 11.061634063720703,
      "learning_rate": 2.2560080526779347e-05,
      "loss": 1.0837,
      "step": 26670
    },
    {
      "epoch": 1.66,
      "grad_norm": 5.179654598236084,
      "learning_rate": 2.2549595269051716e-05,
      "loss": 1.0582,
      "step": 26680
    },
    {
      "epoch": 1.66,
      "grad_norm": 4.727421760559082,
      "learning_rate": 2.253911001132408e-05,
      "loss": 1.1129,
      "step": 26690
    },
    {
      "epoch": 1.66,
      "grad_norm": 7.385718822479248,
      "learning_rate": 2.2528624753596443e-05,
      "loss": 1.0134,
      "step": 26700
    },
    {
      "epoch": 1.66,
      "grad_norm": 8.639348983764648,
      "learning_rate": 2.251813949586881e-05,
      "loss": 1.0394,
      "step": 26710
    },
    {
      "epoch": 1.66,
      "grad_norm": 9.304439544677734,
      "learning_rate": 2.2507654238141174e-05,
      "loss": 1.2132,
      "step": 26720
    },
    {
      "epoch": 1.66,
      "grad_norm": 11.066200256347656,
      "learning_rate": 2.249716898041354e-05,
      "loss": 1.1363,
      "step": 26730
    },
    {
      "epoch": 1.66,
      "grad_norm": 9.59226131439209,
      "learning_rate": 2.2486683722685905e-05,
      "loss": 1.104,
      "step": 26740
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.427692890167236,
      "learning_rate": 2.247619846495827e-05,
      "loss": 1.0449,
      "step": 26750
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.864735126495361,
      "learning_rate": 2.2465713207230635e-05,
      "loss": 1.0228,
      "step": 26760
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.843433380126953,
      "learning_rate": 2.2455227949503e-05,
      "loss": 1.2417,
      "step": 26770
    },
    {
      "epoch": 1.67,
      "grad_norm": 11.797667503356934,
      "learning_rate": 2.2444742691775363e-05,
      "loss": 0.9399,
      "step": 26780
    },
    {
      "epoch": 1.67,
      "grad_norm": 10.661076545715332,
      "learning_rate": 2.243425743404773e-05,
      "loss": 1.0867,
      "step": 26790
    },
    {
      "epoch": 1.67,
      "grad_norm": 11.654475212097168,
      "learning_rate": 2.2423772176320097e-05,
      "loss": 1.0484,
      "step": 26800
    },
    {
      "epoch": 1.67,
      "grad_norm": 10.959793090820312,
      "learning_rate": 2.2413286918592462e-05,
      "loss": 1.1092,
      "step": 26810
    },
    {
      "epoch": 1.67,
      "grad_norm": 8.59924030303955,
      "learning_rate": 2.2402801660864824e-05,
      "loss": 1.0228,
      "step": 26820
    },
    {
      "epoch": 1.67,
      "grad_norm": 7.081762790679932,
      "learning_rate": 2.239231640313719e-05,
      "loss": 1.0951,
      "step": 26830
    },
    {
      "epoch": 1.67,
      "grad_norm": 10.649991989135742,
      "learning_rate": 2.2381831145409554e-05,
      "loss": 1.1158,
      "step": 26840
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.443003177642822,
      "learning_rate": 2.2371345887681923e-05,
      "loss": 1.0737,
      "step": 26850
    },
    {
      "epoch": 1.67,
      "grad_norm": 5.604686737060547,
      "learning_rate": 2.2360860629954285e-05,
      "loss": 1.0789,
      "step": 26860
    },
    {
      "epoch": 1.67,
      "grad_norm": 8.29799747467041,
      "learning_rate": 2.235037537222665e-05,
      "loss": 1.0963,
      "step": 26870
    },
    {
      "epoch": 1.67,
      "grad_norm": 7.669922828674316,
      "learning_rate": 2.2339890114499016e-05,
      "loss": 0.9547,
      "step": 26880
    },
    {
      "epoch": 1.67,
      "grad_norm": 7.544241428375244,
      "learning_rate": 2.232940485677138e-05,
      "loss": 1.0709,
      "step": 26890
    },
    {
      "epoch": 1.67,
      "grad_norm": 12.775601387023926,
      "learning_rate": 2.2318919599043743e-05,
      "loss": 1.0789,
      "step": 26900
    },
    {
      "epoch": 1.68,
      "grad_norm": 5.856772422790527,
      "learning_rate": 2.230843434131611e-05,
      "loss": 1.0565,
      "step": 26910
    },
    {
      "epoch": 1.68,
      "grad_norm": 8.852644920349121,
      "learning_rate": 2.2297949083588477e-05,
      "loss": 1.1252,
      "step": 26920
    },
    {
      "epoch": 1.68,
      "grad_norm": 9.308120727539062,
      "learning_rate": 2.2287463825860842e-05,
      "loss": 1.149,
      "step": 26930
    },
    {
      "epoch": 1.68,
      "grad_norm": 8.808676719665527,
      "learning_rate": 2.2276978568133204e-05,
      "loss": 1.2221,
      "step": 26940
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.4465012550354,
      "learning_rate": 2.226649331040557e-05,
      "loss": 1.0738,
      "step": 26950
    },
    {
      "epoch": 1.68,
      "grad_norm": 5.931910991668701,
      "learning_rate": 2.2256008052677935e-05,
      "loss": 1.0645,
      "step": 26960
    },
    {
      "epoch": 1.68,
      "grad_norm": 10.332311630249023,
      "learning_rate": 2.2245522794950303e-05,
      "loss": 1.1813,
      "step": 26970
    },
    {
      "epoch": 1.68,
      "grad_norm": 10.437993049621582,
      "learning_rate": 2.2235037537222665e-05,
      "loss": 1.1283,
      "step": 26980
    },
    {
      "epoch": 1.68,
      "grad_norm": 9.243430137634277,
      "learning_rate": 2.222455227949503e-05,
      "loss": 1.0396,
      "step": 26990
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.567749500274658,
      "learning_rate": 2.2214067021767396e-05,
      "loss": 1.0016,
      "step": 27000
    },
    {
      "epoch": 1.68,
      "grad_norm": 8.603780746459961,
      "learning_rate": 2.220358176403976e-05,
      "loss": 1.0271,
      "step": 27010
    },
    {
      "epoch": 1.68,
      "grad_norm": 10.017716407775879,
      "learning_rate": 2.2193096506312127e-05,
      "loss": 1.0566,
      "step": 27020
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.593728065490723,
      "learning_rate": 2.2182611248584492e-05,
      "loss": 0.991,
      "step": 27030
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.619984149932861,
      "learning_rate": 2.2172125990856857e-05,
      "loss": 1.1179,
      "step": 27040
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.5567450523376465,
      "learning_rate": 2.2161640733129222e-05,
      "loss": 0.9768,
      "step": 27050
    },
    {
      "epoch": 1.68,
      "grad_norm": 12.157520294189453,
      "learning_rate": 2.2151155475401584e-05,
      "loss": 0.9216,
      "step": 27060
    },
    {
      "epoch": 1.69,
      "grad_norm": 8.754375457763672,
      "learning_rate": 2.214067021767395e-05,
      "loss": 1.1572,
      "step": 27070
    },
    {
      "epoch": 1.69,
      "grad_norm": 9.347681999206543,
      "learning_rate": 2.213018495994632e-05,
      "loss": 0.9484,
      "step": 27080
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.4831929206848145,
      "learning_rate": 2.2119699702218684e-05,
      "loss": 0.9656,
      "step": 27090
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.329488277435303,
      "learning_rate": 2.2109214444491046e-05,
      "loss": 1.0413,
      "step": 27100
    },
    {
      "epoch": 1.69,
      "grad_norm": 9.288773536682129,
      "learning_rate": 2.209872918676341e-05,
      "loss": 1.1941,
      "step": 27110
    },
    {
      "epoch": 1.69,
      "grad_norm": 8.141908645629883,
      "learning_rate": 2.2088243929035776e-05,
      "loss": 1.144,
      "step": 27120
    },
    {
      "epoch": 1.69,
      "grad_norm": 8.54360580444336,
      "learning_rate": 2.207775867130814e-05,
      "loss": 1.1354,
      "step": 27130
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.621323108673096,
      "learning_rate": 2.2067273413580507e-05,
      "loss": 1.1322,
      "step": 27140
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.902056694030762,
      "learning_rate": 2.2056788155852872e-05,
      "loss": 1.1119,
      "step": 27150
    },
    {
      "epoch": 1.69,
      "grad_norm": 9.331924438476562,
      "learning_rate": 2.2046302898125237e-05,
      "loss": 1.0811,
      "step": 27160
    },
    {
      "epoch": 1.69,
      "grad_norm": 10.175644874572754,
      "learning_rate": 2.2035817640397603e-05,
      "loss": 1.0988,
      "step": 27170
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.012213706970215,
      "learning_rate": 2.2025332382669968e-05,
      "loss": 0.9449,
      "step": 27180
    },
    {
      "epoch": 1.69,
      "grad_norm": 11.861845970153809,
      "learning_rate": 2.201484712494233e-05,
      "loss": 1.0809,
      "step": 27190
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.844862461090088,
      "learning_rate": 2.20043618672147e-05,
      "loss": 1.0543,
      "step": 27200
    },
    {
      "epoch": 1.69,
      "grad_norm": 8.46119499206543,
      "learning_rate": 2.1993876609487064e-05,
      "loss": 1.0441,
      "step": 27210
    },
    {
      "epoch": 1.69,
      "grad_norm": 9.931500434875488,
      "learning_rate": 2.1983391351759426e-05,
      "loss": 1.0576,
      "step": 27220
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.724915981292725,
      "learning_rate": 2.197290609403179e-05,
      "loss": 1.1493,
      "step": 27230
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.454085826873779,
      "learning_rate": 2.1962420836304157e-05,
      "loss": 1.0551,
      "step": 27240
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.347861289978027,
      "learning_rate": 2.1951935578576522e-05,
      "loss": 1.0146,
      "step": 27250
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.572733879089355,
      "learning_rate": 2.1941450320848887e-05,
      "loss": 1.0387,
      "step": 27260
    },
    {
      "epoch": 1.7,
      "grad_norm": 12.105634689331055,
      "learning_rate": 2.1930965063121253e-05,
      "loss": 0.9494,
      "step": 27270
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.6892781257629395,
      "learning_rate": 2.1920479805393618e-05,
      "loss": 1.0762,
      "step": 27280
    },
    {
      "epoch": 1.7,
      "grad_norm": 9.946231842041016,
      "learning_rate": 2.1909994547665983e-05,
      "loss": 1.0946,
      "step": 27290
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.919681549072266,
      "learning_rate": 2.189950928993835e-05,
      "loss": 1.1026,
      "step": 27300
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.9716157913208,
      "learning_rate": 2.188902403221071e-05,
      "loss": 1.1219,
      "step": 27310
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.801198959350586,
      "learning_rate": 2.187853877448308e-05,
      "loss": 1.0706,
      "step": 27320
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.761126518249512,
      "learning_rate": 2.1868053516755444e-05,
      "loss": 0.8716,
      "step": 27330
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.561679363250732,
      "learning_rate": 2.185756825902781e-05,
      "loss": 1.2375,
      "step": 27340
    },
    {
      "epoch": 1.7,
      "grad_norm": 9.538490295410156,
      "learning_rate": 2.184708300130017e-05,
      "loss": 1.0125,
      "step": 27350
    },
    {
      "epoch": 1.7,
      "grad_norm": 7.873324394226074,
      "learning_rate": 2.1836597743572537e-05,
      "loss": 1.0826,
      "step": 27360
    },
    {
      "epoch": 1.7,
      "grad_norm": 8.553080558776855,
      "learning_rate": 2.1826112485844902e-05,
      "loss": 1.0288,
      "step": 27370
    },
    {
      "epoch": 1.7,
      "grad_norm": 10.645966529846191,
      "learning_rate": 2.1815627228117268e-05,
      "loss": 1.0338,
      "step": 27380
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.136907577514648,
      "learning_rate": 2.1805141970389633e-05,
      "loss": 1.0274,
      "step": 27390
    },
    {
      "epoch": 1.71,
      "grad_norm": 10.124556541442871,
      "learning_rate": 2.1794656712661998e-05,
      "loss": 1.0403,
      "step": 27400
    },
    {
      "epoch": 1.71,
      "grad_norm": 9.19261646270752,
      "learning_rate": 2.1784171454934363e-05,
      "loss": 1.0989,
      "step": 27410
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.544472694396973,
      "learning_rate": 2.177368619720673e-05,
      "loss": 1.0105,
      "step": 27420
    },
    {
      "epoch": 1.71,
      "grad_norm": 9.156542778015137,
      "learning_rate": 2.1763200939479094e-05,
      "loss": 1.13,
      "step": 27430
    },
    {
      "epoch": 1.71,
      "grad_norm": 8.55378246307373,
      "learning_rate": 2.175271568175146e-05,
      "loss": 1.0069,
      "step": 27440
    },
    {
      "epoch": 1.71,
      "grad_norm": 12.045454978942871,
      "learning_rate": 2.1742230424023825e-05,
      "loss": 1.105,
      "step": 27450
    },
    {
      "epoch": 1.71,
      "grad_norm": 9.356218338012695,
      "learning_rate": 2.173174516629619e-05,
      "loss": 1.094,
      "step": 27460
    },
    {
      "epoch": 1.71,
      "grad_norm": 14.816198348999023,
      "learning_rate": 2.1721259908568552e-05,
      "loss": 1.1281,
      "step": 27470
    },
    {
      "epoch": 1.71,
      "grad_norm": 7.430862903594971,
      "learning_rate": 2.1710774650840917e-05,
      "loss": 1.1598,
      "step": 27480
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.31941556930542,
      "learning_rate": 2.1700289393113286e-05,
      "loss": 1.1124,
      "step": 27490
    },
    {
      "epoch": 1.71,
      "grad_norm": 5.766456127166748,
      "learning_rate": 2.168980413538565e-05,
      "loss": 1.0569,
      "step": 27500
    },
    {
      "epoch": 1.71,
      "grad_norm": 11.109753608703613,
      "learning_rate": 2.1679318877658013e-05,
      "loss": 1.0323,
      "step": 27510
    },
    {
      "epoch": 1.71,
      "grad_norm": 8.176178932189941,
      "learning_rate": 2.166883361993038e-05,
      "loss": 1.1097,
      "step": 27520
    },
    {
      "epoch": 1.71,
      "grad_norm": 7.99873161315918,
      "learning_rate": 2.1658348362202744e-05,
      "loss": 1.1586,
      "step": 27530
    },
    {
      "epoch": 1.71,
      "grad_norm": 10.24547004699707,
      "learning_rate": 2.164786310447511e-05,
      "loss": 0.9719,
      "step": 27540
    },
    {
      "epoch": 1.72,
      "grad_norm": 9.507823944091797,
      "learning_rate": 2.1637377846747474e-05,
      "loss": 1.1244,
      "step": 27550
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.696142196655273,
      "learning_rate": 2.162689258901984e-05,
      "loss": 1.1375,
      "step": 27560
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.344112396240234,
      "learning_rate": 2.1616407331292205e-05,
      "loss": 1.0011,
      "step": 27570
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.92767858505249,
      "learning_rate": 2.160592207356457e-05,
      "loss": 1.0381,
      "step": 27580
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.3812785148620605,
      "learning_rate": 2.1595436815836932e-05,
      "loss": 1.1171,
      "step": 27590
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.848332405090332,
      "learning_rate": 2.1584951558109298e-05,
      "loss": 1.135,
      "step": 27600
    },
    {
      "epoch": 1.72,
      "grad_norm": 11.945801734924316,
      "learning_rate": 2.1574466300381666e-05,
      "loss": 1.0769,
      "step": 27610
    },
    {
      "epoch": 1.72,
      "grad_norm": 7.460800647735596,
      "learning_rate": 2.156398104265403e-05,
      "loss": 1.1184,
      "step": 27620
    },
    {
      "epoch": 1.72,
      "grad_norm": 11.54788875579834,
      "learning_rate": 2.1553495784926394e-05,
      "loss": 1.1112,
      "step": 27630
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.907721519470215,
      "learning_rate": 2.154301052719876e-05,
      "loss": 0.8887,
      "step": 27640
    },
    {
      "epoch": 1.72,
      "grad_norm": 7.945696830749512,
      "learning_rate": 2.1532525269471124e-05,
      "loss": 1.1424,
      "step": 27650
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.993499755859375,
      "learning_rate": 2.152204001174349e-05,
      "loss": 1.0751,
      "step": 27660
    },
    {
      "epoch": 1.72,
      "grad_norm": 12.417642593383789,
      "learning_rate": 2.1511554754015855e-05,
      "loss": 1.2029,
      "step": 27670
    },
    {
      "epoch": 1.72,
      "grad_norm": 10.036255836486816,
      "learning_rate": 2.150106949628822e-05,
      "loss": 1.0102,
      "step": 27680
    },
    {
      "epoch": 1.72,
      "grad_norm": 9.960199356079102,
      "learning_rate": 2.1490584238560585e-05,
      "loss": 1.0345,
      "step": 27690
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.972838401794434,
      "learning_rate": 2.148009898083295e-05,
      "loss": 1.0524,
      "step": 27700
    },
    {
      "epoch": 1.73,
      "grad_norm": 11.272539138793945,
      "learning_rate": 2.1469613723105313e-05,
      "loss": 1.1244,
      "step": 27710
    },
    {
      "epoch": 1.73,
      "grad_norm": 7.678501129150391,
      "learning_rate": 2.1459128465377678e-05,
      "loss": 1.0667,
      "step": 27720
    },
    {
      "epoch": 1.73,
      "grad_norm": 5.217576026916504,
      "learning_rate": 2.1448643207650047e-05,
      "loss": 1.0181,
      "step": 27730
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.208012580871582,
      "learning_rate": 2.1438157949922412e-05,
      "loss": 1.0093,
      "step": 27740
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.975427150726318,
      "learning_rate": 2.1427672692194774e-05,
      "loss": 1.0243,
      "step": 27750
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.808485984802246,
      "learning_rate": 2.141718743446714e-05,
      "loss": 1.1207,
      "step": 27760
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.495051860809326,
      "learning_rate": 2.1406702176739504e-05,
      "loss": 0.9569,
      "step": 27770
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.037904739379883,
      "learning_rate": 2.1396216919011873e-05,
      "loss": 1.0436,
      "step": 27780
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.55755090713501,
      "learning_rate": 2.1385731661284235e-05,
      "loss": 1.0789,
      "step": 27790
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.867666721343994,
      "learning_rate": 2.13752464035566e-05,
      "loss": 1.0375,
      "step": 27800
    },
    {
      "epoch": 1.73,
      "grad_norm": 10.518439292907715,
      "learning_rate": 2.1364761145828966e-05,
      "loss": 1.0747,
      "step": 27810
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.543771743774414,
      "learning_rate": 2.135427588810133e-05,
      "loss": 1.0005,
      "step": 27820
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.613312721252441,
      "learning_rate": 2.1343790630373693e-05,
      "loss": 1.0334,
      "step": 27830
    },
    {
      "epoch": 1.73,
      "grad_norm": 9.449170112609863,
      "learning_rate": 2.133330537264606e-05,
      "loss": 1.1514,
      "step": 27840
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.243673324584961,
      "learning_rate": 2.1322820114918427e-05,
      "loss": 1.0134,
      "step": 27850
    },
    {
      "epoch": 1.73,
      "grad_norm": 7.137185573577881,
      "learning_rate": 2.1312334857190792e-05,
      "loss": 1.1192,
      "step": 27860
    },
    {
      "epoch": 1.74,
      "grad_norm": 10.571348190307617,
      "learning_rate": 2.1301849599463154e-05,
      "loss": 1.0775,
      "step": 27870
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.821014404296875,
      "learning_rate": 2.129136434173552e-05,
      "loss": 1.1333,
      "step": 27880
    },
    {
      "epoch": 1.74,
      "grad_norm": 11.945330619812012,
      "learning_rate": 2.1280879084007885e-05,
      "loss": 1.1244,
      "step": 27890
    },
    {
      "epoch": 1.74,
      "grad_norm": 6.25648832321167,
      "learning_rate": 2.1270393826280253e-05,
      "loss": 1.0557,
      "step": 27900
    },
    {
      "epoch": 1.74,
      "grad_norm": 7.584466457366943,
      "learning_rate": 2.1259908568552615e-05,
      "loss": 1.1033,
      "step": 27910
    },
    {
      "epoch": 1.74,
      "grad_norm": 7.251534461975098,
      "learning_rate": 2.124942331082498e-05,
      "loss": 1.0809,
      "step": 27920
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.490039825439453,
      "learning_rate": 2.1238938053097346e-05,
      "loss": 0.9534,
      "step": 27930
    },
    {
      "epoch": 1.74,
      "grad_norm": 5.814958095550537,
      "learning_rate": 2.122845279536971e-05,
      "loss": 1.179,
      "step": 27940
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.698675632476807,
      "learning_rate": 2.1217967537642077e-05,
      "loss": 1.1088,
      "step": 27950
    },
    {
      "epoch": 1.74,
      "grad_norm": 10.487876892089844,
      "learning_rate": 2.1207482279914442e-05,
      "loss": 1.136,
      "step": 27960
    },
    {
      "epoch": 1.74,
      "grad_norm": 9.318907737731934,
      "learning_rate": 2.1196997022186807e-05,
      "loss": 1.0154,
      "step": 27970
    },
    {
      "epoch": 1.74,
      "grad_norm": 7.477406978607178,
      "learning_rate": 2.1186511764459173e-05,
      "loss": 1.076,
      "step": 27980
    },
    {
      "epoch": 1.74,
      "grad_norm": 10.804237365722656,
      "learning_rate": 2.1176026506731535e-05,
      "loss": 0.995,
      "step": 27990
    },
    {
      "epoch": 1.74,
      "grad_norm": 7.638513088226318,
      "learning_rate": 2.11655412490039e-05,
      "loss": 1.0635,
      "step": 28000
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.751432418823242,
      "learning_rate": 2.1155055991276265e-05,
      "loss": 1.1733,
      "step": 28010
    },
    {
      "epoch": 1.74,
      "grad_norm": 6.8986382484436035,
      "learning_rate": 2.1144570733548634e-05,
      "loss": 1.0708,
      "step": 28020
    },
    {
      "epoch": 1.75,
      "grad_norm": 11.122243881225586,
      "learning_rate": 2.1134085475820996e-05,
      "loss": 1.0935,
      "step": 28030
    },
    {
      "epoch": 1.75,
      "grad_norm": 11.57702922821045,
      "learning_rate": 2.112360021809336e-05,
      "loss": 1.0196,
      "step": 28040
    },
    {
      "epoch": 1.75,
      "grad_norm": 12.275002479553223,
      "learning_rate": 2.1113114960365726e-05,
      "loss": 1.0614,
      "step": 28050
    },
    {
      "epoch": 1.75,
      "grad_norm": 11.292309761047363,
      "learning_rate": 2.110262970263809e-05,
      "loss": 1.0387,
      "step": 28060
    },
    {
      "epoch": 1.75,
      "grad_norm": 8.100686073303223,
      "learning_rate": 2.1092144444910457e-05,
      "loss": 1.0991,
      "step": 28070
    },
    {
      "epoch": 1.75,
      "grad_norm": 8.157206535339355,
      "learning_rate": 2.1081659187182822e-05,
      "loss": 1.2118,
      "step": 28080
    },
    {
      "epoch": 1.75,
      "grad_norm": 11.048992156982422,
      "learning_rate": 2.1071173929455188e-05,
      "loss": 1.1784,
      "step": 28090
    },
    {
      "epoch": 1.75,
      "grad_norm": 10.24255657196045,
      "learning_rate": 2.1060688671727553e-05,
      "loss": 1.0591,
      "step": 28100
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.764870643615723,
      "learning_rate": 2.1050203413999918e-05,
      "loss": 1.0187,
      "step": 28110
    },
    {
      "epoch": 1.75,
      "grad_norm": 8.02857494354248,
      "learning_rate": 2.103971815627228e-05,
      "loss": 1.1244,
      "step": 28120
    },
    {
      "epoch": 1.75,
      "grad_norm": 6.362401008605957,
      "learning_rate": 2.102923289854465e-05,
      "loss": 1.022,
      "step": 28130
    },
    {
      "epoch": 1.75,
      "grad_norm": 8.184293746948242,
      "learning_rate": 2.1018747640817014e-05,
      "loss": 1.0411,
      "step": 28140
    },
    {
      "epoch": 1.75,
      "grad_norm": 6.770114898681641,
      "learning_rate": 2.1008262383089376e-05,
      "loss": 0.9467,
      "step": 28150
    },
    {
      "epoch": 1.75,
      "grad_norm": 11.493258476257324,
      "learning_rate": 2.099777712536174e-05,
      "loss": 1.0228,
      "step": 28160
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.981345176696777,
      "learning_rate": 2.0987291867634107e-05,
      "loss": 1.203,
      "step": 28170
    },
    {
      "epoch": 1.75,
      "grad_norm": 12.216901779174805,
      "learning_rate": 2.0976806609906472e-05,
      "loss": 1.1661,
      "step": 28180
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.687565803527832,
      "learning_rate": 2.0966321352178837e-05,
      "loss": 0.9873,
      "step": 28190
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.905312538146973,
      "learning_rate": 2.0955836094451203e-05,
      "loss": 1.0103,
      "step": 28200
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.18950080871582,
      "learning_rate": 2.0945350836723568e-05,
      "loss": 1.1339,
      "step": 28210
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.964458465576172,
      "learning_rate": 2.0934865578995933e-05,
      "loss": 1.0953,
      "step": 28220
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.649015426635742,
      "learning_rate": 2.09243803212683e-05,
      "loss": 1.0744,
      "step": 28230
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.985541820526123,
      "learning_rate": 2.091389506354066e-05,
      "loss": 0.984,
      "step": 28240
    },
    {
      "epoch": 1.76,
      "grad_norm": 10.695372581481934,
      "learning_rate": 2.090340980581303e-05,
      "loss": 1.0387,
      "step": 28250
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.396071434020996,
      "learning_rate": 2.0892924548085394e-05,
      "loss": 1.0507,
      "step": 28260
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.586015701293945,
      "learning_rate": 2.088243929035776e-05,
      "loss": 1.0391,
      "step": 28270
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.294121742248535,
      "learning_rate": 2.0871954032630122e-05,
      "loss": 1.1607,
      "step": 28280
    },
    {
      "epoch": 1.76,
      "grad_norm": 9.245611190795898,
      "learning_rate": 2.0861468774902487e-05,
      "loss": 1.0908,
      "step": 28290
    },
    {
      "epoch": 1.76,
      "grad_norm": 14.112460136413574,
      "learning_rate": 2.0850983517174852e-05,
      "loss": 1.233,
      "step": 28300
    },
    {
      "epoch": 1.76,
      "grad_norm": 8.798672676086426,
      "learning_rate": 2.0840498259447218e-05,
      "loss": 1.0745,
      "step": 28310
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.707340240478516,
      "learning_rate": 2.0830013001719583e-05,
      "loss": 1.1858,
      "step": 28320
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.5008978843688965,
      "learning_rate": 2.0819527743991948e-05,
      "loss": 1.073,
      "step": 28330
    },
    {
      "epoch": 1.76,
      "grad_norm": 8.024245262145996,
      "learning_rate": 2.0809042486264314e-05,
      "loss": 1.1037,
      "step": 28340
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.651638984680176,
      "learning_rate": 2.079855722853668e-05,
      "loss": 1.0501,
      "step": 28350
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.362945556640625,
      "learning_rate": 2.078807197080904e-05,
      "loss": 1.0688,
      "step": 28360
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.659783363342285,
      "learning_rate": 2.077758671308141e-05,
      "loss": 0.9376,
      "step": 28370
    },
    {
      "epoch": 1.77,
      "grad_norm": 7.757288455963135,
      "learning_rate": 2.0767101455353775e-05,
      "loss": 1.076,
      "step": 28380
    },
    {
      "epoch": 1.77,
      "grad_norm": 11.16738510131836,
      "learning_rate": 2.075661619762614e-05,
      "loss": 1.132,
      "step": 28390
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.365986824035645,
      "learning_rate": 2.0746130939898502e-05,
      "loss": 1.1553,
      "step": 28400
    },
    {
      "epoch": 1.77,
      "grad_norm": 8.3541841506958,
      "learning_rate": 2.0735645682170867e-05,
      "loss": 1.0426,
      "step": 28410
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.276248455047607,
      "learning_rate": 2.0725160424443236e-05,
      "loss": 0.9792,
      "step": 28420
    },
    {
      "epoch": 1.77,
      "grad_norm": 5.969409465789795,
      "learning_rate": 2.07146751667156e-05,
      "loss": 1.0383,
      "step": 28430
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.250720977783203,
      "learning_rate": 2.0704189908987963e-05,
      "loss": 1.09,
      "step": 28440
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.682190895080566,
      "learning_rate": 2.069370465126033e-05,
      "loss": 1.1904,
      "step": 28450
    },
    {
      "epoch": 1.77,
      "grad_norm": 8.466169357299805,
      "learning_rate": 2.0683219393532694e-05,
      "loss": 1.1663,
      "step": 28460
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.902416229248047,
      "learning_rate": 2.067273413580506e-05,
      "loss": 1.0038,
      "step": 28470
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.58765697479248,
      "learning_rate": 2.0662248878077425e-05,
      "loss": 1.0291,
      "step": 28480
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.267970085144043,
      "learning_rate": 2.065176362034979e-05,
      "loss": 1.0989,
      "step": 28490
    },
    {
      "epoch": 1.77,
      "grad_norm": 5.4744391441345215,
      "learning_rate": 2.0641278362622155e-05,
      "loss": 1.0791,
      "step": 28500
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.211003303527832,
      "learning_rate": 2.063079310489452e-05,
      "loss": 1.0616,
      "step": 28510
    },
    {
      "epoch": 1.78,
      "grad_norm": 10.305153846740723,
      "learning_rate": 2.0620307847166882e-05,
      "loss": 1.0302,
      "step": 28520
    },
    {
      "epoch": 1.78,
      "grad_norm": 6.155585289001465,
      "learning_rate": 2.0609822589439248e-05,
      "loss": 1.0417,
      "step": 28530
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.439548969268799,
      "learning_rate": 2.0599337331711616e-05,
      "loss": 1.1573,
      "step": 28540
    },
    {
      "epoch": 1.78,
      "grad_norm": 8.716350555419922,
      "learning_rate": 2.058885207398398e-05,
      "loss": 1.0118,
      "step": 28550
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.606752872467041,
      "learning_rate": 2.0578366816256344e-05,
      "loss": 1.0511,
      "step": 28560
    },
    {
      "epoch": 1.78,
      "grad_norm": 6.934232711791992,
      "learning_rate": 2.056788155852871e-05,
      "loss": 0.9302,
      "step": 28570
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.674137115478516,
      "learning_rate": 2.0557396300801074e-05,
      "loss": 1.0113,
      "step": 28580
    },
    {
      "epoch": 1.78,
      "grad_norm": 10.759804725646973,
      "learning_rate": 2.054691104307344e-05,
      "loss": 1.0334,
      "step": 28590
    },
    {
      "epoch": 1.78,
      "grad_norm": 6.745133876800537,
      "learning_rate": 2.0536425785345805e-05,
      "loss": 1.1359,
      "step": 28600
    },
    {
      "epoch": 1.78,
      "grad_norm": 11.000202178955078,
      "learning_rate": 2.052594052761817e-05,
      "loss": 1.0342,
      "step": 28610
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.968006134033203,
      "learning_rate": 2.0515455269890535e-05,
      "loss": 1.0762,
      "step": 28620
    },
    {
      "epoch": 1.78,
      "grad_norm": 9.071647644042969,
      "learning_rate": 2.05049700121629e-05,
      "loss": 1.0204,
      "step": 28630
    },
    {
      "epoch": 1.78,
      "grad_norm": 6.546223163604736,
      "learning_rate": 2.0494484754435263e-05,
      "loss": 1.0735,
      "step": 28640
    },
    {
      "epoch": 1.78,
      "grad_norm": 9.408778190612793,
      "learning_rate": 2.0483999496707628e-05,
      "loss": 1.1593,
      "step": 28650
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.005241394042969,
      "learning_rate": 2.0473514238979997e-05,
      "loss": 1.0414,
      "step": 28660
    },
    {
      "epoch": 1.78,
      "grad_norm": 9.07295036315918,
      "learning_rate": 2.0463028981252362e-05,
      "loss": 1.0355,
      "step": 28670
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.538865089416504,
      "learning_rate": 2.0452543723524724e-05,
      "loss": 0.9698,
      "step": 28680
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.587182998657227,
      "learning_rate": 2.044205846579709e-05,
      "loss": 1.0323,
      "step": 28690
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.690011501312256,
      "learning_rate": 2.0431573208069455e-05,
      "loss": 0.9757,
      "step": 28700
    },
    {
      "epoch": 1.79,
      "grad_norm": 9.147798538208008,
      "learning_rate": 2.0421087950341823e-05,
      "loss": 1.0705,
      "step": 28710
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.2840681076049805,
      "learning_rate": 2.0410602692614185e-05,
      "loss": 1.0341,
      "step": 28720
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.80573844909668,
      "learning_rate": 2.040011743488655e-05,
      "loss": 1.0668,
      "step": 28730
    },
    {
      "epoch": 1.79,
      "grad_norm": 9.577019691467285,
      "learning_rate": 2.0389632177158916e-05,
      "loss": 1.0677,
      "step": 28740
    },
    {
      "epoch": 1.79,
      "grad_norm": 9.156763076782227,
      "learning_rate": 2.037914691943128e-05,
      "loss": 1.0794,
      "step": 28750
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.343280792236328,
      "learning_rate": 2.0368661661703643e-05,
      "loss": 0.9509,
      "step": 28760
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.094841003417969,
      "learning_rate": 2.0358176403976012e-05,
      "loss": 1.0356,
      "step": 28770
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.182851791381836,
      "learning_rate": 2.0347691146248377e-05,
      "loss": 1.1111,
      "step": 28780
    },
    {
      "epoch": 1.79,
      "grad_norm": 8.90195369720459,
      "learning_rate": 2.0337205888520742e-05,
      "loss": 1.0,
      "step": 28790
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.768863201141357,
      "learning_rate": 2.0326720630793104e-05,
      "loss": 1.0489,
      "step": 28800
    },
    {
      "epoch": 1.79,
      "grad_norm": 11.791679382324219,
      "learning_rate": 2.031623537306547e-05,
      "loss": 1.064,
      "step": 28810
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.781970500946045,
      "learning_rate": 2.0305750115337835e-05,
      "loss": 0.9993,
      "step": 28820
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.343474388122559,
      "learning_rate": 2.0295264857610204e-05,
      "loss": 1.0936,
      "step": 28830
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.2149810791015625,
      "learning_rate": 2.0284779599882566e-05,
      "loss": 1.1482,
      "step": 28840
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.775704383850098,
      "learning_rate": 2.027429434215493e-05,
      "loss": 0.9949,
      "step": 28850
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.825806617736816,
      "learning_rate": 2.0263809084427296e-05,
      "loss": 1.0201,
      "step": 28860
    },
    {
      "epoch": 1.8,
      "grad_norm": 11.002912521362305,
      "learning_rate": 2.025332382669966e-05,
      "loss": 1.0517,
      "step": 28870
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.206748008728027,
      "learning_rate": 2.0242838568972027e-05,
      "loss": 1.0522,
      "step": 28880
    },
    {
      "epoch": 1.8,
      "grad_norm": 9.138026237487793,
      "learning_rate": 2.0232353311244392e-05,
      "loss": 1.0708,
      "step": 28890
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.313522815704346,
      "learning_rate": 2.0221868053516757e-05,
      "loss": 1.2052,
      "step": 28900
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.319493293762207,
      "learning_rate": 2.0211382795789123e-05,
      "loss": 1.0739,
      "step": 28910
    },
    {
      "epoch": 1.8,
      "grad_norm": 10.492657661437988,
      "learning_rate": 2.0200897538061485e-05,
      "loss": 1.0823,
      "step": 28920
    },
    {
      "epoch": 1.8,
      "grad_norm": 9.674180030822754,
      "learning_rate": 2.019041228033385e-05,
      "loss": 1.1677,
      "step": 28930
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.549044609069824,
      "learning_rate": 2.0179927022606215e-05,
      "loss": 1.0619,
      "step": 28940
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.865693092346191,
      "learning_rate": 2.0169441764878584e-05,
      "loss": 1.0715,
      "step": 28950
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.641819000244141,
      "learning_rate": 2.0158956507150946e-05,
      "loss": 0.9687,
      "step": 28960
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.809946060180664,
      "learning_rate": 2.014847124942331e-05,
      "loss": 1.0687,
      "step": 28970
    },
    {
      "epoch": 1.8,
      "grad_norm": 10.682221412658691,
      "learning_rate": 2.0137985991695676e-05,
      "loss": 0.9425,
      "step": 28980
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.512895584106445,
      "learning_rate": 2.0127500733968042e-05,
      "loss": 1.0408,
      "step": 28990
    },
    {
      "epoch": 1.81,
      "grad_norm": 10.685091972351074,
      "learning_rate": 2.0117015476240407e-05,
      "loss": 1.0527,
      "step": 29000
    },
    {
      "epoch": 1.81,
      "grad_norm": 8.252102851867676,
      "learning_rate": 2.0106530218512772e-05,
      "loss": 1.0369,
      "step": 29010
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.44153118133545,
      "learning_rate": 2.0096044960785138e-05,
      "loss": 1.0144,
      "step": 29020
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.525562286376953,
      "learning_rate": 2.0085559703057503e-05,
      "loss": 0.9863,
      "step": 29030
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.984495639801025,
      "learning_rate": 2.007507444532987e-05,
      "loss": 1.0468,
      "step": 29040
    },
    {
      "epoch": 1.81,
      "grad_norm": 7.446178913116455,
      "learning_rate": 2.006458918760223e-05,
      "loss": 1.1115,
      "step": 29050
    },
    {
      "epoch": 1.81,
      "grad_norm": 6.821288108825684,
      "learning_rate": 2.00541039298746e-05,
      "loss": 1.0809,
      "step": 29060
    },
    {
      "epoch": 1.81,
      "grad_norm": 11.306925773620605,
      "learning_rate": 2.0043618672146964e-05,
      "loss": 1.0633,
      "step": 29070
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.665865898132324,
      "learning_rate": 2.0033133414419326e-05,
      "loss": 1.1367,
      "step": 29080
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.803143501281738,
      "learning_rate": 2.002264815669169e-05,
      "loss": 1.1717,
      "step": 29090
    },
    {
      "epoch": 1.81,
      "grad_norm": 7.75337028503418,
      "learning_rate": 2.0012162898964057e-05,
      "loss": 1.0804,
      "step": 29100
    },
    {
      "epoch": 1.81,
      "grad_norm": 4.621340274810791,
      "learning_rate": 2.0001677641236422e-05,
      "loss": 1.0384,
      "step": 29110
    },
    {
      "epoch": 1.81,
      "grad_norm": 5.312727451324463,
      "learning_rate": 1.9991192383508787e-05,
      "loss": 0.8911,
      "step": 29120
    },
    {
      "epoch": 1.81,
      "grad_norm": 8.041598320007324,
      "learning_rate": 1.9980707125781153e-05,
      "loss": 0.9212,
      "step": 29130
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.676839828491211,
      "learning_rate": 1.9970221868053518e-05,
      "loss": 1.1181,
      "step": 29140
    },
    {
      "epoch": 1.81,
      "grad_norm": 9.183780670166016,
      "learning_rate": 1.9959736610325883e-05,
      "loss": 1.111,
      "step": 29150
    },
    {
      "epoch": 1.82,
      "grad_norm": 7.7870635986328125,
      "learning_rate": 1.994925135259825e-05,
      "loss": 1.05,
      "step": 29160
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.557211875915527,
      "learning_rate": 1.993876609487061e-05,
      "loss": 1.0678,
      "step": 29170
    },
    {
      "epoch": 1.82,
      "grad_norm": 11.397027969360352,
      "learning_rate": 1.992828083714298e-05,
      "loss": 0.9811,
      "step": 29180
    },
    {
      "epoch": 1.82,
      "grad_norm": 10.641790390014648,
      "learning_rate": 1.9917795579415345e-05,
      "loss": 1.0212,
      "step": 29190
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.783205032348633,
      "learning_rate": 1.990731032168771e-05,
      "loss": 1.0004,
      "step": 29200
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.22828483581543,
      "learning_rate": 1.9896825063960072e-05,
      "loss": 0.9939,
      "step": 29210
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.822265625,
      "learning_rate": 1.9886339806232437e-05,
      "loss": 1.0051,
      "step": 29220
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.313600540161133,
      "learning_rate": 1.9875854548504802e-05,
      "loss": 1.0819,
      "step": 29230
    },
    {
      "epoch": 1.82,
      "grad_norm": 7.8078155517578125,
      "learning_rate": 1.9865369290777168e-05,
      "loss": 0.9914,
      "step": 29240
    },
    {
      "epoch": 1.82,
      "grad_norm": 14.379860877990723,
      "learning_rate": 1.9854884033049533e-05,
      "loss": 0.9697,
      "step": 29250
    },
    {
      "epoch": 1.82,
      "grad_norm": 6.887848854064941,
      "learning_rate": 1.98443987753219e-05,
      "loss": 1.1138,
      "step": 29260
    },
    {
      "epoch": 1.82,
      "grad_norm": 7.680537223815918,
      "learning_rate": 1.9833913517594264e-05,
      "loss": 1.0866,
      "step": 29270
    },
    {
      "epoch": 1.82,
      "grad_norm": 5.878130912780762,
      "learning_rate": 1.982342825986663e-05,
      "loss": 1.0418,
      "step": 29280
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.337899208068848,
      "learning_rate": 1.981294300213899e-05,
      "loss": 1.0862,
      "step": 29290
    },
    {
      "epoch": 1.82,
      "grad_norm": 9.597046852111816,
      "learning_rate": 1.980245774441136e-05,
      "loss": 1.0982,
      "step": 29300
    },
    {
      "epoch": 1.82,
      "grad_norm": 8.759674072265625,
      "learning_rate": 1.9791972486683725e-05,
      "loss": 1.0165,
      "step": 29310
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.741456985473633,
      "learning_rate": 1.978148722895609e-05,
      "loss": 1.0189,
      "step": 29320
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.502681732177734,
      "learning_rate": 1.9771001971228452e-05,
      "loss": 0.8725,
      "step": 29330
    },
    {
      "epoch": 1.83,
      "grad_norm": 12.952595710754395,
      "learning_rate": 1.9760516713500817e-05,
      "loss": 1.0751,
      "step": 29340
    },
    {
      "epoch": 1.83,
      "grad_norm": 9.754708290100098,
      "learning_rate": 1.9750031455773183e-05,
      "loss": 0.8859,
      "step": 29350
    },
    {
      "epoch": 1.83,
      "grad_norm": 9.643803596496582,
      "learning_rate": 1.973954619804555e-05,
      "loss": 1.2195,
      "step": 29360
    },
    {
      "epoch": 1.83,
      "grad_norm": 10.300775527954102,
      "learning_rate": 1.9729060940317913e-05,
      "loss": 1.063,
      "step": 29370
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.587270259857178,
      "learning_rate": 1.971857568259028e-05,
      "loss": 1.1004,
      "step": 29380
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.668330192565918,
      "learning_rate": 1.9708090424862644e-05,
      "loss": 1.0811,
      "step": 29390
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.0645294189453125,
      "learning_rate": 1.969760516713501e-05,
      "loss": 0.9622,
      "step": 29400
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.5719146728515625,
      "learning_rate": 1.9687119909407375e-05,
      "loss": 1.0938,
      "step": 29410
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.1069560050964355,
      "learning_rate": 1.967663465167974e-05,
      "loss": 1.0171,
      "step": 29420
    },
    {
      "epoch": 1.83,
      "grad_norm": 7.490795612335205,
      "learning_rate": 1.9666149393952105e-05,
      "loss": 1.0637,
      "step": 29430
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.877659797668457,
      "learning_rate": 1.965566413622447e-05,
      "loss": 1.1096,
      "step": 29440
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.052492618560791,
      "learning_rate": 1.9645178878496832e-05,
      "loss": 1.121,
      "step": 29450
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.0726728439331055,
      "learning_rate": 1.9634693620769198e-05,
      "loss": 1.1128,
      "step": 29460
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.986299991607666,
      "learning_rate": 1.9624208363041566e-05,
      "loss": 1.1675,
      "step": 29470
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.162028789520264,
      "learning_rate": 1.9613723105313932e-05,
      "loss": 1.1182,
      "step": 29480
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.7236714363098145,
      "learning_rate": 1.9603237847586294e-05,
      "loss": 1.0825,
      "step": 29490
    },
    {
      "epoch": 1.84,
      "grad_norm": 6.522812366485596,
      "learning_rate": 1.959275258985866e-05,
      "loss": 1.1006,
      "step": 29500
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.979094505310059,
      "learning_rate": 1.9582267332131024e-05,
      "loss": 1.1064,
      "step": 29510
    },
    {
      "epoch": 1.84,
      "grad_norm": 16.46638298034668,
      "learning_rate": 1.957178207440339e-05,
      "loss": 0.9971,
      "step": 29520
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.036965847015381,
      "learning_rate": 1.9561296816675755e-05,
      "loss": 1.0722,
      "step": 29530
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.397957801818848,
      "learning_rate": 1.955081155894812e-05,
      "loss": 1.0728,
      "step": 29540
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.531047821044922,
      "learning_rate": 1.9540326301220486e-05,
      "loss": 1.0219,
      "step": 29550
    },
    {
      "epoch": 1.84,
      "grad_norm": 6.80649471282959,
      "learning_rate": 1.952984104349285e-05,
      "loss": 1.1271,
      "step": 29560
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.088185787200928,
      "learning_rate": 1.9519355785765213e-05,
      "loss": 1.0001,
      "step": 29570
    },
    {
      "epoch": 1.84,
      "grad_norm": 7.553773403167725,
      "learning_rate": 1.9508870528037578e-05,
      "loss": 1.0319,
      "step": 29580
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.212080955505371,
      "learning_rate": 1.9498385270309947e-05,
      "loss": 1.0175,
      "step": 29590
    },
    {
      "epoch": 1.84,
      "grad_norm": 9.12605094909668,
      "learning_rate": 1.9487900012582312e-05,
      "loss": 1.075,
      "step": 29600
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.976605415344238,
      "learning_rate": 1.9477414754854674e-05,
      "loss": 0.9964,
      "step": 29610
    },
    {
      "epoch": 1.84,
      "grad_norm": 9.478828430175781,
      "learning_rate": 1.946692949712704e-05,
      "loss": 0.9675,
      "step": 29620
    },
    {
      "epoch": 1.84,
      "grad_norm": 8.667733192443848,
      "learning_rate": 1.9456444239399405e-05,
      "loss": 1.1396,
      "step": 29630
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.760031700134277,
      "learning_rate": 1.944595898167177e-05,
      "loss": 1.1141,
      "step": 29640
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.735516548156738,
      "learning_rate": 1.9435473723944135e-05,
      "loss": 1.1533,
      "step": 29650
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.596246719360352,
      "learning_rate": 1.94249884662165e-05,
      "loss": 1.1039,
      "step": 29660
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.84195613861084,
      "learning_rate": 1.9414503208488866e-05,
      "loss": 1.0568,
      "step": 29670
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.187906265258789,
      "learning_rate": 1.940401795076123e-05,
      "loss": 1.1388,
      "step": 29680
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.8550262451171875,
      "learning_rate": 1.9393532693033593e-05,
      "loss": 1.0474,
      "step": 29690
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.353359222412109,
      "learning_rate": 1.9383047435305962e-05,
      "loss": 1.0506,
      "step": 29700
    },
    {
      "epoch": 1.85,
      "grad_norm": 7.08024787902832,
      "learning_rate": 1.9372562177578327e-05,
      "loss": 0.9906,
      "step": 29710
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.576531410217285,
      "learning_rate": 1.9362076919850692e-05,
      "loss": 1.1223,
      "step": 29720
    },
    {
      "epoch": 1.85,
      "grad_norm": 10.807754516601562,
      "learning_rate": 1.9351591662123054e-05,
      "loss": 1.0382,
      "step": 29730
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.508693695068359,
      "learning_rate": 1.934110640439542e-05,
      "loss": 0.9369,
      "step": 29740
    },
    {
      "epoch": 1.85,
      "grad_norm": 6.746283531188965,
      "learning_rate": 1.9330621146667785e-05,
      "loss": 0.9886,
      "step": 29750
    },
    {
      "epoch": 1.85,
      "grad_norm": 7.387244701385498,
      "learning_rate": 1.9320135888940154e-05,
      "loss": 1.0524,
      "step": 29760
    },
    {
      "epoch": 1.85,
      "grad_norm": 7.923927307128906,
      "learning_rate": 1.9309650631212516e-05,
      "loss": 1.1551,
      "step": 29770
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.041571617126465,
      "learning_rate": 1.929916537348488e-05,
      "loss": 0.9927,
      "step": 29780
    },
    {
      "epoch": 1.85,
      "grad_norm": 7.481382369995117,
      "learning_rate": 1.9288680115757246e-05,
      "loss": 0.9896,
      "step": 29790
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.975701808929443,
      "learning_rate": 1.927819485802961e-05,
      "loss": 1.1322,
      "step": 29800
    },
    {
      "epoch": 1.86,
      "grad_norm": 5.151128768920898,
      "learning_rate": 1.9267709600301977e-05,
      "loss": 1.0424,
      "step": 29810
    },
    {
      "epoch": 1.86,
      "grad_norm": 8.464588165283203,
      "learning_rate": 1.9257224342574342e-05,
      "loss": 1.0565,
      "step": 29820
    },
    {
      "epoch": 1.86,
      "grad_norm": 7.129062175750732,
      "learning_rate": 1.9246739084846707e-05,
      "loss": 1.0025,
      "step": 29830
    },
    {
      "epoch": 1.86,
      "grad_norm": 8.792035102844238,
      "learning_rate": 1.9236253827119073e-05,
      "loss": 1.1049,
      "step": 29840
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.787286758422852,
      "learning_rate": 1.9225768569391435e-05,
      "loss": 1.0163,
      "step": 29850
    },
    {
      "epoch": 1.86,
      "grad_norm": 8.832351684570312,
      "learning_rate": 1.92152833116638e-05,
      "loss": 0.9499,
      "step": 29860
    },
    {
      "epoch": 1.86,
      "grad_norm": 7.4396162033081055,
      "learning_rate": 1.9204798053936165e-05,
      "loss": 1.0558,
      "step": 29870
    },
    {
      "epoch": 1.86,
      "grad_norm": 12.128040313720703,
      "learning_rate": 1.9194312796208534e-05,
      "loss": 1.1177,
      "step": 29880
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.931763648986816,
      "learning_rate": 1.9183827538480896e-05,
      "loss": 1.017,
      "step": 29890
    },
    {
      "epoch": 1.86,
      "grad_norm": 7.015848636627197,
      "learning_rate": 1.917334228075326e-05,
      "loss": 1.0722,
      "step": 29900
    },
    {
      "epoch": 1.86,
      "grad_norm": 5.874006748199463,
      "learning_rate": 1.9162857023025627e-05,
      "loss": 1.012,
      "step": 29910
    },
    {
      "epoch": 1.86,
      "grad_norm": 6.902742385864258,
      "learning_rate": 1.9152371765297992e-05,
      "loss": 0.9564,
      "step": 29920
    },
    {
      "epoch": 1.86,
      "grad_norm": 9.08357048034668,
      "learning_rate": 1.9141886507570357e-05,
      "loss": 1.0011,
      "step": 29930
    },
    {
      "epoch": 1.86,
      "grad_norm": 13.66051959991455,
      "learning_rate": 1.9131401249842722e-05,
      "loss": 1.0812,
      "step": 29940
    },
    {
      "epoch": 1.86,
      "grad_norm": 8.258036613464355,
      "learning_rate": 1.9120915992115088e-05,
      "loss": 1.0991,
      "step": 29950
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.19218635559082,
      "learning_rate": 1.9110430734387453e-05,
      "loss": 0.9779,
      "step": 29960
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.951647758483887,
      "learning_rate": 1.909994547665982e-05,
      "loss": 1.0984,
      "step": 29970
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.189517974853516,
      "learning_rate": 1.908946021893218e-05,
      "loss": 1.0494,
      "step": 29980
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.920926094055176,
      "learning_rate": 1.9078974961204546e-05,
      "loss": 0.9956,
      "step": 29990
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.947534084320068,
      "learning_rate": 1.9068489703476914e-05,
      "loss": 1.0628,
      "step": 30000
    },
    {
      "epoch": 1.87,
      "grad_norm": 4.543132781982422,
      "learning_rate": 1.9058004445749276e-05,
      "loss": 0.9981,
      "step": 30010
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.182560920715332,
      "learning_rate": 1.904751918802164e-05,
      "loss": 0.8664,
      "step": 30020
    },
    {
      "epoch": 1.87,
      "grad_norm": 13.229806900024414,
      "learning_rate": 1.9037033930294007e-05,
      "loss": 1.2541,
      "step": 30030
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.031903266906738,
      "learning_rate": 1.9026548672566372e-05,
      "loss": 1.0484,
      "step": 30040
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.694596290588379,
      "learning_rate": 1.9016063414838738e-05,
      "loss": 1.1745,
      "step": 30050
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.481448650360107,
      "learning_rate": 1.9005578157111103e-05,
      "loss": 1.0486,
      "step": 30060
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.681742191314697,
      "learning_rate": 1.8995092899383468e-05,
      "loss": 1.014,
      "step": 30070
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.464003562927246,
      "learning_rate": 1.8984607641655833e-05,
      "loss": 1.0383,
      "step": 30080
    },
    {
      "epoch": 1.87,
      "grad_norm": 10.9032564163208,
      "learning_rate": 1.89741223839282e-05,
      "loss": 1.0259,
      "step": 30090
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.350581645965576,
      "learning_rate": 1.896363712620056e-05,
      "loss": 1.1554,
      "step": 30100
    },
    {
      "epoch": 1.87,
      "grad_norm": 6.864658832550049,
      "learning_rate": 1.895315186847293e-05,
      "loss": 1.0866,
      "step": 30110
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.406846046447754,
      "learning_rate": 1.8942666610745295e-05,
      "loss": 1.1017,
      "step": 30120
    },
    {
      "epoch": 1.88,
      "grad_norm": 5.799744606018066,
      "learning_rate": 1.893218135301766e-05,
      "loss": 1.011,
      "step": 30130
    },
    {
      "epoch": 1.88,
      "grad_norm": 10.805747985839844,
      "learning_rate": 1.8921696095290022e-05,
      "loss": 1.1073,
      "step": 30140
    },
    {
      "epoch": 1.88,
      "grad_norm": 8.127053260803223,
      "learning_rate": 1.8911210837562387e-05,
      "loss": 1.1215,
      "step": 30150
    },
    {
      "epoch": 1.88,
      "grad_norm": 8.352496147155762,
      "learning_rate": 1.8900725579834753e-05,
      "loss": 1.1631,
      "step": 30160
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.425571918487549,
      "learning_rate": 1.8890240322107118e-05,
      "loss": 1.0203,
      "step": 30170
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.656449794769287,
      "learning_rate": 1.8879755064379483e-05,
      "loss": 1.0842,
      "step": 30180
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.085459232330322,
      "learning_rate": 1.886926980665185e-05,
      "loss": 1.058,
      "step": 30190
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.136815547943115,
      "learning_rate": 1.8858784548924214e-05,
      "loss": 1.0193,
      "step": 30200
    },
    {
      "epoch": 1.88,
      "grad_norm": 9.570708274841309,
      "learning_rate": 1.884829929119658e-05,
      "loss": 1.0859,
      "step": 30210
    },
    {
      "epoch": 1.88,
      "grad_norm": 9.981172561645508,
      "learning_rate": 1.883781403346894e-05,
      "loss": 1.0565,
      "step": 30220
    },
    {
      "epoch": 1.88,
      "grad_norm": 10.20563793182373,
      "learning_rate": 1.882732877574131e-05,
      "loss": 0.9643,
      "step": 30230
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.533994674682617,
      "learning_rate": 1.8816843518013675e-05,
      "loss": 1.271,
      "step": 30240
    },
    {
      "epoch": 1.88,
      "grad_norm": 9.55909538269043,
      "learning_rate": 1.880635826028604e-05,
      "loss": 1.0918,
      "step": 30250
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.837007999420166,
      "learning_rate": 1.8795873002558402e-05,
      "loss": 1.0151,
      "step": 30260
    },
    {
      "epoch": 1.88,
      "grad_norm": 9.915923118591309,
      "learning_rate": 1.8785387744830768e-05,
      "loss": 1.0608,
      "step": 30270
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.178901672363281,
      "learning_rate": 1.8774902487103133e-05,
      "loss": 1.0153,
      "step": 30280
    },
    {
      "epoch": 1.89,
      "grad_norm": 4.603398323059082,
      "learning_rate": 1.87644172293755e-05,
      "loss": 0.9747,
      "step": 30290
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.26884651184082,
      "learning_rate": 1.8753931971647863e-05,
      "loss": 1.04,
      "step": 30300
    },
    {
      "epoch": 1.89,
      "grad_norm": 7.421210765838623,
      "learning_rate": 1.874344671392023e-05,
      "loss": 0.9856,
      "step": 30310
    },
    {
      "epoch": 1.89,
      "grad_norm": 9.47287654876709,
      "learning_rate": 1.8732961456192594e-05,
      "loss": 1.1483,
      "step": 30320
    },
    {
      "epoch": 1.89,
      "grad_norm": 5.513658046722412,
      "learning_rate": 1.872247619846496e-05,
      "loss": 1.0474,
      "step": 30330
    },
    {
      "epoch": 1.89,
      "grad_norm": 7.452967643737793,
      "learning_rate": 1.871199094073732e-05,
      "loss": 1.1563,
      "step": 30340
    },
    {
      "epoch": 1.89,
      "grad_norm": 9.610113143920898,
      "learning_rate": 1.870150568300969e-05,
      "loss": 1.066,
      "step": 30350
    },
    {
      "epoch": 1.89,
      "grad_norm": 7.990184307098389,
      "learning_rate": 1.8691020425282055e-05,
      "loss": 1.1604,
      "step": 30360
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.272845268249512,
      "learning_rate": 1.868053516755442e-05,
      "loss": 0.9884,
      "step": 30370
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.298565864562988,
      "learning_rate": 1.8670049909826783e-05,
      "loss": 1.0094,
      "step": 30380
    },
    {
      "epoch": 1.89,
      "grad_norm": 9.612516403198242,
      "learning_rate": 1.8659564652099148e-05,
      "loss": 1.1288,
      "step": 30390
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.303585052490234,
      "learning_rate": 1.8649079394371517e-05,
      "loss": 0.9563,
      "step": 30400
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.562297821044922,
      "learning_rate": 1.8638594136643882e-05,
      "loss": 0.8803,
      "step": 30410
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.892321586608887,
      "learning_rate": 1.8628108878916244e-05,
      "loss": 1.0637,
      "step": 30420
    },
    {
      "epoch": 1.89,
      "grad_norm": 10.116159439086914,
      "learning_rate": 1.861762362118861e-05,
      "loss": 1.0314,
      "step": 30430
    },
    {
      "epoch": 1.9,
      "grad_norm": 9.86016845703125,
      "learning_rate": 1.8607138363460974e-05,
      "loss": 0.9771,
      "step": 30440
    },
    {
      "epoch": 1.9,
      "grad_norm": 7.619023323059082,
      "learning_rate": 1.859665310573334e-05,
      "loss": 1.0322,
      "step": 30450
    },
    {
      "epoch": 1.9,
      "grad_norm": 7.470034599304199,
      "learning_rate": 1.8586167848005705e-05,
      "loss": 1.0021,
      "step": 30460
    },
    {
      "epoch": 1.9,
      "grad_norm": 8.670243263244629,
      "learning_rate": 1.857568259027807e-05,
      "loss": 1.1255,
      "step": 30470
    },
    {
      "epoch": 1.9,
      "grad_norm": 8.657827377319336,
      "learning_rate": 1.8565197332550436e-05,
      "loss": 0.9616,
      "step": 30480
    },
    {
      "epoch": 1.9,
      "grad_norm": 8.583307266235352,
      "learning_rate": 1.85547120748228e-05,
      "loss": 1.0484,
      "step": 30490
    },
    {
      "epoch": 1.9,
      "grad_norm": 9.676639556884766,
      "learning_rate": 1.8544226817095163e-05,
      "loss": 1.0939,
      "step": 30500
    },
    {
      "epoch": 1.9,
      "grad_norm": 9.006758689880371,
      "learning_rate": 1.8533741559367528e-05,
      "loss": 1.0285,
      "step": 30510
    },
    {
      "epoch": 1.9,
      "grad_norm": 6.915892124176025,
      "learning_rate": 1.8523256301639897e-05,
      "loss": 1.1187,
      "step": 30520
    },
    {
      "epoch": 1.9,
      "grad_norm": 10.291374206542969,
      "learning_rate": 1.8512771043912262e-05,
      "loss": 0.9847,
      "step": 30530
    },
    {
      "epoch": 1.9,
      "grad_norm": 11.717144012451172,
      "learning_rate": 1.8502285786184624e-05,
      "loss": 1.0435,
      "step": 30540
    },
    {
      "epoch": 1.9,
      "grad_norm": 9.013632774353027,
      "learning_rate": 1.849180052845699e-05,
      "loss": 1.1616,
      "step": 30550
    },
    {
      "epoch": 1.9,
      "grad_norm": 6.4884724617004395,
      "learning_rate": 1.8481315270729355e-05,
      "loss": 1.0995,
      "step": 30560
    },
    {
      "epoch": 1.9,
      "grad_norm": 6.4051079750061035,
      "learning_rate": 1.847083001300172e-05,
      "loss": 1.0259,
      "step": 30570
    },
    {
      "epoch": 1.9,
      "grad_norm": 7.362285614013672,
      "learning_rate": 1.8460344755274085e-05,
      "loss": 1.0578,
      "step": 30580
    },
    {
      "epoch": 1.9,
      "grad_norm": 7.50902795791626,
      "learning_rate": 1.844985949754645e-05,
      "loss": 1.0548,
      "step": 30590
    },
    {
      "epoch": 1.91,
      "grad_norm": 9.923470497131348,
      "learning_rate": 1.8439374239818816e-05,
      "loss": 1.0726,
      "step": 30600
    },
    {
      "epoch": 1.91,
      "grad_norm": 8.897055625915527,
      "learning_rate": 1.842888898209118e-05,
      "loss": 1.0575,
      "step": 30610
    },
    {
      "epoch": 1.91,
      "grad_norm": 9.549362182617188,
      "learning_rate": 1.8418403724363543e-05,
      "loss": 1.0112,
      "step": 30620
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.024450302124023,
      "learning_rate": 1.840791846663591e-05,
      "loss": 1.1612,
      "step": 30630
    },
    {
      "epoch": 1.91,
      "grad_norm": 8.376093864440918,
      "learning_rate": 1.8397433208908277e-05,
      "loss": 1.0992,
      "step": 30640
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.477907657623291,
      "learning_rate": 1.8386947951180643e-05,
      "loss": 0.9858,
      "step": 30650
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.982246398925781,
      "learning_rate": 1.8376462693453004e-05,
      "loss": 1.0898,
      "step": 30660
    },
    {
      "epoch": 1.91,
      "grad_norm": 14.313642501831055,
      "learning_rate": 1.836597743572537e-05,
      "loss": 0.9847,
      "step": 30670
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.185844421386719,
      "learning_rate": 1.8355492177997735e-05,
      "loss": 1.0393,
      "step": 30680
    },
    {
      "epoch": 1.91,
      "grad_norm": 14.04711627960205,
      "learning_rate": 1.8345006920270104e-05,
      "loss": 1.0452,
      "step": 30690
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.414645195007324,
      "learning_rate": 1.8334521662542466e-05,
      "loss": 1.0807,
      "step": 30700
    },
    {
      "epoch": 1.91,
      "grad_norm": 8.059063911437988,
      "learning_rate": 1.832403640481483e-05,
      "loss": 1.1787,
      "step": 30710
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.37269401550293,
      "learning_rate": 1.8313551147087196e-05,
      "loss": 1.0435,
      "step": 30720
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.0208563804626465,
      "learning_rate": 1.830306588935956e-05,
      "loss": 1.1024,
      "step": 30730
    },
    {
      "epoch": 1.91,
      "grad_norm": 9.4694185256958,
      "learning_rate": 1.8292580631631927e-05,
      "loss": 0.9618,
      "step": 30740
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.204214096069336,
      "learning_rate": 1.8282095373904292e-05,
      "loss": 1.0156,
      "step": 30750
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.438805103302002,
      "learning_rate": 1.8271610116176658e-05,
      "loss": 1.1074,
      "step": 30760
    },
    {
      "epoch": 1.92,
      "grad_norm": 11.035211563110352,
      "learning_rate": 1.8261124858449023e-05,
      "loss": 1.0892,
      "step": 30770
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.85659646987915,
      "learning_rate": 1.8250639600721385e-05,
      "loss": 1.0108,
      "step": 30780
    },
    {
      "epoch": 1.92,
      "grad_norm": 7.382397651672363,
      "learning_rate": 1.824015434299375e-05,
      "loss": 1.171,
      "step": 30790
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.460965156555176,
      "learning_rate": 1.8229669085266115e-05,
      "loss": 1.1926,
      "step": 30800
    },
    {
      "epoch": 1.92,
      "grad_norm": 9.6052885055542,
      "learning_rate": 1.8219183827538484e-05,
      "loss": 1.0474,
      "step": 30810
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.471746444702148,
      "learning_rate": 1.8208698569810846e-05,
      "loss": 0.9667,
      "step": 30820
    },
    {
      "epoch": 1.92,
      "grad_norm": 5.080319881439209,
      "learning_rate": 1.819821331208321e-05,
      "loss": 0.9605,
      "step": 30830
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.286090850830078,
      "learning_rate": 1.8187728054355577e-05,
      "loss": 1.0262,
      "step": 30840
    },
    {
      "epoch": 1.92,
      "grad_norm": 7.84279203414917,
      "learning_rate": 1.8177242796627942e-05,
      "loss": 1.0925,
      "step": 30850
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.396784782409668,
      "learning_rate": 1.8166757538900307e-05,
      "loss": 1.0375,
      "step": 30860
    },
    {
      "epoch": 1.92,
      "grad_norm": 19.660667419433594,
      "learning_rate": 1.8156272281172673e-05,
      "loss": 1.0636,
      "step": 30870
    },
    {
      "epoch": 1.92,
      "grad_norm": 5.189163684844971,
      "learning_rate": 1.8145787023445038e-05,
      "loss": 0.9675,
      "step": 30880
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.157760620117188,
      "learning_rate": 1.8135301765717403e-05,
      "loss": 1.2264,
      "step": 30890
    },
    {
      "epoch": 1.92,
      "grad_norm": 9.837869644165039,
      "learning_rate": 1.812481650798977e-05,
      "loss": 1.0593,
      "step": 30900
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.305920600891113,
      "learning_rate": 1.811433125026213e-05,
      "loss": 0.9415,
      "step": 30910
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.354752540588379,
      "learning_rate": 1.8103845992534496e-05,
      "loss": 1.011,
      "step": 30920
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.541295528411865,
      "learning_rate": 1.8093360734806864e-05,
      "loss": 1.049,
      "step": 30930
    },
    {
      "epoch": 1.93,
      "grad_norm": 8.45846939086914,
      "learning_rate": 1.8082875477079226e-05,
      "loss": 1.0284,
      "step": 30940
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.981915473937988,
      "learning_rate": 1.807239021935159e-05,
      "loss": 1.1588,
      "step": 30950
    },
    {
      "epoch": 1.93,
      "grad_norm": 8.110870361328125,
      "learning_rate": 1.8061904961623957e-05,
      "loss": 0.9221,
      "step": 30960
    },
    {
      "epoch": 1.93,
      "grad_norm": 4.904575347900391,
      "learning_rate": 1.8051419703896322e-05,
      "loss": 1.0932,
      "step": 30970
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.1140899658203125,
      "learning_rate": 1.8040934446168688e-05,
      "loss": 0.9788,
      "step": 30980
    },
    {
      "epoch": 1.93,
      "grad_norm": 13.579146385192871,
      "learning_rate": 1.8030449188441053e-05,
      "loss": 1.0836,
      "step": 30990
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.150874137878418,
      "learning_rate": 1.8019963930713418e-05,
      "loss": 1.094,
      "step": 31000
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.167996406555176,
      "learning_rate": 1.8009478672985784e-05,
      "loss": 1.0366,
      "step": 31010
    },
    {
      "epoch": 1.93,
      "grad_norm": 6.0845465660095215,
      "learning_rate": 1.799899341525815e-05,
      "loss": 0.9935,
      "step": 31020
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.312541961669922,
      "learning_rate": 1.798850815753051e-05,
      "loss": 1.2357,
      "step": 31030
    },
    {
      "epoch": 1.93,
      "grad_norm": 7.205752372741699,
      "learning_rate": 1.797802289980288e-05,
      "loss": 1.1424,
      "step": 31040
    },
    {
      "epoch": 1.93,
      "grad_norm": 6.860987663269043,
      "learning_rate": 1.7967537642075245e-05,
      "loss": 1.0272,
      "step": 31050
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.610513687133789,
      "learning_rate": 1.795705238434761e-05,
      "loss": 1.0901,
      "step": 31060
    },
    {
      "epoch": 1.93,
      "grad_norm": 5.864043235778809,
      "learning_rate": 1.7946567126619972e-05,
      "loss": 0.9551,
      "step": 31070
    },
    {
      "epoch": 1.94,
      "grad_norm": 10.144598960876465,
      "learning_rate": 1.7936081868892337e-05,
      "loss": 1.0029,
      "step": 31080
    },
    {
      "epoch": 1.94,
      "grad_norm": 5.772500991821289,
      "learning_rate": 1.7925596611164703e-05,
      "loss": 1.0202,
      "step": 31090
    },
    {
      "epoch": 1.94,
      "grad_norm": 8.17845630645752,
      "learning_rate": 1.7915111353437068e-05,
      "loss": 0.8971,
      "step": 31100
    },
    {
      "epoch": 1.94,
      "grad_norm": 9.299027442932129,
      "learning_rate": 1.7904626095709433e-05,
      "loss": 1.169,
      "step": 31110
    },
    {
      "epoch": 1.94,
      "grad_norm": 8.70113754272461,
      "learning_rate": 1.78941408379818e-05,
      "loss": 1.0699,
      "step": 31120
    },
    {
      "epoch": 1.94,
      "grad_norm": 7.704505920410156,
      "learning_rate": 1.7883655580254164e-05,
      "loss": 0.9452,
      "step": 31130
    },
    {
      "epoch": 1.94,
      "grad_norm": 6.681738376617432,
      "learning_rate": 1.787317032252653e-05,
      "loss": 1.0781,
      "step": 31140
    },
    {
      "epoch": 1.94,
      "grad_norm": 7.3303327560424805,
      "learning_rate": 1.786268506479889e-05,
      "loss": 0.9825,
      "step": 31150
    },
    {
      "epoch": 1.94,
      "grad_norm": 7.59705114364624,
      "learning_rate": 1.785219980707126e-05,
      "loss": 0.9539,
      "step": 31160
    },
    {
      "epoch": 1.94,
      "grad_norm": 6.699504375457764,
      "learning_rate": 1.7841714549343625e-05,
      "loss": 0.9343,
      "step": 31170
    },
    {
      "epoch": 1.94,
      "grad_norm": 10.157816886901855,
      "learning_rate": 1.783122929161599e-05,
      "loss": 1.0617,
      "step": 31180
    },
    {
      "epoch": 1.94,
      "grad_norm": 8.210583686828613,
      "learning_rate": 1.7820744033888352e-05,
      "loss": 1.0797,
      "step": 31190
    },
    {
      "epoch": 1.94,
      "grad_norm": 9.691243171691895,
      "learning_rate": 1.7810258776160718e-05,
      "loss": 1.105,
      "step": 31200
    },
    {
      "epoch": 1.94,
      "grad_norm": 8.376533508300781,
      "learning_rate": 1.7799773518433083e-05,
      "loss": 1.0427,
      "step": 31210
    },
    {
      "epoch": 1.94,
      "grad_norm": 5.697203159332275,
      "learning_rate": 1.778928826070545e-05,
      "loss": 1.0273,
      "step": 31220
    },
    {
      "epoch": 1.94,
      "grad_norm": 7.991754531860352,
      "learning_rate": 1.7778803002977814e-05,
      "loss": 1.0742,
      "step": 31230
    },
    {
      "epoch": 1.94,
      "grad_norm": 6.797334671020508,
      "learning_rate": 1.776831774525018e-05,
      "loss": 1.0263,
      "step": 31240
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.765589237213135,
      "learning_rate": 1.7757832487522544e-05,
      "loss": 0.9741,
      "step": 31250
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.243777275085449,
      "learning_rate": 1.774734722979491e-05,
      "loss": 1.01,
      "step": 31260
    },
    {
      "epoch": 1.95,
      "grad_norm": 9.783952713012695,
      "learning_rate": 1.773686197206727e-05,
      "loss": 1.1142,
      "step": 31270
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.607267379760742,
      "learning_rate": 1.772637671433964e-05,
      "loss": 1.058,
      "step": 31280
    },
    {
      "epoch": 1.95,
      "grad_norm": 9.1481351852417,
      "learning_rate": 1.7715891456612005e-05,
      "loss": 1.1909,
      "step": 31290
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.897415637969971,
      "learning_rate": 1.770540619888437e-05,
      "loss": 0.9086,
      "step": 31300
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.495633602142334,
      "learning_rate": 1.7694920941156733e-05,
      "loss": 1.0853,
      "step": 31310
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.231405258178711,
      "learning_rate": 1.7684435683429098e-05,
      "loss": 0.9834,
      "step": 31320
    },
    {
      "epoch": 1.95,
      "grad_norm": 8.347696304321289,
      "learning_rate": 1.7673950425701467e-05,
      "loss": 1.1051,
      "step": 31330
    },
    {
      "epoch": 1.95,
      "grad_norm": 10.171324729919434,
      "learning_rate": 1.7663465167973832e-05,
      "loss": 1.0001,
      "step": 31340
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.077788352966309,
      "learning_rate": 1.7652979910246194e-05,
      "loss": 1.0029,
      "step": 31350
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.509803295135498,
      "learning_rate": 1.764249465251856e-05,
      "loss": 1.0884,
      "step": 31360
    },
    {
      "epoch": 1.95,
      "grad_norm": 8.237293243408203,
      "learning_rate": 1.7632009394790925e-05,
      "loss": 1.0357,
      "step": 31370
    },
    {
      "epoch": 1.95,
      "grad_norm": 7.8726887702941895,
      "learning_rate": 1.762152413706329e-05,
      "loss": 0.9875,
      "step": 31380
    },
    {
      "epoch": 1.95,
      "grad_norm": 11.115584373474121,
      "learning_rate": 1.7611038879335655e-05,
      "loss": 1.0894,
      "step": 31390
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.526839256286621,
      "learning_rate": 1.760055362160802e-05,
      "loss": 1.0225,
      "step": 31400
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.24763822555542,
      "learning_rate": 1.7590068363880386e-05,
      "loss": 1.2397,
      "step": 31410
    },
    {
      "epoch": 1.96,
      "grad_norm": 5.556335926055908,
      "learning_rate": 1.757958310615275e-05,
      "loss": 1.0551,
      "step": 31420
    },
    {
      "epoch": 1.96,
      "grad_norm": 10.53329849243164,
      "learning_rate": 1.7569097848425113e-05,
      "loss": 1.1204,
      "step": 31430
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.067819118499756,
      "learning_rate": 1.755861259069748e-05,
      "loss": 1.0635,
      "step": 31440
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.070340633392334,
      "learning_rate": 1.7548127332969847e-05,
      "loss": 1.0584,
      "step": 31450
    },
    {
      "epoch": 1.96,
      "grad_norm": 9.060050964355469,
      "learning_rate": 1.7537642075242212e-05,
      "loss": 1.0857,
      "step": 31460
    },
    {
      "epoch": 1.96,
      "grad_norm": 5.890470027923584,
      "learning_rate": 1.7527156817514574e-05,
      "loss": 1.047,
      "step": 31470
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.17022180557251,
      "learning_rate": 1.751667155978694e-05,
      "loss": 1.1284,
      "step": 31480
    },
    {
      "epoch": 1.96,
      "grad_norm": 11.041619300842285,
      "learning_rate": 1.7506186302059305e-05,
      "loss": 1.0434,
      "step": 31490
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.2428669929504395,
      "learning_rate": 1.749570104433167e-05,
      "loss": 1.093,
      "step": 31500
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.5456061363220215,
      "learning_rate": 1.7485215786604035e-05,
      "loss": 1.0721,
      "step": 31510
    },
    {
      "epoch": 1.96,
      "grad_norm": 9.795943260192871,
      "learning_rate": 1.74747305288764e-05,
      "loss": 1.0392,
      "step": 31520
    },
    {
      "epoch": 1.96,
      "grad_norm": 8.986363410949707,
      "learning_rate": 1.7464245271148766e-05,
      "loss": 1.0588,
      "step": 31530
    },
    {
      "epoch": 1.96,
      "grad_norm": 9.191258430480957,
      "learning_rate": 1.745376001342113e-05,
      "loss": 1.0459,
      "step": 31540
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.443429946899414,
      "learning_rate": 1.7443274755693493e-05,
      "loss": 1.0903,
      "step": 31550
    },
    {
      "epoch": 1.96,
      "grad_norm": 8.486044883728027,
      "learning_rate": 1.743278949796586e-05,
      "loss": 1.0892,
      "step": 31560
    },
    {
      "epoch": 1.97,
      "grad_norm": 9.987685203552246,
      "learning_rate": 1.7422304240238227e-05,
      "loss": 1.0695,
      "step": 31570
    },
    {
      "epoch": 1.97,
      "grad_norm": 9.157032012939453,
      "learning_rate": 1.7411818982510593e-05,
      "loss": 1.0574,
      "step": 31580
    },
    {
      "epoch": 1.97,
      "grad_norm": 6.351627349853516,
      "learning_rate": 1.7401333724782955e-05,
      "loss": 1.0043,
      "step": 31590
    },
    {
      "epoch": 1.97,
      "grad_norm": 12.692713737487793,
      "learning_rate": 1.739084846705532e-05,
      "loss": 1.1607,
      "step": 31600
    },
    {
      "epoch": 1.97,
      "grad_norm": 7.179603099822998,
      "learning_rate": 1.7380363209327685e-05,
      "loss": 1.0775,
      "step": 31610
    },
    {
      "epoch": 1.97,
      "grad_norm": 10.989863395690918,
      "learning_rate": 1.736987795160005e-05,
      "loss": 1.0986,
      "step": 31620
    },
    {
      "epoch": 1.97,
      "grad_norm": 6.417691707611084,
      "learning_rate": 1.7359392693872416e-05,
      "loss": 1.1125,
      "step": 31630
    },
    {
      "epoch": 1.97,
      "grad_norm": 8.77169132232666,
      "learning_rate": 1.734890743614478e-05,
      "loss": 1.0066,
      "step": 31640
    },
    {
      "epoch": 1.97,
      "grad_norm": 7.125898838043213,
      "learning_rate": 1.7338422178417146e-05,
      "loss": 1.1228,
      "step": 31650
    },
    {
      "epoch": 1.97,
      "grad_norm": 10.211129188537598,
      "learning_rate": 1.7327936920689512e-05,
      "loss": 1.1834,
      "step": 31660
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.868198871612549,
      "learning_rate": 1.7317451662961877e-05,
      "loss": 1.175,
      "step": 31670
    },
    {
      "epoch": 1.97,
      "grad_norm": 8.727399826049805,
      "learning_rate": 1.7306966405234242e-05,
      "loss": 1.1374,
      "step": 31680
    },
    {
      "epoch": 1.97,
      "grad_norm": 6.104619979858398,
      "learning_rate": 1.7296481147506608e-05,
      "loss": 1.0795,
      "step": 31690
    },
    {
      "epoch": 1.97,
      "grad_norm": 5.5920090675354,
      "learning_rate": 1.7285995889778973e-05,
      "loss": 1.0722,
      "step": 31700
    },
    {
      "epoch": 1.97,
      "grad_norm": 6.30331563949585,
      "learning_rate": 1.7275510632051335e-05,
      "loss": 1.1265,
      "step": 31710
    },
    {
      "epoch": 1.97,
      "grad_norm": 9.203070640563965,
      "learning_rate": 1.72650253743237e-05,
      "loss": 0.9986,
      "step": 31720
    },
    {
      "epoch": 1.98,
      "grad_norm": 10.884053230285645,
      "learning_rate": 1.7254540116596066e-05,
      "loss": 1.091,
      "step": 31730
    },
    {
      "epoch": 1.98,
      "grad_norm": 8.452082633972168,
      "learning_rate": 1.7244054858868434e-05,
      "loss": 1.1029,
      "step": 31740
    },
    {
      "epoch": 1.98,
      "grad_norm": 12.96640396118164,
      "learning_rate": 1.7233569601140796e-05,
      "loss": 0.9954,
      "step": 31750
    },
    {
      "epoch": 1.98,
      "grad_norm": 8.36799430847168,
      "learning_rate": 1.722308434341316e-05,
      "loss": 1.0902,
      "step": 31760
    },
    {
      "epoch": 1.98,
      "grad_norm": 9.461566925048828,
      "learning_rate": 1.7212599085685527e-05,
      "loss": 1.0502,
      "step": 31770
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.6510467529296875,
      "learning_rate": 1.7202113827957892e-05,
      "loss": 0.9992,
      "step": 31780
    },
    {
      "epoch": 1.98,
      "grad_norm": 6.279942035675049,
      "learning_rate": 1.7191628570230257e-05,
      "loss": 0.9045,
      "step": 31790
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.312714099884033,
      "learning_rate": 1.7181143312502623e-05,
      "loss": 0.9966,
      "step": 31800
    },
    {
      "epoch": 1.98,
      "grad_norm": 8.68256664276123,
      "learning_rate": 1.7170658054774988e-05,
      "loss": 0.9773,
      "step": 31810
    },
    {
      "epoch": 1.98,
      "grad_norm": 14.316298484802246,
      "learning_rate": 1.7160172797047353e-05,
      "loss": 1.162,
      "step": 31820
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.403358459472656,
      "learning_rate": 1.714968753931972e-05,
      "loss": 1.0437,
      "step": 31830
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.837701320648193,
      "learning_rate": 1.713920228159208e-05,
      "loss": 1.1324,
      "step": 31840
    },
    {
      "epoch": 1.98,
      "grad_norm": 6.205317497253418,
      "learning_rate": 1.7128717023864446e-05,
      "loss": 0.9714,
      "step": 31850
    },
    {
      "epoch": 1.98,
      "grad_norm": 8.716877937316895,
      "learning_rate": 1.7118231766136815e-05,
      "loss": 1.0709,
      "step": 31860
    },
    {
      "epoch": 1.98,
      "grad_norm": 9.217137336730957,
      "learning_rate": 1.7107746508409176e-05,
      "loss": 1.1451,
      "step": 31870
    },
    {
      "epoch": 1.98,
      "grad_norm": 7.986303329467773,
      "learning_rate": 1.7097261250681542e-05,
      "loss": 1.1334,
      "step": 31880
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.52856731414795,
      "learning_rate": 1.7086775992953907e-05,
      "loss": 1.0253,
      "step": 31890
    },
    {
      "epoch": 1.99,
      "grad_norm": 9.679969787597656,
      "learning_rate": 1.7076290735226272e-05,
      "loss": 1.1176,
      "step": 31900
    },
    {
      "epoch": 1.99,
      "grad_norm": 9.704488754272461,
      "learning_rate": 1.7065805477498638e-05,
      "loss": 1.1424,
      "step": 31910
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.318367958068848,
      "learning_rate": 1.7055320219771003e-05,
      "loss": 1.0352,
      "step": 31920
    },
    {
      "epoch": 1.99,
      "grad_norm": 10.433475494384766,
      "learning_rate": 1.704483496204337e-05,
      "loss": 1.1233,
      "step": 31930
    },
    {
      "epoch": 1.99,
      "grad_norm": 5.304745197296143,
      "learning_rate": 1.7034349704315734e-05,
      "loss": 1.0777,
      "step": 31940
    },
    {
      "epoch": 1.99,
      "grad_norm": 12.667737007141113,
      "learning_rate": 1.70238644465881e-05,
      "loss": 1.058,
      "step": 31950
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.988224983215332,
      "learning_rate": 1.701337918886046e-05,
      "loss": 1.1071,
      "step": 31960
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.18002986907959,
      "learning_rate": 1.7002893931132826e-05,
      "loss": 1.013,
      "step": 31970
    },
    {
      "epoch": 1.99,
      "grad_norm": 7.040700435638428,
      "learning_rate": 1.6992408673405195e-05,
      "loss": 1.0625,
      "step": 31980
    },
    {
      "epoch": 1.99,
      "grad_norm": 7.648688793182373,
      "learning_rate": 1.698192341567756e-05,
      "loss": 1.0206,
      "step": 31990
    },
    {
      "epoch": 1.99,
      "grad_norm": 7.475271224975586,
      "learning_rate": 1.6971438157949922e-05,
      "loss": 0.9185,
      "step": 32000
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.637887001037598,
      "learning_rate": 1.6960952900222287e-05,
      "loss": 1.104,
      "step": 32010
    },
    {
      "epoch": 1.99,
      "grad_norm": 7.663377285003662,
      "learning_rate": 1.6950467642494653e-05,
      "loss": 0.9736,
      "step": 32020
    },
    {
      "epoch": 1.99,
      "grad_norm": 10.127082824707031,
      "learning_rate": 1.6939982384767018e-05,
      "loss": 1.0719,
      "step": 32030
    },
    {
      "epoch": 1.99,
      "grad_norm": 9.643074035644531,
      "learning_rate": 1.6929497127039383e-05,
      "loss": 0.9455,
      "step": 32040
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.370200157165527,
      "learning_rate": 1.691901186931175e-05,
      "loss": 1.1398,
      "step": 32050
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.022872924804688,
      "learning_rate": 1.6908526611584114e-05,
      "loss": 0.9883,
      "step": 32060
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.979551315307617,
      "learning_rate": 1.689804135385648e-05,
      "loss": 0.9842,
      "step": 32070
    },
    {
      "epoch": 2.0,
      "grad_norm": 16.22152328491211,
      "learning_rate": 1.688755609612884e-05,
      "loss": 1.2076,
      "step": 32080
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.767590522766113,
      "learning_rate": 1.687707083840121e-05,
      "loss": 1.0643,
      "step": 32090
    },
    {
      "epoch": 2.0,
      "grad_norm": 12.0066499710083,
      "learning_rate": 1.6866585580673575e-05,
      "loss": 1.1996,
      "step": 32100
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.401473045349121,
      "learning_rate": 1.685610032294594e-05,
      "loss": 1.0129,
      "step": 32110
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.894269943237305,
      "learning_rate": 1.6845615065218302e-05,
      "loss": 0.9588,
      "step": 32120
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.1635738611221313,
      "eval_runtime": 174.1888,
      "eval_samples_per_second": 368.83,
      "eval_steps_per_second": 5.764,
      "step": 32124
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.937256813049316,
      "learning_rate": 4.012303272545591e-05,
      "loss": 0.8694,
      "step": 32130
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.679360389709473,
      "learning_rate": 4.011991006744941e-05,
      "loss": 0.7838,
      "step": 32140
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.77933406829834,
      "learning_rate": 4.011678740944292e-05,
      "loss": 0.9984,
      "step": 32150
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.564040184020996,
      "learning_rate": 4.0113664751436426e-05,
      "loss": 0.7372,
      "step": 32160
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.75923490524292,
      "learning_rate": 4.011054209342993e-05,
      "loss": 0.821,
      "step": 32170
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.487642288208008,
      "learning_rate": 4.010741943542343e-05,
      "loss": 0.9029,
      "step": 32180
    },
    {
      "epoch": 2.0,
      "grad_norm": 23.548633575439453,
      "learning_rate": 4.010429677741694e-05,
      "loss": 0.8806,
      "step": 32190
    },
    {
      "epoch": 2.0,
      "grad_norm": 11.795506477355957,
      "learning_rate": 4.0101174119410446e-05,
      "loss": 0.9907,
      "step": 32200
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.2299165725708,
      "learning_rate": 4.009805146140395e-05,
      "loss": 0.8039,
      "step": 32210
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.627490043640137,
      "learning_rate": 4.009492880339745e-05,
      "loss": 0.9419,
      "step": 32220
    },
    {
      "epoch": 2.01,
      "grad_norm": 9.619279861450195,
      "learning_rate": 4.009180614539096e-05,
      "loss": 0.8466,
      "step": 32230
    },
    {
      "epoch": 2.01,
      "grad_norm": 9.0626859664917,
      "learning_rate": 4.008868348738447e-05,
      "loss": 0.8776,
      "step": 32240
    },
    {
      "epoch": 2.01,
      "grad_norm": 10.431816101074219,
      "learning_rate": 4.008556082937797e-05,
      "loss": 0.7768,
      "step": 32250
    },
    {
      "epoch": 2.01,
      "grad_norm": 14.998357772827148,
      "learning_rate": 4.0082438171371474e-05,
      "loss": 0.9356,
      "step": 32260
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.169227600097656,
      "learning_rate": 4.007931551336498e-05,
      "loss": 0.9074,
      "step": 32270
    },
    {
      "epoch": 2.01,
      "grad_norm": 13.529717445373535,
      "learning_rate": 4.007619285535849e-05,
      "loss": 0.9881,
      "step": 32280
    },
    {
      "epoch": 2.01,
      "grad_norm": 10.847229957580566,
      "learning_rate": 4.007307019735199e-05,
      "loss": 0.9536,
      "step": 32290
    },
    {
      "epoch": 2.01,
      "grad_norm": 6.937437534332275,
      "learning_rate": 4.0069947539345494e-05,
      "loss": 0.8191,
      "step": 32300
    },
    {
      "epoch": 2.01,
      "grad_norm": 13.797843933105469,
      "learning_rate": 4.0066824881339e-05,
      "loss": 0.9352,
      "step": 32310
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.479080200195312,
      "learning_rate": 4.00637022233325e-05,
      "loss": 0.9513,
      "step": 32320
    },
    {
      "epoch": 2.01,
      "grad_norm": 8.89217758178711,
      "learning_rate": 4.006057956532601e-05,
      "loss": 0.8417,
      "step": 32330
    },
    {
      "epoch": 2.01,
      "grad_norm": 10.214631080627441,
      "learning_rate": 4.0057456907319515e-05,
      "loss": 0.926,
      "step": 32340
    },
    {
      "epoch": 2.01,
      "grad_norm": 12.62796688079834,
      "learning_rate": 4.005433424931302e-05,
      "loss": 0.9309,
      "step": 32350
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.761475563049316,
      "learning_rate": 4.005121159130652e-05,
      "loss": 0.8784,
      "step": 32360
    },
    {
      "epoch": 2.02,
      "grad_norm": 8.173376083374023,
      "learning_rate": 4.004808893330003e-05,
      "loss": 0.9811,
      "step": 32370
    },
    {
      "epoch": 2.02,
      "grad_norm": 8.635945320129395,
      "learning_rate": 4.0044966275293535e-05,
      "loss": 0.7815,
      "step": 32380
    },
    {
      "epoch": 2.02,
      "grad_norm": 9.218510627746582,
      "learning_rate": 4.004184361728704e-05,
      "loss": 0.9036,
      "step": 32390
    },
    {
      "epoch": 2.02,
      "grad_norm": 11.442638397216797,
      "learning_rate": 4.003872095928054e-05,
      "loss": 0.8898,
      "step": 32400
    },
    {
      "epoch": 2.02,
      "grad_norm": 13.487329483032227,
      "learning_rate": 4.003559830127405e-05,
      "loss": 0.7693,
      "step": 32410
    },
    {
      "epoch": 2.02,
      "grad_norm": 7.629593849182129,
      "learning_rate": 4.0032475643267556e-05,
      "loss": 0.9463,
      "step": 32420
    },
    {
      "epoch": 2.02,
      "grad_norm": 17.738460540771484,
      "learning_rate": 4.0029352985261056e-05,
      "loss": 0.9839,
      "step": 32430
    },
    {
      "epoch": 2.02,
      "grad_norm": 9.592342376708984,
      "learning_rate": 4.002623032725456e-05,
      "loss": 0.9106,
      "step": 32440
    },
    {
      "epoch": 2.02,
      "grad_norm": 10.875075340270996,
      "learning_rate": 4.002310766924807e-05,
      "loss": 1.0335,
      "step": 32450
    },
    {
      "epoch": 2.02,
      "grad_norm": 10.960769653320312,
      "learning_rate": 4.0019985011241576e-05,
      "loss": 0.844,
      "step": 32460
    },
    {
      "epoch": 2.02,
      "grad_norm": 10.17574405670166,
      "learning_rate": 4.0016862353235076e-05,
      "loss": 0.7592,
      "step": 32470
    },
    {
      "epoch": 2.02,
      "grad_norm": 8.790353775024414,
      "learning_rate": 4.001373969522858e-05,
      "loss": 0.87,
      "step": 32480
    },
    {
      "epoch": 2.02,
      "grad_norm": 16.25098419189453,
      "learning_rate": 4.001061703722209e-05,
      "loss": 0.9061,
      "step": 32490
    },
    {
      "epoch": 2.02,
      "grad_norm": 15.14785385131836,
      "learning_rate": 4.000749437921559e-05,
      "loss": 0.9274,
      "step": 32500
    },
    {
      "epoch": 2.02,
      "grad_norm": 8.96028995513916,
      "learning_rate": 4.0004371721209096e-05,
      "loss": 0.9488,
      "step": 32510
    },
    {
      "epoch": 2.02,
      "grad_norm": 9.563126564025879,
      "learning_rate": 4.00012490632026e-05,
      "loss": 1.043,
      "step": 32520
    },
    {
      "epoch": 2.03,
      "grad_norm": 15.2332124710083,
      "learning_rate": 3.999812640519611e-05,
      "loss": 0.8652,
      "step": 32530
    },
    {
      "epoch": 2.03,
      "grad_norm": 7.150716781616211,
      "learning_rate": 3.999500374718961e-05,
      "loss": 0.8673,
      "step": 32540
    },
    {
      "epoch": 2.03,
      "grad_norm": 11.547948837280273,
      "learning_rate": 3.999188108918312e-05,
      "loss": 1.0496,
      "step": 32550
    },
    {
      "epoch": 2.03,
      "grad_norm": 14.678922653198242,
      "learning_rate": 3.9988758431176624e-05,
      "loss": 0.9597,
      "step": 32560
    },
    {
      "epoch": 2.03,
      "grad_norm": 7.8866987228393555,
      "learning_rate": 3.9985635773170124e-05,
      "loss": 0.9167,
      "step": 32570
    },
    {
      "epoch": 2.03,
      "grad_norm": 10.943099021911621,
      "learning_rate": 3.998251311516363e-05,
      "loss": 0.8675,
      "step": 32580
    },
    {
      "epoch": 2.03,
      "grad_norm": 14.357861518859863,
      "learning_rate": 3.997939045715714e-05,
      "loss": 0.8992,
      "step": 32590
    },
    {
      "epoch": 2.03,
      "grad_norm": 14.400179862976074,
      "learning_rate": 3.997626779915064e-05,
      "loss": 1.0659,
      "step": 32600
    },
    {
      "epoch": 2.03,
      "grad_norm": 18.91126251220703,
      "learning_rate": 3.9973145141144144e-05,
      "loss": 1.0502,
      "step": 32610
    },
    {
      "epoch": 2.03,
      "grad_norm": 10.01711368560791,
      "learning_rate": 3.997002248313765e-05,
      "loss": 0.9491,
      "step": 32620
    },
    {
      "epoch": 2.03,
      "grad_norm": 9.400378227233887,
      "learning_rate": 3.996689982513115e-05,
      "loss": 0.9119,
      "step": 32630
    },
    {
      "epoch": 2.03,
      "grad_norm": 10.591450691223145,
      "learning_rate": 3.996377716712466e-05,
      "loss": 0.8974,
      "step": 32640
    },
    {
      "epoch": 2.03,
      "grad_norm": 13.593283653259277,
      "learning_rate": 3.9960654509118165e-05,
      "loss": 0.945,
      "step": 32650
    },
    {
      "epoch": 2.03,
      "grad_norm": 14.608980178833008,
      "learning_rate": 3.995753185111167e-05,
      "loss": 0.9278,
      "step": 32660
    },
    {
      "epoch": 2.03,
      "grad_norm": 11.420561790466309,
      "learning_rate": 3.995440919310517e-05,
      "loss": 0.8725,
      "step": 32670
    },
    {
      "epoch": 2.03,
      "grad_norm": 11.010306358337402,
      "learning_rate": 3.995128653509868e-05,
      "loss": 0.9738,
      "step": 32680
    },
    {
      "epoch": 2.04,
      "grad_norm": 11.885629653930664,
      "learning_rate": 3.9948163877092185e-05,
      "loss": 0.8524,
      "step": 32690
    },
    {
      "epoch": 2.04,
      "grad_norm": 8.036046981811523,
      "learning_rate": 3.9945041219085685e-05,
      "loss": 0.7968,
      "step": 32700
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.581616401672363,
      "learning_rate": 3.994191856107919e-05,
      "loss": 0.9173,
      "step": 32710
    },
    {
      "epoch": 2.04,
      "grad_norm": 10.625001907348633,
      "learning_rate": 3.99387959030727e-05,
      "loss": 0.9572,
      "step": 32720
    },
    {
      "epoch": 2.04,
      "grad_norm": 14.408846855163574,
      "learning_rate": 3.99356732450662e-05,
      "loss": 0.9797,
      "step": 32730
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.810531616210938,
      "learning_rate": 3.9932550587059706e-05,
      "loss": 1.0099,
      "step": 32740
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.024836540222168,
      "learning_rate": 3.992942792905321e-05,
      "loss": 0.7788,
      "step": 32750
    },
    {
      "epoch": 2.04,
      "grad_norm": 9.020439147949219,
      "learning_rate": 3.992630527104671e-05,
      "loss": 0.9357,
      "step": 32760
    },
    {
      "epoch": 2.04,
      "grad_norm": 8.29531192779541,
      "learning_rate": 3.992318261304022e-05,
      "loss": 0.8163,
      "step": 32770
    },
    {
      "epoch": 2.04,
      "grad_norm": 11.591922760009766,
      "learning_rate": 3.9920059955033726e-05,
      "loss": 0.8087,
      "step": 32780
    },
    {
      "epoch": 2.04,
      "grad_norm": 12.323933601379395,
      "learning_rate": 3.9916937297027226e-05,
      "loss": 0.9209,
      "step": 32790
    },
    {
      "epoch": 2.04,
      "grad_norm": 10.805459022521973,
      "learning_rate": 3.991381463902073e-05,
      "loss": 0.9633,
      "step": 32800
    },
    {
      "epoch": 2.04,
      "grad_norm": 6.322305679321289,
      "learning_rate": 3.991069198101424e-05,
      "loss": 0.9066,
      "step": 32810
    },
    {
      "epoch": 2.04,
      "grad_norm": 7.255049705505371,
      "learning_rate": 3.9907569323007746e-05,
      "loss": 0.9188,
      "step": 32820
    },
    {
      "epoch": 2.04,
      "grad_norm": 8.865386962890625,
      "learning_rate": 3.9904446665001246e-05,
      "loss": 0.8223,
      "step": 32830
    },
    {
      "epoch": 2.04,
      "grad_norm": 12.288843154907227,
      "learning_rate": 3.990132400699475e-05,
      "loss": 1.0075,
      "step": 32840
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.757453918457031,
      "learning_rate": 3.989820134898826e-05,
      "loss": 0.872,
      "step": 32850
    },
    {
      "epoch": 2.05,
      "grad_norm": 12.678224563598633,
      "learning_rate": 3.989507869098176e-05,
      "loss": 1.0043,
      "step": 32860
    },
    {
      "epoch": 2.05,
      "grad_norm": 10.348434448242188,
      "learning_rate": 3.989195603297527e-05,
      "loss": 0.8492,
      "step": 32870
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.523487091064453,
      "learning_rate": 3.9888833374968774e-05,
      "loss": 0.9061,
      "step": 32880
    },
    {
      "epoch": 2.05,
      "grad_norm": 12.494001388549805,
      "learning_rate": 3.988571071696228e-05,
      "loss": 0.8711,
      "step": 32890
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.638995170593262,
      "learning_rate": 3.988258805895578e-05,
      "loss": 0.8055,
      "step": 32900
    },
    {
      "epoch": 2.05,
      "grad_norm": 9.803427696228027,
      "learning_rate": 3.987946540094929e-05,
      "loss": 0.7953,
      "step": 32910
    },
    {
      "epoch": 2.05,
      "grad_norm": 12.269448280334473,
      "learning_rate": 3.9876342742942794e-05,
      "loss": 1.096,
      "step": 32920
    },
    {
      "epoch": 2.05,
      "grad_norm": 13.938922882080078,
      "learning_rate": 3.98732200849363e-05,
      "loss": 0.8238,
      "step": 32930
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.491734504699707,
      "learning_rate": 3.98700974269298e-05,
      "loss": 0.834,
      "step": 32940
    },
    {
      "epoch": 2.05,
      "grad_norm": 12.039922714233398,
      "learning_rate": 3.986697476892331e-05,
      "loss": 0.9928,
      "step": 32950
    },
    {
      "epoch": 2.05,
      "grad_norm": 14.76683235168457,
      "learning_rate": 3.9863852110916815e-05,
      "loss": 0.9202,
      "step": 32960
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.073516845703125,
      "learning_rate": 3.9860729452910315e-05,
      "loss": 0.8933,
      "step": 32970
    },
    {
      "epoch": 2.05,
      "grad_norm": 10.078410148620605,
      "learning_rate": 3.985760679490382e-05,
      "loss": 0.8199,
      "step": 32980
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.653555870056152,
      "learning_rate": 3.985448413689733e-05,
      "loss": 0.8807,
      "step": 32990
    },
    {
      "epoch": 2.05,
      "grad_norm": 17.479137420654297,
      "learning_rate": 3.9851361478890835e-05,
      "loss": 0.9732,
      "step": 33000
    },
    {
      "epoch": 2.06,
      "grad_norm": 12.070083618164062,
      "learning_rate": 3.9848238820884335e-05,
      "loss": 0.9318,
      "step": 33010
    },
    {
      "epoch": 2.06,
      "grad_norm": 7.011051177978516,
      "learning_rate": 3.984511616287784e-05,
      "loss": 0.9112,
      "step": 33020
    },
    {
      "epoch": 2.06,
      "grad_norm": 13.532998085021973,
      "learning_rate": 3.984199350487135e-05,
      "loss": 0.9593,
      "step": 33030
    },
    {
      "epoch": 2.06,
      "grad_norm": 9.368322372436523,
      "learning_rate": 3.983887084686485e-05,
      "loss": 1.0147,
      "step": 33040
    },
    {
      "epoch": 2.06,
      "grad_norm": 11.861870765686035,
      "learning_rate": 3.9835748188858356e-05,
      "loss": 1.0415,
      "step": 33050
    },
    {
      "epoch": 2.06,
      "grad_norm": 13.45455265045166,
      "learning_rate": 3.983262553085186e-05,
      "loss": 1.0195,
      "step": 33060
    },
    {
      "epoch": 2.06,
      "grad_norm": 8.013449668884277,
      "learning_rate": 3.982950287284537e-05,
      "loss": 0.9161,
      "step": 33070
    },
    {
      "epoch": 2.06,
      "grad_norm": 10.690513610839844,
      "learning_rate": 3.982638021483887e-05,
      "loss": 0.9056,
      "step": 33080
    },
    {
      "epoch": 2.06,
      "grad_norm": 10.293542861938477,
      "learning_rate": 3.9823257556832376e-05,
      "loss": 0.9201,
      "step": 33090
    },
    {
      "epoch": 2.06,
      "grad_norm": 15.270747184753418,
      "learning_rate": 3.982013489882588e-05,
      "loss": 0.8237,
      "step": 33100
    },
    {
      "epoch": 2.06,
      "grad_norm": 8.661290168762207,
      "learning_rate": 3.981701224081938e-05,
      "loss": 0.8818,
      "step": 33110
    },
    {
      "epoch": 2.06,
      "grad_norm": 13.328078269958496,
      "learning_rate": 3.981388958281289e-05,
      "loss": 0.9655,
      "step": 33120
    },
    {
      "epoch": 2.06,
      "grad_norm": 13.234599113464355,
      "learning_rate": 3.9810766924806396e-05,
      "loss": 0.9502,
      "step": 33130
    },
    {
      "epoch": 2.06,
      "grad_norm": 9.658319473266602,
      "learning_rate": 3.98076442667999e-05,
      "loss": 0.9045,
      "step": 33140
    },
    {
      "epoch": 2.06,
      "grad_norm": 6.598461151123047,
      "learning_rate": 3.98045216087934e-05,
      "loss": 1.0493,
      "step": 33150
    },
    {
      "epoch": 2.06,
      "grad_norm": 11.487719535827637,
      "learning_rate": 3.980139895078691e-05,
      "loss": 0.9171,
      "step": 33160
    },
    {
      "epoch": 2.07,
      "grad_norm": 10.89101505279541,
      "learning_rate": 3.979827629278042e-05,
      "loss": 1.0009,
      "step": 33170
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.284619331359863,
      "learning_rate": 3.9795153634773924e-05,
      "loss": 1.0014,
      "step": 33180
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.404661178588867,
      "learning_rate": 3.9792030976767424e-05,
      "loss": 1.0152,
      "step": 33190
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.0816011428833,
      "learning_rate": 3.978890831876093e-05,
      "loss": 0.8063,
      "step": 33200
    },
    {
      "epoch": 2.07,
      "grad_norm": 11.825540542602539,
      "learning_rate": 3.978578566075444e-05,
      "loss": 1.0262,
      "step": 33210
    },
    {
      "epoch": 2.07,
      "grad_norm": 15.356521606445312,
      "learning_rate": 3.978266300274794e-05,
      "loss": 0.9207,
      "step": 33220
    },
    {
      "epoch": 2.07,
      "grad_norm": 10.971209526062012,
      "learning_rate": 3.9779540344741444e-05,
      "loss": 0.9237,
      "step": 33230
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.989069938659668,
      "learning_rate": 3.977641768673495e-05,
      "loss": 0.8686,
      "step": 33240
    },
    {
      "epoch": 2.07,
      "grad_norm": 10.967549324035645,
      "learning_rate": 3.977329502872846e-05,
      "loss": 1.0661,
      "step": 33250
    },
    {
      "epoch": 2.07,
      "grad_norm": 9.728742599487305,
      "learning_rate": 3.977017237072196e-05,
      "loss": 0.9509,
      "step": 33260
    },
    {
      "epoch": 2.07,
      "grad_norm": 7.178773403167725,
      "learning_rate": 3.9767049712715465e-05,
      "loss": 1.0126,
      "step": 33270
    },
    {
      "epoch": 2.07,
      "grad_norm": 11.614214897155762,
      "learning_rate": 3.976392705470897e-05,
      "loss": 0.9526,
      "step": 33280
    },
    {
      "epoch": 2.07,
      "grad_norm": 12.170454978942871,
      "learning_rate": 3.976080439670247e-05,
      "loss": 0.8904,
      "step": 33290
    },
    {
      "epoch": 2.07,
      "grad_norm": 7.306878566741943,
      "learning_rate": 3.975768173869598e-05,
      "loss": 0.9085,
      "step": 33300
    },
    {
      "epoch": 2.07,
      "grad_norm": 8.976337432861328,
      "learning_rate": 3.9754559080689485e-05,
      "loss": 1.0077,
      "step": 33310
    },
    {
      "epoch": 2.07,
      "grad_norm": 15.525259017944336,
      "learning_rate": 3.975143642268299e-05,
      "loss": 0.9366,
      "step": 33320
    },
    {
      "epoch": 2.08,
      "grad_norm": 10.554275512695312,
      "learning_rate": 3.974831376467649e-05,
      "loss": 0.8623,
      "step": 33330
    },
    {
      "epoch": 2.08,
      "grad_norm": 7.776504993438721,
      "learning_rate": 3.974519110667e-05,
      "loss": 0.8338,
      "step": 33340
    },
    {
      "epoch": 2.08,
      "grad_norm": 8.760443687438965,
      "learning_rate": 3.9742068448663506e-05,
      "loss": 1.0047,
      "step": 33350
    },
    {
      "epoch": 2.08,
      "grad_norm": 16.182132720947266,
      "learning_rate": 3.973894579065701e-05,
      "loss": 0.9529,
      "step": 33360
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.564725875854492,
      "learning_rate": 3.973582313265051e-05,
      "loss": 0.9785,
      "step": 33370
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.275291442871094,
      "learning_rate": 3.973270047464402e-05,
      "loss": 0.9722,
      "step": 33380
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.114128112792969,
      "learning_rate": 3.9729577816637526e-05,
      "loss": 0.9224,
      "step": 33390
    },
    {
      "epoch": 2.08,
      "grad_norm": 10.926776885986328,
      "learning_rate": 3.9726455158631026e-05,
      "loss": 0.9582,
      "step": 33400
    },
    {
      "epoch": 2.08,
      "grad_norm": 5.375739097595215,
      "learning_rate": 3.972333250062453e-05,
      "loss": 0.8481,
      "step": 33410
    },
    {
      "epoch": 2.08,
      "grad_norm": 10.79642391204834,
      "learning_rate": 3.972020984261804e-05,
      "loss": 0.9267,
      "step": 33420
    },
    {
      "epoch": 2.08,
      "grad_norm": 9.338967323303223,
      "learning_rate": 3.9717087184611546e-05,
      "loss": 0.8697,
      "step": 33430
    },
    {
      "epoch": 2.08,
      "grad_norm": 8.088994026184082,
      "learning_rate": 3.9713964526605046e-05,
      "loss": 0.9136,
      "step": 33440
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.749377250671387,
      "learning_rate": 3.971084186859855e-05,
      "loss": 0.9873,
      "step": 33450
    },
    {
      "epoch": 2.08,
      "grad_norm": 11.015168190002441,
      "learning_rate": 3.970771921059206e-05,
      "loss": 0.8835,
      "step": 33460
    },
    {
      "epoch": 2.08,
      "grad_norm": 10.566510200500488,
      "learning_rate": 3.970459655258556e-05,
      "loss": 0.8287,
      "step": 33470
    },
    {
      "epoch": 2.08,
      "grad_norm": 11.627199172973633,
      "learning_rate": 3.970147389457907e-05,
      "loss": 0.9191,
      "step": 33480
    },
    {
      "epoch": 2.09,
      "grad_norm": 10.933215141296387,
      "learning_rate": 3.9698351236572574e-05,
      "loss": 1.0212,
      "step": 33490
    },
    {
      "epoch": 2.09,
      "grad_norm": 10.72277545928955,
      "learning_rate": 3.969522857856608e-05,
      "loss": 0.9887,
      "step": 33500
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.113136291503906,
      "learning_rate": 3.969210592055958e-05,
      "loss": 1.0141,
      "step": 33510
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.887140274047852,
      "learning_rate": 3.968898326255309e-05,
      "loss": 0.8787,
      "step": 33520
    },
    {
      "epoch": 2.09,
      "grad_norm": 12.588582038879395,
      "learning_rate": 3.9685860604546594e-05,
      "loss": 1.0386,
      "step": 33530
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.42086410522461,
      "learning_rate": 3.96827379465401e-05,
      "loss": 1.0116,
      "step": 33540
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.4274263381958,
      "learning_rate": 3.96796152885336e-05,
      "loss": 0.9003,
      "step": 33550
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.451874732971191,
      "learning_rate": 3.967649263052711e-05,
      "loss": 0.9577,
      "step": 33560
    },
    {
      "epoch": 2.09,
      "grad_norm": 8.646950721740723,
      "learning_rate": 3.9673369972520615e-05,
      "loss": 0.8312,
      "step": 33570
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.328496932983398,
      "learning_rate": 3.9670247314514115e-05,
      "loss": 1.1075,
      "step": 33580
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.185506820678711,
      "learning_rate": 3.966712465650762e-05,
      "loss": 0.9786,
      "step": 33590
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.710427284240723,
      "learning_rate": 3.966400199850113e-05,
      "loss": 0.9691,
      "step": 33600
    },
    {
      "epoch": 2.09,
      "grad_norm": 6.305935859680176,
      "learning_rate": 3.9660879340494635e-05,
      "loss": 0.818,
      "step": 33610
    },
    {
      "epoch": 2.09,
      "grad_norm": 11.390512466430664,
      "learning_rate": 3.9657756682488135e-05,
      "loss": 0.8968,
      "step": 33620
    },
    {
      "epoch": 2.09,
      "grad_norm": 16.532123565673828,
      "learning_rate": 3.965463402448164e-05,
      "loss": 0.9846,
      "step": 33630
    },
    {
      "epoch": 2.09,
      "grad_norm": 11.554447174072266,
      "learning_rate": 3.965151136647515e-05,
      "loss": 0.9498,
      "step": 33640
    },
    {
      "epoch": 2.1,
      "grad_norm": 7.159631252288818,
      "learning_rate": 3.964838870846865e-05,
      "loss": 0.9634,
      "step": 33650
    },
    {
      "epoch": 2.1,
      "grad_norm": 8.986442565917969,
      "learning_rate": 3.9645266050462156e-05,
      "loss": 0.9584,
      "step": 33660
    },
    {
      "epoch": 2.1,
      "grad_norm": 8.864797592163086,
      "learning_rate": 3.964214339245566e-05,
      "loss": 0.9098,
      "step": 33670
    },
    {
      "epoch": 2.1,
      "grad_norm": 7.167109966278076,
      "learning_rate": 3.963902073444917e-05,
      "loss": 0.9986,
      "step": 33680
    },
    {
      "epoch": 2.1,
      "grad_norm": 10.514774322509766,
      "learning_rate": 3.963589807644267e-05,
      "loss": 1.0033,
      "step": 33690
    },
    {
      "epoch": 2.1,
      "grad_norm": 13.11417007446289,
      "learning_rate": 3.9632775418436176e-05,
      "loss": 0.9993,
      "step": 33700
    },
    {
      "epoch": 2.1,
      "grad_norm": 9.790458679199219,
      "learning_rate": 3.962965276042968e-05,
      "loss": 0.9794,
      "step": 33710
    },
    {
      "epoch": 2.1,
      "grad_norm": 15.8804931640625,
      "learning_rate": 3.962653010242319e-05,
      "loss": 1.0097,
      "step": 33720
    },
    {
      "epoch": 2.1,
      "grad_norm": 11.36761474609375,
      "learning_rate": 3.962340744441669e-05,
      "loss": 1.0182,
      "step": 33730
    },
    {
      "epoch": 2.1,
      "grad_norm": 15.289397239685059,
      "learning_rate": 3.9620284786410196e-05,
      "loss": 0.9982,
      "step": 33740
    },
    {
      "epoch": 2.1,
      "grad_norm": 13.88658618927002,
      "learning_rate": 3.96171621284037e-05,
      "loss": 0.9791,
      "step": 33750
    },
    {
      "epoch": 2.1,
      "grad_norm": 10.581360816955566,
      "learning_rate": 3.96140394703972e-05,
      "loss": 0.9939,
      "step": 33760
    },
    {
      "epoch": 2.1,
      "grad_norm": 9.157598495483398,
      "learning_rate": 3.961091681239071e-05,
      "loss": 0.8604,
      "step": 33770
    },
    {
      "epoch": 2.1,
      "grad_norm": 10.685870170593262,
      "learning_rate": 3.960779415438422e-05,
      "loss": 0.983,
      "step": 33780
    },
    {
      "epoch": 2.1,
      "grad_norm": 12.032144546508789,
      "learning_rate": 3.9604671496377724e-05,
      "loss": 0.9995,
      "step": 33790
    },
    {
      "epoch": 2.1,
      "grad_norm": 8.254409790039062,
      "learning_rate": 3.9601548838371224e-05,
      "loss": 0.9272,
      "step": 33800
    },
    {
      "epoch": 2.1,
      "grad_norm": 10.181702613830566,
      "learning_rate": 3.959842618036473e-05,
      "loss": 0.903,
      "step": 33810
    },
    {
      "epoch": 2.11,
      "grad_norm": 17.795412063598633,
      "learning_rate": 3.959530352235824e-05,
      "loss": 1.0252,
      "step": 33820
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.248013496398926,
      "learning_rate": 3.959218086435174e-05,
      "loss": 0.9995,
      "step": 33830
    },
    {
      "epoch": 2.11,
      "grad_norm": 9.361116409301758,
      "learning_rate": 3.9589058206345244e-05,
      "loss": 0.9409,
      "step": 33840
    },
    {
      "epoch": 2.11,
      "grad_norm": 9.658496856689453,
      "learning_rate": 3.958593554833875e-05,
      "loss": 0.895,
      "step": 33850
    },
    {
      "epoch": 2.11,
      "grad_norm": 9.586577415466309,
      "learning_rate": 3.958281289033226e-05,
      "loss": 0.9229,
      "step": 33860
    },
    {
      "epoch": 2.11,
      "grad_norm": 8.70502758026123,
      "learning_rate": 3.957969023232576e-05,
      "loss": 0.9865,
      "step": 33870
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.257774353027344,
      "learning_rate": 3.9576567574319265e-05,
      "loss": 1.0224,
      "step": 33880
    },
    {
      "epoch": 2.11,
      "grad_norm": 7.209299564361572,
      "learning_rate": 3.957344491631277e-05,
      "loss": 0.8858,
      "step": 33890
    },
    {
      "epoch": 2.11,
      "grad_norm": 12.975212097167969,
      "learning_rate": 3.957032225830628e-05,
      "loss": 0.9475,
      "step": 33900
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.835596084594727,
      "learning_rate": 3.956719960029978e-05,
      "loss": 0.8404,
      "step": 33910
    },
    {
      "epoch": 2.11,
      "grad_norm": 11.778449058532715,
      "learning_rate": 3.9564076942293285e-05,
      "loss": 0.9103,
      "step": 33920
    },
    {
      "epoch": 2.11,
      "grad_norm": 14.420088768005371,
      "learning_rate": 3.956095428428679e-05,
      "loss": 0.9249,
      "step": 33930
    },
    {
      "epoch": 2.11,
      "grad_norm": 14.261272430419922,
      "learning_rate": 3.955783162628029e-05,
      "loss": 1.0603,
      "step": 33940
    },
    {
      "epoch": 2.11,
      "grad_norm": 12.348002433776855,
      "learning_rate": 3.95547089682738e-05,
      "loss": 0.9111,
      "step": 33950
    },
    {
      "epoch": 2.11,
      "grad_norm": 12.55174732208252,
      "learning_rate": 3.9551586310267306e-05,
      "loss": 1.1236,
      "step": 33960
    },
    {
      "epoch": 2.11,
      "grad_norm": 8.587811470031738,
      "learning_rate": 3.9548463652260806e-05,
      "loss": 1.0008,
      "step": 33970
    },
    {
      "epoch": 2.12,
      "grad_norm": 14.32214069366455,
      "learning_rate": 3.954534099425431e-05,
      "loss": 1.0441,
      "step": 33980
    },
    {
      "epoch": 2.12,
      "grad_norm": 12.014692306518555,
      "learning_rate": 3.954221833624782e-05,
      "loss": 0.858,
      "step": 33990
    },
    {
      "epoch": 2.12,
      "grad_norm": 11.817367553710938,
      "learning_rate": 3.953909567824132e-05,
      "loss": 0.8299,
      "step": 34000
    },
    {
      "epoch": 2.12,
      "grad_norm": 15.074539184570312,
      "learning_rate": 3.9535973020234826e-05,
      "loss": 1.084,
      "step": 34010
    },
    {
      "epoch": 2.12,
      "grad_norm": 10.573291778564453,
      "learning_rate": 3.953285036222833e-05,
      "loss": 0.963,
      "step": 34020
    },
    {
      "epoch": 2.12,
      "grad_norm": 13.287904739379883,
      "learning_rate": 3.952972770422183e-05,
      "loss": 0.9096,
      "step": 34030
    },
    {
      "epoch": 2.12,
      "grad_norm": 14.318142890930176,
      "learning_rate": 3.952660504621534e-05,
      "loss": 1.0632,
      "step": 34040
    },
    {
      "epoch": 2.12,
      "grad_norm": 12.412789344787598,
      "learning_rate": 3.9523482388208846e-05,
      "loss": 0.9126,
      "step": 34050
    },
    {
      "epoch": 2.12,
      "grad_norm": 8.01786994934082,
      "learning_rate": 3.9520359730202347e-05,
      "loss": 0.9278,
      "step": 34060
    },
    {
      "epoch": 2.12,
      "grad_norm": 8.934804916381836,
      "learning_rate": 3.951723707219585e-05,
      "loss": 0.8683,
      "step": 34070
    },
    {
      "epoch": 2.12,
      "grad_norm": 12.048003196716309,
      "learning_rate": 3.951411441418936e-05,
      "loss": 0.9985,
      "step": 34080
    },
    {
      "epoch": 2.12,
      "grad_norm": 11.594597816467285,
      "learning_rate": 3.951099175618286e-05,
      "loss": 0.9742,
      "step": 34090
    },
    {
      "epoch": 2.12,
      "grad_norm": 9.37389850616455,
      "learning_rate": 3.950786909817637e-05,
      "loss": 1.0343,
      "step": 34100
    },
    {
      "epoch": 2.12,
      "grad_norm": 10.885437965393066,
      "learning_rate": 3.9504746440169874e-05,
      "loss": 0.8225,
      "step": 34110
    },
    {
      "epoch": 2.12,
      "grad_norm": 10.168147087097168,
      "learning_rate": 3.950162378216338e-05,
      "loss": 0.9257,
      "step": 34120
    },
    {
      "epoch": 2.12,
      "grad_norm": 10.243001937866211,
      "learning_rate": 3.949850112415688e-05,
      "loss": 0.9232,
      "step": 34130
    },
    {
      "epoch": 2.13,
      "grad_norm": 9.797444343566895,
      "learning_rate": 3.949537846615039e-05,
      "loss": 0.95,
      "step": 34140
    },
    {
      "epoch": 2.13,
      "grad_norm": 16.138320922851562,
      "learning_rate": 3.9492255808143894e-05,
      "loss": 0.9235,
      "step": 34150
    },
    {
      "epoch": 2.13,
      "grad_norm": 12.735955238342285,
      "learning_rate": 3.9489133150137394e-05,
      "loss": 1.0778,
      "step": 34160
    },
    {
      "epoch": 2.13,
      "grad_norm": 11.856477737426758,
      "learning_rate": 3.94860104921309e-05,
      "loss": 0.9727,
      "step": 34170
    },
    {
      "epoch": 2.13,
      "grad_norm": 8.868813514709473,
      "learning_rate": 3.948288783412441e-05,
      "loss": 0.925,
      "step": 34180
    },
    {
      "epoch": 2.13,
      "grad_norm": 11.702218055725098,
      "learning_rate": 3.947976517611791e-05,
      "loss": 0.9053,
      "step": 34190
    },
    {
      "epoch": 2.13,
      "grad_norm": 11.381255149841309,
      "learning_rate": 3.9476642518111415e-05,
      "loss": 0.9868,
      "step": 34200
    },
    {
      "epoch": 2.13,
      "grad_norm": 13.685918807983398,
      "learning_rate": 3.947351986010492e-05,
      "loss": 0.9987,
      "step": 34210
    },
    {
      "epoch": 2.13,
      "grad_norm": 7.0524516105651855,
      "learning_rate": 3.947039720209843e-05,
      "loss": 0.8864,
      "step": 34220
    },
    {
      "epoch": 2.13,
      "grad_norm": 7.796684741973877,
      "learning_rate": 3.946727454409193e-05,
      "loss": 0.8383,
      "step": 34230
    },
    {
      "epoch": 2.13,
      "grad_norm": 11.488349914550781,
      "learning_rate": 3.9464151886085435e-05,
      "loss": 0.9596,
      "step": 34240
    },
    {
      "epoch": 2.13,
      "grad_norm": 10.639707565307617,
      "learning_rate": 3.946102922807894e-05,
      "loss": 0.9813,
      "step": 34250
    },
    {
      "epoch": 2.13,
      "grad_norm": 13.536571502685547,
      "learning_rate": 3.945790657007244e-05,
      "loss": 0.9117,
      "step": 34260
    },
    {
      "epoch": 2.13,
      "grad_norm": 9.52862548828125,
      "learning_rate": 3.945478391206595e-05,
      "loss": 1.0097,
      "step": 34270
    },
    {
      "epoch": 2.13,
      "grad_norm": 9.542129516601562,
      "learning_rate": 3.9451661254059456e-05,
      "loss": 0.9887,
      "step": 34280
    },
    {
      "epoch": 2.13,
      "grad_norm": 10.626983642578125,
      "learning_rate": 3.944853859605296e-05,
      "loss": 0.8447,
      "step": 34290
    },
    {
      "epoch": 2.14,
      "grad_norm": 17.239500045776367,
      "learning_rate": 3.944541593804646e-05,
      "loss": 1.0219,
      "step": 34300
    },
    {
      "epoch": 2.14,
      "grad_norm": 15.28193473815918,
      "learning_rate": 3.944229328003997e-05,
      "loss": 1.0947,
      "step": 34310
    },
    {
      "epoch": 2.14,
      "grad_norm": 14.259634017944336,
      "learning_rate": 3.9439170622033476e-05,
      "loss": 1.0354,
      "step": 34320
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.32409954071045,
      "learning_rate": 3.943604796402698e-05,
      "loss": 0.9898,
      "step": 34330
    },
    {
      "epoch": 2.14,
      "grad_norm": 8.221850395202637,
      "learning_rate": 3.943292530602048e-05,
      "loss": 0.934,
      "step": 34340
    },
    {
      "epoch": 2.14,
      "grad_norm": 9.063467979431152,
      "learning_rate": 3.942980264801399e-05,
      "loss": 0.8933,
      "step": 34350
    },
    {
      "epoch": 2.14,
      "grad_norm": 8.326353073120117,
      "learning_rate": 3.9426679990007497e-05,
      "loss": 0.9716,
      "step": 34360
    },
    {
      "epoch": 2.14,
      "grad_norm": 10.091511726379395,
      "learning_rate": 3.9423557332000997e-05,
      "loss": 0.9108,
      "step": 34370
    },
    {
      "epoch": 2.14,
      "grad_norm": 10.493016242980957,
      "learning_rate": 3.94204346739945e-05,
      "loss": 0.9349,
      "step": 34380
    },
    {
      "epoch": 2.14,
      "grad_norm": 13.7815523147583,
      "learning_rate": 3.941731201598801e-05,
      "loss": 1.0448,
      "step": 34390
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.498465538024902,
      "learning_rate": 3.941418935798152e-05,
      "loss": 0.8977,
      "step": 34400
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.180057525634766,
      "learning_rate": 3.941106669997502e-05,
      "loss": 0.9641,
      "step": 34410
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.020181655883789,
      "learning_rate": 3.9407944041968524e-05,
      "loss": 0.9694,
      "step": 34420
    },
    {
      "epoch": 2.14,
      "grad_norm": 12.172078132629395,
      "learning_rate": 3.940482138396203e-05,
      "loss": 0.9954,
      "step": 34430
    },
    {
      "epoch": 2.14,
      "grad_norm": 7.701535224914551,
      "learning_rate": 3.940169872595553e-05,
      "loss": 0.9007,
      "step": 34440
    },
    {
      "epoch": 2.14,
      "grad_norm": 11.155875205993652,
      "learning_rate": 3.939857606794904e-05,
      "loss": 0.987,
      "step": 34450
    },
    {
      "epoch": 2.15,
      "grad_norm": 10.065743446350098,
      "learning_rate": 3.9395453409942544e-05,
      "loss": 0.9344,
      "step": 34460
    },
    {
      "epoch": 2.15,
      "grad_norm": 11.735358238220215,
      "learning_rate": 3.939233075193605e-05,
      "loss": 1.051,
      "step": 34470
    },
    {
      "epoch": 2.15,
      "grad_norm": 13.111937522888184,
      "learning_rate": 3.938920809392955e-05,
      "loss": 0.9987,
      "step": 34480
    },
    {
      "epoch": 2.15,
      "grad_norm": 9.924117088317871,
      "learning_rate": 3.938608543592306e-05,
      "loss": 0.9398,
      "step": 34490
    },
    {
      "epoch": 2.15,
      "grad_norm": 9.652956008911133,
      "learning_rate": 3.9382962777916565e-05,
      "loss": 0.9233,
      "step": 34500
    },
    {
      "epoch": 2.15,
      "grad_norm": 15.61044979095459,
      "learning_rate": 3.937984011991007e-05,
      "loss": 0.9123,
      "step": 34510
    },
    {
      "epoch": 2.15,
      "grad_norm": 12.442867279052734,
      "learning_rate": 3.937671746190357e-05,
      "loss": 1.0043,
      "step": 34520
    },
    {
      "epoch": 2.15,
      "grad_norm": 9.767669677734375,
      "learning_rate": 3.937359480389708e-05,
      "loss": 0.8662,
      "step": 34530
    },
    {
      "epoch": 2.15,
      "grad_norm": 9.740616798400879,
      "learning_rate": 3.9370472145890585e-05,
      "loss": 0.8537,
      "step": 34540
    },
    {
      "epoch": 2.15,
      "grad_norm": 13.026805877685547,
      "learning_rate": 3.9367349487884085e-05,
      "loss": 0.955,
      "step": 34550
    },
    {
      "epoch": 2.15,
      "grad_norm": 12.58801555633545,
      "learning_rate": 3.936422682987759e-05,
      "loss": 0.9302,
      "step": 34560
    },
    {
      "epoch": 2.15,
      "grad_norm": 13.878125190734863,
      "learning_rate": 3.93611041718711e-05,
      "loss": 0.8869,
      "step": 34570
    },
    {
      "epoch": 2.15,
      "grad_norm": 10.3814115524292,
      "learning_rate": 3.9357981513864606e-05,
      "loss": 0.9888,
      "step": 34580
    },
    {
      "epoch": 2.15,
      "grad_norm": 13.11436653137207,
      "learning_rate": 3.9354858855858106e-05,
      "loss": 0.943,
      "step": 34590
    },
    {
      "epoch": 2.15,
      "grad_norm": 8.517058372497559,
      "learning_rate": 3.935173619785161e-05,
      "loss": 0.953,
      "step": 34600
    },
    {
      "epoch": 2.15,
      "grad_norm": 8.47908878326416,
      "learning_rate": 3.934861353984512e-05,
      "loss": 0.9388,
      "step": 34610
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.354208946228027,
      "learning_rate": 3.934549088183862e-05,
      "loss": 0.9306,
      "step": 34620
    },
    {
      "epoch": 2.16,
      "grad_norm": 9.854585647583008,
      "learning_rate": 3.9342368223832126e-05,
      "loss": 0.9422,
      "step": 34630
    },
    {
      "epoch": 2.16,
      "grad_norm": 15.199372291564941,
      "learning_rate": 3.933924556582563e-05,
      "loss": 0.8716,
      "step": 34640
    },
    {
      "epoch": 2.16,
      "grad_norm": 11.035394668579102,
      "learning_rate": 3.933612290781914e-05,
      "loss": 0.8916,
      "step": 34650
    },
    {
      "epoch": 2.16,
      "grad_norm": 10.984890937805176,
      "learning_rate": 3.933300024981264e-05,
      "loss": 1.1003,
      "step": 34660
    },
    {
      "epoch": 2.16,
      "grad_norm": 7.492180824279785,
      "learning_rate": 3.9329877591806147e-05,
      "loss": 0.9834,
      "step": 34670
    },
    {
      "epoch": 2.16,
      "grad_norm": 10.582244873046875,
      "learning_rate": 3.932675493379965e-05,
      "loss": 0.9926,
      "step": 34680
    },
    {
      "epoch": 2.16,
      "grad_norm": 11.61484432220459,
      "learning_rate": 3.932363227579316e-05,
      "loss": 0.9563,
      "step": 34690
    },
    {
      "epoch": 2.16,
      "grad_norm": 11.966711044311523,
      "learning_rate": 3.932050961778666e-05,
      "loss": 1.0545,
      "step": 34700
    },
    {
      "epoch": 2.16,
      "grad_norm": 12.511361122131348,
      "learning_rate": 3.931738695978017e-05,
      "loss": 0.885,
      "step": 34710
    },
    {
      "epoch": 2.16,
      "grad_norm": 12.993096351623535,
      "learning_rate": 3.9314264301773674e-05,
      "loss": 1.0094,
      "step": 34720
    },
    {
      "epoch": 2.16,
      "grad_norm": 16.356943130493164,
      "learning_rate": 3.9311141643767174e-05,
      "loss": 0.8007,
      "step": 34730
    },
    {
      "epoch": 2.16,
      "grad_norm": 11.276902198791504,
      "learning_rate": 3.930801898576068e-05,
      "loss": 0.931,
      "step": 34740
    },
    {
      "epoch": 2.16,
      "grad_norm": 14.189369201660156,
      "learning_rate": 3.930489632775419e-05,
      "loss": 1.0609,
      "step": 34750
    },
    {
      "epoch": 2.16,
      "grad_norm": 10.486001014709473,
      "learning_rate": 3.9301773669747694e-05,
      "loss": 1.0439,
      "step": 34760
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.111126899719238,
      "learning_rate": 3.9298651011741194e-05,
      "loss": 0.8286,
      "step": 34770
    },
    {
      "epoch": 2.17,
      "grad_norm": 18.243324279785156,
      "learning_rate": 3.92955283537347e-05,
      "loss": 1.0685,
      "step": 34780
    },
    {
      "epoch": 2.17,
      "grad_norm": 18.51824378967285,
      "learning_rate": 3.929240569572821e-05,
      "loss": 0.8762,
      "step": 34790
    },
    {
      "epoch": 2.17,
      "grad_norm": 6.409940719604492,
      "learning_rate": 3.928928303772171e-05,
      "loss": 1.0071,
      "step": 34800
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.722267150878906,
      "learning_rate": 3.9286160379715215e-05,
      "loss": 0.9476,
      "step": 34810
    },
    {
      "epoch": 2.17,
      "grad_norm": 6.397946834564209,
      "learning_rate": 3.928303772170872e-05,
      "loss": 1.0478,
      "step": 34820
    },
    {
      "epoch": 2.17,
      "grad_norm": 11.540529251098633,
      "learning_rate": 3.927991506370223e-05,
      "loss": 1.0305,
      "step": 34830
    },
    {
      "epoch": 2.17,
      "grad_norm": 9.916952133178711,
      "learning_rate": 3.927679240569573e-05,
      "loss": 0.8604,
      "step": 34840
    },
    {
      "epoch": 2.17,
      "grad_norm": 7.820743083953857,
      "learning_rate": 3.9273669747689235e-05,
      "loss": 0.8565,
      "step": 34850
    },
    {
      "epoch": 2.17,
      "grad_norm": 8.855181694030762,
      "learning_rate": 3.927054708968274e-05,
      "loss": 0.8732,
      "step": 34860
    },
    {
      "epoch": 2.17,
      "grad_norm": 10.685189247131348,
      "learning_rate": 3.926742443167625e-05,
      "loss": 1.0134,
      "step": 34870
    },
    {
      "epoch": 2.17,
      "grad_norm": 12.113517761230469,
      "learning_rate": 3.926430177366975e-05,
      "loss": 0.9588,
      "step": 34880
    },
    {
      "epoch": 2.17,
      "grad_norm": 11.784873962402344,
      "learning_rate": 3.9261179115663256e-05,
      "loss": 0.9814,
      "step": 34890
    },
    {
      "epoch": 2.17,
      "grad_norm": 14.214582443237305,
      "learning_rate": 3.925805645765676e-05,
      "loss": 0.9915,
      "step": 34900
    },
    {
      "epoch": 2.17,
      "grad_norm": 9.51725959777832,
      "learning_rate": 3.925493379965026e-05,
      "loss": 0.9395,
      "step": 34910
    },
    {
      "epoch": 2.17,
      "grad_norm": 16.978229522705078,
      "learning_rate": 3.925181114164377e-05,
      "loss": 0.9644,
      "step": 34920
    },
    {
      "epoch": 2.17,
      "grad_norm": 13.069697380065918,
      "learning_rate": 3.9248688483637276e-05,
      "loss": 0.9001,
      "step": 34930
    },
    {
      "epoch": 2.18,
      "grad_norm": 14.686964988708496,
      "learning_rate": 3.924556582563078e-05,
      "loss": 0.9567,
      "step": 34940
    },
    {
      "epoch": 2.18,
      "grad_norm": 10.860160827636719,
      "learning_rate": 3.924244316762428e-05,
      "loss": 0.9255,
      "step": 34950
    },
    {
      "epoch": 2.18,
      "grad_norm": 9.291914939880371,
      "learning_rate": 3.923932050961779e-05,
      "loss": 0.7992,
      "step": 34960
    },
    {
      "epoch": 2.18,
      "grad_norm": 8.605788230895996,
      "learning_rate": 3.9236197851611297e-05,
      "loss": 0.9536,
      "step": 34970
    },
    {
      "epoch": 2.18,
      "grad_norm": 16.405473709106445,
      "learning_rate": 3.9233075193604797e-05,
      "loss": 1.0276,
      "step": 34980
    },
    {
      "epoch": 2.18,
      "grad_norm": 10.389277458190918,
      "learning_rate": 3.92299525355983e-05,
      "loss": 1.101,
      "step": 34990
    },
    {
      "epoch": 2.18,
      "grad_norm": 9.276790618896484,
      "learning_rate": 3.922682987759181e-05,
      "loss": 0.9446,
      "step": 35000
    },
    {
      "epoch": 2.18,
      "grad_norm": 7.630592346191406,
      "learning_rate": 3.922370721958532e-05,
      "loss": 1.0167,
      "step": 35010
    },
    {
      "epoch": 2.18,
      "grad_norm": 11.08318042755127,
      "learning_rate": 3.922058456157882e-05,
      "loss": 0.9752,
      "step": 35020
    },
    {
      "epoch": 2.18,
      "grad_norm": 7.401177406311035,
      "learning_rate": 3.9217461903572324e-05,
      "loss": 0.9074,
      "step": 35030
    },
    {
      "epoch": 2.18,
      "grad_norm": 9.562548637390137,
      "learning_rate": 3.921433924556583e-05,
      "loss": 0.9836,
      "step": 35040
    },
    {
      "epoch": 2.18,
      "grad_norm": 12.47355842590332,
      "learning_rate": 3.921121658755934e-05,
      "loss": 0.993,
      "step": 35050
    },
    {
      "epoch": 2.18,
      "grad_norm": 11.705482482910156,
      "learning_rate": 3.920809392955284e-05,
      "loss": 0.9685,
      "step": 35060
    },
    {
      "epoch": 2.18,
      "grad_norm": 6.471365928649902,
      "learning_rate": 3.9204971271546344e-05,
      "loss": 0.9486,
      "step": 35070
    },
    {
      "epoch": 2.18,
      "grad_norm": 13.270581245422363,
      "learning_rate": 3.920184861353985e-05,
      "loss": 0.9601,
      "step": 35080
    },
    {
      "epoch": 2.18,
      "grad_norm": 7.807347774505615,
      "learning_rate": 3.919872595553335e-05,
      "loss": 0.9806,
      "step": 35090
    },
    {
      "epoch": 2.19,
      "grad_norm": 9.635931015014648,
      "learning_rate": 3.919560329752686e-05,
      "loss": 0.9481,
      "step": 35100
    },
    {
      "epoch": 2.19,
      "grad_norm": 12.069170951843262,
      "learning_rate": 3.9192480639520365e-05,
      "loss": 0.8983,
      "step": 35110
    },
    {
      "epoch": 2.19,
      "grad_norm": 10.048856735229492,
      "learning_rate": 3.918935798151387e-05,
      "loss": 0.9744,
      "step": 35120
    },
    {
      "epoch": 2.19,
      "grad_norm": 10.744630813598633,
      "learning_rate": 3.918623532350737e-05,
      "loss": 1.0245,
      "step": 35130
    },
    {
      "epoch": 2.19,
      "grad_norm": 15.165785789489746,
      "learning_rate": 3.918311266550088e-05,
      "loss": 1.0722,
      "step": 35140
    },
    {
      "epoch": 2.19,
      "grad_norm": 10.134316444396973,
      "learning_rate": 3.9179990007494385e-05,
      "loss": 0.9643,
      "step": 35150
    },
    {
      "epoch": 2.19,
      "grad_norm": 12.140454292297363,
      "learning_rate": 3.9176867349487885e-05,
      "loss": 1.0066,
      "step": 35160
    },
    {
      "epoch": 2.19,
      "grad_norm": 11.215799331665039,
      "learning_rate": 3.917374469148139e-05,
      "loss": 0.874,
      "step": 35170
    },
    {
      "epoch": 2.19,
      "grad_norm": 8.8158597946167,
      "learning_rate": 3.91706220334749e-05,
      "loss": 0.9526,
      "step": 35180
    },
    {
      "epoch": 2.19,
      "grad_norm": 8.21320629119873,
      "learning_rate": 3.9167499375468406e-05,
      "loss": 0.9873,
      "step": 35190
    },
    {
      "epoch": 2.19,
      "grad_norm": 19.16503143310547,
      "learning_rate": 3.9164376717461906e-05,
      "loss": 0.8895,
      "step": 35200
    },
    {
      "epoch": 2.19,
      "grad_norm": 12.026265144348145,
      "learning_rate": 3.916125405945541e-05,
      "loss": 0.9044,
      "step": 35210
    },
    {
      "epoch": 2.19,
      "grad_norm": 13.721312522888184,
      "learning_rate": 3.915813140144892e-05,
      "loss": 0.9286,
      "step": 35220
    },
    {
      "epoch": 2.19,
      "grad_norm": 10.773457527160645,
      "learning_rate": 3.915500874344242e-05,
      "loss": 0.9281,
      "step": 35230
    },
    {
      "epoch": 2.19,
      "grad_norm": 12.795297622680664,
      "learning_rate": 3.9151886085435926e-05,
      "loss": 0.9815,
      "step": 35240
    },
    {
      "epoch": 2.19,
      "grad_norm": 9.115944862365723,
      "learning_rate": 3.914876342742943e-05,
      "loss": 0.8262,
      "step": 35250
    },
    {
      "epoch": 2.2,
      "grad_norm": 10.241606712341309,
      "learning_rate": 3.914564076942294e-05,
      "loss": 0.9561,
      "step": 35260
    },
    {
      "epoch": 2.2,
      "grad_norm": 13.008254051208496,
      "learning_rate": 3.914251811141644e-05,
      "loss": 1.0287,
      "step": 35270
    },
    {
      "epoch": 2.2,
      "grad_norm": 11.539776802062988,
      "learning_rate": 3.9139395453409947e-05,
      "loss": 0.9455,
      "step": 35280
    },
    {
      "epoch": 2.2,
      "grad_norm": 11.185090065002441,
      "learning_rate": 3.913627279540345e-05,
      "loss": 0.945,
      "step": 35290
    },
    {
      "epoch": 2.2,
      "grad_norm": 11.123217582702637,
      "learning_rate": 3.913315013739695e-05,
      "loss": 1.1354,
      "step": 35300
    },
    {
      "epoch": 2.2,
      "grad_norm": 10.487441062927246,
      "learning_rate": 3.913002747939046e-05,
      "loss": 0.8888,
      "step": 35310
    },
    {
      "epoch": 2.2,
      "grad_norm": 17.20446014404297,
      "learning_rate": 3.912690482138397e-05,
      "loss": 0.832,
      "step": 35320
    },
    {
      "epoch": 2.2,
      "grad_norm": 9.02760124206543,
      "learning_rate": 3.912378216337747e-05,
      "loss": 1.0612,
      "step": 35330
    },
    {
      "epoch": 2.2,
      "grad_norm": 9.739546775817871,
      "learning_rate": 3.9120659505370974e-05,
      "loss": 1.014,
      "step": 35340
    },
    {
      "epoch": 2.2,
      "grad_norm": 12.689715385437012,
      "learning_rate": 3.911753684736448e-05,
      "loss": 1.0595,
      "step": 35350
    },
    {
      "epoch": 2.2,
      "grad_norm": 11.94592571258545,
      "learning_rate": 3.911441418935799e-05,
      "loss": 0.8236,
      "step": 35360
    },
    {
      "epoch": 2.2,
      "grad_norm": 9.000870704650879,
      "learning_rate": 3.911129153135149e-05,
      "loss": 0.9709,
      "step": 35370
    },
    {
      "epoch": 2.2,
      "grad_norm": 10.266287803649902,
      "learning_rate": 3.9108168873344994e-05,
      "loss": 0.8813,
      "step": 35380
    },
    {
      "epoch": 2.2,
      "grad_norm": 15.292987823486328,
      "learning_rate": 3.91050462153385e-05,
      "loss": 0.8774,
      "step": 35390
    },
    {
      "epoch": 2.2,
      "grad_norm": 13.770797729492188,
      "learning_rate": 3.9101923557332e-05,
      "loss": 1.0014,
      "step": 35400
    },
    {
      "epoch": 2.2,
      "grad_norm": 9.39171314239502,
      "learning_rate": 3.909880089932551e-05,
      "loss": 0.8705,
      "step": 35410
    },
    {
      "epoch": 2.21,
      "grad_norm": 10.398990631103516,
      "learning_rate": 3.9095678241319015e-05,
      "loss": 0.9375,
      "step": 35420
    },
    {
      "epoch": 2.21,
      "grad_norm": 9.352910995483398,
      "learning_rate": 3.9092555583312515e-05,
      "loss": 0.9928,
      "step": 35430
    },
    {
      "epoch": 2.21,
      "grad_norm": 17.003812789916992,
      "learning_rate": 3.908943292530602e-05,
      "loss": 1.1229,
      "step": 35440
    },
    {
      "epoch": 2.21,
      "grad_norm": 8.431013107299805,
      "learning_rate": 3.908631026729953e-05,
      "loss": 0.9575,
      "step": 35450
    },
    {
      "epoch": 2.21,
      "grad_norm": 9.67617130279541,
      "learning_rate": 3.908318760929303e-05,
      "loss": 1.0068,
      "step": 35460
    },
    {
      "epoch": 2.21,
      "grad_norm": 13.353803634643555,
      "learning_rate": 3.9080064951286535e-05,
      "loss": 1.0248,
      "step": 35470
    },
    {
      "epoch": 2.21,
      "grad_norm": 12.842033386230469,
      "learning_rate": 3.907694229328004e-05,
      "loss": 0.9935,
      "step": 35480
    },
    {
      "epoch": 2.21,
      "grad_norm": 7.622885227203369,
      "learning_rate": 3.907381963527354e-05,
      "loss": 0.8882,
      "step": 35490
    },
    {
      "epoch": 2.21,
      "grad_norm": 8.548160552978516,
      "learning_rate": 3.907069697726705e-05,
      "loss": 0.8952,
      "step": 35500
    },
    {
      "epoch": 2.21,
      "grad_norm": 11.88526725769043,
      "learning_rate": 3.9067574319260556e-05,
      "loss": 0.9105,
      "step": 35510
    },
    {
      "epoch": 2.21,
      "grad_norm": 15.77983283996582,
      "learning_rate": 3.9064451661254056e-05,
      "loss": 1.0304,
      "step": 35520
    },
    {
      "epoch": 2.21,
      "grad_norm": 19.774824142456055,
      "learning_rate": 3.906132900324756e-05,
      "loss": 0.9619,
      "step": 35530
    },
    {
      "epoch": 2.21,
      "grad_norm": 12.792145729064941,
      "learning_rate": 3.905820634524107e-05,
      "loss": 0.9891,
      "step": 35540
    },
    {
      "epoch": 2.21,
      "grad_norm": 11.841286659240723,
      "learning_rate": 3.9055083687234576e-05,
      "loss": 0.88,
      "step": 35550
    },
    {
      "epoch": 2.21,
      "grad_norm": 7.310885429382324,
      "learning_rate": 3.9051961029228076e-05,
      "loss": 1.0145,
      "step": 35560
    },
    {
      "epoch": 2.21,
      "grad_norm": 12.181077003479004,
      "learning_rate": 3.904883837122158e-05,
      "loss": 1.0408,
      "step": 35570
    },
    {
      "epoch": 2.22,
      "grad_norm": 9.667537689208984,
      "learning_rate": 3.904571571321509e-05,
      "loss": 0.9465,
      "step": 35580
    },
    {
      "epoch": 2.22,
      "grad_norm": 13.204558372497559,
      "learning_rate": 3.904259305520859e-05,
      "loss": 0.8863,
      "step": 35590
    },
    {
      "epoch": 2.22,
      "grad_norm": 12.473257064819336,
      "learning_rate": 3.9039470397202097e-05,
      "loss": 1.0255,
      "step": 35600
    },
    {
      "epoch": 2.22,
      "grad_norm": 17.271543502807617,
      "learning_rate": 3.90363477391956e-05,
      "loss": 1.0971,
      "step": 35610
    },
    {
      "epoch": 2.22,
      "grad_norm": 14.901105880737305,
      "learning_rate": 3.903322508118911e-05,
      "loss": 0.8746,
      "step": 35620
    },
    {
      "epoch": 2.22,
      "grad_norm": 10.286293983459473,
      "learning_rate": 3.903010242318261e-05,
      "loss": 0.9242,
      "step": 35630
    },
    {
      "epoch": 2.22,
      "grad_norm": 8.942526817321777,
      "learning_rate": 3.902697976517612e-05,
      "loss": 0.8998,
      "step": 35640
    },
    {
      "epoch": 2.22,
      "grad_norm": 7.172992706298828,
      "learning_rate": 3.9023857107169624e-05,
      "loss": 0.91,
      "step": 35650
    },
    {
      "epoch": 2.22,
      "grad_norm": 11.426563262939453,
      "learning_rate": 3.902073444916313e-05,
      "loss": 1.0907,
      "step": 35660
    },
    {
      "epoch": 2.22,
      "grad_norm": 11.345118522644043,
      "learning_rate": 3.901761179115663e-05,
      "loss": 0.8501,
      "step": 35670
    },
    {
      "epoch": 2.22,
      "grad_norm": 9.213621139526367,
      "learning_rate": 3.901448913315014e-05,
      "loss": 0.9533,
      "step": 35680
    },
    {
      "epoch": 2.22,
      "grad_norm": 9.603803634643555,
      "learning_rate": 3.9011366475143644e-05,
      "loss": 0.9138,
      "step": 35690
    },
    {
      "epoch": 2.22,
      "grad_norm": 8.940028190612793,
      "learning_rate": 3.9008243817137144e-05,
      "loss": 0.9254,
      "step": 35700
    },
    {
      "epoch": 2.22,
      "grad_norm": 10.938557624816895,
      "learning_rate": 3.900512115913065e-05,
      "loss": 1.0582,
      "step": 35710
    },
    {
      "epoch": 2.22,
      "grad_norm": 10.97323226928711,
      "learning_rate": 3.900199850112416e-05,
      "loss": 0.9486,
      "step": 35720
    },
    {
      "epoch": 2.22,
      "grad_norm": 8.973730087280273,
      "learning_rate": 3.8998875843117665e-05,
      "loss": 0.9574,
      "step": 35730
    },
    {
      "epoch": 2.23,
      "grad_norm": 11.114324569702148,
      "learning_rate": 3.8995753185111165e-05,
      "loss": 0.9745,
      "step": 35740
    },
    {
      "epoch": 2.23,
      "grad_norm": 11.706839561462402,
      "learning_rate": 3.899263052710467e-05,
      "loss": 0.8901,
      "step": 35750
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.582472801208496,
      "learning_rate": 3.898950786909818e-05,
      "loss": 0.9409,
      "step": 35760
    },
    {
      "epoch": 2.23,
      "grad_norm": 12.452085494995117,
      "learning_rate": 3.898638521109168e-05,
      "loss": 1.0253,
      "step": 35770
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.735420227050781,
      "learning_rate": 3.8983262553085185e-05,
      "loss": 0.9837,
      "step": 35780
    },
    {
      "epoch": 2.23,
      "grad_norm": 9.42928695678711,
      "learning_rate": 3.898013989507869e-05,
      "loss": 0.8886,
      "step": 35790
    },
    {
      "epoch": 2.23,
      "grad_norm": 13.778857231140137,
      "learning_rate": 3.89770172370722e-05,
      "loss": 0.9627,
      "step": 35800
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.75706958770752,
      "learning_rate": 3.89738945790657e-05,
      "loss": 1.082,
      "step": 35810
    },
    {
      "epoch": 2.23,
      "grad_norm": 11.273160934448242,
      "learning_rate": 3.8970771921059206e-05,
      "loss": 0.9669,
      "step": 35820
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.83608341217041,
      "learning_rate": 3.896764926305271e-05,
      "loss": 0.9597,
      "step": 35830
    },
    {
      "epoch": 2.23,
      "grad_norm": 12.208744049072266,
      "learning_rate": 3.896452660504622e-05,
      "loss": 0.9684,
      "step": 35840
    },
    {
      "epoch": 2.23,
      "grad_norm": 14.607172012329102,
      "learning_rate": 3.896140394703972e-05,
      "loss": 0.905,
      "step": 35850
    },
    {
      "epoch": 2.23,
      "grad_norm": 12.232610702514648,
      "learning_rate": 3.8958281289033226e-05,
      "loss": 1.0345,
      "step": 35860
    },
    {
      "epoch": 2.23,
      "grad_norm": 14.607450485229492,
      "learning_rate": 3.895515863102673e-05,
      "loss": 1.1163,
      "step": 35870
    },
    {
      "epoch": 2.23,
      "grad_norm": 10.47677993774414,
      "learning_rate": 3.895203597302023e-05,
      "loss": 0.8721,
      "step": 35880
    },
    {
      "epoch": 2.23,
      "grad_norm": 8.930818557739258,
      "learning_rate": 3.894891331501374e-05,
      "loss": 0.9925,
      "step": 35890
    },
    {
      "epoch": 2.24,
      "grad_norm": 9.820505142211914,
      "learning_rate": 3.8945790657007247e-05,
      "loss": 0.8796,
      "step": 35900
    },
    {
      "epoch": 2.24,
      "grad_norm": 7.58588981628418,
      "learning_rate": 3.894266799900075e-05,
      "loss": 0.9483,
      "step": 35910
    },
    {
      "epoch": 2.24,
      "grad_norm": 10.812275886535645,
      "learning_rate": 3.8939545340994253e-05,
      "loss": 0.965,
      "step": 35920
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.30448579788208,
      "learning_rate": 3.893642268298776e-05,
      "loss": 0.8468,
      "step": 35930
    },
    {
      "epoch": 2.24,
      "grad_norm": 14.187880516052246,
      "learning_rate": 3.893330002498127e-05,
      "loss": 0.9318,
      "step": 35940
    },
    {
      "epoch": 2.24,
      "grad_norm": 11.108755111694336,
      "learning_rate": 3.893017736697477e-05,
      "loss": 0.9946,
      "step": 35950
    },
    {
      "epoch": 2.24,
      "grad_norm": 16.02427864074707,
      "learning_rate": 3.8927054708968274e-05,
      "loss": 0.9732,
      "step": 35960
    },
    {
      "epoch": 2.24,
      "grad_norm": 15.822454452514648,
      "learning_rate": 3.892393205096178e-05,
      "loss": 1.0533,
      "step": 35970
    },
    {
      "epoch": 2.24,
      "grad_norm": 8.608529090881348,
      "learning_rate": 3.892080939295529e-05,
      "loss": 0.8752,
      "step": 35980
    },
    {
      "epoch": 2.24,
      "grad_norm": 12.050591468811035,
      "learning_rate": 3.891768673494879e-05,
      "loss": 0.9678,
      "step": 35990
    },
    {
      "epoch": 2.24,
      "grad_norm": 9.86457347869873,
      "learning_rate": 3.8914564076942294e-05,
      "loss": 0.9593,
      "step": 36000
    },
    {
      "epoch": 2.24,
      "grad_norm": 8.851832389831543,
      "learning_rate": 3.89114414189358e-05,
      "loss": 0.8902,
      "step": 36010
    },
    {
      "epoch": 2.24,
      "grad_norm": 20.311134338378906,
      "learning_rate": 3.890831876092931e-05,
      "loss": 1.0226,
      "step": 36020
    },
    {
      "epoch": 2.24,
      "grad_norm": 15.012502670288086,
      "learning_rate": 3.890519610292281e-05,
      "loss": 1.0356,
      "step": 36030
    },
    {
      "epoch": 2.24,
      "grad_norm": 12.28267765045166,
      "learning_rate": 3.8902073444916315e-05,
      "loss": 1.0105,
      "step": 36040
    },
    {
      "epoch": 2.24,
      "grad_norm": 9.19038200378418,
      "learning_rate": 3.889895078690982e-05,
      "loss": 0.9511,
      "step": 36050
    },
    {
      "epoch": 2.25,
      "grad_norm": 8.973297119140625,
      "learning_rate": 3.889582812890332e-05,
      "loss": 0.9602,
      "step": 36060
    },
    {
      "epoch": 2.25,
      "grad_norm": 12.33769416809082,
      "learning_rate": 3.889270547089683e-05,
      "loss": 0.9646,
      "step": 36070
    },
    {
      "epoch": 2.25,
      "grad_norm": 10.17026424407959,
      "learning_rate": 3.8889582812890335e-05,
      "loss": 0.9938,
      "step": 36080
    },
    {
      "epoch": 2.25,
      "grad_norm": 9.74362850189209,
      "learning_rate": 3.888646015488384e-05,
      "loss": 0.9258,
      "step": 36090
    },
    {
      "epoch": 2.25,
      "grad_norm": 9.678190231323242,
      "learning_rate": 3.888333749687734e-05,
      "loss": 0.9208,
      "step": 36100
    },
    {
      "epoch": 2.25,
      "grad_norm": 10.730633735656738,
      "learning_rate": 3.888021483887085e-05,
      "loss": 0.9601,
      "step": 36110
    },
    {
      "epoch": 2.25,
      "grad_norm": 13.744840621948242,
      "learning_rate": 3.8877092180864356e-05,
      "loss": 0.9795,
      "step": 36120
    },
    {
      "epoch": 2.25,
      "grad_norm": 11.12697696685791,
      "learning_rate": 3.8873969522857856e-05,
      "loss": 0.9583,
      "step": 36130
    },
    {
      "epoch": 2.25,
      "grad_norm": 11.33481216430664,
      "learning_rate": 3.887084686485136e-05,
      "loss": 1.0325,
      "step": 36140
    },
    {
      "epoch": 2.25,
      "grad_norm": 11.608757972717285,
      "learning_rate": 3.886772420684487e-05,
      "loss": 0.9656,
      "step": 36150
    },
    {
      "epoch": 2.25,
      "grad_norm": 10.301556587219238,
      "learning_rate": 3.8864601548838376e-05,
      "loss": 1.0909,
      "step": 36160
    },
    {
      "epoch": 2.25,
      "grad_norm": 8.488957405090332,
      "learning_rate": 3.8861478890831876e-05,
      "loss": 1.0714,
      "step": 36170
    },
    {
      "epoch": 2.25,
      "grad_norm": 11.448131561279297,
      "learning_rate": 3.885835623282538e-05,
      "loss": 0.8764,
      "step": 36180
    },
    {
      "epoch": 2.25,
      "grad_norm": 10.582549095153809,
      "learning_rate": 3.885523357481889e-05,
      "loss": 1.1231,
      "step": 36190
    },
    {
      "epoch": 2.25,
      "grad_norm": 12.105289459228516,
      "learning_rate": 3.8852110916812397e-05,
      "loss": 0.9786,
      "step": 36200
    },
    {
      "epoch": 2.25,
      "grad_norm": 7.69342565536499,
      "learning_rate": 3.8848988258805897e-05,
      "loss": 0.8697,
      "step": 36210
    },
    {
      "epoch": 2.26,
      "grad_norm": 10.75528335571289,
      "learning_rate": 3.88458656007994e-05,
      "loss": 0.9274,
      "step": 36220
    },
    {
      "epoch": 2.26,
      "grad_norm": 7.858701229095459,
      "learning_rate": 3.884274294279291e-05,
      "loss": 0.9618,
      "step": 36230
    },
    {
      "epoch": 2.26,
      "grad_norm": 8.896081924438477,
      "learning_rate": 3.883962028478641e-05,
      "loss": 0.956,
      "step": 36240
    },
    {
      "epoch": 2.26,
      "grad_norm": 8.763434410095215,
      "learning_rate": 3.883649762677992e-05,
      "loss": 1.0008,
      "step": 36250
    },
    {
      "epoch": 2.26,
      "grad_norm": 9.608561515808105,
      "learning_rate": 3.8833374968773424e-05,
      "loss": 0.942,
      "step": 36260
    },
    {
      "epoch": 2.26,
      "grad_norm": 14.259650230407715,
      "learning_rate": 3.883025231076693e-05,
      "loss": 1.0062,
      "step": 36270
    },
    {
      "epoch": 2.26,
      "grad_norm": 12.597956657409668,
      "learning_rate": 3.882712965276043e-05,
      "loss": 0.9724,
      "step": 36280
    },
    {
      "epoch": 2.26,
      "grad_norm": 12.958850860595703,
      "learning_rate": 3.882400699475394e-05,
      "loss": 1.0717,
      "step": 36290
    },
    {
      "epoch": 2.26,
      "grad_norm": 8.039216041564941,
      "learning_rate": 3.8820884336747444e-05,
      "loss": 0.9528,
      "step": 36300
    },
    {
      "epoch": 2.26,
      "grad_norm": 13.426382064819336,
      "learning_rate": 3.8817761678740944e-05,
      "loss": 1.1148,
      "step": 36310
    },
    {
      "epoch": 2.26,
      "grad_norm": 9.588080406188965,
      "learning_rate": 3.881463902073445e-05,
      "loss": 0.9543,
      "step": 36320
    },
    {
      "epoch": 2.26,
      "grad_norm": 11.960529327392578,
      "learning_rate": 3.881151636272796e-05,
      "loss": 0.98,
      "step": 36330
    },
    {
      "epoch": 2.26,
      "grad_norm": 12.223709106445312,
      "learning_rate": 3.8808393704721465e-05,
      "loss": 1.0322,
      "step": 36340
    },
    {
      "epoch": 2.26,
      "grad_norm": 14.659862518310547,
      "learning_rate": 3.8805271046714965e-05,
      "loss": 1.0549,
      "step": 36350
    },
    {
      "epoch": 2.26,
      "grad_norm": 7.818958282470703,
      "learning_rate": 3.880214838870847e-05,
      "loss": 0.9289,
      "step": 36360
    },
    {
      "epoch": 2.26,
      "grad_norm": 9.05467700958252,
      "learning_rate": 3.879902573070198e-05,
      "loss": 1.0378,
      "step": 36370
    },
    {
      "epoch": 2.26,
      "grad_norm": 6.9346137046813965,
      "learning_rate": 3.879590307269548e-05,
      "loss": 1.0503,
      "step": 36380
    },
    {
      "epoch": 2.27,
      "grad_norm": 7.84200382232666,
      "learning_rate": 3.8792780414688985e-05,
      "loss": 0.9997,
      "step": 36390
    },
    {
      "epoch": 2.27,
      "grad_norm": 13.6288480758667,
      "learning_rate": 3.878965775668249e-05,
      "loss": 1.0116,
      "step": 36400
    },
    {
      "epoch": 2.27,
      "grad_norm": 8.005256652832031,
      "learning_rate": 3.8786535098676e-05,
      "loss": 1.0002,
      "step": 36410
    },
    {
      "epoch": 2.27,
      "grad_norm": 14.563302993774414,
      "learning_rate": 3.87834124406695e-05,
      "loss": 0.9204,
      "step": 36420
    },
    {
      "epoch": 2.27,
      "grad_norm": 10.522621154785156,
      "learning_rate": 3.8780289782663006e-05,
      "loss": 0.923,
      "step": 36430
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.299461364746094,
      "learning_rate": 3.877716712465651e-05,
      "loss": 0.897,
      "step": 36440
    },
    {
      "epoch": 2.27,
      "grad_norm": 10.39816665649414,
      "learning_rate": 3.877404446665002e-05,
      "loss": 1.0184,
      "step": 36450
    },
    {
      "epoch": 2.27,
      "grad_norm": 7.409549236297607,
      "learning_rate": 3.877092180864352e-05,
      "loss": 0.9613,
      "step": 36460
    },
    {
      "epoch": 2.27,
      "grad_norm": 10.923566818237305,
      "learning_rate": 3.8767799150637026e-05,
      "loss": 1.0665,
      "step": 36470
    },
    {
      "epoch": 2.27,
      "grad_norm": 13.230963706970215,
      "learning_rate": 3.876467649263053e-05,
      "loss": 0.997,
      "step": 36480
    },
    {
      "epoch": 2.27,
      "grad_norm": 13.56004524230957,
      "learning_rate": 3.876155383462403e-05,
      "loss": 0.9828,
      "step": 36490
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.695420265197754,
      "learning_rate": 3.875843117661754e-05,
      "loss": 1.0158,
      "step": 36500
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.00795841217041,
      "learning_rate": 3.8755308518611047e-05,
      "loss": 1.0607,
      "step": 36510
    },
    {
      "epoch": 2.27,
      "grad_norm": 11.147038459777832,
      "learning_rate": 3.875218586060455e-05,
      "loss": 0.9139,
      "step": 36520
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.901243209838867,
      "learning_rate": 3.8749063202598053e-05,
      "loss": 0.8391,
      "step": 36530
    },
    {
      "epoch": 2.27,
      "grad_norm": 9.674158096313477,
      "learning_rate": 3.874594054459156e-05,
      "loss": 1.013,
      "step": 36540
    },
    {
      "epoch": 2.28,
      "grad_norm": 10.510775566101074,
      "learning_rate": 3.874281788658507e-05,
      "loss": 0.9845,
      "step": 36550
    },
    {
      "epoch": 2.28,
      "grad_norm": 13.251155853271484,
      "learning_rate": 3.873969522857857e-05,
      "loss": 0.9932,
      "step": 36560
    },
    {
      "epoch": 2.28,
      "grad_norm": 8.853309631347656,
      "learning_rate": 3.8736572570572074e-05,
      "loss": 0.9873,
      "step": 36570
    },
    {
      "epoch": 2.28,
      "grad_norm": 12.076472282409668,
      "learning_rate": 3.873344991256558e-05,
      "loss": 0.8468,
      "step": 36580
    },
    {
      "epoch": 2.28,
      "grad_norm": 16.003273010253906,
      "learning_rate": 3.873032725455909e-05,
      "loss": 0.9735,
      "step": 36590
    },
    {
      "epoch": 2.28,
      "grad_norm": 5.581704616546631,
      "learning_rate": 3.872720459655259e-05,
      "loss": 0.9001,
      "step": 36600
    },
    {
      "epoch": 2.28,
      "grad_norm": 8.420724868774414,
      "learning_rate": 3.8724081938546094e-05,
      "loss": 1.0045,
      "step": 36610
    },
    {
      "epoch": 2.28,
      "grad_norm": 13.508744239807129,
      "learning_rate": 3.87209592805396e-05,
      "loss": 0.9983,
      "step": 36620
    },
    {
      "epoch": 2.28,
      "grad_norm": 16.231090545654297,
      "learning_rate": 3.871783662253311e-05,
      "loss": 0.9849,
      "step": 36630
    },
    {
      "epoch": 2.28,
      "grad_norm": 10.874719619750977,
      "learning_rate": 3.871471396452661e-05,
      "loss": 0.9448,
      "step": 36640
    },
    {
      "epoch": 2.28,
      "grad_norm": 12.908809661865234,
      "learning_rate": 3.8711591306520115e-05,
      "loss": 1.1123,
      "step": 36650
    },
    {
      "epoch": 2.28,
      "grad_norm": 10.380318641662598,
      "learning_rate": 3.870846864851362e-05,
      "loss": 0.929,
      "step": 36660
    },
    {
      "epoch": 2.28,
      "grad_norm": 11.75063419342041,
      "learning_rate": 3.870534599050712e-05,
      "loss": 1.0654,
      "step": 36670
    },
    {
      "epoch": 2.28,
      "grad_norm": 8.965432167053223,
      "learning_rate": 3.870222333250063e-05,
      "loss": 0.9751,
      "step": 36680
    },
    {
      "epoch": 2.28,
      "grad_norm": 8.345535278320312,
      "learning_rate": 3.8699100674494135e-05,
      "loss": 1.0048,
      "step": 36690
    },
    {
      "epoch": 2.28,
      "grad_norm": 7.822111129760742,
      "learning_rate": 3.8695978016487635e-05,
      "loss": 0.9599,
      "step": 36700
    },
    {
      "epoch": 2.29,
      "grad_norm": 16.023788452148438,
      "learning_rate": 3.869285535848114e-05,
      "loss": 1.123,
      "step": 36710
    },
    {
      "epoch": 2.29,
      "grad_norm": 13.263774871826172,
      "learning_rate": 3.868973270047465e-05,
      "loss": 1.0176,
      "step": 36720
    },
    {
      "epoch": 2.29,
      "grad_norm": 8.69388484954834,
      "learning_rate": 3.868661004246815e-05,
      "loss": 1.0002,
      "step": 36730
    },
    {
      "epoch": 2.29,
      "grad_norm": 12.48392391204834,
      "learning_rate": 3.8683487384461656e-05,
      "loss": 0.9618,
      "step": 36740
    },
    {
      "epoch": 2.29,
      "grad_norm": 10.632101058959961,
      "learning_rate": 3.868036472645516e-05,
      "loss": 0.9351,
      "step": 36750
    },
    {
      "epoch": 2.29,
      "grad_norm": 9.846927642822266,
      "learning_rate": 3.867724206844866e-05,
      "loss": 1.0424,
      "step": 36760
    },
    {
      "epoch": 2.29,
      "grad_norm": 6.957947254180908,
      "learning_rate": 3.867411941044217e-05,
      "loss": 0.9582,
      "step": 36770
    },
    {
      "epoch": 2.29,
      "grad_norm": 12.231313705444336,
      "learning_rate": 3.8670996752435676e-05,
      "loss": 1.0451,
      "step": 36780
    },
    {
      "epoch": 2.29,
      "grad_norm": 13.198702812194824,
      "learning_rate": 3.8667874094429176e-05,
      "loss": 0.9804,
      "step": 36790
    },
    {
      "epoch": 2.29,
      "grad_norm": 8.10938549041748,
      "learning_rate": 3.866475143642268e-05,
      "loss": 0.8431,
      "step": 36800
    },
    {
      "epoch": 2.29,
      "grad_norm": 10.871583938598633,
      "learning_rate": 3.866162877841619e-05,
      "loss": 1.0706,
      "step": 36810
    },
    {
      "epoch": 2.29,
      "grad_norm": 11.742256164550781,
      "learning_rate": 3.8658506120409697e-05,
      "loss": 1.0977,
      "step": 36820
    },
    {
      "epoch": 2.29,
      "grad_norm": 12.509836196899414,
      "learning_rate": 3.8655383462403197e-05,
      "loss": 0.9852,
      "step": 36830
    },
    {
      "epoch": 2.29,
      "grad_norm": 8.566596031188965,
      "learning_rate": 3.8652260804396703e-05,
      "loss": 0.9566,
      "step": 36840
    },
    {
      "epoch": 2.29,
      "grad_norm": 11.850958824157715,
      "learning_rate": 3.864913814639021e-05,
      "loss": 0.9663,
      "step": 36850
    },
    {
      "epoch": 2.29,
      "grad_norm": 9.53205680847168,
      "learning_rate": 3.864601548838371e-05,
      "loss": 0.9319,
      "step": 36860
    },
    {
      "epoch": 2.3,
      "grad_norm": 9.442461967468262,
      "learning_rate": 3.864289283037722e-05,
      "loss": 0.9024,
      "step": 36870
    },
    {
      "epoch": 2.3,
      "grad_norm": 22.829374313354492,
      "learning_rate": 3.8639770172370724e-05,
      "loss": 0.9648,
      "step": 36880
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.08291244506836,
      "learning_rate": 3.8636647514364224e-05,
      "loss": 1.0221,
      "step": 36890
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.06307601928711,
      "learning_rate": 3.863352485635773e-05,
      "loss": 1.0114,
      "step": 36900
    },
    {
      "epoch": 2.3,
      "grad_norm": 6.687790393829346,
      "learning_rate": 3.863040219835124e-05,
      "loss": 0.9506,
      "step": 36910
    },
    {
      "epoch": 2.3,
      "grad_norm": 11.09647274017334,
      "learning_rate": 3.862727954034474e-05,
      "loss": 0.9042,
      "step": 36920
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.361054420471191,
      "learning_rate": 3.8624156882338244e-05,
      "loss": 1.1222,
      "step": 36930
    },
    {
      "epoch": 2.3,
      "grad_norm": 6.781146049499512,
      "learning_rate": 3.862103422433175e-05,
      "loss": 0.9318,
      "step": 36940
    },
    {
      "epoch": 2.3,
      "grad_norm": 9.109055519104004,
      "learning_rate": 3.861791156632526e-05,
      "loss": 0.8897,
      "step": 36950
    },
    {
      "epoch": 2.3,
      "grad_norm": 14.698562622070312,
      "learning_rate": 3.861478890831876e-05,
      "loss": 0.9426,
      "step": 36960
    },
    {
      "epoch": 2.3,
      "grad_norm": 12.672518730163574,
      "learning_rate": 3.8611666250312265e-05,
      "loss": 0.9087,
      "step": 36970
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.867524147033691,
      "learning_rate": 3.860854359230577e-05,
      "loss": 1.0405,
      "step": 36980
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.697135925292969,
      "learning_rate": 3.860542093429928e-05,
      "loss": 0.9862,
      "step": 36990
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.529868125915527,
      "learning_rate": 3.860229827629278e-05,
      "loss": 0.9993,
      "step": 37000
    },
    {
      "epoch": 2.3,
      "grad_norm": 14.60083293914795,
      "learning_rate": 3.8599175618286285e-05,
      "loss": 1.0248,
      "step": 37010
    },
    {
      "epoch": 2.3,
      "grad_norm": 18.32086753845215,
      "learning_rate": 3.859605296027979e-05,
      "loss": 1.0534,
      "step": 37020
    },
    {
      "epoch": 2.31,
      "grad_norm": 10.654779434204102,
      "learning_rate": 3.859293030227329e-05,
      "loss": 1.0154,
      "step": 37030
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.532121658325195,
      "learning_rate": 3.85898076442668e-05,
      "loss": 1.0327,
      "step": 37040
    },
    {
      "epoch": 2.31,
      "grad_norm": 11.110847473144531,
      "learning_rate": 3.8586684986260306e-05,
      "loss": 1.0273,
      "step": 37050
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.667407035827637,
      "learning_rate": 3.858356232825381e-05,
      "loss": 0.911,
      "step": 37060
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.05471420288086,
      "learning_rate": 3.858043967024731e-05,
      "loss": 0.9543,
      "step": 37070
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.697090148925781,
      "learning_rate": 3.857731701224082e-05,
      "loss": 1.029,
      "step": 37080
    },
    {
      "epoch": 2.31,
      "grad_norm": 11.112993240356445,
      "learning_rate": 3.8574194354234326e-05,
      "loss": 1.0282,
      "step": 37090
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.865066528320312,
      "learning_rate": 3.8571071696227826e-05,
      "loss": 1.008,
      "step": 37100
    },
    {
      "epoch": 2.31,
      "grad_norm": 13.527832984924316,
      "learning_rate": 3.856794903822133e-05,
      "loss": 0.8758,
      "step": 37110
    },
    {
      "epoch": 2.31,
      "grad_norm": 7.276375770568848,
      "learning_rate": 3.856482638021484e-05,
      "loss": 0.912,
      "step": 37120
    },
    {
      "epoch": 2.31,
      "grad_norm": 9.317765235900879,
      "learning_rate": 3.8561703722208347e-05,
      "loss": 0.9346,
      "step": 37130
    },
    {
      "epoch": 2.31,
      "grad_norm": 22.63779067993164,
      "learning_rate": 3.855858106420185e-05,
      "loss": 1.0415,
      "step": 37140
    },
    {
      "epoch": 2.31,
      "grad_norm": 8.655106544494629,
      "learning_rate": 3.8555458406195353e-05,
      "loss": 0.8474,
      "step": 37150
    },
    {
      "epoch": 2.31,
      "grad_norm": 17.510997772216797,
      "learning_rate": 3.855233574818886e-05,
      "loss": 1.0833,
      "step": 37160
    },
    {
      "epoch": 2.31,
      "grad_norm": 9.925509452819824,
      "learning_rate": 3.854921309018237e-05,
      "loss": 0.9297,
      "step": 37170
    },
    {
      "epoch": 2.31,
      "grad_norm": 9.356637001037598,
      "learning_rate": 3.854609043217587e-05,
      "loss": 0.9851,
      "step": 37180
    },
    {
      "epoch": 2.32,
      "grad_norm": 12.490924835205078,
      "learning_rate": 3.8542967774169374e-05,
      "loss": 1.0645,
      "step": 37190
    },
    {
      "epoch": 2.32,
      "grad_norm": 10.034598350524902,
      "learning_rate": 3.853984511616288e-05,
      "loss": 0.989,
      "step": 37200
    },
    {
      "epoch": 2.32,
      "grad_norm": 8.236750602722168,
      "learning_rate": 3.853672245815638e-05,
      "loss": 0.9603,
      "step": 37210
    },
    {
      "epoch": 2.32,
      "grad_norm": 10.525484085083008,
      "learning_rate": 3.853359980014989e-05,
      "loss": 0.9911,
      "step": 37220
    },
    {
      "epoch": 2.32,
      "grad_norm": 14.564477920532227,
      "learning_rate": 3.8530477142143394e-05,
      "loss": 0.9675,
      "step": 37230
    },
    {
      "epoch": 2.32,
      "grad_norm": 12.521455764770508,
      "learning_rate": 3.85273544841369e-05,
      "loss": 0.9258,
      "step": 37240
    },
    {
      "epoch": 2.32,
      "grad_norm": 11.554253578186035,
      "learning_rate": 3.85242318261304e-05,
      "loss": 0.8977,
      "step": 37250
    },
    {
      "epoch": 2.32,
      "grad_norm": 15.131412506103516,
      "learning_rate": 3.852110916812391e-05,
      "loss": 1.0102,
      "step": 37260
    },
    {
      "epoch": 2.32,
      "grad_norm": 15.459673881530762,
      "learning_rate": 3.8517986510117415e-05,
      "loss": 1.1087,
      "step": 37270
    },
    {
      "epoch": 2.32,
      "grad_norm": 8.690804481506348,
      "learning_rate": 3.8514863852110915e-05,
      "loss": 1.0986,
      "step": 37280
    },
    {
      "epoch": 2.32,
      "grad_norm": 11.76205062866211,
      "learning_rate": 3.851174119410442e-05,
      "loss": 0.9549,
      "step": 37290
    },
    {
      "epoch": 2.32,
      "grad_norm": 10.27025318145752,
      "learning_rate": 3.850861853609793e-05,
      "loss": 0.9857,
      "step": 37300
    },
    {
      "epoch": 2.32,
      "grad_norm": 14.143631935119629,
      "learning_rate": 3.8505495878091435e-05,
      "loss": 0.9543,
      "step": 37310
    },
    {
      "epoch": 2.32,
      "grad_norm": 10.006418228149414,
      "learning_rate": 3.8502373220084935e-05,
      "loss": 1.0008,
      "step": 37320
    },
    {
      "epoch": 2.32,
      "grad_norm": 8.956402778625488,
      "learning_rate": 3.849925056207844e-05,
      "loss": 1.0116,
      "step": 37330
    },
    {
      "epoch": 2.32,
      "grad_norm": 13.78866195678711,
      "learning_rate": 3.849612790407195e-05,
      "loss": 0.9617,
      "step": 37340
    },
    {
      "epoch": 2.33,
      "grad_norm": 9.84256649017334,
      "learning_rate": 3.849300524606545e-05,
      "loss": 0.86,
      "step": 37350
    },
    {
      "epoch": 2.33,
      "grad_norm": 9.348043441772461,
      "learning_rate": 3.8489882588058956e-05,
      "loss": 1.0633,
      "step": 37360
    },
    {
      "epoch": 2.33,
      "grad_norm": 10.844382286071777,
      "learning_rate": 3.848675993005246e-05,
      "loss": 0.9402,
      "step": 37370
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.908493995666504,
      "learning_rate": 3.848363727204597e-05,
      "loss": 0.9253,
      "step": 37380
    },
    {
      "epoch": 2.33,
      "grad_norm": 14.860551834106445,
      "learning_rate": 3.848051461403947e-05,
      "loss": 0.9461,
      "step": 37390
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.678568840026855,
      "learning_rate": 3.8477391956032976e-05,
      "loss": 1.108,
      "step": 37400
    },
    {
      "epoch": 2.33,
      "grad_norm": 8.527726173400879,
      "learning_rate": 3.847426929802648e-05,
      "loss": 1.0045,
      "step": 37410
    },
    {
      "epoch": 2.33,
      "grad_norm": 13.998490333557129,
      "learning_rate": 3.847114664001999e-05,
      "loss": 1.0112,
      "step": 37420
    },
    {
      "epoch": 2.33,
      "grad_norm": 7.288351535797119,
      "learning_rate": 3.846802398201349e-05,
      "loss": 0.9145,
      "step": 37430
    },
    {
      "epoch": 2.33,
      "grad_norm": 10.724761009216309,
      "learning_rate": 3.8464901324006997e-05,
      "loss": 1.0868,
      "step": 37440
    },
    {
      "epoch": 2.33,
      "grad_norm": 8.229022979736328,
      "learning_rate": 3.8461778666000503e-05,
      "loss": 0.833,
      "step": 37450
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.808921813964844,
      "learning_rate": 3.8458656007994003e-05,
      "loss": 0.9395,
      "step": 37460
    },
    {
      "epoch": 2.33,
      "grad_norm": 12.281257629394531,
      "learning_rate": 3.845553334998751e-05,
      "loss": 1.0818,
      "step": 37470
    },
    {
      "epoch": 2.33,
      "grad_norm": 10.161493301391602,
      "learning_rate": 3.845241069198102e-05,
      "loss": 0.9601,
      "step": 37480
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.549586296081543,
      "learning_rate": 3.8449288033974524e-05,
      "loss": 1.0205,
      "step": 37490
    },
    {
      "epoch": 2.33,
      "grad_norm": 11.515607833862305,
      "learning_rate": 3.8446165375968024e-05,
      "loss": 0.9636,
      "step": 37500
    },
    {
      "epoch": 2.34,
      "grad_norm": 10.466939926147461,
      "learning_rate": 3.844304271796153e-05,
      "loss": 0.8648,
      "step": 37510
    },
    {
      "epoch": 2.34,
      "grad_norm": 10.108506202697754,
      "learning_rate": 3.843992005995504e-05,
      "loss": 0.9821,
      "step": 37520
    },
    {
      "epoch": 2.34,
      "grad_norm": 13.481550216674805,
      "learning_rate": 3.843679740194854e-05,
      "loss": 0.9298,
      "step": 37530
    },
    {
      "epoch": 2.34,
      "grad_norm": 13.964456558227539,
      "learning_rate": 3.8433674743942044e-05,
      "loss": 0.9173,
      "step": 37540
    },
    {
      "epoch": 2.34,
      "grad_norm": 10.52627944946289,
      "learning_rate": 3.843055208593555e-05,
      "loss": 0.919,
      "step": 37550
    },
    {
      "epoch": 2.34,
      "grad_norm": 11.714581489562988,
      "learning_rate": 3.842742942792906e-05,
      "loss": 1.0895,
      "step": 37560
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.244332313537598,
      "learning_rate": 3.842430676992256e-05,
      "loss": 0.9643,
      "step": 37570
    },
    {
      "epoch": 2.34,
      "grad_norm": 14.846198081970215,
      "learning_rate": 3.8421184111916065e-05,
      "loss": 0.9708,
      "step": 37580
    },
    {
      "epoch": 2.34,
      "grad_norm": 10.2326078414917,
      "learning_rate": 3.841806145390957e-05,
      "loss": 0.9465,
      "step": 37590
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.907840728759766,
      "learning_rate": 3.841493879590308e-05,
      "loss": 1.0458,
      "step": 37600
    },
    {
      "epoch": 2.34,
      "grad_norm": 12.97687816619873,
      "learning_rate": 3.841181613789658e-05,
      "loss": 0.9771,
      "step": 37610
    },
    {
      "epoch": 2.34,
      "grad_norm": 8.950495719909668,
      "learning_rate": 3.8408693479890085e-05,
      "loss": 0.9465,
      "step": 37620
    },
    {
      "epoch": 2.34,
      "grad_norm": 13.530076026916504,
      "learning_rate": 3.840557082188359e-05,
      "loss": 1.1394,
      "step": 37630
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.418289184570312,
      "learning_rate": 3.840244816387709e-05,
      "loss": 0.9394,
      "step": 37640
    },
    {
      "epoch": 2.34,
      "grad_norm": 13.036623001098633,
      "learning_rate": 3.83993255058706e-05,
      "loss": 1.0414,
      "step": 37650
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.106208801269531,
      "learning_rate": 3.8396202847864106e-05,
      "loss": 1.0231,
      "step": 37660
    },
    {
      "epoch": 2.35,
      "grad_norm": 8.782283782958984,
      "learning_rate": 3.839308018985761e-05,
      "loss": 0.9237,
      "step": 37670
    },
    {
      "epoch": 2.35,
      "grad_norm": 16.473154067993164,
      "learning_rate": 3.838995753185111e-05,
      "loss": 0.9157,
      "step": 37680
    },
    {
      "epoch": 2.35,
      "grad_norm": 12.707192420959473,
      "learning_rate": 3.838683487384462e-05,
      "loss": 1.0767,
      "step": 37690
    },
    {
      "epoch": 2.35,
      "grad_norm": 11.409317970275879,
      "learning_rate": 3.8383712215838126e-05,
      "loss": 1.0746,
      "step": 37700
    },
    {
      "epoch": 2.35,
      "grad_norm": 12.735909461975098,
      "learning_rate": 3.8380589557831626e-05,
      "loss": 0.918,
      "step": 37710
    },
    {
      "epoch": 2.35,
      "grad_norm": 11.970611572265625,
      "learning_rate": 3.837746689982513e-05,
      "loss": 1.027,
      "step": 37720
    },
    {
      "epoch": 2.35,
      "grad_norm": 9.853402137756348,
      "learning_rate": 3.837434424181864e-05,
      "loss": 0.8771,
      "step": 37730
    },
    {
      "epoch": 2.35,
      "grad_norm": 11.781632423400879,
      "learning_rate": 3.8371221583812147e-05,
      "loss": 1.0318,
      "step": 37740
    },
    {
      "epoch": 2.35,
      "grad_norm": 14.526285171508789,
      "learning_rate": 3.836809892580565e-05,
      "loss": 1.023,
      "step": 37750
    },
    {
      "epoch": 2.35,
      "grad_norm": 14.687151908874512,
      "learning_rate": 3.8364976267799153e-05,
      "loss": 0.9834,
      "step": 37760
    },
    {
      "epoch": 2.35,
      "grad_norm": 11.941786766052246,
      "learning_rate": 3.836185360979266e-05,
      "loss": 0.9697,
      "step": 37770
    },
    {
      "epoch": 2.35,
      "grad_norm": 10.488479614257812,
      "learning_rate": 3.835873095178617e-05,
      "loss": 0.9931,
      "step": 37780
    },
    {
      "epoch": 2.35,
      "grad_norm": 8.10230827331543,
      "learning_rate": 3.835560829377967e-05,
      "loss": 0.9895,
      "step": 37790
    },
    {
      "epoch": 2.35,
      "grad_norm": 13.902464866638184,
      "learning_rate": 3.8352485635773174e-05,
      "loss": 0.9957,
      "step": 37800
    },
    {
      "epoch": 2.35,
      "grad_norm": 9.486969947814941,
      "learning_rate": 3.834936297776668e-05,
      "loss": 0.8744,
      "step": 37810
    },
    {
      "epoch": 2.35,
      "grad_norm": 8.319576263427734,
      "learning_rate": 3.834624031976018e-05,
      "loss": 0.8832,
      "step": 37820
    },
    {
      "epoch": 2.36,
      "grad_norm": 9.95810317993164,
      "learning_rate": 3.834311766175369e-05,
      "loss": 0.8771,
      "step": 37830
    },
    {
      "epoch": 2.36,
      "grad_norm": 17.29616928100586,
      "learning_rate": 3.8339995003747194e-05,
      "loss": 1.0144,
      "step": 37840
    },
    {
      "epoch": 2.36,
      "grad_norm": 9.343497276306152,
      "learning_rate": 3.83368723457407e-05,
      "loss": 0.8289,
      "step": 37850
    },
    {
      "epoch": 2.36,
      "grad_norm": 15.99986457824707,
      "learning_rate": 3.83337496877342e-05,
      "loss": 1.163,
      "step": 37860
    },
    {
      "epoch": 2.36,
      "grad_norm": 13.530644416809082,
      "learning_rate": 3.833062702972771e-05,
      "loss": 1.1413,
      "step": 37870
    },
    {
      "epoch": 2.36,
      "grad_norm": 11.610394477844238,
      "learning_rate": 3.8327504371721215e-05,
      "loss": 0.9891,
      "step": 37880
    },
    {
      "epoch": 2.36,
      "grad_norm": 10.37986946105957,
      "learning_rate": 3.8324381713714715e-05,
      "loss": 1.0563,
      "step": 37890
    },
    {
      "epoch": 2.36,
      "grad_norm": 10.935993194580078,
      "learning_rate": 3.832125905570822e-05,
      "loss": 1.0658,
      "step": 37900
    },
    {
      "epoch": 2.36,
      "grad_norm": 7.42020320892334,
      "learning_rate": 3.831813639770173e-05,
      "loss": 1.001,
      "step": 37910
    },
    {
      "epoch": 2.36,
      "grad_norm": 9.652356147766113,
      "learning_rate": 3.8315013739695235e-05,
      "loss": 1.0837,
      "step": 37920
    },
    {
      "epoch": 2.36,
      "grad_norm": 8.9816312789917,
      "learning_rate": 3.8311891081688735e-05,
      "loss": 1.0477,
      "step": 37930
    },
    {
      "epoch": 2.36,
      "grad_norm": 12.785737037658691,
      "learning_rate": 3.830876842368224e-05,
      "loss": 0.991,
      "step": 37940
    },
    {
      "epoch": 2.36,
      "grad_norm": 8.0328950881958,
      "learning_rate": 3.830564576567575e-05,
      "loss": 1.0303,
      "step": 37950
    },
    {
      "epoch": 2.36,
      "grad_norm": 14.694860458374023,
      "learning_rate": 3.8302523107669256e-05,
      "loss": 0.9518,
      "step": 37960
    },
    {
      "epoch": 2.36,
      "grad_norm": 10.652745246887207,
      "learning_rate": 3.8299400449662756e-05,
      "loss": 0.969,
      "step": 37970
    },
    {
      "epoch": 2.36,
      "grad_norm": 8.89072322845459,
      "learning_rate": 3.829627779165626e-05,
      "loss": 0.9683,
      "step": 37980
    },
    {
      "epoch": 2.37,
      "grad_norm": 9.914995193481445,
      "learning_rate": 3.829315513364977e-05,
      "loss": 0.931,
      "step": 37990
    },
    {
      "epoch": 2.37,
      "grad_norm": 11.67082405090332,
      "learning_rate": 3.829003247564327e-05,
      "loss": 1.1212,
      "step": 38000
    },
    {
      "epoch": 2.37,
      "grad_norm": 7.981449604034424,
      "learning_rate": 3.8286909817636776e-05,
      "loss": 0.8468,
      "step": 38010
    },
    {
      "epoch": 2.37,
      "grad_norm": 12.883980751037598,
      "learning_rate": 3.828378715963028e-05,
      "loss": 0.9922,
      "step": 38020
    },
    {
      "epoch": 2.37,
      "grad_norm": 9.232527732849121,
      "learning_rate": 3.828066450162378e-05,
      "loss": 1.017,
      "step": 38030
    },
    {
      "epoch": 2.37,
      "grad_norm": 10.808493614196777,
      "learning_rate": 3.827754184361729e-05,
      "loss": 1.0123,
      "step": 38040
    },
    {
      "epoch": 2.37,
      "grad_norm": 17.394710540771484,
      "learning_rate": 3.8274419185610797e-05,
      "loss": 1.0326,
      "step": 38050
    },
    {
      "epoch": 2.37,
      "grad_norm": 11.578790664672852,
      "learning_rate": 3.8271296527604303e-05,
      "loss": 1.0486,
      "step": 38060
    },
    {
      "epoch": 2.37,
      "grad_norm": 13.138315200805664,
      "learning_rate": 3.8268173869597803e-05,
      "loss": 0.9349,
      "step": 38070
    },
    {
      "epoch": 2.37,
      "grad_norm": 11.854784965515137,
      "learning_rate": 3.826505121159131e-05,
      "loss": 1.0409,
      "step": 38080
    },
    {
      "epoch": 2.37,
      "grad_norm": 11.419816970825195,
      "learning_rate": 3.826192855358482e-05,
      "loss": 0.9022,
      "step": 38090
    },
    {
      "epoch": 2.37,
      "grad_norm": 10.885337829589844,
      "learning_rate": 3.825880589557832e-05,
      "loss": 0.8656,
      "step": 38100
    },
    {
      "epoch": 2.37,
      "grad_norm": 16.65559196472168,
      "learning_rate": 3.8255683237571824e-05,
      "loss": 1.0799,
      "step": 38110
    },
    {
      "epoch": 2.37,
      "grad_norm": 12.939348220825195,
      "learning_rate": 3.825256057956533e-05,
      "loss": 0.9846,
      "step": 38120
    },
    {
      "epoch": 2.37,
      "grad_norm": 12.695541381835938,
      "learning_rate": 3.824943792155883e-05,
      "loss": 0.9116,
      "step": 38130
    },
    {
      "epoch": 2.37,
      "grad_norm": 10.39283561706543,
      "learning_rate": 3.824631526355234e-05,
      "loss": 0.9592,
      "step": 38140
    },
    {
      "epoch": 2.38,
      "grad_norm": 11.433241844177246,
      "learning_rate": 3.8243192605545844e-05,
      "loss": 0.9416,
      "step": 38150
    },
    {
      "epoch": 2.38,
      "grad_norm": 9.592645645141602,
      "learning_rate": 3.8240069947539344e-05,
      "loss": 1.0586,
      "step": 38160
    },
    {
      "epoch": 2.38,
      "grad_norm": 12.0565767288208,
      "learning_rate": 3.823694728953285e-05,
      "loss": 1.0214,
      "step": 38170
    },
    {
      "epoch": 2.38,
      "grad_norm": 10.082743644714355,
      "learning_rate": 3.823382463152636e-05,
      "loss": 1.1274,
      "step": 38180
    },
    {
      "epoch": 2.38,
      "grad_norm": 10.954415321350098,
      "learning_rate": 3.823070197351986e-05,
      "loss": 1.0301,
      "step": 38190
    },
    {
      "epoch": 2.38,
      "grad_norm": 9.958542823791504,
      "learning_rate": 3.8227579315513365e-05,
      "loss": 0.9676,
      "step": 38200
    },
    {
      "epoch": 2.38,
      "grad_norm": 10.638389587402344,
      "learning_rate": 3.822445665750687e-05,
      "loss": 0.901,
      "step": 38210
    },
    {
      "epoch": 2.38,
      "grad_norm": 8.893000602722168,
      "learning_rate": 3.822133399950037e-05,
      "loss": 0.8762,
      "step": 38220
    },
    {
      "epoch": 2.38,
      "grad_norm": 12.719574928283691,
      "learning_rate": 3.821821134149388e-05,
      "loss": 1.0777,
      "step": 38230
    },
    {
      "epoch": 2.38,
      "grad_norm": 9.395512580871582,
      "learning_rate": 3.8215088683487385e-05,
      "loss": 0.8394,
      "step": 38240
    },
    {
      "epoch": 2.38,
      "grad_norm": 7.581181049346924,
      "learning_rate": 3.8211966025480885e-05,
      "loss": 0.9999,
      "step": 38250
    },
    {
      "epoch": 2.38,
      "grad_norm": 11.692632675170898,
      "learning_rate": 3.820884336747439e-05,
      "loss": 0.9891,
      "step": 38260
    },
    {
      "epoch": 2.38,
      "grad_norm": 12.421756744384766,
      "learning_rate": 3.82057207094679e-05,
      "loss": 1.0102,
      "step": 38270
    },
    {
      "epoch": 2.38,
      "grad_norm": 7.690932750701904,
      "learning_rate": 3.8202598051461406e-05,
      "loss": 0.8815,
      "step": 38280
    },
    {
      "epoch": 2.38,
      "grad_norm": 11.194082260131836,
      "learning_rate": 3.8199475393454906e-05,
      "loss": 1.1264,
      "step": 38290
    },
    {
      "epoch": 2.38,
      "grad_norm": 13.30522346496582,
      "learning_rate": 3.819635273544841e-05,
      "loss": 0.9608,
      "step": 38300
    },
    {
      "epoch": 2.39,
      "grad_norm": 11.683990478515625,
      "learning_rate": 3.819323007744192e-05,
      "loss": 0.9585,
      "step": 38310
    },
    {
      "epoch": 2.39,
      "grad_norm": 8.768548965454102,
      "learning_rate": 3.8190107419435426e-05,
      "loss": 0.9351,
      "step": 38320
    },
    {
      "epoch": 2.39,
      "grad_norm": 16.186845779418945,
      "learning_rate": 3.8186984761428926e-05,
      "loss": 0.9313,
      "step": 38330
    },
    {
      "epoch": 2.39,
      "grad_norm": 9.47612476348877,
      "learning_rate": 3.818386210342243e-05,
      "loss": 0.956,
      "step": 38340
    },
    {
      "epoch": 2.39,
      "grad_norm": 11.911308288574219,
      "learning_rate": 3.818073944541594e-05,
      "loss": 0.9889,
      "step": 38350
    },
    {
      "epoch": 2.39,
      "grad_norm": 7.8399152755737305,
      "learning_rate": 3.817761678740944e-05,
      "loss": 0.8394,
      "step": 38360
    },
    {
      "epoch": 2.39,
      "grad_norm": 9.71229076385498,
      "learning_rate": 3.817449412940295e-05,
      "loss": 1.0241,
      "step": 38370
    },
    {
      "epoch": 2.39,
      "grad_norm": 12.23608112335205,
      "learning_rate": 3.8171371471396453e-05,
      "loss": 1.0014,
      "step": 38380
    },
    {
      "epoch": 2.39,
      "grad_norm": 14.219218254089355,
      "learning_rate": 3.816824881338996e-05,
      "loss": 0.882,
      "step": 38390
    },
    {
      "epoch": 2.39,
      "grad_norm": 12.337923049926758,
      "learning_rate": 3.816512615538346e-05,
      "loss": 1.0962,
      "step": 38400
    },
    {
      "epoch": 2.39,
      "grad_norm": 13.39686393737793,
      "learning_rate": 3.816200349737697e-05,
      "loss": 1.042,
      "step": 38410
    },
    {
      "epoch": 2.39,
      "grad_norm": 9.57068920135498,
      "learning_rate": 3.8158880839370474e-05,
      "loss": 0.9652,
      "step": 38420
    },
    {
      "epoch": 2.39,
      "grad_norm": 9.891621589660645,
      "learning_rate": 3.8155758181363974e-05,
      "loss": 0.9554,
      "step": 38430
    },
    {
      "epoch": 2.39,
      "grad_norm": 16.114383697509766,
      "learning_rate": 3.815263552335748e-05,
      "loss": 1.0321,
      "step": 38440
    },
    {
      "epoch": 2.39,
      "grad_norm": 13.318967819213867,
      "learning_rate": 3.814951286535099e-05,
      "loss": 0.9521,
      "step": 38450
    },
    {
      "epoch": 2.39,
      "grad_norm": 9.95463752746582,
      "learning_rate": 3.8146390207344494e-05,
      "loss": 1.0759,
      "step": 38460
    },
    {
      "epoch": 2.4,
      "grad_norm": 13.884184837341309,
      "learning_rate": 3.8143267549337994e-05,
      "loss": 0.9734,
      "step": 38470
    },
    {
      "epoch": 2.4,
      "grad_norm": 10.17883586883545,
      "learning_rate": 3.81401448913315e-05,
      "loss": 1.0713,
      "step": 38480
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.88284969329834,
      "learning_rate": 3.813702223332501e-05,
      "loss": 1.0419,
      "step": 38490
    },
    {
      "epoch": 2.4,
      "grad_norm": 14.433444023132324,
      "learning_rate": 3.813389957531851e-05,
      "loss": 1.0807,
      "step": 38500
    },
    {
      "epoch": 2.4,
      "grad_norm": 10.073493003845215,
      "learning_rate": 3.8130776917312015e-05,
      "loss": 1.0137,
      "step": 38510
    },
    {
      "epoch": 2.4,
      "grad_norm": 11.17778205871582,
      "learning_rate": 3.812765425930552e-05,
      "loss": 0.955,
      "step": 38520
    },
    {
      "epoch": 2.4,
      "grad_norm": 17.0310001373291,
      "learning_rate": 3.812453160129903e-05,
      "loss": 0.9787,
      "step": 38530
    },
    {
      "epoch": 2.4,
      "grad_norm": 10.903484344482422,
      "learning_rate": 3.812140894329253e-05,
      "loss": 0.9916,
      "step": 38540
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.15468692779541,
      "learning_rate": 3.8118286285286035e-05,
      "loss": 0.8913,
      "step": 38550
    },
    {
      "epoch": 2.4,
      "grad_norm": 9.450961112976074,
      "learning_rate": 3.811516362727954e-05,
      "loss": 0.9378,
      "step": 38560
    },
    {
      "epoch": 2.4,
      "grad_norm": 14.336992263793945,
      "learning_rate": 3.811204096927305e-05,
      "loss": 1.0332,
      "step": 38570
    },
    {
      "epoch": 2.4,
      "grad_norm": 11.721687316894531,
      "learning_rate": 3.810891831126655e-05,
      "loss": 0.9957,
      "step": 38580
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.386336326599121,
      "learning_rate": 3.8105795653260056e-05,
      "loss": 0.9777,
      "step": 38590
    },
    {
      "epoch": 2.4,
      "grad_norm": 8.61636734008789,
      "learning_rate": 3.810267299525356e-05,
      "loss": 0.8989,
      "step": 38600
    },
    {
      "epoch": 2.4,
      "grad_norm": 16.30357551574707,
      "learning_rate": 3.809955033724706e-05,
      "loss": 0.8634,
      "step": 38610
    },
    {
      "epoch": 2.4,
      "grad_norm": 14.571222305297852,
      "learning_rate": 3.809642767924057e-05,
      "loss": 1.0649,
      "step": 38620
    },
    {
      "epoch": 2.41,
      "grad_norm": 9.365256309509277,
      "learning_rate": 3.8093305021234076e-05,
      "loss": 0.9459,
      "step": 38630
    },
    {
      "epoch": 2.41,
      "grad_norm": 12.248117446899414,
      "learning_rate": 3.809018236322758e-05,
      "loss": 1.0229,
      "step": 38640
    },
    {
      "epoch": 2.41,
      "grad_norm": 13.072920799255371,
      "learning_rate": 3.808705970522108e-05,
      "loss": 1.146,
      "step": 38650
    },
    {
      "epoch": 2.41,
      "grad_norm": 13.132472038269043,
      "learning_rate": 3.808393704721459e-05,
      "loss": 0.9685,
      "step": 38660
    },
    {
      "epoch": 2.41,
      "grad_norm": 10.296693801879883,
      "learning_rate": 3.80808143892081e-05,
      "loss": 1.0598,
      "step": 38670
    },
    {
      "epoch": 2.41,
      "grad_norm": 9.300819396972656,
      "learning_rate": 3.80776917312016e-05,
      "loss": 0.9745,
      "step": 38680
    },
    {
      "epoch": 2.41,
      "grad_norm": 11.067235946655273,
      "learning_rate": 3.8074569073195103e-05,
      "loss": 0.9428,
      "step": 38690
    },
    {
      "epoch": 2.41,
      "grad_norm": 9.85993480682373,
      "learning_rate": 3.807144641518861e-05,
      "loss": 0.9399,
      "step": 38700
    },
    {
      "epoch": 2.41,
      "grad_norm": 13.46998119354248,
      "learning_rate": 3.806832375718212e-05,
      "loss": 1.0422,
      "step": 38710
    },
    {
      "epoch": 2.41,
      "grad_norm": 13.694881439208984,
      "learning_rate": 3.806520109917562e-05,
      "loss": 1.0095,
      "step": 38720
    },
    {
      "epoch": 2.41,
      "grad_norm": 9.583033561706543,
      "learning_rate": 3.8062078441169124e-05,
      "loss": 0.885,
      "step": 38730
    },
    {
      "epoch": 2.41,
      "grad_norm": 19.773988723754883,
      "learning_rate": 3.805895578316263e-05,
      "loss": 1.0627,
      "step": 38740
    },
    {
      "epoch": 2.41,
      "grad_norm": 12.112406730651855,
      "learning_rate": 3.805583312515614e-05,
      "loss": 0.9969,
      "step": 38750
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.655770301818848,
      "learning_rate": 3.805271046714964e-05,
      "loss": 1.0427,
      "step": 38760
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.409450054168701,
      "learning_rate": 3.8049587809143144e-05,
      "loss": 1.0109,
      "step": 38770
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.52139949798584,
      "learning_rate": 3.804646515113665e-05,
      "loss": 0.9662,
      "step": 38780
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.79336929321289,
      "learning_rate": 3.804334249313015e-05,
      "loss": 0.9832,
      "step": 38790
    },
    {
      "epoch": 2.42,
      "grad_norm": 8.642022132873535,
      "learning_rate": 3.804021983512366e-05,
      "loss": 1.0066,
      "step": 38800
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.229512214660645,
      "learning_rate": 3.8037097177117165e-05,
      "loss": 0.9253,
      "step": 38810
    },
    {
      "epoch": 2.42,
      "grad_norm": 7.4245524406433105,
      "learning_rate": 3.803397451911067e-05,
      "loss": 1.0198,
      "step": 38820
    },
    {
      "epoch": 2.42,
      "grad_norm": 10.258864402770996,
      "learning_rate": 3.803085186110417e-05,
      "loss": 1.0357,
      "step": 38830
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.507156372070312,
      "learning_rate": 3.802772920309768e-05,
      "loss": 1.0061,
      "step": 38840
    },
    {
      "epoch": 2.42,
      "grad_norm": 9.321362495422363,
      "learning_rate": 3.8024606545091185e-05,
      "loss": 0.8195,
      "step": 38850
    },
    {
      "epoch": 2.42,
      "grad_norm": 9.439506530761719,
      "learning_rate": 3.8021483887084685e-05,
      "loss": 0.9175,
      "step": 38860
    },
    {
      "epoch": 2.42,
      "grad_norm": 9.711533546447754,
      "learning_rate": 3.801836122907819e-05,
      "loss": 0.8984,
      "step": 38870
    },
    {
      "epoch": 2.42,
      "grad_norm": 11.037654876708984,
      "learning_rate": 3.80152385710717e-05,
      "loss": 1.0868,
      "step": 38880
    },
    {
      "epoch": 2.42,
      "grad_norm": 11.763463973999023,
      "learning_rate": 3.8012115913065206e-05,
      "loss": 0.9872,
      "step": 38890
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.882518768310547,
      "learning_rate": 3.8008993255058706e-05,
      "loss": 0.9492,
      "step": 38900
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.509861946105957,
      "learning_rate": 3.800587059705221e-05,
      "loss": 0.9782,
      "step": 38910
    },
    {
      "epoch": 2.42,
      "grad_norm": 9.40978717803955,
      "learning_rate": 3.800274793904572e-05,
      "loss": 0.892,
      "step": 38920
    },
    {
      "epoch": 2.42,
      "grad_norm": 12.944245338439941,
      "learning_rate": 3.7999625281039226e-05,
      "loss": 1.1453,
      "step": 38930
    },
    {
      "epoch": 2.42,
      "grad_norm": 16.16292381286621,
      "learning_rate": 3.7996502623032726e-05,
      "loss": 1.0129,
      "step": 38940
    },
    {
      "epoch": 2.42,
      "grad_norm": 7.3976664543151855,
      "learning_rate": 3.799337996502623e-05,
      "loss": 1.0204,
      "step": 38950
    },
    {
      "epoch": 2.43,
      "grad_norm": 6.42374849319458,
      "learning_rate": 3.799025730701974e-05,
      "loss": 1.0746,
      "step": 38960
    },
    {
      "epoch": 2.43,
      "grad_norm": 8.069747924804688,
      "learning_rate": 3.798713464901324e-05,
      "loss": 0.9402,
      "step": 38970
    },
    {
      "epoch": 2.43,
      "grad_norm": 12.847113609313965,
      "learning_rate": 3.798401199100675e-05,
      "loss": 0.8795,
      "step": 38980
    },
    {
      "epoch": 2.43,
      "grad_norm": 10.262689590454102,
      "learning_rate": 3.7980889333000253e-05,
      "loss": 0.9367,
      "step": 38990
    },
    {
      "epoch": 2.43,
      "grad_norm": 15.456069946289062,
      "learning_rate": 3.797776667499376e-05,
      "loss": 0.9274,
      "step": 39000
    },
    {
      "epoch": 2.43,
      "grad_norm": 21.689714431762695,
      "learning_rate": 3.797464401698726e-05,
      "loss": 1.0074,
      "step": 39010
    },
    {
      "epoch": 2.43,
      "grad_norm": 13.10452651977539,
      "learning_rate": 3.797152135898077e-05,
      "loss": 0.912,
      "step": 39020
    },
    {
      "epoch": 2.43,
      "grad_norm": 11.469882011413574,
      "learning_rate": 3.7968398700974274e-05,
      "loss": 0.9518,
      "step": 39030
    },
    {
      "epoch": 2.43,
      "grad_norm": 15.759564399719238,
      "learning_rate": 3.7965276042967774e-05,
      "loss": 1.0666,
      "step": 39040
    },
    {
      "epoch": 2.43,
      "grad_norm": 6.553382873535156,
      "learning_rate": 3.796215338496128e-05,
      "loss": 0.9935,
      "step": 39050
    },
    {
      "epoch": 2.43,
      "grad_norm": 7.773561000823975,
      "learning_rate": 3.795903072695479e-05,
      "loss": 0.8686,
      "step": 39060
    },
    {
      "epoch": 2.43,
      "grad_norm": 9.335993766784668,
      "learning_rate": 3.7955908068948294e-05,
      "loss": 0.9611,
      "step": 39070
    },
    {
      "epoch": 2.43,
      "grad_norm": 9.230768203735352,
      "learning_rate": 3.7952785410941794e-05,
      "loss": 0.9584,
      "step": 39080
    },
    {
      "epoch": 2.43,
      "grad_norm": 12.64996337890625,
      "learning_rate": 3.79496627529353e-05,
      "loss": 1.0802,
      "step": 39090
    },
    {
      "epoch": 2.43,
      "grad_norm": 14.088906288146973,
      "learning_rate": 3.794654009492881e-05,
      "loss": 0.8911,
      "step": 39100
    },
    {
      "epoch": 2.43,
      "grad_norm": 11.008219718933105,
      "learning_rate": 3.7943417436922315e-05,
      "loss": 0.9121,
      "step": 39110
    },
    {
      "epoch": 2.44,
      "grad_norm": 12.969032287597656,
      "learning_rate": 3.7940294778915815e-05,
      "loss": 0.8162,
      "step": 39120
    },
    {
      "epoch": 2.44,
      "grad_norm": 15.227788925170898,
      "learning_rate": 3.793717212090932e-05,
      "loss": 0.9002,
      "step": 39130
    },
    {
      "epoch": 2.44,
      "grad_norm": 9.440983772277832,
      "learning_rate": 3.793404946290283e-05,
      "loss": 0.9981,
      "step": 39140
    },
    {
      "epoch": 2.44,
      "grad_norm": 14.177451133728027,
      "learning_rate": 3.793092680489633e-05,
      "loss": 0.9069,
      "step": 39150
    },
    {
      "epoch": 2.44,
      "grad_norm": 8.3811616897583,
      "learning_rate": 3.7927804146889835e-05,
      "loss": 0.9133,
      "step": 39160
    },
    {
      "epoch": 2.44,
      "grad_norm": 9.981456756591797,
      "learning_rate": 3.792468148888334e-05,
      "loss": 1.0225,
      "step": 39170
    },
    {
      "epoch": 2.44,
      "grad_norm": 13.353926658630371,
      "learning_rate": 3.792155883087685e-05,
      "loss": 0.9206,
      "step": 39180
    },
    {
      "epoch": 2.44,
      "grad_norm": 15.387636184692383,
      "learning_rate": 3.791843617287035e-05,
      "loss": 1.028,
      "step": 39190
    },
    {
      "epoch": 2.44,
      "grad_norm": 9.448241233825684,
      "learning_rate": 3.7915313514863856e-05,
      "loss": 0.9775,
      "step": 39200
    },
    {
      "epoch": 2.44,
      "grad_norm": 11.95162582397461,
      "learning_rate": 3.791219085685736e-05,
      "loss": 0.9666,
      "step": 39210
    },
    {
      "epoch": 2.44,
      "grad_norm": 9.417427062988281,
      "learning_rate": 3.790906819885086e-05,
      "loss": 0.969,
      "step": 39220
    },
    {
      "epoch": 2.44,
      "grad_norm": 6.951226711273193,
      "learning_rate": 3.790594554084437e-05,
      "loss": 1.0383,
      "step": 39230
    },
    {
      "epoch": 2.44,
      "grad_norm": 10.088658332824707,
      "learning_rate": 3.7902822882837876e-05,
      "loss": 0.8967,
      "step": 39240
    },
    {
      "epoch": 2.44,
      "grad_norm": 12.169382095336914,
      "learning_rate": 3.789970022483138e-05,
      "loss": 1.0356,
      "step": 39250
    },
    {
      "epoch": 2.44,
      "grad_norm": 9.208552360534668,
      "learning_rate": 3.789657756682488e-05,
      "loss": 1.0888,
      "step": 39260
    },
    {
      "epoch": 2.44,
      "grad_norm": 7.0303263664245605,
      "learning_rate": 3.789345490881839e-05,
      "loss": 0.9274,
      "step": 39270
    },
    {
      "epoch": 2.45,
      "grad_norm": 11.149125099182129,
      "learning_rate": 3.78903322508119e-05,
      "loss": 1.0639,
      "step": 39280
    },
    {
      "epoch": 2.45,
      "grad_norm": 8.888374328613281,
      "learning_rate": 3.7887209592805403e-05,
      "loss": 1.0789,
      "step": 39290
    },
    {
      "epoch": 2.45,
      "grad_norm": 10.158194541931152,
      "learning_rate": 3.7884086934798903e-05,
      "loss": 0.8739,
      "step": 39300
    },
    {
      "epoch": 2.45,
      "grad_norm": 10.327569961547852,
      "learning_rate": 3.788096427679241e-05,
      "loss": 1.0968,
      "step": 39310
    },
    {
      "epoch": 2.45,
      "grad_norm": 11.950754165649414,
      "learning_rate": 3.787784161878592e-05,
      "loss": 0.8989,
      "step": 39320
    },
    {
      "epoch": 2.45,
      "grad_norm": 9.01708698272705,
      "learning_rate": 3.787471896077942e-05,
      "loss": 0.9678,
      "step": 39330
    },
    {
      "epoch": 2.45,
      "grad_norm": 9.733610153198242,
      "learning_rate": 3.7871596302772924e-05,
      "loss": 1.0214,
      "step": 39340
    },
    {
      "epoch": 2.45,
      "grad_norm": 9.044780731201172,
      "learning_rate": 3.786847364476643e-05,
      "loss": 1.0527,
      "step": 39350
    },
    {
      "epoch": 2.45,
      "grad_norm": 15.30293083190918,
      "learning_rate": 3.786535098675994e-05,
      "loss": 1.0123,
      "step": 39360
    },
    {
      "epoch": 2.45,
      "grad_norm": 7.764115810394287,
      "learning_rate": 3.786222832875344e-05,
      "loss": 0.97,
      "step": 39370
    },
    {
      "epoch": 2.45,
      "grad_norm": 10.582477569580078,
      "learning_rate": 3.7859105670746944e-05,
      "loss": 0.9336,
      "step": 39380
    },
    {
      "epoch": 2.45,
      "grad_norm": 12.152289390563965,
      "learning_rate": 3.785598301274045e-05,
      "loss": 1.0864,
      "step": 39390
    },
    {
      "epoch": 2.45,
      "grad_norm": 8.62619400024414,
      "learning_rate": 3.785286035473395e-05,
      "loss": 1.0009,
      "step": 39400
    },
    {
      "epoch": 2.45,
      "grad_norm": 14.482359886169434,
      "learning_rate": 3.784973769672746e-05,
      "loss": 1.0544,
      "step": 39410
    },
    {
      "epoch": 2.45,
      "grad_norm": 12.035476684570312,
      "learning_rate": 3.7846615038720965e-05,
      "loss": 1.0539,
      "step": 39420
    },
    {
      "epoch": 2.45,
      "grad_norm": 14.55361557006836,
      "learning_rate": 3.7843492380714465e-05,
      "loss": 0.9254,
      "step": 39430
    },
    {
      "epoch": 2.46,
      "grad_norm": 7.545970916748047,
      "learning_rate": 3.784036972270797e-05,
      "loss": 0.9623,
      "step": 39440
    },
    {
      "epoch": 2.46,
      "grad_norm": 10.868471145629883,
      "learning_rate": 3.783724706470148e-05,
      "loss": 1.046,
      "step": 39450
    },
    {
      "epoch": 2.46,
      "grad_norm": 12.510184288024902,
      "learning_rate": 3.783412440669498e-05,
      "loss": 0.9454,
      "step": 39460
    },
    {
      "epoch": 2.46,
      "grad_norm": 10.846746444702148,
      "learning_rate": 3.7831001748688485e-05,
      "loss": 0.9852,
      "step": 39470
    },
    {
      "epoch": 2.46,
      "grad_norm": 12.273642539978027,
      "learning_rate": 3.782787909068199e-05,
      "loss": 1.0172,
      "step": 39480
    },
    {
      "epoch": 2.46,
      "grad_norm": 9.89220142364502,
      "learning_rate": 3.782475643267549e-05,
      "loss": 1.0107,
      "step": 39490
    },
    {
      "epoch": 2.46,
      "grad_norm": 7.985515594482422,
      "learning_rate": 3.7821633774669e-05,
      "loss": 1.0328,
      "step": 39500
    },
    {
      "epoch": 2.46,
      "grad_norm": 7.616355895996094,
      "learning_rate": 3.7818511116662506e-05,
      "loss": 0.9604,
      "step": 39510
    },
    {
      "epoch": 2.46,
      "grad_norm": 11.485967636108398,
      "learning_rate": 3.781538845865601e-05,
      "loss": 1.0645,
      "step": 39520
    },
    {
      "epoch": 2.46,
      "grad_norm": 13.95846176147461,
      "learning_rate": 3.781226580064951e-05,
      "loss": 1.0489,
      "step": 39530
    },
    {
      "epoch": 2.46,
      "grad_norm": 9.60983943939209,
      "learning_rate": 3.780914314264302e-05,
      "loss": 0.96,
      "step": 39540
    },
    {
      "epoch": 2.46,
      "grad_norm": 15.941104888916016,
      "learning_rate": 3.7806020484636526e-05,
      "loss": 1.0109,
      "step": 39550
    },
    {
      "epoch": 2.46,
      "grad_norm": 9.49417781829834,
      "learning_rate": 3.7802897826630026e-05,
      "loss": 1.0059,
      "step": 39560
    },
    {
      "epoch": 2.46,
      "grad_norm": 11.430459976196289,
      "learning_rate": 3.779977516862353e-05,
      "loss": 1.054,
      "step": 39570
    },
    {
      "epoch": 2.46,
      "grad_norm": 10.713991165161133,
      "learning_rate": 3.779665251061704e-05,
      "loss": 0.9879,
      "step": 39580
    },
    {
      "epoch": 2.46,
      "grad_norm": 10.887486457824707,
      "learning_rate": 3.779352985261054e-05,
      "loss": 1.0241,
      "step": 39590
    },
    {
      "epoch": 2.47,
      "grad_norm": 8.849505424499512,
      "learning_rate": 3.779040719460405e-05,
      "loss": 0.9597,
      "step": 39600
    },
    {
      "epoch": 2.47,
      "grad_norm": 13.005012512207031,
      "learning_rate": 3.7787284536597553e-05,
      "loss": 0.9367,
      "step": 39610
    },
    {
      "epoch": 2.47,
      "grad_norm": 10.40251636505127,
      "learning_rate": 3.7784161878591054e-05,
      "loss": 0.9081,
      "step": 39620
    },
    {
      "epoch": 2.47,
      "grad_norm": 11.791104316711426,
      "learning_rate": 3.778103922058456e-05,
      "loss": 0.9033,
      "step": 39630
    },
    {
      "epoch": 2.47,
      "grad_norm": 11.960711479187012,
      "learning_rate": 3.777791656257807e-05,
      "loss": 1.1194,
      "step": 39640
    },
    {
      "epoch": 2.47,
      "grad_norm": 9.74857234954834,
      "learning_rate": 3.777479390457157e-05,
      "loss": 0.8868,
      "step": 39650
    },
    {
      "epoch": 2.47,
      "grad_norm": 11.597066879272461,
      "learning_rate": 3.7771671246565074e-05,
      "loss": 1.1009,
      "step": 39660
    },
    {
      "epoch": 2.47,
      "grad_norm": 13.914210319519043,
      "learning_rate": 3.776854858855858e-05,
      "loss": 1.0112,
      "step": 39670
    },
    {
      "epoch": 2.47,
      "grad_norm": 7.936957359313965,
      "learning_rate": 3.776542593055209e-05,
      "loss": 0.929,
      "step": 39680
    },
    {
      "epoch": 2.47,
      "grad_norm": 11.346126556396484,
      "learning_rate": 3.776230327254559e-05,
      "loss": 1.0125,
      "step": 39690
    },
    {
      "epoch": 2.47,
      "grad_norm": 11.460160255432129,
      "learning_rate": 3.7759180614539094e-05,
      "loss": 0.9849,
      "step": 39700
    },
    {
      "epoch": 2.47,
      "grad_norm": 9.465987205505371,
      "learning_rate": 3.77560579565326e-05,
      "loss": 1.0328,
      "step": 39710
    },
    {
      "epoch": 2.47,
      "grad_norm": 10.037487030029297,
      "learning_rate": 3.775293529852611e-05,
      "loss": 0.9071,
      "step": 39720
    },
    {
      "epoch": 2.47,
      "grad_norm": 15.671050071716309,
      "learning_rate": 3.774981264051961e-05,
      "loss": 0.9949,
      "step": 39730
    },
    {
      "epoch": 2.47,
      "grad_norm": 13.524590492248535,
      "learning_rate": 3.7746689982513115e-05,
      "loss": 1.0649,
      "step": 39740
    },
    {
      "epoch": 2.47,
      "grad_norm": 12.300387382507324,
      "learning_rate": 3.774356732450662e-05,
      "loss": 0.993,
      "step": 39750
    },
    {
      "epoch": 2.48,
      "grad_norm": 11.11841106414795,
      "learning_rate": 3.774044466650012e-05,
      "loss": 0.9637,
      "step": 39760
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.557154178619385,
      "learning_rate": 3.773732200849363e-05,
      "loss": 1.0115,
      "step": 39770
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.256136894226074,
      "learning_rate": 3.7734199350487135e-05,
      "loss": 0.9666,
      "step": 39780
    },
    {
      "epoch": 2.48,
      "grad_norm": 9.133935928344727,
      "learning_rate": 3.773107669248064e-05,
      "loss": 0.9056,
      "step": 39790
    },
    {
      "epoch": 2.48,
      "grad_norm": 12.413148880004883,
      "learning_rate": 3.772795403447414e-05,
      "loss": 0.8945,
      "step": 39800
    },
    {
      "epoch": 2.48,
      "grad_norm": 13.046372413635254,
      "learning_rate": 3.772483137646765e-05,
      "loss": 1.0548,
      "step": 39810
    },
    {
      "epoch": 2.48,
      "grad_norm": 12.830598831176758,
      "learning_rate": 3.7721708718461156e-05,
      "loss": 0.9906,
      "step": 39820
    },
    {
      "epoch": 2.48,
      "grad_norm": 10.305078506469727,
      "learning_rate": 3.7718586060454656e-05,
      "loss": 0.9545,
      "step": 39830
    },
    {
      "epoch": 2.48,
      "grad_norm": 9.605855941772461,
      "learning_rate": 3.771546340244816e-05,
      "loss": 1.0183,
      "step": 39840
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.858325004577637,
      "learning_rate": 3.771234074444167e-05,
      "loss": 1.1227,
      "step": 39850
    },
    {
      "epoch": 2.48,
      "grad_norm": 7.574192523956299,
      "learning_rate": 3.7709218086435176e-05,
      "loss": 0.9938,
      "step": 39860
    },
    {
      "epoch": 2.48,
      "grad_norm": 13.951848030090332,
      "learning_rate": 3.7706095428428676e-05,
      "loss": 0.9679,
      "step": 39870
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.142681121826172,
      "learning_rate": 3.770297277042218e-05,
      "loss": 1.0673,
      "step": 39880
    },
    {
      "epoch": 2.48,
      "grad_norm": 7.845825672149658,
      "learning_rate": 3.769985011241569e-05,
      "loss": 0.9939,
      "step": 39890
    },
    {
      "epoch": 2.48,
      "grad_norm": 9.220118522644043,
      "learning_rate": 3.76967274544092e-05,
      "loss": 1.2135,
      "step": 39900
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.111909866333008,
      "learning_rate": 3.76936047964027e-05,
      "loss": 1.0655,
      "step": 39910
    },
    {
      "epoch": 2.49,
      "grad_norm": 13.305377006530762,
      "learning_rate": 3.7690482138396203e-05,
      "loss": 1.0393,
      "step": 39920
    },
    {
      "epoch": 2.49,
      "grad_norm": 7.806215286254883,
      "learning_rate": 3.768735948038971e-05,
      "loss": 0.953,
      "step": 39930
    },
    {
      "epoch": 2.49,
      "grad_norm": 16.74614715576172,
      "learning_rate": 3.768423682238321e-05,
      "loss": 0.9338,
      "step": 39940
    },
    {
      "epoch": 2.49,
      "grad_norm": 12.558258056640625,
      "learning_rate": 3.768111416437672e-05,
      "loss": 1.0928,
      "step": 39950
    },
    {
      "epoch": 2.49,
      "grad_norm": 9.827335357666016,
      "learning_rate": 3.7677991506370224e-05,
      "loss": 1.0794,
      "step": 39960
    },
    {
      "epoch": 2.49,
      "grad_norm": 12.113718032836914,
      "learning_rate": 3.767486884836373e-05,
      "loss": 1.059,
      "step": 39970
    },
    {
      "epoch": 2.49,
      "grad_norm": 8.895373344421387,
      "learning_rate": 3.767174619035723e-05,
      "loss": 0.9354,
      "step": 39980
    },
    {
      "epoch": 2.49,
      "grad_norm": 7.1040215492248535,
      "learning_rate": 3.766862353235074e-05,
      "loss": 1.0431,
      "step": 39990
    },
    {
      "epoch": 2.49,
      "grad_norm": 7.255061149597168,
      "learning_rate": 3.7665500874344244e-05,
      "loss": 1.0206,
      "step": 40000
    },
    {
      "epoch": 2.49,
      "grad_norm": 10.050207138061523,
      "learning_rate": 3.7662378216337744e-05,
      "loss": 1.0013,
      "step": 40010
    },
    {
      "epoch": 2.49,
      "grad_norm": 7.177517414093018,
      "learning_rate": 3.765925555833125e-05,
      "loss": 0.9936,
      "step": 40020
    },
    {
      "epoch": 2.49,
      "grad_norm": 8.581631660461426,
      "learning_rate": 3.765613290032476e-05,
      "loss": 1.0636,
      "step": 40030
    },
    {
      "epoch": 2.49,
      "grad_norm": 11.278681755065918,
      "learning_rate": 3.7653010242318265e-05,
      "loss": 0.8948,
      "step": 40040
    },
    {
      "epoch": 2.49,
      "grad_norm": 9.19692611694336,
      "learning_rate": 3.7649887584311765e-05,
      "loss": 1.036,
      "step": 40050
    },
    {
      "epoch": 2.49,
      "grad_norm": 9.276712417602539,
      "learning_rate": 3.764676492630527e-05,
      "loss": 1.0142,
      "step": 40060
    },
    {
      "epoch": 2.49,
      "grad_norm": 10.556754112243652,
      "learning_rate": 3.764364226829878e-05,
      "loss": 0.9411,
      "step": 40070
    },
    {
      "epoch": 2.5,
      "grad_norm": 12.017180442810059,
      "learning_rate": 3.7640519610292285e-05,
      "loss": 1.0571,
      "step": 40080
    },
    {
      "epoch": 2.5,
      "grad_norm": 11.284090995788574,
      "learning_rate": 3.7637396952285785e-05,
      "loss": 0.9417,
      "step": 40090
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.91807222366333,
      "learning_rate": 3.763427429427929e-05,
      "loss": 0.9934,
      "step": 40100
    },
    {
      "epoch": 2.5,
      "grad_norm": 12.374013900756836,
      "learning_rate": 3.76311516362728e-05,
      "loss": 0.9361,
      "step": 40110
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.722199440002441,
      "learning_rate": 3.76280289782663e-05,
      "loss": 0.9665,
      "step": 40120
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.788967132568359,
      "learning_rate": 3.7624906320259806e-05,
      "loss": 0.9571,
      "step": 40130
    },
    {
      "epoch": 2.5,
      "grad_norm": 10.682755470275879,
      "learning_rate": 3.762178366225331e-05,
      "loss": 0.9404,
      "step": 40140
    },
    {
      "epoch": 2.5,
      "grad_norm": 14.061286926269531,
      "learning_rate": 3.761866100424682e-05,
      "loss": 0.9553,
      "step": 40150
    },
    {
      "epoch": 2.5,
      "grad_norm": 10.882692337036133,
      "learning_rate": 3.761553834624032e-05,
      "loss": 1.0405,
      "step": 40160
    },
    {
      "epoch": 2.5,
      "grad_norm": 6.975602626800537,
      "learning_rate": 3.7612415688233826e-05,
      "loss": 0.9624,
      "step": 40170
    },
    {
      "epoch": 2.5,
      "grad_norm": 11.387686729431152,
      "learning_rate": 3.760929303022733e-05,
      "loss": 1.0019,
      "step": 40180
    },
    {
      "epoch": 2.5,
      "grad_norm": 12.629343032836914,
      "learning_rate": 3.760617037222083e-05,
      "loss": 1.058,
      "step": 40190
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.392536163330078,
      "learning_rate": 3.760304771421434e-05,
      "loss": 1.0673,
      "step": 40200
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.973917961120605,
      "learning_rate": 3.759992505620785e-05,
      "loss": 0.9138,
      "step": 40210
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.055521011352539,
      "learning_rate": 3.7596802398201353e-05,
      "loss": 0.9927,
      "step": 40220
    },
    {
      "epoch": 2.5,
      "grad_norm": 12.458894729614258,
      "learning_rate": 3.7593679740194854e-05,
      "loss": 0.9274,
      "step": 40230
    },
    {
      "epoch": 2.51,
      "grad_norm": 6.968339920043945,
      "learning_rate": 3.759055708218836e-05,
      "loss": 0.9781,
      "step": 40240
    },
    {
      "epoch": 2.51,
      "grad_norm": 11.18885326385498,
      "learning_rate": 3.758743442418187e-05,
      "loss": 0.9352,
      "step": 40250
    },
    {
      "epoch": 2.51,
      "grad_norm": 9.48410415649414,
      "learning_rate": 3.7584311766175374e-05,
      "loss": 1.0832,
      "step": 40260
    },
    {
      "epoch": 2.51,
      "grad_norm": 9.395259857177734,
      "learning_rate": 3.7581189108168874e-05,
      "loss": 0.9216,
      "step": 40270
    },
    {
      "epoch": 2.51,
      "grad_norm": 9.283365249633789,
      "learning_rate": 3.757806645016238e-05,
      "loss": 1.0273,
      "step": 40280
    },
    {
      "epoch": 2.51,
      "grad_norm": 10.6925048828125,
      "learning_rate": 3.757494379215589e-05,
      "loss": 1.0374,
      "step": 40290
    },
    {
      "epoch": 2.51,
      "grad_norm": 7.8918986320495605,
      "learning_rate": 3.757182113414939e-05,
      "loss": 0.9186,
      "step": 40300
    },
    {
      "epoch": 2.51,
      "grad_norm": 10.943805694580078,
      "learning_rate": 3.7568698476142894e-05,
      "loss": 0.9433,
      "step": 40310
    },
    {
      "epoch": 2.51,
      "grad_norm": 12.72361946105957,
      "learning_rate": 3.75655758181364e-05,
      "loss": 0.8897,
      "step": 40320
    },
    {
      "epoch": 2.51,
      "grad_norm": 10.438437461853027,
      "learning_rate": 3.756245316012991e-05,
      "loss": 0.9356,
      "step": 40330
    },
    {
      "epoch": 2.51,
      "grad_norm": 12.00994873046875,
      "learning_rate": 3.755933050212341e-05,
      "loss": 0.9723,
      "step": 40340
    },
    {
      "epoch": 2.51,
      "grad_norm": 7.532621383666992,
      "learning_rate": 3.7556207844116915e-05,
      "loss": 1.1059,
      "step": 40350
    },
    {
      "epoch": 2.51,
      "grad_norm": 12.540168762207031,
      "learning_rate": 3.755308518611042e-05,
      "loss": 1.0283,
      "step": 40360
    },
    {
      "epoch": 2.51,
      "grad_norm": 10.390116691589355,
      "learning_rate": 3.754996252810392e-05,
      "loss": 0.9184,
      "step": 40370
    },
    {
      "epoch": 2.51,
      "grad_norm": 7.907962799072266,
      "learning_rate": 3.754683987009743e-05,
      "loss": 1.0221,
      "step": 40380
    },
    {
      "epoch": 2.51,
      "grad_norm": 14.11220932006836,
      "learning_rate": 3.7543717212090935e-05,
      "loss": 0.967,
      "step": 40390
    },
    {
      "epoch": 2.52,
      "grad_norm": 8.886579513549805,
      "learning_rate": 3.754059455408444e-05,
      "loss": 1.0474,
      "step": 40400
    },
    {
      "epoch": 2.52,
      "grad_norm": 10.48112678527832,
      "learning_rate": 3.753747189607794e-05,
      "loss": 0.984,
      "step": 40410
    },
    {
      "epoch": 2.52,
      "grad_norm": 7.891409873962402,
      "learning_rate": 3.753434923807145e-05,
      "loss": 0.9672,
      "step": 40420
    },
    {
      "epoch": 2.52,
      "grad_norm": 9.76008415222168,
      "learning_rate": 3.7531226580064956e-05,
      "loss": 1.0169,
      "step": 40430
    },
    {
      "epoch": 2.52,
      "grad_norm": 14.615966796875,
      "learning_rate": 3.752810392205846e-05,
      "loss": 0.9343,
      "step": 40440
    },
    {
      "epoch": 2.52,
      "grad_norm": 13.11437702178955,
      "learning_rate": 3.752498126405196e-05,
      "loss": 0.9869,
      "step": 40450
    },
    {
      "epoch": 2.52,
      "grad_norm": 10.69332218170166,
      "learning_rate": 3.752185860604547e-05,
      "loss": 0.9213,
      "step": 40460
    },
    {
      "epoch": 2.52,
      "grad_norm": 10.292718887329102,
      "learning_rate": 3.7518735948038976e-05,
      "loss": 1.0993,
      "step": 40470
    },
    {
      "epoch": 2.52,
      "grad_norm": 14.216611862182617,
      "learning_rate": 3.7515613290032476e-05,
      "loss": 1.0243,
      "step": 40480
    },
    {
      "epoch": 2.52,
      "grad_norm": 14.84519100189209,
      "learning_rate": 3.751249063202598e-05,
      "loss": 0.9515,
      "step": 40490
    },
    {
      "epoch": 2.52,
      "grad_norm": 8.982004165649414,
      "learning_rate": 3.750936797401949e-05,
      "loss": 0.9245,
      "step": 40500
    },
    {
      "epoch": 2.52,
      "grad_norm": 8.878153800964355,
      "learning_rate": 3.7506245316013e-05,
      "loss": 0.9826,
      "step": 40510
    },
    {
      "epoch": 2.52,
      "grad_norm": 7.473509311676025,
      "learning_rate": 3.75031226580065e-05,
      "loss": 1.0132,
      "step": 40520
    },
    {
      "epoch": 2.52,
      "grad_norm": 8.70817756652832,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.872,
      "step": 40530
    },
    {
      "epoch": 2.52,
      "grad_norm": 11.918397903442383,
      "learning_rate": 3.749687734199351e-05,
      "loss": 1.0301,
      "step": 40540
    },
    {
      "epoch": 2.52,
      "grad_norm": 12.480426788330078,
      "learning_rate": 3.749375468398701e-05,
      "loss": 1.117,
      "step": 40550
    },
    {
      "epoch": 2.53,
      "grad_norm": 8.371625900268555,
      "learning_rate": 3.749063202598052e-05,
      "loss": 1.1023,
      "step": 40560
    },
    {
      "epoch": 2.53,
      "grad_norm": 9.708089828491211,
      "learning_rate": 3.7487509367974024e-05,
      "loss": 0.917,
      "step": 40570
    },
    {
      "epoch": 2.53,
      "grad_norm": 10.56725025177002,
      "learning_rate": 3.748438670996753e-05,
      "loss": 1.0059,
      "step": 40580
    },
    {
      "epoch": 2.53,
      "grad_norm": 7.094467639923096,
      "learning_rate": 3.748126405196103e-05,
      "loss": 1.1215,
      "step": 40590
    },
    {
      "epoch": 2.53,
      "grad_norm": 17.06683921813965,
      "learning_rate": 3.747814139395454e-05,
      "loss": 1.1701,
      "step": 40600
    },
    {
      "epoch": 2.53,
      "grad_norm": 9.105050086975098,
      "learning_rate": 3.7475018735948044e-05,
      "loss": 1.0992,
      "step": 40610
    },
    {
      "epoch": 2.53,
      "grad_norm": 7.344869136810303,
      "learning_rate": 3.7471896077941544e-05,
      "loss": 1.072,
      "step": 40620
    },
    {
      "epoch": 2.53,
      "grad_norm": 10.641472816467285,
      "learning_rate": 3.746877341993505e-05,
      "loss": 0.9201,
      "step": 40630
    },
    {
      "epoch": 2.53,
      "grad_norm": 10.717754364013672,
      "learning_rate": 3.746565076192856e-05,
      "loss": 0.956,
      "step": 40640
    },
    {
      "epoch": 2.53,
      "grad_norm": 8.827030181884766,
      "learning_rate": 3.7462528103922065e-05,
      "loss": 0.962,
      "step": 40650
    },
    {
      "epoch": 2.53,
      "grad_norm": 11.170310020446777,
      "learning_rate": 3.7459405445915565e-05,
      "loss": 1.0471,
      "step": 40660
    },
    {
      "epoch": 2.53,
      "grad_norm": 15.535715103149414,
      "learning_rate": 3.745628278790907e-05,
      "loss": 0.9767,
      "step": 40670
    },
    {
      "epoch": 2.53,
      "grad_norm": 14.194441795349121,
      "learning_rate": 3.745316012990258e-05,
      "loss": 0.999,
      "step": 40680
    },
    {
      "epoch": 2.53,
      "grad_norm": 10.937793731689453,
      "learning_rate": 3.7450037471896085e-05,
      "loss": 1.0461,
      "step": 40690
    },
    {
      "epoch": 2.53,
      "grad_norm": 8.502359390258789,
      "learning_rate": 3.7446914813889585e-05,
      "loss": 0.9872,
      "step": 40700
    },
    {
      "epoch": 2.53,
      "grad_norm": 12.624713897705078,
      "learning_rate": 3.744379215588309e-05,
      "loss": 0.9799,
      "step": 40710
    },
    {
      "epoch": 2.54,
      "grad_norm": 12.09447193145752,
      "learning_rate": 3.74406694978766e-05,
      "loss": 0.9603,
      "step": 40720
    },
    {
      "epoch": 2.54,
      "grad_norm": 11.76760196685791,
      "learning_rate": 3.74375468398701e-05,
      "loss": 1.0243,
      "step": 40730
    },
    {
      "epoch": 2.54,
      "grad_norm": 9.926275253295898,
      "learning_rate": 3.7434424181863606e-05,
      "loss": 1.1138,
      "step": 40740
    },
    {
      "epoch": 2.54,
      "grad_norm": 11.427628517150879,
      "learning_rate": 3.743130152385711e-05,
      "loss": 1.0197,
      "step": 40750
    },
    {
      "epoch": 2.54,
      "grad_norm": 18.394107818603516,
      "learning_rate": 3.742817886585062e-05,
      "loss": 1.1903,
      "step": 40760
    },
    {
      "epoch": 2.54,
      "grad_norm": 9.230974197387695,
      "learning_rate": 3.742505620784412e-05,
      "loss": 0.8558,
      "step": 40770
    },
    {
      "epoch": 2.54,
      "grad_norm": 7.1496968269348145,
      "learning_rate": 3.7421933549837626e-05,
      "loss": 0.9625,
      "step": 40780
    },
    {
      "epoch": 2.54,
      "grad_norm": 9.259814262390137,
      "learning_rate": 3.741881089183113e-05,
      "loss": 1.0138,
      "step": 40790
    },
    {
      "epoch": 2.54,
      "grad_norm": 5.701774597167969,
      "learning_rate": 3.741568823382463e-05,
      "loss": 0.9467,
      "step": 40800
    },
    {
      "epoch": 2.54,
      "grad_norm": 7.97011137008667,
      "learning_rate": 3.741256557581814e-05,
      "loss": 1.1881,
      "step": 40810
    },
    {
      "epoch": 2.54,
      "grad_norm": 8.5916166305542,
      "learning_rate": 3.740944291781165e-05,
      "loss": 1.0485,
      "step": 40820
    },
    {
      "epoch": 2.54,
      "grad_norm": 12.898039817810059,
      "learning_rate": 3.740632025980515e-05,
      "loss": 1.0198,
      "step": 40830
    },
    {
      "epoch": 2.54,
      "grad_norm": 16.346975326538086,
      "learning_rate": 3.7403197601798654e-05,
      "loss": 1.0922,
      "step": 40840
    },
    {
      "epoch": 2.54,
      "grad_norm": 12.352734565734863,
      "learning_rate": 3.740007494379216e-05,
      "loss": 1.0625,
      "step": 40850
    },
    {
      "epoch": 2.54,
      "grad_norm": 8.607818603515625,
      "learning_rate": 3.739695228578566e-05,
      "loss": 0.9169,
      "step": 40860
    },
    {
      "epoch": 2.54,
      "grad_norm": 10.502251625061035,
      "learning_rate": 3.739382962777917e-05,
      "loss": 0.9662,
      "step": 40870
    },
    {
      "epoch": 2.55,
      "grad_norm": 16.094167709350586,
      "learning_rate": 3.7390706969772674e-05,
      "loss": 0.986,
      "step": 40880
    },
    {
      "epoch": 2.55,
      "grad_norm": 13.535866737365723,
      "learning_rate": 3.7387584311766174e-05,
      "loss": 0.9945,
      "step": 40890
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.186516761779785,
      "learning_rate": 3.738446165375968e-05,
      "loss": 1.036,
      "step": 40900
    },
    {
      "epoch": 2.55,
      "grad_norm": 11.253878593444824,
      "learning_rate": 3.738133899575319e-05,
      "loss": 1.066,
      "step": 40910
    },
    {
      "epoch": 2.55,
      "grad_norm": 12.904399871826172,
      "learning_rate": 3.737821633774669e-05,
      "loss": 1.0665,
      "step": 40920
    },
    {
      "epoch": 2.55,
      "grad_norm": 16.808029174804688,
      "learning_rate": 3.7375093679740194e-05,
      "loss": 1.1049,
      "step": 40930
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.720198631286621,
      "learning_rate": 3.73719710217337e-05,
      "loss": 0.8949,
      "step": 40940
    },
    {
      "epoch": 2.55,
      "grad_norm": 7.729666709899902,
      "learning_rate": 3.73688483637272e-05,
      "loss": 0.9641,
      "step": 40950
    },
    {
      "epoch": 2.55,
      "grad_norm": 29.17075538635254,
      "learning_rate": 3.736572570572071e-05,
      "loss": 1.1231,
      "step": 40960
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.333272933959961,
      "learning_rate": 3.7362603047714215e-05,
      "loss": 1.0628,
      "step": 40970
    },
    {
      "epoch": 2.55,
      "grad_norm": 8.159368515014648,
      "learning_rate": 3.735948038970772e-05,
      "loss": 0.9868,
      "step": 40980
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.833589553833008,
      "learning_rate": 3.735635773170122e-05,
      "loss": 1.0373,
      "step": 40990
    },
    {
      "epoch": 2.55,
      "grad_norm": 11.894883155822754,
      "learning_rate": 3.735323507369473e-05,
      "loss": 1.0481,
      "step": 41000
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.730470657348633,
      "learning_rate": 3.7350112415688235e-05,
      "loss": 0.9814,
      "step": 41010
    },
    {
      "epoch": 2.55,
      "grad_norm": 9.305837631225586,
      "learning_rate": 3.7346989757681735e-05,
      "loss": 0.8476,
      "step": 41020
    },
    {
      "epoch": 2.55,
      "grad_norm": 11.481263160705566,
      "learning_rate": 3.734386709967524e-05,
      "loss": 1.0712,
      "step": 41030
    },
    {
      "epoch": 2.56,
      "grad_norm": 10.506675720214844,
      "learning_rate": 3.734074444166875e-05,
      "loss": 0.925,
      "step": 41040
    },
    {
      "epoch": 2.56,
      "grad_norm": 8.223625183105469,
      "learning_rate": 3.7337621783662256e-05,
      "loss": 0.9274,
      "step": 41050
    },
    {
      "epoch": 2.56,
      "grad_norm": 18.287744522094727,
      "learning_rate": 3.7334499125655756e-05,
      "loss": 1.0533,
      "step": 41060
    },
    {
      "epoch": 2.56,
      "grad_norm": 12.724382400512695,
      "learning_rate": 3.733137646764926e-05,
      "loss": 1.027,
      "step": 41070
    },
    {
      "epoch": 2.56,
      "grad_norm": 14.64574146270752,
      "learning_rate": 3.732825380964277e-05,
      "loss": 1.0792,
      "step": 41080
    },
    {
      "epoch": 2.56,
      "grad_norm": 8.436500549316406,
      "learning_rate": 3.732513115163627e-05,
      "loss": 1.0405,
      "step": 41090
    },
    {
      "epoch": 2.56,
      "grad_norm": 12.274386405944824,
      "learning_rate": 3.7322008493629776e-05,
      "loss": 1.0235,
      "step": 41100
    },
    {
      "epoch": 2.56,
      "grad_norm": 6.703240871429443,
      "learning_rate": 3.731888583562328e-05,
      "loss": 1.0046,
      "step": 41110
    },
    {
      "epoch": 2.56,
      "grad_norm": 11.789722442626953,
      "learning_rate": 3.731576317761679e-05,
      "loss": 0.9265,
      "step": 41120
    },
    {
      "epoch": 2.56,
      "grad_norm": 10.788278579711914,
      "learning_rate": 3.731264051961029e-05,
      "loss": 0.9588,
      "step": 41130
    },
    {
      "epoch": 2.56,
      "grad_norm": 9.999079704284668,
      "learning_rate": 3.73095178616038e-05,
      "loss": 1.0781,
      "step": 41140
    },
    {
      "epoch": 2.56,
      "grad_norm": 11.028349876403809,
      "learning_rate": 3.7306395203597304e-05,
      "loss": 1.0427,
      "step": 41150
    },
    {
      "epoch": 2.56,
      "grad_norm": 11.488422393798828,
      "learning_rate": 3.7303272545590804e-05,
      "loss": 1.029,
      "step": 41160
    },
    {
      "epoch": 2.56,
      "grad_norm": 13.254814147949219,
      "learning_rate": 3.730014988758431e-05,
      "loss": 1.0098,
      "step": 41170
    },
    {
      "epoch": 2.56,
      "grad_norm": 10.311463356018066,
      "learning_rate": 3.729702722957782e-05,
      "loss": 1.1182,
      "step": 41180
    },
    {
      "epoch": 2.56,
      "grad_norm": 9.662984848022461,
      "learning_rate": 3.7293904571571324e-05,
      "loss": 0.9618,
      "step": 41190
    },
    {
      "epoch": 2.57,
      "grad_norm": 13.002614974975586,
      "learning_rate": 3.7290781913564824e-05,
      "loss": 0.997,
      "step": 41200
    },
    {
      "epoch": 2.57,
      "grad_norm": 8.491500854492188,
      "learning_rate": 3.728765925555833e-05,
      "loss": 1.0597,
      "step": 41210
    },
    {
      "epoch": 2.57,
      "grad_norm": 10.433866500854492,
      "learning_rate": 3.728453659755184e-05,
      "loss": 0.9823,
      "step": 41220
    },
    {
      "epoch": 2.57,
      "grad_norm": 9.269392013549805,
      "learning_rate": 3.7281413939545344e-05,
      "loss": 1.0403,
      "step": 41230
    },
    {
      "epoch": 2.57,
      "grad_norm": 11.507659912109375,
      "learning_rate": 3.7278291281538844e-05,
      "loss": 0.9416,
      "step": 41240
    },
    {
      "epoch": 2.57,
      "grad_norm": 16.61595916748047,
      "learning_rate": 3.727516862353235e-05,
      "loss": 1.1051,
      "step": 41250
    },
    {
      "epoch": 2.57,
      "grad_norm": 9.42498779296875,
      "learning_rate": 3.727204596552586e-05,
      "loss": 1.0092,
      "step": 41260
    },
    {
      "epoch": 2.57,
      "grad_norm": 11.736701011657715,
      "learning_rate": 3.726892330751936e-05,
      "loss": 0.9814,
      "step": 41270
    },
    {
      "epoch": 2.57,
      "grad_norm": 10.109199523925781,
      "learning_rate": 3.7265800649512865e-05,
      "loss": 0.9675,
      "step": 41280
    },
    {
      "epoch": 2.57,
      "grad_norm": 8.483701705932617,
      "learning_rate": 3.726267799150637e-05,
      "loss": 0.9007,
      "step": 41290
    },
    {
      "epoch": 2.57,
      "grad_norm": 17.433664321899414,
      "learning_rate": 3.725955533349988e-05,
      "loss": 1.0445,
      "step": 41300
    },
    {
      "epoch": 2.57,
      "grad_norm": 27.834299087524414,
      "learning_rate": 3.725643267549338e-05,
      "loss": 1.0571,
      "step": 41310
    },
    {
      "epoch": 2.57,
      "grad_norm": 11.562244415283203,
      "learning_rate": 3.7253310017486885e-05,
      "loss": 1.1092,
      "step": 41320
    },
    {
      "epoch": 2.57,
      "grad_norm": 8.279326438903809,
      "learning_rate": 3.725018735948039e-05,
      "loss": 1.0278,
      "step": 41330
    },
    {
      "epoch": 2.57,
      "grad_norm": 9.93579387664795,
      "learning_rate": 3.724706470147389e-05,
      "loss": 0.9624,
      "step": 41340
    },
    {
      "epoch": 2.57,
      "grad_norm": 8.946966171264648,
      "learning_rate": 3.72439420434674e-05,
      "loss": 1.067,
      "step": 41350
    },
    {
      "epoch": 2.58,
      "grad_norm": 9.93406867980957,
      "learning_rate": 3.7240819385460906e-05,
      "loss": 1.0202,
      "step": 41360
    },
    {
      "epoch": 2.58,
      "grad_norm": 9.528949737548828,
      "learning_rate": 3.723769672745441e-05,
      "loss": 1.015,
      "step": 41370
    },
    {
      "epoch": 2.58,
      "grad_norm": 11.638452529907227,
      "learning_rate": 3.723457406944791e-05,
      "loss": 0.9462,
      "step": 41380
    },
    {
      "epoch": 2.58,
      "grad_norm": 10.310562133789062,
      "learning_rate": 3.723145141144142e-05,
      "loss": 0.9847,
      "step": 41390
    },
    {
      "epoch": 2.58,
      "grad_norm": 18.091169357299805,
      "learning_rate": 3.7228328753434926e-05,
      "loss": 1.1343,
      "step": 41400
    },
    {
      "epoch": 2.58,
      "grad_norm": 11.233304023742676,
      "learning_rate": 3.722520609542843e-05,
      "loss": 0.9756,
      "step": 41410
    },
    {
      "epoch": 2.58,
      "grad_norm": 9.485177040100098,
      "learning_rate": 3.722208343742193e-05,
      "loss": 1.0239,
      "step": 41420
    },
    {
      "epoch": 2.58,
      "grad_norm": 9.418403625488281,
      "learning_rate": 3.721896077941544e-05,
      "loss": 1.022,
      "step": 41430
    },
    {
      "epoch": 2.58,
      "grad_norm": 7.758428573608398,
      "learning_rate": 3.721583812140895e-05,
      "loss": 0.9161,
      "step": 41440
    },
    {
      "epoch": 2.58,
      "grad_norm": 10.522608757019043,
      "learning_rate": 3.721271546340245e-05,
      "loss": 1.0108,
      "step": 41450
    },
    {
      "epoch": 2.58,
      "grad_norm": 8.857268333435059,
      "learning_rate": 3.7209592805395954e-05,
      "loss": 0.9598,
      "step": 41460
    },
    {
      "epoch": 2.58,
      "grad_norm": 9.568591117858887,
      "learning_rate": 3.720647014738946e-05,
      "loss": 1.0299,
      "step": 41470
    },
    {
      "epoch": 2.58,
      "grad_norm": 13.545886039733887,
      "learning_rate": 3.720334748938297e-05,
      "loss": 1.045,
      "step": 41480
    },
    {
      "epoch": 2.58,
      "grad_norm": 11.256861686706543,
      "learning_rate": 3.720022483137647e-05,
      "loss": 0.9692,
      "step": 41490
    },
    {
      "epoch": 2.58,
      "grad_norm": 15.493202209472656,
      "learning_rate": 3.7197102173369974e-05,
      "loss": 1.0643,
      "step": 41500
    },
    {
      "epoch": 2.58,
      "grad_norm": 17.907869338989258,
      "learning_rate": 3.719397951536348e-05,
      "loss": 1.0594,
      "step": 41510
    },
    {
      "epoch": 2.58,
      "grad_norm": 12.89268684387207,
      "learning_rate": 3.719085685735698e-05,
      "loss": 0.9356,
      "step": 41520
    },
    {
      "epoch": 2.59,
      "grad_norm": 5.8992815017700195,
      "learning_rate": 3.718773419935049e-05,
      "loss": 0.9741,
      "step": 41530
    },
    {
      "epoch": 2.59,
      "grad_norm": 8.07728385925293,
      "learning_rate": 3.7184611541343994e-05,
      "loss": 1.085,
      "step": 41540
    },
    {
      "epoch": 2.59,
      "grad_norm": 11.585379600524902,
      "learning_rate": 3.71814888833375e-05,
      "loss": 0.8397,
      "step": 41550
    },
    {
      "epoch": 2.59,
      "grad_norm": 11.002923965454102,
      "learning_rate": 3.7178366225331e-05,
      "loss": 1.0628,
      "step": 41560
    },
    {
      "epoch": 2.59,
      "grad_norm": 11.280956268310547,
      "learning_rate": 3.717524356732451e-05,
      "loss": 1.0069,
      "step": 41570
    },
    {
      "epoch": 2.59,
      "grad_norm": 9.6590576171875,
      "learning_rate": 3.7172120909318015e-05,
      "loss": 1.0935,
      "step": 41580
    },
    {
      "epoch": 2.59,
      "grad_norm": 12.453352928161621,
      "learning_rate": 3.716899825131152e-05,
      "loss": 0.9468,
      "step": 41590
    },
    {
      "epoch": 2.59,
      "grad_norm": 10.407097816467285,
      "learning_rate": 3.716587559330502e-05,
      "loss": 0.9127,
      "step": 41600
    },
    {
      "epoch": 2.59,
      "grad_norm": 7.100574970245361,
      "learning_rate": 3.716275293529853e-05,
      "loss": 1.1325,
      "step": 41610
    },
    {
      "epoch": 2.59,
      "grad_norm": 8.816553115844727,
      "learning_rate": 3.7159630277292035e-05,
      "loss": 1.0314,
      "step": 41620
    },
    {
      "epoch": 2.59,
      "grad_norm": 11.23751449584961,
      "learning_rate": 3.7156507619285535e-05,
      "loss": 0.9734,
      "step": 41630
    },
    {
      "epoch": 2.59,
      "grad_norm": 12.054997444152832,
      "learning_rate": 3.715338496127904e-05,
      "loss": 0.9409,
      "step": 41640
    },
    {
      "epoch": 2.59,
      "grad_norm": 19.18995475769043,
      "learning_rate": 3.715026230327255e-05,
      "loss": 0.991,
      "step": 41650
    },
    {
      "epoch": 2.59,
      "grad_norm": 12.3184175491333,
      "learning_rate": 3.7147139645266056e-05,
      "loss": 1.0624,
      "step": 41660
    },
    {
      "epoch": 2.59,
      "grad_norm": 10.560214042663574,
      "learning_rate": 3.7144016987259556e-05,
      "loss": 0.9618,
      "step": 41670
    },
    {
      "epoch": 2.59,
      "grad_norm": 12.504806518554688,
      "learning_rate": 3.714089432925306e-05,
      "loss": 0.9745,
      "step": 41680
    },
    {
      "epoch": 2.6,
      "grad_norm": 8.804640769958496,
      "learning_rate": 3.713777167124657e-05,
      "loss": 0.9919,
      "step": 41690
    },
    {
      "epoch": 2.6,
      "grad_norm": 10.022083282470703,
      "learning_rate": 3.713464901324007e-05,
      "loss": 1.0797,
      "step": 41700
    },
    {
      "epoch": 2.6,
      "grad_norm": 8.480022430419922,
      "learning_rate": 3.7131526355233576e-05,
      "loss": 0.9253,
      "step": 41710
    },
    {
      "epoch": 2.6,
      "grad_norm": 7.778538703918457,
      "learning_rate": 3.712840369722708e-05,
      "loss": 0.9903,
      "step": 41720
    },
    {
      "epoch": 2.6,
      "grad_norm": 17.132709503173828,
      "learning_rate": 3.712528103922059e-05,
      "loss": 1.0225,
      "step": 41730
    },
    {
      "epoch": 2.6,
      "grad_norm": 11.154963493347168,
      "learning_rate": 3.712215838121409e-05,
      "loss": 1.0078,
      "step": 41740
    },
    {
      "epoch": 2.6,
      "grad_norm": 14.85748291015625,
      "learning_rate": 3.71190357232076e-05,
      "loss": 0.9627,
      "step": 41750
    },
    {
      "epoch": 2.6,
      "grad_norm": 11.833035469055176,
      "learning_rate": 3.7115913065201104e-05,
      "loss": 0.8986,
      "step": 41760
    },
    {
      "epoch": 2.6,
      "grad_norm": 9.30924129486084,
      "learning_rate": 3.7112790407194604e-05,
      "loss": 1.039,
      "step": 41770
    },
    {
      "epoch": 2.6,
      "grad_norm": 16.65715789794922,
      "learning_rate": 3.710966774918811e-05,
      "loss": 0.9379,
      "step": 41780
    },
    {
      "epoch": 2.6,
      "grad_norm": 11.50411605834961,
      "learning_rate": 3.710654509118162e-05,
      "loss": 0.9972,
      "step": 41790
    },
    {
      "epoch": 2.6,
      "grad_norm": 14.318318367004395,
      "learning_rate": 3.7103422433175124e-05,
      "loss": 1.0337,
      "step": 41800
    },
    {
      "epoch": 2.6,
      "grad_norm": 10.84655475616455,
      "learning_rate": 3.7100299775168624e-05,
      "loss": 0.8801,
      "step": 41810
    },
    {
      "epoch": 2.6,
      "grad_norm": 14.733116149902344,
      "learning_rate": 3.709717711716213e-05,
      "loss": 0.911,
      "step": 41820
    },
    {
      "epoch": 2.6,
      "grad_norm": 11.921972274780273,
      "learning_rate": 3.709405445915564e-05,
      "loss": 1.043,
      "step": 41830
    },
    {
      "epoch": 2.6,
      "grad_norm": 18.36801528930664,
      "learning_rate": 3.7090931801149144e-05,
      "loss": 1.1237,
      "step": 41840
    },
    {
      "epoch": 2.61,
      "grad_norm": 12.623766899108887,
      "learning_rate": 3.7087809143142644e-05,
      "loss": 1.0228,
      "step": 41850
    },
    {
      "epoch": 2.61,
      "grad_norm": 8.395429611206055,
      "learning_rate": 3.708468648513615e-05,
      "loss": 0.9216,
      "step": 41860
    },
    {
      "epoch": 2.61,
      "grad_norm": 16.28189468383789,
      "learning_rate": 3.708156382712966e-05,
      "loss": 0.9127,
      "step": 41870
    },
    {
      "epoch": 2.61,
      "grad_norm": 6.5122785568237305,
      "learning_rate": 3.707844116912316e-05,
      "loss": 1.0725,
      "step": 41880
    },
    {
      "epoch": 2.61,
      "grad_norm": 13.921687126159668,
      "learning_rate": 3.7075318511116665e-05,
      "loss": 1.0344,
      "step": 41890
    },
    {
      "epoch": 2.61,
      "grad_norm": 13.694787979125977,
      "learning_rate": 3.707219585311017e-05,
      "loss": 1.106,
      "step": 41900
    },
    {
      "epoch": 2.61,
      "grad_norm": 11.287208557128906,
      "learning_rate": 3.706907319510368e-05,
      "loss": 1.0491,
      "step": 41910
    },
    {
      "epoch": 2.61,
      "grad_norm": 11.029388427734375,
      "learning_rate": 3.706595053709718e-05,
      "loss": 0.9614,
      "step": 41920
    },
    {
      "epoch": 2.61,
      "grad_norm": 10.058652877807617,
      "learning_rate": 3.7062827879090685e-05,
      "loss": 1.0521,
      "step": 41930
    },
    {
      "epoch": 2.61,
      "grad_norm": 10.048192024230957,
      "learning_rate": 3.705970522108419e-05,
      "loss": 0.9808,
      "step": 41940
    },
    {
      "epoch": 2.61,
      "grad_norm": 10.325950622558594,
      "learning_rate": 3.705658256307769e-05,
      "loss": 1.0581,
      "step": 41950
    },
    {
      "epoch": 2.61,
      "grad_norm": 8.511435508728027,
      "learning_rate": 3.70534599050712e-05,
      "loss": 1.0659,
      "step": 41960
    },
    {
      "epoch": 2.61,
      "grad_norm": 10.711931228637695,
      "learning_rate": 3.7050337247064706e-05,
      "loss": 1.0461,
      "step": 41970
    },
    {
      "epoch": 2.61,
      "grad_norm": 14.634241104125977,
      "learning_rate": 3.704721458905821e-05,
      "loss": 1.1305,
      "step": 41980
    },
    {
      "epoch": 2.61,
      "grad_norm": 7.333959579467773,
      "learning_rate": 3.704409193105171e-05,
      "loss": 0.9973,
      "step": 41990
    },
    {
      "epoch": 2.61,
      "grad_norm": 6.961575031280518,
      "learning_rate": 3.704096927304522e-05,
      "loss": 0.9585,
      "step": 42000
    },
    {
      "epoch": 2.62,
      "grad_norm": 7.611414909362793,
      "learning_rate": 3.7037846615038726e-05,
      "loss": 0.899,
      "step": 42010
    },
    {
      "epoch": 2.62,
      "grad_norm": 13.456538200378418,
      "learning_rate": 3.703472395703223e-05,
      "loss": 1.1399,
      "step": 42020
    },
    {
      "epoch": 2.62,
      "grad_norm": 12.01324462890625,
      "learning_rate": 3.703160129902573e-05,
      "loss": 1.012,
      "step": 42030
    },
    {
      "epoch": 2.62,
      "grad_norm": 10.466711044311523,
      "learning_rate": 3.702847864101924e-05,
      "loss": 0.9447,
      "step": 42040
    },
    {
      "epoch": 2.62,
      "grad_norm": 17.264005661010742,
      "learning_rate": 3.702535598301275e-05,
      "loss": 0.9248,
      "step": 42050
    },
    {
      "epoch": 2.62,
      "grad_norm": 12.679649353027344,
      "learning_rate": 3.702223332500625e-05,
      "loss": 0.9803,
      "step": 42060
    },
    {
      "epoch": 2.62,
      "grad_norm": 7.273024082183838,
      "learning_rate": 3.7019110666999754e-05,
      "loss": 0.8466,
      "step": 42070
    },
    {
      "epoch": 2.62,
      "grad_norm": 14.686009407043457,
      "learning_rate": 3.701598800899326e-05,
      "loss": 1.0402,
      "step": 42080
    },
    {
      "epoch": 2.62,
      "grad_norm": 8.467018127441406,
      "learning_rate": 3.701286535098677e-05,
      "loss": 0.9441,
      "step": 42090
    },
    {
      "epoch": 2.62,
      "grad_norm": 16.104581832885742,
      "learning_rate": 3.700974269298027e-05,
      "loss": 0.9914,
      "step": 42100
    },
    {
      "epoch": 2.62,
      "grad_norm": 13.17457103729248,
      "learning_rate": 3.7006620034973774e-05,
      "loss": 1.1556,
      "step": 42110
    },
    {
      "epoch": 2.62,
      "grad_norm": 7.360210418701172,
      "learning_rate": 3.700349737696728e-05,
      "loss": 0.9685,
      "step": 42120
    },
    {
      "epoch": 2.62,
      "grad_norm": 7.529273509979248,
      "learning_rate": 3.700037471896078e-05,
      "loss": 0.9082,
      "step": 42130
    },
    {
      "epoch": 2.62,
      "grad_norm": 10.22980785369873,
      "learning_rate": 3.699725206095429e-05,
      "loss": 0.9891,
      "step": 42140
    },
    {
      "epoch": 2.62,
      "grad_norm": 12.251274108886719,
      "learning_rate": 3.6994129402947794e-05,
      "loss": 1.0058,
      "step": 42150
    },
    {
      "epoch": 2.62,
      "grad_norm": 12.998135566711426,
      "learning_rate": 3.6991006744941294e-05,
      "loss": 1.0872,
      "step": 42160
    },
    {
      "epoch": 2.63,
      "grad_norm": 7.259578227996826,
      "learning_rate": 3.69878840869348e-05,
      "loss": 1.1066,
      "step": 42170
    },
    {
      "epoch": 2.63,
      "grad_norm": 10.800679206848145,
      "learning_rate": 3.698476142892831e-05,
      "loss": 1.1715,
      "step": 42180
    },
    {
      "epoch": 2.63,
      "grad_norm": 7.02061653137207,
      "learning_rate": 3.6981638770921815e-05,
      "loss": 0.9381,
      "step": 42190
    },
    {
      "epoch": 2.63,
      "grad_norm": 13.319306373596191,
      "learning_rate": 3.6978516112915315e-05,
      "loss": 0.9383,
      "step": 42200
    },
    {
      "epoch": 2.63,
      "grad_norm": 12.765995979309082,
      "learning_rate": 3.697539345490882e-05,
      "loss": 1.068,
      "step": 42210
    },
    {
      "epoch": 2.63,
      "grad_norm": 9.600409507751465,
      "learning_rate": 3.697227079690233e-05,
      "loss": 1.0678,
      "step": 42220
    },
    {
      "epoch": 2.63,
      "grad_norm": 8.380352020263672,
      "learning_rate": 3.696914813889583e-05,
      "loss": 0.981,
      "step": 42230
    },
    {
      "epoch": 2.63,
      "grad_norm": 7.0258073806762695,
      "learning_rate": 3.6966025480889335e-05,
      "loss": 0.9632,
      "step": 42240
    },
    {
      "epoch": 2.63,
      "grad_norm": 9.035696983337402,
      "learning_rate": 3.696290282288284e-05,
      "loss": 1.0564,
      "step": 42250
    },
    {
      "epoch": 2.63,
      "grad_norm": 7.124237537384033,
      "learning_rate": 3.695978016487634e-05,
      "loss": 1.1135,
      "step": 42260
    },
    {
      "epoch": 2.63,
      "grad_norm": 10.372834205627441,
      "learning_rate": 3.695665750686985e-05,
      "loss": 1.0813,
      "step": 42270
    },
    {
      "epoch": 2.63,
      "grad_norm": 10.418990135192871,
      "learning_rate": 3.6953534848863356e-05,
      "loss": 0.9464,
      "step": 42280
    },
    {
      "epoch": 2.63,
      "grad_norm": 8.89376449584961,
      "learning_rate": 3.6950412190856856e-05,
      "loss": 0.9908,
      "step": 42290
    },
    {
      "epoch": 2.63,
      "grad_norm": 11.75887393951416,
      "learning_rate": 3.694728953285036e-05,
      "loss": 1.1068,
      "step": 42300
    },
    {
      "epoch": 2.63,
      "grad_norm": 9.996281623840332,
      "learning_rate": 3.694416687484387e-05,
      "loss": 0.883,
      "step": 42310
    },
    {
      "epoch": 2.63,
      "grad_norm": 10.579100608825684,
      "learning_rate": 3.694104421683737e-05,
      "loss": 0.8539,
      "step": 42320
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.778470039367676,
      "learning_rate": 3.6937921558830876e-05,
      "loss": 0.9627,
      "step": 42330
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.74154281616211,
      "learning_rate": 3.693479890082438e-05,
      "loss": 1.0932,
      "step": 42340
    },
    {
      "epoch": 2.64,
      "grad_norm": 18.317150115966797,
      "learning_rate": 3.693167624281788e-05,
      "loss": 0.9267,
      "step": 42350
    },
    {
      "epoch": 2.64,
      "grad_norm": 10.215109825134277,
      "learning_rate": 3.692855358481139e-05,
      "loss": 0.8705,
      "step": 42360
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.913527488708496,
      "learning_rate": 3.69254309268049e-05,
      "loss": 0.9841,
      "step": 42370
    },
    {
      "epoch": 2.64,
      "grad_norm": 7.72910213470459,
      "learning_rate": 3.6922308268798404e-05,
      "loss": 0.9322,
      "step": 42380
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.400603294372559,
      "learning_rate": 3.6919185610791904e-05,
      "loss": 0.9834,
      "step": 42390
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.189790725708008,
      "learning_rate": 3.691606295278541e-05,
      "loss": 0.9458,
      "step": 42400
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.289742469787598,
      "learning_rate": 3.691294029477892e-05,
      "loss": 0.9055,
      "step": 42410
    },
    {
      "epoch": 2.64,
      "grad_norm": 9.178112030029297,
      "learning_rate": 3.690981763677242e-05,
      "loss": 1.2217,
      "step": 42420
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.082930088043213,
      "learning_rate": 3.6906694978765924e-05,
      "loss": 0.9929,
      "step": 42430
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.215767860412598,
      "learning_rate": 3.690357232075943e-05,
      "loss": 0.9316,
      "step": 42440
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.412260055541992,
      "learning_rate": 3.690044966275294e-05,
      "loss": 1.0626,
      "step": 42450
    },
    {
      "epoch": 2.64,
      "grad_norm": 10.517178535461426,
      "learning_rate": 3.689732700474644e-05,
      "loss": 1.0817,
      "step": 42460
    },
    {
      "epoch": 2.64,
      "grad_norm": 13.296849250793457,
      "learning_rate": 3.6894204346739944e-05,
      "loss": 1.0883,
      "step": 42470
    },
    {
      "epoch": 2.64,
      "grad_norm": 8.445160865783691,
      "learning_rate": 3.689108168873345e-05,
      "loss": 1.0444,
      "step": 42480
    },
    {
      "epoch": 2.65,
      "grad_norm": 8.617724418640137,
      "learning_rate": 3.688795903072695e-05,
      "loss": 0.9166,
      "step": 42490
    },
    {
      "epoch": 2.65,
      "grad_norm": 7.794239044189453,
      "learning_rate": 3.688483637272046e-05,
      "loss": 0.9768,
      "step": 42500
    },
    {
      "epoch": 2.65,
      "grad_norm": 10.52927017211914,
      "learning_rate": 3.6881713714713965e-05,
      "loss": 1.0848,
      "step": 42510
    },
    {
      "epoch": 2.65,
      "grad_norm": 20.03642463684082,
      "learning_rate": 3.687859105670747e-05,
      "loss": 0.9404,
      "step": 42520
    },
    {
      "epoch": 2.65,
      "grad_norm": 7.031342029571533,
      "learning_rate": 3.687546839870097e-05,
      "loss": 0.9956,
      "step": 42530
    },
    {
      "epoch": 2.65,
      "grad_norm": 7.052414417266846,
      "learning_rate": 3.687234574069448e-05,
      "loss": 0.8435,
      "step": 42540
    },
    {
      "epoch": 2.65,
      "grad_norm": 10.43084716796875,
      "learning_rate": 3.6869223082687985e-05,
      "loss": 1.0021,
      "step": 42550
    },
    {
      "epoch": 2.65,
      "grad_norm": 8.715672492980957,
      "learning_rate": 3.686610042468149e-05,
      "loss": 0.8746,
      "step": 42560
    },
    {
      "epoch": 2.65,
      "grad_norm": 12.260629653930664,
      "learning_rate": 3.686297776667499e-05,
      "loss": 1.09,
      "step": 42570
    },
    {
      "epoch": 2.65,
      "grad_norm": 15.418560981750488,
      "learning_rate": 3.68598551086685e-05,
      "loss": 1.1232,
      "step": 42580
    },
    {
      "epoch": 2.65,
      "grad_norm": 12.396323204040527,
      "learning_rate": 3.6856732450662006e-05,
      "loss": 1.0623,
      "step": 42590
    },
    {
      "epoch": 2.65,
      "grad_norm": 13.566102981567383,
      "learning_rate": 3.6853609792655506e-05,
      "loss": 1.012,
      "step": 42600
    },
    {
      "epoch": 2.65,
      "grad_norm": 9.907402038574219,
      "learning_rate": 3.685048713464901e-05,
      "loss": 1.0634,
      "step": 42610
    },
    {
      "epoch": 2.65,
      "grad_norm": 12.58547306060791,
      "learning_rate": 3.684736447664252e-05,
      "loss": 0.9479,
      "step": 42620
    },
    {
      "epoch": 2.65,
      "grad_norm": 10.491077423095703,
      "learning_rate": 3.6844241818636026e-05,
      "loss": 0.9677,
      "step": 42630
    },
    {
      "epoch": 2.65,
      "grad_norm": 13.200661659240723,
      "learning_rate": 3.6841119160629526e-05,
      "loss": 1.0334,
      "step": 42640
    },
    {
      "epoch": 2.66,
      "grad_norm": 12.523919105529785,
      "learning_rate": 3.683799650262303e-05,
      "loss": 1.0112,
      "step": 42650
    },
    {
      "epoch": 2.66,
      "grad_norm": 6.331995010375977,
      "learning_rate": 3.683487384461654e-05,
      "loss": 0.9231,
      "step": 42660
    },
    {
      "epoch": 2.66,
      "grad_norm": 8.72370433807373,
      "learning_rate": 3.683175118661004e-05,
      "loss": 1.0499,
      "step": 42670
    },
    {
      "epoch": 2.66,
      "grad_norm": 10.754430770874023,
      "learning_rate": 3.682862852860355e-05,
      "loss": 0.9081,
      "step": 42680
    },
    {
      "epoch": 2.66,
      "grad_norm": 9.082999229431152,
      "learning_rate": 3.6825505870597054e-05,
      "loss": 1.0488,
      "step": 42690
    },
    {
      "epoch": 2.66,
      "grad_norm": 8.190637588500977,
      "learning_rate": 3.682238321259056e-05,
      "loss": 0.9252,
      "step": 42700
    },
    {
      "epoch": 2.66,
      "grad_norm": 12.378159523010254,
      "learning_rate": 3.681926055458406e-05,
      "loss": 1.0362,
      "step": 42710
    },
    {
      "epoch": 2.66,
      "grad_norm": 9.431669235229492,
      "learning_rate": 3.681613789657757e-05,
      "loss": 0.9614,
      "step": 42720
    },
    {
      "epoch": 2.66,
      "grad_norm": 8.793773651123047,
      "learning_rate": 3.6813015238571074e-05,
      "loss": 1.0412,
      "step": 42730
    },
    {
      "epoch": 2.66,
      "grad_norm": 10.386996269226074,
      "learning_rate": 3.6809892580564574e-05,
      "loss": 0.9993,
      "step": 42740
    },
    {
      "epoch": 2.66,
      "grad_norm": 11.898816108703613,
      "learning_rate": 3.680676992255808e-05,
      "loss": 1.0982,
      "step": 42750
    },
    {
      "epoch": 2.66,
      "grad_norm": 9.52119255065918,
      "learning_rate": 3.680364726455159e-05,
      "loss": 1.0036,
      "step": 42760
    },
    {
      "epoch": 2.66,
      "grad_norm": 12.055440902709961,
      "learning_rate": 3.6800524606545094e-05,
      "loss": 1.0149,
      "step": 42770
    },
    {
      "epoch": 2.66,
      "grad_norm": 9.05111312866211,
      "learning_rate": 3.6797401948538594e-05,
      "loss": 0.9312,
      "step": 42780
    },
    {
      "epoch": 2.66,
      "grad_norm": 10.901725769042969,
      "learning_rate": 3.67942792905321e-05,
      "loss": 1.1001,
      "step": 42790
    },
    {
      "epoch": 2.66,
      "grad_norm": 15.411699295043945,
      "learning_rate": 3.679115663252561e-05,
      "loss": 1.0318,
      "step": 42800
    },
    {
      "epoch": 2.67,
      "grad_norm": 10.487997055053711,
      "learning_rate": 3.6788033974519115e-05,
      "loss": 1.0206,
      "step": 42810
    },
    {
      "epoch": 2.67,
      "grad_norm": 10.052359580993652,
      "learning_rate": 3.6784911316512615e-05,
      "loss": 0.8577,
      "step": 42820
    },
    {
      "epoch": 2.67,
      "grad_norm": 11.464762687683105,
      "learning_rate": 3.678178865850612e-05,
      "loss": 0.9781,
      "step": 42830
    },
    {
      "epoch": 2.67,
      "grad_norm": 7.705286979675293,
      "learning_rate": 3.677866600049963e-05,
      "loss": 0.9943,
      "step": 42840
    },
    {
      "epoch": 2.67,
      "grad_norm": 12.100622177124023,
      "learning_rate": 3.677554334249313e-05,
      "loss": 1.0432,
      "step": 42850
    },
    {
      "epoch": 2.67,
      "grad_norm": 6.474550247192383,
      "learning_rate": 3.6772420684486635e-05,
      "loss": 1.1366,
      "step": 42860
    },
    {
      "epoch": 2.67,
      "grad_norm": 7.5118513107299805,
      "learning_rate": 3.676929802648014e-05,
      "loss": 1.0027,
      "step": 42870
    },
    {
      "epoch": 2.67,
      "grad_norm": 11.495898246765137,
      "learning_rate": 3.676617536847365e-05,
      "loss": 0.96,
      "step": 42880
    },
    {
      "epoch": 2.67,
      "grad_norm": 10.369009017944336,
      "learning_rate": 3.676305271046715e-05,
      "loss": 1.0682,
      "step": 42890
    },
    {
      "epoch": 2.67,
      "grad_norm": 10.455848693847656,
      "learning_rate": 3.6759930052460656e-05,
      "loss": 0.8905,
      "step": 42900
    },
    {
      "epoch": 2.67,
      "grad_norm": 9.377781867980957,
      "learning_rate": 3.675680739445416e-05,
      "loss": 1.0563,
      "step": 42910
    },
    {
      "epoch": 2.67,
      "grad_norm": 8.905921936035156,
      "learning_rate": 3.675368473644766e-05,
      "loss": 1.0801,
      "step": 42920
    },
    {
      "epoch": 2.67,
      "grad_norm": 9.144073486328125,
      "learning_rate": 3.675056207844117e-05,
      "loss": 0.998,
      "step": 42930
    },
    {
      "epoch": 2.67,
      "grad_norm": 8.920161247253418,
      "learning_rate": 3.6747439420434676e-05,
      "loss": 0.9787,
      "step": 42940
    },
    {
      "epoch": 2.67,
      "grad_norm": 9.688187599182129,
      "learning_rate": 3.674431676242818e-05,
      "loss": 1.0052,
      "step": 42950
    },
    {
      "epoch": 2.67,
      "grad_norm": 11.31838607788086,
      "learning_rate": 3.674119410442168e-05,
      "loss": 0.8873,
      "step": 42960
    },
    {
      "epoch": 2.68,
      "grad_norm": 9.116744041442871,
      "learning_rate": 3.673807144641519e-05,
      "loss": 1.1703,
      "step": 42970
    },
    {
      "epoch": 2.68,
      "grad_norm": 9.655693054199219,
      "learning_rate": 3.67349487884087e-05,
      "loss": 0.9736,
      "step": 42980
    },
    {
      "epoch": 2.68,
      "grad_norm": 9.289030075073242,
      "learning_rate": 3.6731826130402204e-05,
      "loss": 0.9578,
      "step": 42990
    },
    {
      "epoch": 2.68,
      "grad_norm": 11.551688194274902,
      "learning_rate": 3.6728703472395704e-05,
      "loss": 1.1073,
      "step": 43000
    },
    {
      "epoch": 2.68,
      "grad_norm": 13.874494552612305,
      "learning_rate": 3.672558081438921e-05,
      "loss": 1.0164,
      "step": 43010
    },
    {
      "epoch": 2.68,
      "grad_norm": 9.96611213684082,
      "learning_rate": 3.672245815638272e-05,
      "loss": 1.1102,
      "step": 43020
    },
    {
      "epoch": 2.68,
      "grad_norm": 5.898728370666504,
      "learning_rate": 3.671933549837622e-05,
      "loss": 0.9884,
      "step": 43030
    },
    {
      "epoch": 2.68,
      "grad_norm": 7.747194766998291,
      "learning_rate": 3.6716212840369724e-05,
      "loss": 0.9193,
      "step": 43040
    },
    {
      "epoch": 2.68,
      "grad_norm": 11.986407279968262,
      "learning_rate": 3.671309018236323e-05,
      "loss": 0.9797,
      "step": 43050
    },
    {
      "epoch": 2.68,
      "grad_norm": 13.265576362609863,
      "learning_rate": 3.670996752435674e-05,
      "loss": 0.9253,
      "step": 43060
    },
    {
      "epoch": 2.68,
      "grad_norm": 9.64359188079834,
      "learning_rate": 3.670684486635024e-05,
      "loss": 0.9633,
      "step": 43070
    },
    {
      "epoch": 2.68,
      "grad_norm": 12.523921012878418,
      "learning_rate": 3.6703722208343744e-05,
      "loss": 1.0617,
      "step": 43080
    },
    {
      "epoch": 2.68,
      "grad_norm": 18.010787963867188,
      "learning_rate": 3.670059955033725e-05,
      "loss": 0.9705,
      "step": 43090
    },
    {
      "epoch": 2.68,
      "grad_norm": 10.516366004943848,
      "learning_rate": 3.669747689233075e-05,
      "loss": 0.9924,
      "step": 43100
    },
    {
      "epoch": 2.68,
      "grad_norm": 12.002214431762695,
      "learning_rate": 3.669435423432426e-05,
      "loss": 1.0309,
      "step": 43110
    },
    {
      "epoch": 2.68,
      "grad_norm": 11.112213134765625,
      "learning_rate": 3.6691231576317765e-05,
      "loss": 1.0523,
      "step": 43120
    },
    {
      "epoch": 2.69,
      "grad_norm": 8.263660430908203,
      "learning_rate": 3.668810891831127e-05,
      "loss": 0.9805,
      "step": 43130
    },
    {
      "epoch": 2.69,
      "grad_norm": 6.716468811035156,
      "learning_rate": 3.668498626030477e-05,
      "loss": 1.0409,
      "step": 43140
    },
    {
      "epoch": 2.69,
      "grad_norm": 14.34814453125,
      "learning_rate": 3.668186360229828e-05,
      "loss": 1.0807,
      "step": 43150
    },
    {
      "epoch": 2.69,
      "grad_norm": 11.865032196044922,
      "learning_rate": 3.6678740944291785e-05,
      "loss": 1.1034,
      "step": 43160
    },
    {
      "epoch": 2.69,
      "grad_norm": 16.460817337036133,
      "learning_rate": 3.667561828628529e-05,
      "loss": 1.0554,
      "step": 43170
    },
    {
      "epoch": 2.69,
      "grad_norm": 8.630508422851562,
      "learning_rate": 3.667249562827879e-05,
      "loss": 1.0296,
      "step": 43180
    },
    {
      "epoch": 2.69,
      "grad_norm": 10.15287971496582,
      "learning_rate": 3.66693729702723e-05,
      "loss": 1.0115,
      "step": 43190
    },
    {
      "epoch": 2.69,
      "grad_norm": 12.733477592468262,
      "learning_rate": 3.6666250312265806e-05,
      "loss": 0.9338,
      "step": 43200
    },
    {
      "epoch": 2.69,
      "grad_norm": 10.138069152832031,
      "learning_rate": 3.6663127654259306e-05,
      "loss": 0.9447,
      "step": 43210
    },
    {
      "epoch": 2.69,
      "grad_norm": 7.294477939605713,
      "learning_rate": 3.666000499625281e-05,
      "loss": 0.8699,
      "step": 43220
    },
    {
      "epoch": 2.69,
      "grad_norm": 11.657830238342285,
      "learning_rate": 3.665688233824632e-05,
      "loss": 1.0359,
      "step": 43230
    },
    {
      "epoch": 2.69,
      "grad_norm": 11.489737510681152,
      "learning_rate": 3.6653759680239826e-05,
      "loss": 1.0959,
      "step": 43240
    },
    {
      "epoch": 2.69,
      "grad_norm": 13.697135925292969,
      "learning_rate": 3.6650637022233326e-05,
      "loss": 1.1002,
      "step": 43250
    },
    {
      "epoch": 2.69,
      "grad_norm": 9.091465950012207,
      "learning_rate": 3.664751436422683e-05,
      "loss": 1.1139,
      "step": 43260
    },
    {
      "epoch": 2.69,
      "grad_norm": 11.075105667114258,
      "learning_rate": 3.664439170622034e-05,
      "loss": 0.9958,
      "step": 43270
    },
    {
      "epoch": 2.69,
      "grad_norm": 18.215871810913086,
      "learning_rate": 3.664126904821384e-05,
      "loss": 0.9753,
      "step": 43280
    },
    {
      "epoch": 2.7,
      "grad_norm": 15.57547664642334,
      "learning_rate": 3.663814639020735e-05,
      "loss": 1.1497,
      "step": 43290
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.32059097290039,
      "learning_rate": 3.6635023732200854e-05,
      "loss": 0.9167,
      "step": 43300
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.265636444091797,
      "learning_rate": 3.663190107419436e-05,
      "loss": 1.1464,
      "step": 43310
    },
    {
      "epoch": 2.7,
      "grad_norm": 10.45937728881836,
      "learning_rate": 3.662877841618786e-05,
      "loss": 1.0067,
      "step": 43320
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.282510757446289,
      "learning_rate": 3.662565575818137e-05,
      "loss": 0.9471,
      "step": 43330
    },
    {
      "epoch": 2.7,
      "grad_norm": 10.281115531921387,
      "learning_rate": 3.6622533100174874e-05,
      "loss": 1.1856,
      "step": 43340
    },
    {
      "epoch": 2.7,
      "grad_norm": 10.575610160827637,
      "learning_rate": 3.661941044216838e-05,
      "loss": 1.0365,
      "step": 43350
    },
    {
      "epoch": 2.7,
      "grad_norm": 12.377567291259766,
      "learning_rate": 3.661628778416188e-05,
      "loss": 1.0103,
      "step": 43360
    },
    {
      "epoch": 2.7,
      "grad_norm": 6.266674041748047,
      "learning_rate": 3.661316512615539e-05,
      "loss": 1.1624,
      "step": 43370
    },
    {
      "epoch": 2.7,
      "grad_norm": 8.713739395141602,
      "learning_rate": 3.6610042468148894e-05,
      "loss": 0.992,
      "step": 43380
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.201497077941895,
      "learning_rate": 3.6606919810142394e-05,
      "loss": 1.136,
      "step": 43390
    },
    {
      "epoch": 2.7,
      "grad_norm": 8.536947250366211,
      "learning_rate": 3.66037971521359e-05,
      "loss": 0.9351,
      "step": 43400
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.496996879577637,
      "learning_rate": 3.660067449412941e-05,
      "loss": 0.9819,
      "step": 43410
    },
    {
      "epoch": 2.7,
      "grad_norm": 11.846323013305664,
      "learning_rate": 3.6597551836122915e-05,
      "loss": 1.0556,
      "step": 43420
    },
    {
      "epoch": 2.7,
      "grad_norm": 7.7505202293396,
      "learning_rate": 3.6594429178116415e-05,
      "loss": 0.9593,
      "step": 43430
    },
    {
      "epoch": 2.7,
      "grad_norm": 13.760045051574707,
      "learning_rate": 3.659130652010992e-05,
      "loss": 1.0379,
      "step": 43440
    },
    {
      "epoch": 2.71,
      "grad_norm": 10.132259368896484,
      "learning_rate": 3.658818386210343e-05,
      "loss": 1.0205,
      "step": 43450
    },
    {
      "epoch": 2.71,
      "grad_norm": 23.95659637451172,
      "learning_rate": 3.658506120409693e-05,
      "loss": 1.1123,
      "step": 43460
    },
    {
      "epoch": 2.71,
      "grad_norm": 10.427411079406738,
      "learning_rate": 3.6581938546090435e-05,
      "loss": 1.1496,
      "step": 43470
    },
    {
      "epoch": 2.71,
      "grad_norm": 7.152646064758301,
      "learning_rate": 3.657881588808394e-05,
      "loss": 0.9322,
      "step": 43480
    },
    {
      "epoch": 2.71,
      "grad_norm": 10.212165832519531,
      "learning_rate": 3.657569323007745e-05,
      "loss": 1.0449,
      "step": 43490
    },
    {
      "epoch": 2.71,
      "grad_norm": 5.502686500549316,
      "learning_rate": 3.657257057207095e-05,
      "loss": 1.0523,
      "step": 43500
    },
    {
      "epoch": 2.71,
      "grad_norm": 7.634947299957275,
      "learning_rate": 3.6569447914064456e-05,
      "loss": 0.8948,
      "step": 43510
    },
    {
      "epoch": 2.71,
      "grad_norm": 6.909984111785889,
      "learning_rate": 3.656632525605796e-05,
      "loss": 0.9393,
      "step": 43520
    },
    {
      "epoch": 2.71,
      "grad_norm": 8.96808910369873,
      "learning_rate": 3.656320259805146e-05,
      "loss": 0.9994,
      "step": 43530
    },
    {
      "epoch": 2.71,
      "grad_norm": 14.408041000366211,
      "learning_rate": 3.656007994004497e-05,
      "loss": 1.0517,
      "step": 43540
    },
    {
      "epoch": 2.71,
      "grad_norm": 10.723587989807129,
      "learning_rate": 3.6556957282038476e-05,
      "loss": 1.0008,
      "step": 43550
    },
    {
      "epoch": 2.71,
      "grad_norm": 11.480748176574707,
      "learning_rate": 3.6553834624031976e-05,
      "loss": 1.0579,
      "step": 43560
    },
    {
      "epoch": 2.71,
      "grad_norm": 8.360631942749023,
      "learning_rate": 3.655071196602548e-05,
      "loss": 1.0894,
      "step": 43570
    },
    {
      "epoch": 2.71,
      "grad_norm": 8.698003768920898,
      "learning_rate": 3.654758930801899e-05,
      "loss": 1.0394,
      "step": 43580
    },
    {
      "epoch": 2.71,
      "grad_norm": 8.484376907348633,
      "learning_rate": 3.654446665001249e-05,
      "loss": 1.0393,
      "step": 43590
    },
    {
      "epoch": 2.71,
      "grad_norm": 12.976353645324707,
      "learning_rate": 3.6541343992006e-05,
      "loss": 1.2604,
      "step": 43600
    },
    {
      "epoch": 2.72,
      "grad_norm": 11.504830360412598,
      "learning_rate": 3.6538221333999504e-05,
      "loss": 1.0375,
      "step": 43610
    },
    {
      "epoch": 2.72,
      "grad_norm": 11.260871887207031,
      "learning_rate": 3.6535098675993004e-05,
      "loss": 1.1135,
      "step": 43620
    },
    {
      "epoch": 2.72,
      "grad_norm": 7.927159309387207,
      "learning_rate": 3.653197601798651e-05,
      "loss": 0.9122,
      "step": 43630
    },
    {
      "epoch": 2.72,
      "grad_norm": 11.844850540161133,
      "learning_rate": 3.652885335998002e-05,
      "loss": 0.9834,
      "step": 43640
    },
    {
      "epoch": 2.72,
      "grad_norm": 11.106390953063965,
      "learning_rate": 3.6525730701973524e-05,
      "loss": 0.8978,
      "step": 43650
    },
    {
      "epoch": 2.72,
      "grad_norm": 9.589587211608887,
      "learning_rate": 3.6522608043967024e-05,
      "loss": 0.9913,
      "step": 43660
    },
    {
      "epoch": 2.72,
      "grad_norm": 13.82726001739502,
      "learning_rate": 3.651948538596053e-05,
      "loss": 0.9783,
      "step": 43670
    },
    {
      "epoch": 2.72,
      "grad_norm": 17.390844345092773,
      "learning_rate": 3.651636272795404e-05,
      "loss": 1.1465,
      "step": 43680
    },
    {
      "epoch": 2.72,
      "grad_norm": 8.373700141906738,
      "learning_rate": 3.651324006994754e-05,
      "loss": 1.0361,
      "step": 43690
    },
    {
      "epoch": 2.72,
      "grad_norm": 12.144984245300293,
      "learning_rate": 3.6510117411941045e-05,
      "loss": 0.9712,
      "step": 43700
    },
    {
      "epoch": 2.72,
      "grad_norm": 12.527329444885254,
      "learning_rate": 3.650699475393455e-05,
      "loss": 1.0222,
      "step": 43710
    },
    {
      "epoch": 2.72,
      "grad_norm": 7.904127597808838,
      "learning_rate": 3.650387209592805e-05,
      "loss": 1.0224,
      "step": 43720
    },
    {
      "epoch": 2.72,
      "grad_norm": 9.286699295043945,
      "learning_rate": 3.650074943792156e-05,
      "loss": 1.0818,
      "step": 43730
    },
    {
      "epoch": 2.72,
      "grad_norm": 12.247879981994629,
      "learning_rate": 3.6497626779915065e-05,
      "loss": 1.1102,
      "step": 43740
    },
    {
      "epoch": 2.72,
      "grad_norm": 9.9092435836792,
      "learning_rate": 3.6494504121908565e-05,
      "loss": 0.9538,
      "step": 43750
    },
    {
      "epoch": 2.72,
      "grad_norm": 8.499526977539062,
      "learning_rate": 3.649138146390207e-05,
      "loss": 1.0606,
      "step": 43760
    },
    {
      "epoch": 2.73,
      "grad_norm": 12.569096565246582,
      "learning_rate": 3.648825880589558e-05,
      "loss": 1.0696,
      "step": 43770
    },
    {
      "epoch": 2.73,
      "grad_norm": 13.910578727722168,
      "learning_rate": 3.6485136147889085e-05,
      "loss": 0.9758,
      "step": 43780
    },
    {
      "epoch": 2.73,
      "grad_norm": 8.807723999023438,
      "learning_rate": 3.6482013489882585e-05,
      "loss": 1.0699,
      "step": 43790
    },
    {
      "epoch": 2.73,
      "grad_norm": 8.67133903503418,
      "learning_rate": 3.647889083187609e-05,
      "loss": 0.9851,
      "step": 43800
    },
    {
      "epoch": 2.73,
      "grad_norm": 5.266408443450928,
      "learning_rate": 3.64757681738696e-05,
      "loss": 0.8804,
      "step": 43810
    },
    {
      "epoch": 2.73,
      "grad_norm": 7.943084239959717,
      "learning_rate": 3.64726455158631e-05,
      "loss": 1.0443,
      "step": 43820
    },
    {
      "epoch": 2.73,
      "grad_norm": 10.096467018127441,
      "learning_rate": 3.6469522857856606e-05,
      "loss": 0.9946,
      "step": 43830
    },
    {
      "epoch": 2.73,
      "grad_norm": 8.23243522644043,
      "learning_rate": 3.646640019985011e-05,
      "loss": 1.1675,
      "step": 43840
    },
    {
      "epoch": 2.73,
      "grad_norm": 8.148456573486328,
      "learning_rate": 3.646327754184362e-05,
      "loss": 1.0058,
      "step": 43850
    },
    {
      "epoch": 2.73,
      "grad_norm": 11.481650352478027,
      "learning_rate": 3.646015488383712e-05,
      "loss": 0.9996,
      "step": 43860
    },
    {
      "epoch": 2.73,
      "grad_norm": 9.936450004577637,
      "learning_rate": 3.6457032225830626e-05,
      "loss": 1.0754,
      "step": 43870
    },
    {
      "epoch": 2.73,
      "grad_norm": 13.707408905029297,
      "learning_rate": 3.645390956782413e-05,
      "loss": 1.115,
      "step": 43880
    },
    {
      "epoch": 2.73,
      "grad_norm": 12.43124771118164,
      "learning_rate": 3.645078690981763e-05,
      "loss": 0.9491,
      "step": 43890
    },
    {
      "epoch": 2.73,
      "grad_norm": 7.574726581573486,
      "learning_rate": 3.644766425181114e-05,
      "loss": 1.0292,
      "step": 43900
    },
    {
      "epoch": 2.73,
      "grad_norm": 14.4528226852417,
      "learning_rate": 3.644454159380465e-05,
      "loss": 0.9194,
      "step": 43910
    },
    {
      "epoch": 2.73,
      "grad_norm": 9.987133979797363,
      "learning_rate": 3.6441418935798154e-05,
      "loss": 0.9115,
      "step": 43920
    },
    {
      "epoch": 2.74,
      "grad_norm": 12.205598831176758,
      "learning_rate": 3.6438296277791654e-05,
      "loss": 0.9619,
      "step": 43930
    },
    {
      "epoch": 2.74,
      "grad_norm": 13.876221656799316,
      "learning_rate": 3.643517361978516e-05,
      "loss": 0.9772,
      "step": 43940
    },
    {
      "epoch": 2.74,
      "grad_norm": 11.086947441101074,
      "learning_rate": 3.643205096177867e-05,
      "loss": 1.0717,
      "step": 43950
    },
    {
      "epoch": 2.74,
      "grad_norm": 8.595273971557617,
      "learning_rate": 3.6428928303772174e-05,
      "loss": 1.0897,
      "step": 43960
    },
    {
      "epoch": 2.74,
      "grad_norm": 10.79072093963623,
      "learning_rate": 3.6425805645765674e-05,
      "loss": 1.0892,
      "step": 43970
    },
    {
      "epoch": 2.74,
      "grad_norm": 5.6458916664123535,
      "learning_rate": 3.642268298775918e-05,
      "loss": 0.9514,
      "step": 43980
    },
    {
      "epoch": 2.74,
      "grad_norm": 8.149847030639648,
      "learning_rate": 3.641956032975269e-05,
      "loss": 1.1144,
      "step": 43990
    },
    {
      "epoch": 2.74,
      "grad_norm": 12.271775245666504,
      "learning_rate": 3.641643767174619e-05,
      "loss": 0.9391,
      "step": 44000
    },
    {
      "epoch": 2.74,
      "grad_norm": 11.405702590942383,
      "learning_rate": 3.6413315013739695e-05,
      "loss": 1.1306,
      "step": 44010
    },
    {
      "epoch": 2.74,
      "grad_norm": 8.57220458984375,
      "learning_rate": 3.64101923557332e-05,
      "loss": 1.0042,
      "step": 44020
    },
    {
      "epoch": 2.74,
      "grad_norm": 14.42602252960205,
      "learning_rate": 3.640706969772671e-05,
      "loss": 1.0873,
      "step": 44030
    },
    {
      "epoch": 2.74,
      "grad_norm": 10.553718566894531,
      "learning_rate": 3.640394703972021e-05,
      "loss": 0.8869,
      "step": 44040
    },
    {
      "epoch": 2.74,
      "grad_norm": 12.211121559143066,
      "learning_rate": 3.6400824381713715e-05,
      "loss": 0.9002,
      "step": 44050
    },
    {
      "epoch": 2.74,
      "grad_norm": 13.941487312316895,
      "learning_rate": 3.639770172370722e-05,
      "loss": 1.1731,
      "step": 44060
    },
    {
      "epoch": 2.74,
      "grad_norm": 9.25267219543457,
      "learning_rate": 3.639457906570072e-05,
      "loss": 0.9499,
      "step": 44070
    },
    {
      "epoch": 2.74,
      "grad_norm": 8.169867515563965,
      "learning_rate": 3.639145640769423e-05,
      "loss": 0.8437,
      "step": 44080
    },
    {
      "epoch": 2.74,
      "grad_norm": 13.72032642364502,
      "learning_rate": 3.6388333749687735e-05,
      "loss": 1.045,
      "step": 44090
    },
    {
      "epoch": 2.75,
      "grad_norm": 11.180190086364746,
      "learning_rate": 3.638521109168124e-05,
      "loss": 1.0579,
      "step": 44100
    },
    {
      "epoch": 2.75,
      "grad_norm": 7.965151786804199,
      "learning_rate": 3.638208843367474e-05,
      "loss": 0.9335,
      "step": 44110
    },
    {
      "epoch": 2.75,
      "grad_norm": 12.322738647460938,
      "learning_rate": 3.637896577566825e-05,
      "loss": 1.1418,
      "step": 44120
    },
    {
      "epoch": 2.75,
      "grad_norm": 11.006247520446777,
      "learning_rate": 3.6375843117661756e-05,
      "loss": 1.0399,
      "step": 44130
    },
    {
      "epoch": 2.75,
      "grad_norm": 11.288686752319336,
      "learning_rate": 3.637272045965526e-05,
      "loss": 1.0181,
      "step": 44140
    },
    {
      "epoch": 2.75,
      "grad_norm": 10.701443672180176,
      "learning_rate": 3.636959780164876e-05,
      "loss": 1.1708,
      "step": 44150
    },
    {
      "epoch": 2.75,
      "grad_norm": 9.350090026855469,
      "learning_rate": 3.636647514364227e-05,
      "loss": 1.0467,
      "step": 44160
    },
    {
      "epoch": 2.75,
      "grad_norm": 6.805398464202881,
      "learning_rate": 3.6363352485635776e-05,
      "loss": 0.9518,
      "step": 44170
    },
    {
      "epoch": 2.75,
      "grad_norm": 11.609001159667969,
      "learning_rate": 3.6360229827629276e-05,
      "loss": 1.0146,
      "step": 44180
    },
    {
      "epoch": 2.75,
      "grad_norm": 7.066641807556152,
      "learning_rate": 3.635710716962278e-05,
      "loss": 1.0053,
      "step": 44190
    },
    {
      "epoch": 2.75,
      "grad_norm": 7.712360858917236,
      "learning_rate": 3.635398451161629e-05,
      "loss": 0.9183,
      "step": 44200
    },
    {
      "epoch": 2.75,
      "grad_norm": 8.093742370605469,
      "learning_rate": 3.63508618536098e-05,
      "loss": 0.9525,
      "step": 44210
    },
    {
      "epoch": 2.75,
      "grad_norm": 12.35116195678711,
      "learning_rate": 3.63477391956033e-05,
      "loss": 0.9915,
      "step": 44220
    },
    {
      "epoch": 2.75,
      "grad_norm": 13.219287872314453,
      "learning_rate": 3.6344616537596804e-05,
      "loss": 0.8544,
      "step": 44230
    },
    {
      "epoch": 2.75,
      "grad_norm": 12.43625545501709,
      "learning_rate": 3.634149387959031e-05,
      "loss": 1.1123,
      "step": 44240
    },
    {
      "epoch": 2.75,
      "grad_norm": 12.485894203186035,
      "learning_rate": 3.633837122158381e-05,
      "loss": 1.1135,
      "step": 44250
    },
    {
      "epoch": 2.76,
      "grad_norm": 11.007296562194824,
      "learning_rate": 3.633524856357732e-05,
      "loss": 0.9812,
      "step": 44260
    },
    {
      "epoch": 2.76,
      "grad_norm": 21.469154357910156,
      "learning_rate": 3.6332125905570824e-05,
      "loss": 0.8702,
      "step": 44270
    },
    {
      "epoch": 2.76,
      "grad_norm": 12.42199420928955,
      "learning_rate": 3.632900324756433e-05,
      "loss": 0.9982,
      "step": 44280
    },
    {
      "epoch": 2.76,
      "grad_norm": 12.112875938415527,
      "learning_rate": 3.632588058955783e-05,
      "loss": 1.0265,
      "step": 44290
    },
    {
      "epoch": 2.76,
      "grad_norm": 8.05484390258789,
      "learning_rate": 3.632275793155134e-05,
      "loss": 0.9932,
      "step": 44300
    },
    {
      "epoch": 2.76,
      "grad_norm": 11.166105270385742,
      "learning_rate": 3.6319635273544845e-05,
      "loss": 1.0307,
      "step": 44310
    },
    {
      "epoch": 2.76,
      "grad_norm": 13.81272029876709,
      "learning_rate": 3.631651261553835e-05,
      "loss": 1.1218,
      "step": 44320
    },
    {
      "epoch": 2.76,
      "grad_norm": 11.609037399291992,
      "learning_rate": 3.631338995753185e-05,
      "loss": 1.0337,
      "step": 44330
    },
    {
      "epoch": 2.76,
      "grad_norm": 11.194450378417969,
      "learning_rate": 3.631026729952536e-05,
      "loss": 0.9669,
      "step": 44340
    },
    {
      "epoch": 2.76,
      "grad_norm": 9.451542854309082,
      "learning_rate": 3.6307144641518865e-05,
      "loss": 1.0782,
      "step": 44350
    },
    {
      "epoch": 2.76,
      "grad_norm": 11.356019973754883,
      "learning_rate": 3.6304021983512365e-05,
      "loss": 1.0512,
      "step": 44360
    },
    {
      "epoch": 2.76,
      "grad_norm": 8.962904930114746,
      "learning_rate": 3.630089932550587e-05,
      "loss": 0.993,
      "step": 44370
    },
    {
      "epoch": 2.76,
      "grad_norm": 8.120594024658203,
      "learning_rate": 3.629777666749938e-05,
      "loss": 1.0203,
      "step": 44380
    },
    {
      "epoch": 2.76,
      "grad_norm": 7.82053804397583,
      "learning_rate": 3.6294654009492885e-05,
      "loss": 0.9167,
      "step": 44390
    },
    {
      "epoch": 2.76,
      "grad_norm": 9.756836891174316,
      "learning_rate": 3.6291531351486385e-05,
      "loss": 0.9076,
      "step": 44400
    },
    {
      "epoch": 2.76,
      "grad_norm": 10.160816192626953,
      "learning_rate": 3.628840869347989e-05,
      "loss": 0.964,
      "step": 44410
    },
    {
      "epoch": 2.77,
      "grad_norm": 11.734208106994629,
      "learning_rate": 3.62852860354734e-05,
      "loss": 1.0655,
      "step": 44420
    },
    {
      "epoch": 2.77,
      "grad_norm": 14.207481384277344,
      "learning_rate": 3.62821633774669e-05,
      "loss": 1.0772,
      "step": 44430
    },
    {
      "epoch": 2.77,
      "grad_norm": 13.62618350982666,
      "learning_rate": 3.6279040719460406e-05,
      "loss": 1.2135,
      "step": 44440
    },
    {
      "epoch": 2.77,
      "grad_norm": 9.99954891204834,
      "learning_rate": 3.627591806145391e-05,
      "loss": 1.0126,
      "step": 44450
    },
    {
      "epoch": 2.77,
      "grad_norm": 9.010321617126465,
      "learning_rate": 3.627279540344742e-05,
      "loss": 0.9966,
      "step": 44460
    },
    {
      "epoch": 2.77,
      "grad_norm": 9.533447265625,
      "learning_rate": 3.626967274544092e-05,
      "loss": 0.9932,
      "step": 44470
    },
    {
      "epoch": 2.77,
      "grad_norm": 12.220602989196777,
      "learning_rate": 3.6266550087434426e-05,
      "loss": 1.07,
      "step": 44480
    },
    {
      "epoch": 2.77,
      "grad_norm": 10.219480514526367,
      "learning_rate": 3.626342742942793e-05,
      "loss": 0.987,
      "step": 44490
    },
    {
      "epoch": 2.77,
      "grad_norm": 8.090121269226074,
      "learning_rate": 3.626030477142144e-05,
      "loss": 0.9517,
      "step": 44500
    },
    {
      "epoch": 2.77,
      "grad_norm": 7.647576332092285,
      "learning_rate": 3.625718211341494e-05,
      "loss": 0.9571,
      "step": 44510
    },
    {
      "epoch": 2.77,
      "grad_norm": 11.27292251586914,
      "learning_rate": 3.625405945540845e-05,
      "loss": 1.1015,
      "step": 44520
    },
    {
      "epoch": 2.77,
      "grad_norm": 8.383203506469727,
      "learning_rate": 3.6250936797401954e-05,
      "loss": 1.0637,
      "step": 44530
    },
    {
      "epoch": 2.77,
      "grad_norm": 10.348735809326172,
      "learning_rate": 3.6247814139395454e-05,
      "loss": 0.9562,
      "step": 44540
    },
    {
      "epoch": 2.77,
      "grad_norm": 12.087971687316895,
      "learning_rate": 3.624469148138896e-05,
      "loss": 1.049,
      "step": 44550
    },
    {
      "epoch": 2.77,
      "grad_norm": 10.682034492492676,
      "learning_rate": 3.624156882338247e-05,
      "loss": 1.1193,
      "step": 44560
    },
    {
      "epoch": 2.77,
      "grad_norm": 7.5203375816345215,
      "learning_rate": 3.6238446165375974e-05,
      "loss": 0.953,
      "step": 44570
    },
    {
      "epoch": 2.78,
      "grad_norm": 12.2345609664917,
      "learning_rate": 3.6235323507369474e-05,
      "loss": 1.0463,
      "step": 44580
    },
    {
      "epoch": 2.78,
      "grad_norm": 11.182764053344727,
      "learning_rate": 3.623220084936298e-05,
      "loss": 1.008,
      "step": 44590
    },
    {
      "epoch": 2.78,
      "grad_norm": 8.646235466003418,
      "learning_rate": 3.622907819135649e-05,
      "loss": 1.0339,
      "step": 44600
    },
    {
      "epoch": 2.78,
      "grad_norm": 11.243837356567383,
      "learning_rate": 3.622595553334999e-05,
      "loss": 1.013,
      "step": 44610
    },
    {
      "epoch": 2.78,
      "grad_norm": 9.74502182006836,
      "learning_rate": 3.6222832875343495e-05,
      "loss": 0.9995,
      "step": 44620
    },
    {
      "epoch": 2.78,
      "grad_norm": 6.963320732116699,
      "learning_rate": 3.6219710217337e-05,
      "loss": 1.0127,
      "step": 44630
    },
    {
      "epoch": 2.78,
      "grad_norm": 7.837499141693115,
      "learning_rate": 3.621658755933051e-05,
      "loss": 1.0129,
      "step": 44640
    },
    {
      "epoch": 2.78,
      "grad_norm": 6.129426002502441,
      "learning_rate": 3.621346490132401e-05,
      "loss": 0.9364,
      "step": 44650
    },
    {
      "epoch": 2.78,
      "grad_norm": 8.838516235351562,
      "learning_rate": 3.6210342243317515e-05,
      "loss": 0.9228,
      "step": 44660
    },
    {
      "epoch": 2.78,
      "grad_norm": 8.504661560058594,
      "learning_rate": 3.620721958531102e-05,
      "loss": 1.035,
      "step": 44670
    },
    {
      "epoch": 2.78,
      "grad_norm": 8.890097618103027,
      "learning_rate": 3.620409692730453e-05,
      "loss": 0.9844,
      "step": 44680
    },
    {
      "epoch": 2.78,
      "grad_norm": 9.12814712524414,
      "learning_rate": 3.620097426929803e-05,
      "loss": 1.0264,
      "step": 44690
    },
    {
      "epoch": 2.78,
      "grad_norm": 9.127779960632324,
      "learning_rate": 3.6197851611291535e-05,
      "loss": 1.0337,
      "step": 44700
    },
    {
      "epoch": 2.78,
      "grad_norm": 9.038191795349121,
      "learning_rate": 3.619472895328504e-05,
      "loss": 0.9533,
      "step": 44710
    },
    {
      "epoch": 2.78,
      "grad_norm": 14.826909065246582,
      "learning_rate": 3.619160629527854e-05,
      "loss": 1.1249,
      "step": 44720
    },
    {
      "epoch": 2.78,
      "grad_norm": 12.67345142364502,
      "learning_rate": 3.618848363727205e-05,
      "loss": 0.9997,
      "step": 44730
    },
    {
      "epoch": 2.79,
      "grad_norm": 9.035088539123535,
      "learning_rate": 3.6185360979265556e-05,
      "loss": 1.0398,
      "step": 44740
    },
    {
      "epoch": 2.79,
      "grad_norm": 12.661409378051758,
      "learning_rate": 3.618223832125906e-05,
      "loss": 1.2064,
      "step": 44750
    },
    {
      "epoch": 2.79,
      "grad_norm": 13.180337905883789,
      "learning_rate": 3.617911566325256e-05,
      "loss": 0.9991,
      "step": 44760
    },
    {
      "epoch": 2.79,
      "grad_norm": 15.081548690795898,
      "learning_rate": 3.617599300524607e-05,
      "loss": 0.9109,
      "step": 44770
    },
    {
      "epoch": 2.79,
      "grad_norm": 15.990571022033691,
      "learning_rate": 3.6172870347239576e-05,
      "loss": 0.9832,
      "step": 44780
    },
    {
      "epoch": 2.79,
      "grad_norm": 8.11233139038086,
      "learning_rate": 3.6169747689233076e-05,
      "loss": 1.0523,
      "step": 44790
    },
    {
      "epoch": 2.79,
      "grad_norm": 10.165297508239746,
      "learning_rate": 3.616662503122658e-05,
      "loss": 1.0285,
      "step": 44800
    },
    {
      "epoch": 2.79,
      "grad_norm": 7.709747314453125,
      "learning_rate": 3.616350237322009e-05,
      "loss": 0.9257,
      "step": 44810
    },
    {
      "epoch": 2.79,
      "grad_norm": 9.163202285766602,
      "learning_rate": 3.61603797152136e-05,
      "loss": 0.982,
      "step": 44820
    },
    {
      "epoch": 2.79,
      "grad_norm": 12.165059089660645,
      "learning_rate": 3.61572570572071e-05,
      "loss": 1.1213,
      "step": 44830
    },
    {
      "epoch": 2.79,
      "grad_norm": 8.390347480773926,
      "learning_rate": 3.6154134399200604e-05,
      "loss": 0.9799,
      "step": 44840
    },
    {
      "epoch": 2.79,
      "grad_norm": 13.256075859069824,
      "learning_rate": 3.615101174119411e-05,
      "loss": 1.0057,
      "step": 44850
    },
    {
      "epoch": 2.79,
      "grad_norm": 12.078577041625977,
      "learning_rate": 3.614788908318761e-05,
      "loss": 0.955,
      "step": 44860
    },
    {
      "epoch": 2.79,
      "grad_norm": 10.69705581665039,
      "learning_rate": 3.614476642518112e-05,
      "loss": 1.0068,
      "step": 44870
    },
    {
      "epoch": 2.79,
      "grad_norm": 9.230559349060059,
      "learning_rate": 3.6141643767174624e-05,
      "loss": 1.0271,
      "step": 44880
    },
    {
      "epoch": 2.79,
      "grad_norm": 11.31505012512207,
      "learning_rate": 3.613852110916813e-05,
      "loss": 0.9607,
      "step": 44890
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.157637119293213,
      "learning_rate": 3.613539845116163e-05,
      "loss": 1.0844,
      "step": 44900
    },
    {
      "epoch": 2.8,
      "grad_norm": 11.580699920654297,
      "learning_rate": 3.613227579315514e-05,
      "loss": 1.0468,
      "step": 44910
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.27602481842041,
      "learning_rate": 3.6129153135148645e-05,
      "loss": 0.9748,
      "step": 44920
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.080289363861084,
      "learning_rate": 3.6126030477142145e-05,
      "loss": 1.0481,
      "step": 44930
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.7237548828125,
      "learning_rate": 3.612290781913565e-05,
      "loss": 0.9708,
      "step": 44940
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.44077205657959,
      "learning_rate": 3.611978516112916e-05,
      "loss": 1.0492,
      "step": 44950
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.127594947814941,
      "learning_rate": 3.611666250312266e-05,
      "loss": 0.8827,
      "step": 44960
    },
    {
      "epoch": 2.8,
      "grad_norm": 13.68983268737793,
      "learning_rate": 3.6113539845116165e-05,
      "loss": 0.9739,
      "step": 44970
    },
    {
      "epoch": 2.8,
      "grad_norm": 13.08303165435791,
      "learning_rate": 3.611041718710967e-05,
      "loss": 0.9601,
      "step": 44980
    },
    {
      "epoch": 2.8,
      "grad_norm": 8.438424110412598,
      "learning_rate": 3.610729452910317e-05,
      "loss": 0.9106,
      "step": 44990
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.207418441772461,
      "learning_rate": 3.610417187109668e-05,
      "loss": 1.0453,
      "step": 45000
    },
    {
      "epoch": 2.8,
      "grad_norm": 16.89274024963379,
      "learning_rate": 3.6101049213090185e-05,
      "loss": 1.1158,
      "step": 45010
    },
    {
      "epoch": 2.8,
      "grad_norm": 8.630633354187012,
      "learning_rate": 3.6097926555083685e-05,
      "loss": 0.9918,
      "step": 45020
    },
    {
      "epoch": 2.8,
      "grad_norm": 9.972505569458008,
      "learning_rate": 3.609480389707719e-05,
      "loss": 1.0455,
      "step": 45030
    },
    {
      "epoch": 2.8,
      "grad_norm": 17.909130096435547,
      "learning_rate": 3.60916812390707e-05,
      "loss": 1.0049,
      "step": 45040
    },
    {
      "epoch": 2.8,
      "grad_norm": 13.712882041931152,
      "learning_rate": 3.60885585810642e-05,
      "loss": 1.0262,
      "step": 45050
    },
    {
      "epoch": 2.81,
      "grad_norm": 20.28278350830078,
      "learning_rate": 3.6085435923057706e-05,
      "loss": 1.0308,
      "step": 45060
    },
    {
      "epoch": 2.81,
      "grad_norm": 11.098248481750488,
      "learning_rate": 3.608231326505121e-05,
      "loss": 0.9873,
      "step": 45070
    },
    {
      "epoch": 2.81,
      "grad_norm": 10.135427474975586,
      "learning_rate": 3.607919060704471e-05,
      "loss": 1.1779,
      "step": 45080
    },
    {
      "epoch": 2.81,
      "grad_norm": 13.255526542663574,
      "learning_rate": 3.607606794903822e-05,
      "loss": 1.1001,
      "step": 45090
    },
    {
      "epoch": 2.81,
      "grad_norm": 10.708661079406738,
      "learning_rate": 3.6072945291031726e-05,
      "loss": 0.9643,
      "step": 45100
    },
    {
      "epoch": 2.81,
      "grad_norm": 11.09165096282959,
      "learning_rate": 3.606982263302523e-05,
      "loss": 1.1401,
      "step": 45110
    },
    {
      "epoch": 2.81,
      "grad_norm": 9.670648574829102,
      "learning_rate": 3.606669997501873e-05,
      "loss": 1.1043,
      "step": 45120
    },
    {
      "epoch": 2.81,
      "grad_norm": 5.6623854637146,
      "learning_rate": 3.606357731701224e-05,
      "loss": 0.8954,
      "step": 45130
    },
    {
      "epoch": 2.81,
      "grad_norm": 11.763015747070312,
      "learning_rate": 3.606045465900575e-05,
      "loss": 1.033,
      "step": 45140
    },
    {
      "epoch": 2.81,
      "grad_norm": 8.782272338867188,
      "learning_rate": 3.605733200099925e-05,
      "loss": 1.0805,
      "step": 45150
    },
    {
      "epoch": 2.81,
      "grad_norm": 12.9789457321167,
      "learning_rate": 3.6054209342992754e-05,
      "loss": 0.9285,
      "step": 45160
    },
    {
      "epoch": 2.81,
      "grad_norm": 10.747945785522461,
      "learning_rate": 3.605108668498626e-05,
      "loss": 0.9728,
      "step": 45170
    },
    {
      "epoch": 2.81,
      "grad_norm": 8.772741317749023,
      "learning_rate": 3.604796402697977e-05,
      "loss": 0.9739,
      "step": 45180
    },
    {
      "epoch": 2.81,
      "grad_norm": 9.992866516113281,
      "learning_rate": 3.604484136897327e-05,
      "loss": 1.055,
      "step": 45190
    },
    {
      "epoch": 2.81,
      "grad_norm": 8.414956092834473,
      "learning_rate": 3.6041718710966774e-05,
      "loss": 0.9356,
      "step": 45200
    },
    {
      "epoch": 2.81,
      "grad_norm": 11.758025169372559,
      "learning_rate": 3.603859605296028e-05,
      "loss": 1.0977,
      "step": 45210
    },
    {
      "epoch": 2.82,
      "grad_norm": 9.033855438232422,
      "learning_rate": 3.603547339495378e-05,
      "loss": 1.0763,
      "step": 45220
    },
    {
      "epoch": 2.82,
      "grad_norm": 5.886842727661133,
      "learning_rate": 3.603235073694729e-05,
      "loss": 0.9835,
      "step": 45230
    },
    {
      "epoch": 2.82,
      "grad_norm": 13.672877311706543,
      "learning_rate": 3.6029228078940795e-05,
      "loss": 1.0993,
      "step": 45240
    },
    {
      "epoch": 2.82,
      "grad_norm": 7.58850622177124,
      "learning_rate": 3.60261054209343e-05,
      "loss": 0.9981,
      "step": 45250
    },
    {
      "epoch": 2.82,
      "grad_norm": 14.438541412353516,
      "learning_rate": 3.60229827629278e-05,
      "loss": 1.0205,
      "step": 45260
    },
    {
      "epoch": 2.82,
      "grad_norm": 6.74864387512207,
      "learning_rate": 3.601986010492131e-05,
      "loss": 1.0748,
      "step": 45270
    },
    {
      "epoch": 2.82,
      "grad_norm": 10.094736099243164,
      "learning_rate": 3.6016737446914815e-05,
      "loss": 1.0155,
      "step": 45280
    },
    {
      "epoch": 2.82,
      "grad_norm": 9.69811725616455,
      "learning_rate": 3.601361478890832e-05,
      "loss": 0.9774,
      "step": 45290
    },
    {
      "epoch": 2.82,
      "grad_norm": 10.339715957641602,
      "learning_rate": 3.601049213090182e-05,
      "loss": 1.0402,
      "step": 45300
    },
    {
      "epoch": 2.82,
      "grad_norm": 9.62894344329834,
      "learning_rate": 3.600736947289533e-05,
      "loss": 1.1283,
      "step": 45310
    },
    {
      "epoch": 2.82,
      "grad_norm": 9.031723976135254,
      "learning_rate": 3.6004246814888835e-05,
      "loss": 1.0876,
      "step": 45320
    },
    {
      "epoch": 2.82,
      "grad_norm": 15.01245403289795,
      "learning_rate": 3.6001124156882335e-05,
      "loss": 0.9546,
      "step": 45330
    },
    {
      "epoch": 2.82,
      "grad_norm": 9.651046752929688,
      "learning_rate": 3.599800149887584e-05,
      "loss": 1.0977,
      "step": 45340
    },
    {
      "epoch": 2.82,
      "grad_norm": 15.760987281799316,
      "learning_rate": 3.599487884086935e-05,
      "loss": 1.0121,
      "step": 45350
    },
    {
      "epoch": 2.82,
      "grad_norm": 10.789928436279297,
      "learning_rate": 3.5991756182862856e-05,
      "loss": 0.9649,
      "step": 45360
    },
    {
      "epoch": 2.82,
      "grad_norm": 10.395730972290039,
      "learning_rate": 3.5988633524856356e-05,
      "loss": 0.9594,
      "step": 45370
    },
    {
      "epoch": 2.83,
      "grad_norm": 10.358633041381836,
      "learning_rate": 3.598551086684986e-05,
      "loss": 1.0873,
      "step": 45380
    },
    {
      "epoch": 2.83,
      "grad_norm": 13.019888877868652,
      "learning_rate": 3.598238820884337e-05,
      "loss": 1.0188,
      "step": 45390
    },
    {
      "epoch": 2.83,
      "grad_norm": 11.427478790283203,
      "learning_rate": 3.597926555083687e-05,
      "loss": 0.9263,
      "step": 45400
    },
    {
      "epoch": 2.83,
      "grad_norm": 11.9422607421875,
      "learning_rate": 3.5976142892830376e-05,
      "loss": 0.9243,
      "step": 45410
    },
    {
      "epoch": 2.83,
      "grad_norm": 18.289831161499023,
      "learning_rate": 3.597302023482388e-05,
      "loss": 1.1439,
      "step": 45420
    },
    {
      "epoch": 2.83,
      "grad_norm": 11.474027633666992,
      "learning_rate": 3.596989757681739e-05,
      "loss": 0.985,
      "step": 45430
    },
    {
      "epoch": 2.83,
      "grad_norm": 6.730504512786865,
      "learning_rate": 3.596677491881089e-05,
      "loss": 0.9602,
      "step": 45440
    },
    {
      "epoch": 2.83,
      "grad_norm": 14.706388473510742,
      "learning_rate": 3.59636522608044e-05,
      "loss": 1.0181,
      "step": 45450
    },
    {
      "epoch": 2.83,
      "grad_norm": 12.554044723510742,
      "learning_rate": 3.5960529602797904e-05,
      "loss": 1.037,
      "step": 45460
    },
    {
      "epoch": 2.83,
      "grad_norm": 14.851448059082031,
      "learning_rate": 3.595740694479141e-05,
      "loss": 1.0638,
      "step": 45470
    },
    {
      "epoch": 2.83,
      "grad_norm": 8.42319107055664,
      "learning_rate": 3.595428428678491e-05,
      "loss": 0.9854,
      "step": 45480
    },
    {
      "epoch": 2.83,
      "grad_norm": 8.496663093566895,
      "learning_rate": 3.595116162877842e-05,
      "loss": 1.0076,
      "step": 45490
    },
    {
      "epoch": 2.83,
      "grad_norm": 10.051125526428223,
      "learning_rate": 3.5948038970771924e-05,
      "loss": 1.0585,
      "step": 45500
    },
    {
      "epoch": 2.83,
      "grad_norm": 6.9835615158081055,
      "learning_rate": 3.5944916312765424e-05,
      "loss": 1.0348,
      "step": 45510
    },
    {
      "epoch": 2.83,
      "grad_norm": 10.543012619018555,
      "learning_rate": 3.594179365475893e-05,
      "loss": 0.9599,
      "step": 45520
    },
    {
      "epoch": 2.83,
      "grad_norm": 7.993178367614746,
      "learning_rate": 3.593867099675244e-05,
      "loss": 0.9038,
      "step": 45530
    },
    {
      "epoch": 2.84,
      "grad_norm": 7.619803428649902,
      "learning_rate": 3.5935548338745945e-05,
      "loss": 1.0,
      "step": 45540
    },
    {
      "epoch": 2.84,
      "grad_norm": 12.546673774719238,
      "learning_rate": 3.5932425680739445e-05,
      "loss": 0.9231,
      "step": 45550
    },
    {
      "epoch": 2.84,
      "grad_norm": 12.155662536621094,
      "learning_rate": 3.592930302273295e-05,
      "loss": 1.0165,
      "step": 45560
    },
    {
      "epoch": 2.84,
      "grad_norm": 9.086241722106934,
      "learning_rate": 3.592618036472646e-05,
      "loss": 1.0228,
      "step": 45570
    },
    {
      "epoch": 2.84,
      "grad_norm": 12.69955825805664,
      "learning_rate": 3.592305770671996e-05,
      "loss": 1.0899,
      "step": 45580
    },
    {
      "epoch": 2.84,
      "grad_norm": 9.117853164672852,
      "learning_rate": 3.5919935048713465e-05,
      "loss": 1.0464,
      "step": 45590
    },
    {
      "epoch": 2.84,
      "grad_norm": 7.626620769500732,
      "learning_rate": 3.591681239070697e-05,
      "loss": 1.1924,
      "step": 45600
    },
    {
      "epoch": 2.84,
      "grad_norm": 6.4679436683654785,
      "learning_rate": 3.591368973270048e-05,
      "loss": 0.9254,
      "step": 45610
    },
    {
      "epoch": 2.84,
      "grad_norm": 10.187349319458008,
      "learning_rate": 3.591056707469398e-05,
      "loss": 1.0891,
      "step": 45620
    },
    {
      "epoch": 2.84,
      "grad_norm": 11.95893669128418,
      "learning_rate": 3.5907444416687485e-05,
      "loss": 1.0144,
      "step": 45630
    },
    {
      "epoch": 2.84,
      "grad_norm": 7.153001308441162,
      "learning_rate": 3.590432175868099e-05,
      "loss": 1.0123,
      "step": 45640
    },
    {
      "epoch": 2.84,
      "grad_norm": 9.174745559692383,
      "learning_rate": 3.59011991006745e-05,
      "loss": 0.9031,
      "step": 45650
    },
    {
      "epoch": 2.84,
      "grad_norm": 11.640678405761719,
      "learning_rate": 3.5898076442668e-05,
      "loss": 1.018,
      "step": 45660
    },
    {
      "epoch": 2.84,
      "grad_norm": 13.073885917663574,
      "learning_rate": 3.5894953784661506e-05,
      "loss": 1.0915,
      "step": 45670
    },
    {
      "epoch": 2.84,
      "grad_norm": 10.855218887329102,
      "learning_rate": 3.589183112665501e-05,
      "loss": 1.0135,
      "step": 45680
    },
    {
      "epoch": 2.84,
      "grad_norm": 8.682793617248535,
      "learning_rate": 3.588870846864851e-05,
      "loss": 1.0475,
      "step": 45690
    },
    {
      "epoch": 2.85,
      "grad_norm": 14.660282135009766,
      "learning_rate": 3.588558581064202e-05,
      "loss": 1.0823,
      "step": 45700
    },
    {
      "epoch": 2.85,
      "grad_norm": 11.85317611694336,
      "learning_rate": 3.5882463152635526e-05,
      "loss": 1.0416,
      "step": 45710
    },
    {
      "epoch": 2.85,
      "grad_norm": 10.678177833557129,
      "learning_rate": 3.587934049462903e-05,
      "loss": 0.9334,
      "step": 45720
    },
    {
      "epoch": 2.85,
      "grad_norm": 13.832361221313477,
      "learning_rate": 3.587621783662253e-05,
      "loss": 0.9805,
      "step": 45730
    },
    {
      "epoch": 2.85,
      "grad_norm": 9.84050464630127,
      "learning_rate": 3.587309517861604e-05,
      "loss": 0.8919,
      "step": 45740
    },
    {
      "epoch": 2.85,
      "grad_norm": 17.305814743041992,
      "learning_rate": 3.586997252060955e-05,
      "loss": 0.9962,
      "step": 45750
    },
    {
      "epoch": 2.85,
      "grad_norm": 13.628447532653809,
      "learning_rate": 3.586684986260305e-05,
      "loss": 1.0826,
      "step": 45760
    },
    {
      "epoch": 2.85,
      "grad_norm": 8.787839889526367,
      "learning_rate": 3.5863727204596554e-05,
      "loss": 0.997,
      "step": 45770
    },
    {
      "epoch": 2.85,
      "grad_norm": 13.146846771240234,
      "learning_rate": 3.586060454659006e-05,
      "loss": 0.969,
      "step": 45780
    },
    {
      "epoch": 2.85,
      "grad_norm": 9.954790115356445,
      "learning_rate": 3.585748188858357e-05,
      "loss": 1.036,
      "step": 45790
    },
    {
      "epoch": 2.85,
      "grad_norm": 10.655244827270508,
      "learning_rate": 3.585435923057707e-05,
      "loss": 0.95,
      "step": 45800
    },
    {
      "epoch": 2.85,
      "grad_norm": 30.554115295410156,
      "learning_rate": 3.5851236572570574e-05,
      "loss": 1.0172,
      "step": 45810
    },
    {
      "epoch": 2.85,
      "grad_norm": 7.904720783233643,
      "learning_rate": 3.584811391456408e-05,
      "loss": 0.972,
      "step": 45820
    },
    {
      "epoch": 2.85,
      "grad_norm": 11.994596481323242,
      "learning_rate": 3.584499125655759e-05,
      "loss": 0.9109,
      "step": 45830
    },
    {
      "epoch": 2.85,
      "grad_norm": 8.9241361618042,
      "learning_rate": 3.584186859855109e-05,
      "loss": 1.0742,
      "step": 45840
    },
    {
      "epoch": 2.85,
      "grad_norm": 13.436097145080566,
      "learning_rate": 3.5838745940544595e-05,
      "loss": 0.9935,
      "step": 45850
    },
    {
      "epoch": 2.86,
      "grad_norm": 11.641470909118652,
      "learning_rate": 3.58356232825381e-05,
      "loss": 0.9404,
      "step": 45860
    },
    {
      "epoch": 2.86,
      "grad_norm": 11.172096252441406,
      "learning_rate": 3.58325006245316e-05,
      "loss": 1.0574,
      "step": 45870
    },
    {
      "epoch": 2.86,
      "grad_norm": 10.469766616821289,
      "learning_rate": 3.582937796652511e-05,
      "loss": 1.0605,
      "step": 45880
    },
    {
      "epoch": 2.86,
      "grad_norm": 8.445768356323242,
      "learning_rate": 3.5826255308518615e-05,
      "loss": 1.1,
      "step": 45890
    },
    {
      "epoch": 2.86,
      "grad_norm": 10.631608963012695,
      "learning_rate": 3.582313265051212e-05,
      "loss": 1.0521,
      "step": 45900
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.34987735748291,
      "learning_rate": 3.582000999250562e-05,
      "loss": 1.1419,
      "step": 45910
    },
    {
      "epoch": 2.86,
      "grad_norm": 10.999831199645996,
      "learning_rate": 3.581688733449913e-05,
      "loss": 1.0339,
      "step": 45920
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.557555198669434,
      "learning_rate": 3.5813764676492635e-05,
      "loss": 1.0079,
      "step": 45930
    },
    {
      "epoch": 2.86,
      "grad_norm": 8.26156234741211,
      "learning_rate": 3.5810642018486135e-05,
      "loss": 1.0214,
      "step": 45940
    },
    {
      "epoch": 2.86,
      "grad_norm": 11.715693473815918,
      "learning_rate": 3.580751936047964e-05,
      "loss": 1.0449,
      "step": 45950
    },
    {
      "epoch": 2.86,
      "grad_norm": 7.8527398109436035,
      "learning_rate": 3.580439670247315e-05,
      "loss": 0.9042,
      "step": 45960
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.600207328796387,
      "learning_rate": 3.5801274044466656e-05,
      "loss": 1.0186,
      "step": 45970
    },
    {
      "epoch": 2.86,
      "grad_norm": 12.750566482543945,
      "learning_rate": 3.5798151386460156e-05,
      "loss": 1.0487,
      "step": 45980
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.166172981262207,
      "learning_rate": 3.579502872845366e-05,
      "loss": 1.0758,
      "step": 45990
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.514860153198242,
      "learning_rate": 3.579190607044717e-05,
      "loss": 1.0928,
      "step": 46000
    },
    {
      "epoch": 2.86,
      "grad_norm": 9.910959243774414,
      "learning_rate": 3.578878341244067e-05,
      "loss": 1.0987,
      "step": 46010
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.485554695129395,
      "learning_rate": 3.5785660754434176e-05,
      "loss": 1.1094,
      "step": 46020
    },
    {
      "epoch": 2.87,
      "grad_norm": 8.935652732849121,
      "learning_rate": 3.578253809642768e-05,
      "loss": 1.045,
      "step": 46030
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.535470008850098,
      "learning_rate": 3.577941543842119e-05,
      "loss": 1.0654,
      "step": 46040
    },
    {
      "epoch": 2.87,
      "grad_norm": 11.634700775146484,
      "learning_rate": 3.577629278041469e-05,
      "loss": 0.9863,
      "step": 46050
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.954460144042969,
      "learning_rate": 3.57731701224082e-05,
      "loss": 0.9394,
      "step": 46060
    },
    {
      "epoch": 2.87,
      "grad_norm": 10.709638595581055,
      "learning_rate": 3.5770047464401704e-05,
      "loss": 1.04,
      "step": 46070
    },
    {
      "epoch": 2.87,
      "grad_norm": 7.103936195373535,
      "learning_rate": 3.576692480639521e-05,
      "loss": 0.9888,
      "step": 46080
    },
    {
      "epoch": 2.87,
      "grad_norm": 14.912322998046875,
      "learning_rate": 3.576380214838871e-05,
      "loss": 0.9884,
      "step": 46090
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.884800910949707,
      "learning_rate": 3.576067949038222e-05,
      "loss": 1.0675,
      "step": 46100
    },
    {
      "epoch": 2.87,
      "grad_norm": 9.68830394744873,
      "learning_rate": 3.5757556832375724e-05,
      "loss": 0.9334,
      "step": 46110
    },
    {
      "epoch": 2.87,
      "grad_norm": 16.33005142211914,
      "learning_rate": 3.5754434174369224e-05,
      "loss": 1.144,
      "step": 46120
    },
    {
      "epoch": 2.87,
      "grad_norm": 15.058099746704102,
      "learning_rate": 3.575131151636273e-05,
      "loss": 1.0631,
      "step": 46130
    },
    {
      "epoch": 2.87,
      "grad_norm": 11.72200870513916,
      "learning_rate": 3.574818885835624e-05,
      "loss": 1.0034,
      "step": 46140
    },
    {
      "epoch": 2.87,
      "grad_norm": 8.991742134094238,
      "learning_rate": 3.5745066200349745e-05,
      "loss": 0.9775,
      "step": 46150
    },
    {
      "epoch": 2.87,
      "grad_norm": 8.915334701538086,
      "learning_rate": 3.5741943542343245e-05,
      "loss": 0.9036,
      "step": 46160
    },
    {
      "epoch": 2.87,
      "grad_norm": 11.677569389343262,
      "learning_rate": 3.573882088433675e-05,
      "loss": 0.9594,
      "step": 46170
    },
    {
      "epoch": 2.88,
      "grad_norm": 14.944267272949219,
      "learning_rate": 3.573569822633026e-05,
      "loss": 1.0439,
      "step": 46180
    },
    {
      "epoch": 2.88,
      "grad_norm": 10.622644424438477,
      "learning_rate": 3.573257556832376e-05,
      "loss": 0.9202,
      "step": 46190
    },
    {
      "epoch": 2.88,
      "grad_norm": 11.49739933013916,
      "learning_rate": 3.5729452910317265e-05,
      "loss": 1.0674,
      "step": 46200
    },
    {
      "epoch": 2.88,
      "grad_norm": 10.942131042480469,
      "learning_rate": 3.572633025231077e-05,
      "loss": 1.0527,
      "step": 46210
    },
    {
      "epoch": 2.88,
      "grad_norm": 7.382995128631592,
      "learning_rate": 3.572320759430428e-05,
      "loss": 1.0056,
      "step": 46220
    },
    {
      "epoch": 2.88,
      "grad_norm": 11.250632286071777,
      "learning_rate": 3.572008493629778e-05,
      "loss": 0.8794,
      "step": 46230
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.517207145690918,
      "learning_rate": 3.5716962278291285e-05,
      "loss": 1.0945,
      "step": 46240
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.708572387695312,
      "learning_rate": 3.571383962028479e-05,
      "loss": 1.0621,
      "step": 46250
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.55241584777832,
      "learning_rate": 3.571071696227829e-05,
      "loss": 1.0156,
      "step": 46260
    },
    {
      "epoch": 2.88,
      "grad_norm": 11.225136756896973,
      "learning_rate": 3.57075943042718e-05,
      "loss": 0.9493,
      "step": 46270
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.631592750549316,
      "learning_rate": 3.5704471646265306e-05,
      "loss": 1.0703,
      "step": 46280
    },
    {
      "epoch": 2.88,
      "grad_norm": 10.529804229736328,
      "learning_rate": 3.5701348988258806e-05,
      "loss": 1.1254,
      "step": 46290
    },
    {
      "epoch": 2.88,
      "grad_norm": 8.75252628326416,
      "learning_rate": 3.569822633025231e-05,
      "loss": 1.0497,
      "step": 46300
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.0316162109375,
      "learning_rate": 3.569510367224582e-05,
      "loss": 1.0648,
      "step": 46310
    },
    {
      "epoch": 2.88,
      "grad_norm": 10.662087440490723,
      "learning_rate": 3.569198101423932e-05,
      "loss": 0.9739,
      "step": 46320
    },
    {
      "epoch": 2.88,
      "grad_norm": 9.001957893371582,
      "learning_rate": 3.5688858356232826e-05,
      "loss": 1.0002,
      "step": 46330
    },
    {
      "epoch": 2.89,
      "grad_norm": 12.245185852050781,
      "learning_rate": 3.568573569822633e-05,
      "loss": 1.1521,
      "step": 46340
    },
    {
      "epoch": 2.89,
      "grad_norm": 8.207895278930664,
      "learning_rate": 3.568261304021984e-05,
      "loss": 1.064,
      "step": 46350
    },
    {
      "epoch": 2.89,
      "grad_norm": 15.001923561096191,
      "learning_rate": 3.567949038221334e-05,
      "loss": 0.9542,
      "step": 46360
    },
    {
      "epoch": 2.89,
      "grad_norm": 11.468794822692871,
      "learning_rate": 3.567636772420685e-05,
      "loss": 1.0763,
      "step": 46370
    },
    {
      "epoch": 2.89,
      "grad_norm": 12.591468811035156,
      "learning_rate": 3.5673245066200354e-05,
      "loss": 1.1308,
      "step": 46380
    },
    {
      "epoch": 2.89,
      "grad_norm": 8.702507972717285,
      "learning_rate": 3.5670122408193854e-05,
      "loss": 0.9041,
      "step": 46390
    },
    {
      "epoch": 2.89,
      "grad_norm": 10.307100296020508,
      "learning_rate": 3.566699975018736e-05,
      "loss": 0.9646,
      "step": 46400
    },
    {
      "epoch": 2.89,
      "grad_norm": 9.604654312133789,
      "learning_rate": 3.566387709218087e-05,
      "loss": 1.1087,
      "step": 46410
    },
    {
      "epoch": 2.89,
      "grad_norm": 12.18792724609375,
      "learning_rate": 3.566075443417437e-05,
      "loss": 0.9616,
      "step": 46420
    },
    {
      "epoch": 2.89,
      "grad_norm": 8.98824691772461,
      "learning_rate": 3.5657631776167874e-05,
      "loss": 1.0187,
      "step": 46430
    },
    {
      "epoch": 2.89,
      "grad_norm": 11.398750305175781,
      "learning_rate": 3.565450911816138e-05,
      "loss": 1.0577,
      "step": 46440
    },
    {
      "epoch": 2.89,
      "grad_norm": 10.453592300415039,
      "learning_rate": 3.565138646015488e-05,
      "loss": 0.9666,
      "step": 46450
    },
    {
      "epoch": 2.89,
      "grad_norm": 11.542067527770996,
      "learning_rate": 3.564826380214839e-05,
      "loss": 1.1181,
      "step": 46460
    },
    {
      "epoch": 2.89,
      "grad_norm": 13.948614120483398,
      "learning_rate": 3.5645141144141895e-05,
      "loss": 1.0216,
      "step": 46470
    },
    {
      "epoch": 2.89,
      "grad_norm": 10.090639114379883,
      "learning_rate": 3.5642018486135395e-05,
      "loss": 1.1248,
      "step": 46480
    },
    {
      "epoch": 2.89,
      "grad_norm": 13.943977355957031,
      "learning_rate": 3.56388958281289e-05,
      "loss": 1.0247,
      "step": 46490
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.663677215576172,
      "learning_rate": 3.563577317012241e-05,
      "loss": 1.0858,
      "step": 46500
    },
    {
      "epoch": 2.9,
      "grad_norm": 9.812111854553223,
      "learning_rate": 3.5632650512115915e-05,
      "loss": 0.971,
      "step": 46510
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.947280883789062,
      "learning_rate": 3.5629527854109415e-05,
      "loss": 1.0521,
      "step": 46520
    },
    {
      "epoch": 2.9,
      "grad_norm": 7.797520637512207,
      "learning_rate": 3.562640519610292e-05,
      "loss": 1.0396,
      "step": 46530
    },
    {
      "epoch": 2.9,
      "grad_norm": 11.55717658996582,
      "learning_rate": 3.562328253809643e-05,
      "loss": 0.9976,
      "step": 46540
    },
    {
      "epoch": 2.9,
      "grad_norm": 9.986298561096191,
      "learning_rate": 3.562015988008993e-05,
      "loss": 1.0403,
      "step": 46550
    },
    {
      "epoch": 2.9,
      "grad_norm": 13.113203048706055,
      "learning_rate": 3.5617037222083436e-05,
      "loss": 1.007,
      "step": 46560
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.517894744873047,
      "learning_rate": 3.561391456407694e-05,
      "loss": 1.0276,
      "step": 46570
    },
    {
      "epoch": 2.9,
      "grad_norm": 8.796492576599121,
      "learning_rate": 3.561079190607045e-05,
      "loss": 1.0237,
      "step": 46580
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.285085678100586,
      "learning_rate": 3.560766924806395e-05,
      "loss": 0.903,
      "step": 46590
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.601120948791504,
      "learning_rate": 3.5604546590057456e-05,
      "loss": 0.9517,
      "step": 46600
    },
    {
      "epoch": 2.9,
      "grad_norm": 8.78409481048584,
      "learning_rate": 3.560142393205096e-05,
      "loss": 1.0692,
      "step": 46610
    },
    {
      "epoch": 2.9,
      "grad_norm": 9.332533836364746,
      "learning_rate": 3.559830127404447e-05,
      "loss": 0.9868,
      "step": 46620
    },
    {
      "epoch": 2.9,
      "grad_norm": 8.127514839172363,
      "learning_rate": 3.559517861603797e-05,
      "loss": 1.0801,
      "step": 46630
    },
    {
      "epoch": 2.9,
      "grad_norm": 11.584582328796387,
      "learning_rate": 3.5592055958031476e-05,
      "loss": 1.0068,
      "step": 46640
    },
    {
      "epoch": 2.9,
      "grad_norm": 7.125937461853027,
      "learning_rate": 3.558893330002498e-05,
      "loss": 1.0668,
      "step": 46650
    },
    {
      "epoch": 2.9,
      "grad_norm": 13.720525741577148,
      "learning_rate": 3.558581064201848e-05,
      "loss": 1.111,
      "step": 46660
    },
    {
      "epoch": 2.91,
      "grad_norm": 7.1239471435546875,
      "learning_rate": 3.558268798401199e-05,
      "loss": 1.0082,
      "step": 46670
    },
    {
      "epoch": 2.91,
      "grad_norm": 7.146164417266846,
      "learning_rate": 3.55795653260055e-05,
      "loss": 1.0463,
      "step": 46680
    },
    {
      "epoch": 2.91,
      "grad_norm": 8.248055458068848,
      "learning_rate": 3.5576442667999004e-05,
      "loss": 1.0357,
      "step": 46690
    },
    {
      "epoch": 2.91,
      "grad_norm": 11.8974609375,
      "learning_rate": 3.5573320009992504e-05,
      "loss": 1.1037,
      "step": 46700
    },
    {
      "epoch": 2.91,
      "grad_norm": 10.933379173278809,
      "learning_rate": 3.557019735198601e-05,
      "loss": 1.0307,
      "step": 46710
    },
    {
      "epoch": 2.91,
      "grad_norm": 5.859170913696289,
      "learning_rate": 3.556707469397952e-05,
      "loss": 1.0511,
      "step": 46720
    },
    {
      "epoch": 2.91,
      "grad_norm": 7.493452072143555,
      "learning_rate": 3.556395203597302e-05,
      "loss": 1.0262,
      "step": 46730
    },
    {
      "epoch": 2.91,
      "grad_norm": 11.028633117675781,
      "learning_rate": 3.5560829377966524e-05,
      "loss": 0.9569,
      "step": 46740
    },
    {
      "epoch": 2.91,
      "grad_norm": 11.423737525939941,
      "learning_rate": 3.555770671996003e-05,
      "loss": 0.8948,
      "step": 46750
    },
    {
      "epoch": 2.91,
      "grad_norm": 13.057272911071777,
      "learning_rate": 3.555458406195354e-05,
      "loss": 1.0508,
      "step": 46760
    },
    {
      "epoch": 2.91,
      "grad_norm": 12.807660102844238,
      "learning_rate": 3.555146140394704e-05,
      "loss": 0.9701,
      "step": 46770
    },
    {
      "epoch": 2.91,
      "grad_norm": 12.743827819824219,
      "learning_rate": 3.5548338745940545e-05,
      "loss": 0.9995,
      "step": 46780
    },
    {
      "epoch": 2.91,
      "grad_norm": 8.932244300842285,
      "learning_rate": 3.554521608793405e-05,
      "loss": 1.0476,
      "step": 46790
    },
    {
      "epoch": 2.91,
      "grad_norm": 9.840483665466309,
      "learning_rate": 3.554209342992756e-05,
      "loss": 0.9685,
      "step": 46800
    },
    {
      "epoch": 2.91,
      "grad_norm": 15.968314170837402,
      "learning_rate": 3.553897077192106e-05,
      "loss": 0.8768,
      "step": 46810
    },
    {
      "epoch": 2.91,
      "grad_norm": 11.79337215423584,
      "learning_rate": 3.5535848113914565e-05,
      "loss": 1.0482,
      "step": 46820
    },
    {
      "epoch": 2.92,
      "grad_norm": 17.894271850585938,
      "learning_rate": 3.553272545590807e-05,
      "loss": 1.1982,
      "step": 46830
    },
    {
      "epoch": 2.92,
      "grad_norm": 9.132003784179688,
      "learning_rate": 3.552960279790157e-05,
      "loss": 1.0537,
      "step": 46840
    },
    {
      "epoch": 2.92,
      "grad_norm": 10.247393608093262,
      "learning_rate": 3.552648013989508e-05,
      "loss": 1.1012,
      "step": 46850
    },
    {
      "epoch": 2.92,
      "grad_norm": 8.547977447509766,
      "learning_rate": 3.5523357481888585e-05,
      "loss": 1.0436,
      "step": 46860
    },
    {
      "epoch": 2.92,
      "grad_norm": 8.40695858001709,
      "learning_rate": 3.552023482388209e-05,
      "loss": 0.9937,
      "step": 46870
    },
    {
      "epoch": 2.92,
      "grad_norm": 11.066277503967285,
      "learning_rate": 3.551711216587559e-05,
      "loss": 0.9837,
      "step": 46880
    },
    {
      "epoch": 2.92,
      "grad_norm": 12.473034858703613,
      "learning_rate": 3.55139895078691e-05,
      "loss": 1.0003,
      "step": 46890
    },
    {
      "epoch": 2.92,
      "grad_norm": 12.2023344039917,
      "learning_rate": 3.5510866849862606e-05,
      "loss": 0.9905,
      "step": 46900
    },
    {
      "epoch": 2.92,
      "grad_norm": 13.25189208984375,
      "learning_rate": 3.5507744191856106e-05,
      "loss": 0.9816,
      "step": 46910
    },
    {
      "epoch": 2.92,
      "grad_norm": 8.660146713256836,
      "learning_rate": 3.550462153384961e-05,
      "loss": 1.0162,
      "step": 46920
    },
    {
      "epoch": 2.92,
      "grad_norm": 9.380706787109375,
      "learning_rate": 3.550149887584312e-05,
      "loss": 1.1377,
      "step": 46930
    },
    {
      "epoch": 2.92,
      "grad_norm": 12.50516414642334,
      "learning_rate": 3.5498376217836626e-05,
      "loss": 1.1188,
      "step": 46940
    },
    {
      "epoch": 2.92,
      "grad_norm": 10.52381420135498,
      "learning_rate": 3.5495253559830126e-05,
      "loss": 1.0611,
      "step": 46950
    },
    {
      "epoch": 2.92,
      "grad_norm": 9.058857917785645,
      "learning_rate": 3.549213090182363e-05,
      "loss": 1.1011,
      "step": 46960
    },
    {
      "epoch": 2.92,
      "grad_norm": 18.380767822265625,
      "learning_rate": 3.548900824381714e-05,
      "loss": 1.0469,
      "step": 46970
    },
    {
      "epoch": 2.92,
      "grad_norm": 7.839993000030518,
      "learning_rate": 3.548588558581065e-05,
      "loss": 1.032,
      "step": 46980
    },
    {
      "epoch": 2.93,
      "grad_norm": 13.220233917236328,
      "learning_rate": 3.548276292780415e-05,
      "loss": 1.0024,
      "step": 46990
    },
    {
      "epoch": 2.93,
      "grad_norm": 9.796040534973145,
      "learning_rate": 3.5479640269797654e-05,
      "loss": 1.0749,
      "step": 47000
    },
    {
      "epoch": 2.93,
      "grad_norm": 9.612306594848633,
      "learning_rate": 3.547651761179116e-05,
      "loss": 0.9839,
      "step": 47010
    },
    {
      "epoch": 2.93,
      "grad_norm": 9.54792308807373,
      "learning_rate": 3.547339495378466e-05,
      "loss": 1.0554,
      "step": 47020
    },
    {
      "epoch": 2.93,
      "grad_norm": 10.255537033081055,
      "learning_rate": 3.547027229577817e-05,
      "loss": 0.9766,
      "step": 47030
    },
    {
      "epoch": 2.93,
      "grad_norm": 11.420289993286133,
      "learning_rate": 3.5467149637771674e-05,
      "loss": 1.0532,
      "step": 47040
    },
    {
      "epoch": 2.93,
      "grad_norm": 7.318055152893066,
      "learning_rate": 3.546402697976518e-05,
      "loss": 0.8976,
      "step": 47050
    },
    {
      "epoch": 2.93,
      "grad_norm": 15.423476219177246,
      "learning_rate": 3.546090432175868e-05,
      "loss": 0.9885,
      "step": 47060
    },
    {
      "epoch": 2.93,
      "grad_norm": 15.866782188415527,
      "learning_rate": 3.545778166375219e-05,
      "loss": 1.0403,
      "step": 47070
    },
    {
      "epoch": 2.93,
      "grad_norm": 10.907949447631836,
      "learning_rate": 3.5454659005745695e-05,
      "loss": 1.1579,
      "step": 47080
    },
    {
      "epoch": 2.93,
      "grad_norm": 8.118754386901855,
      "learning_rate": 3.5451536347739195e-05,
      "loss": 0.9531,
      "step": 47090
    },
    {
      "epoch": 2.93,
      "grad_norm": 9.032116889953613,
      "learning_rate": 3.54484136897327e-05,
      "loss": 0.9113,
      "step": 47100
    },
    {
      "epoch": 2.93,
      "grad_norm": 13.653590202331543,
      "learning_rate": 3.544529103172621e-05,
      "loss": 1.1304,
      "step": 47110
    },
    {
      "epoch": 2.93,
      "grad_norm": 9.201334953308105,
      "learning_rate": 3.5442168373719715e-05,
      "loss": 0.9684,
      "step": 47120
    },
    {
      "epoch": 2.93,
      "grad_norm": 7.762892246246338,
      "learning_rate": 3.5439045715713215e-05,
      "loss": 0.9262,
      "step": 47130
    },
    {
      "epoch": 2.93,
      "grad_norm": 12.20981502532959,
      "learning_rate": 3.543592305770672e-05,
      "loss": 1.0635,
      "step": 47140
    },
    {
      "epoch": 2.94,
      "grad_norm": 19.670154571533203,
      "learning_rate": 3.543280039970023e-05,
      "loss": 1.1323,
      "step": 47150
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.3614501953125,
      "learning_rate": 3.542967774169373e-05,
      "loss": 1.0838,
      "step": 47160
    },
    {
      "epoch": 2.94,
      "grad_norm": 9.700319290161133,
      "learning_rate": 3.5426555083687236e-05,
      "loss": 1.0491,
      "step": 47170
    },
    {
      "epoch": 2.94,
      "grad_norm": 9.172201156616211,
      "learning_rate": 3.542343242568074e-05,
      "loss": 1.0124,
      "step": 47180
    },
    {
      "epoch": 2.94,
      "grad_norm": 7.046750545501709,
      "learning_rate": 3.542030976767425e-05,
      "loss": 0.95,
      "step": 47190
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.499998092651367,
      "learning_rate": 3.541718710966775e-05,
      "loss": 0.9981,
      "step": 47200
    },
    {
      "epoch": 2.94,
      "grad_norm": 8.531981468200684,
      "learning_rate": 3.5414064451661256e-05,
      "loss": 1.0001,
      "step": 47210
    },
    {
      "epoch": 2.94,
      "grad_norm": 19.11680793762207,
      "learning_rate": 3.541094179365476e-05,
      "loss": 1.0319,
      "step": 47220
    },
    {
      "epoch": 2.94,
      "grad_norm": 9.965700149536133,
      "learning_rate": 3.540781913564827e-05,
      "loss": 1.0205,
      "step": 47230
    },
    {
      "epoch": 2.94,
      "grad_norm": 13.451648712158203,
      "learning_rate": 3.540469647764177e-05,
      "loss": 1.11,
      "step": 47240
    },
    {
      "epoch": 2.94,
      "grad_norm": 13.913082122802734,
      "learning_rate": 3.5401573819635276e-05,
      "loss": 1.0218,
      "step": 47250
    },
    {
      "epoch": 2.94,
      "grad_norm": 12.02046012878418,
      "learning_rate": 3.539845116162878e-05,
      "loss": 1.0594,
      "step": 47260
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.00578784942627,
      "learning_rate": 3.539532850362228e-05,
      "loss": 1.0524,
      "step": 47270
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.439963340759277,
      "learning_rate": 3.539220584561579e-05,
      "loss": 1.0849,
      "step": 47280
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.01477336883545,
      "learning_rate": 3.53890831876093e-05,
      "loss": 0.9706,
      "step": 47290
    },
    {
      "epoch": 2.94,
      "grad_norm": 10.511835098266602,
      "learning_rate": 3.5385960529602804e-05,
      "loss": 1.0245,
      "step": 47300
    },
    {
      "epoch": 2.95,
      "grad_norm": 11.210227966308594,
      "learning_rate": 3.5382837871596304e-05,
      "loss": 1.1624,
      "step": 47310
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.914618492126465,
      "learning_rate": 3.537971521358981e-05,
      "loss": 1.0147,
      "step": 47320
    },
    {
      "epoch": 2.95,
      "grad_norm": 10.43260383605957,
      "learning_rate": 3.537659255558332e-05,
      "loss": 0.9864,
      "step": 47330
    },
    {
      "epoch": 2.95,
      "grad_norm": 7.633604526519775,
      "learning_rate": 3.537346989757682e-05,
      "loss": 0.9958,
      "step": 47340
    },
    {
      "epoch": 2.95,
      "grad_norm": 10.642326354980469,
      "learning_rate": 3.5370347239570324e-05,
      "loss": 0.9239,
      "step": 47350
    },
    {
      "epoch": 2.95,
      "grad_norm": 10.425050735473633,
      "learning_rate": 3.536722458156383e-05,
      "loss": 1.0012,
      "step": 47360
    },
    {
      "epoch": 2.95,
      "grad_norm": 9.325035095214844,
      "learning_rate": 3.536410192355734e-05,
      "loss": 1.0632,
      "step": 47370
    },
    {
      "epoch": 2.95,
      "grad_norm": 10.303995132446289,
      "learning_rate": 3.536097926555084e-05,
      "loss": 1.0727,
      "step": 47380
    },
    {
      "epoch": 2.95,
      "grad_norm": 8.997198104858398,
      "learning_rate": 3.5357856607544345e-05,
      "loss": 1.1798,
      "step": 47390
    },
    {
      "epoch": 2.95,
      "grad_norm": 11.52261734008789,
      "learning_rate": 3.535473394953785e-05,
      "loss": 1.0002,
      "step": 47400
    },
    {
      "epoch": 2.95,
      "grad_norm": 9.933147430419922,
      "learning_rate": 3.535161129153136e-05,
      "loss": 0.9625,
      "step": 47410
    },
    {
      "epoch": 2.95,
      "grad_norm": 8.856391906738281,
      "learning_rate": 3.534848863352486e-05,
      "loss": 1.0293,
      "step": 47420
    },
    {
      "epoch": 2.95,
      "grad_norm": 14.711904525756836,
      "learning_rate": 3.5345365975518365e-05,
      "loss": 0.9792,
      "step": 47430
    },
    {
      "epoch": 2.95,
      "grad_norm": 8.434662818908691,
      "learning_rate": 3.534224331751187e-05,
      "loss": 0.9993,
      "step": 47440
    },
    {
      "epoch": 2.95,
      "grad_norm": 8.578326225280762,
      "learning_rate": 3.533912065950537e-05,
      "loss": 1.018,
      "step": 47450
    },
    {
      "epoch": 2.95,
      "grad_norm": 11.865578651428223,
      "learning_rate": 3.533599800149888e-05,
      "loss": 0.9966,
      "step": 47460
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.727740287780762,
      "learning_rate": 3.5332875343492385e-05,
      "loss": 0.991,
      "step": 47470
    },
    {
      "epoch": 2.96,
      "grad_norm": 14.479262351989746,
      "learning_rate": 3.532975268548589e-05,
      "loss": 0.9847,
      "step": 47480
    },
    {
      "epoch": 2.96,
      "grad_norm": 13.697281837463379,
      "learning_rate": 3.532663002747939e-05,
      "loss": 1.069,
      "step": 47490
    },
    {
      "epoch": 2.96,
      "grad_norm": 12.288238525390625,
      "learning_rate": 3.53235073694729e-05,
      "loss": 0.9983,
      "step": 47500
    },
    {
      "epoch": 2.96,
      "grad_norm": 12.660965919494629,
      "learning_rate": 3.5320384711466406e-05,
      "loss": 1.0537,
      "step": 47510
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.096807479858398,
      "learning_rate": 3.5317262053459906e-05,
      "loss": 1.1053,
      "step": 47520
    },
    {
      "epoch": 2.96,
      "grad_norm": 13.905394554138184,
      "learning_rate": 3.531413939545341e-05,
      "loss": 1.0851,
      "step": 47530
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.843155384063721,
      "learning_rate": 3.531101673744692e-05,
      "loss": 0.9912,
      "step": 47540
    },
    {
      "epoch": 2.96,
      "grad_norm": 13.125173568725586,
      "learning_rate": 3.5307894079440426e-05,
      "loss": 0.9975,
      "step": 47550
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.18982219696045,
      "learning_rate": 3.5304771421433926e-05,
      "loss": 0.9862,
      "step": 47560
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.117908477783203,
      "learning_rate": 3.530164876342743e-05,
      "loss": 0.9857,
      "step": 47570
    },
    {
      "epoch": 2.96,
      "grad_norm": 10.16366195678711,
      "learning_rate": 3.529852610542094e-05,
      "loss": 1.0554,
      "step": 47580
    },
    {
      "epoch": 2.96,
      "grad_norm": 10.29614543914795,
      "learning_rate": 3.529540344741445e-05,
      "loss": 0.9942,
      "step": 47590
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.257901191711426,
      "learning_rate": 3.529228078940795e-05,
      "loss": 1.0437,
      "step": 47600
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.638237476348877,
      "learning_rate": 3.5289158131401454e-05,
      "loss": 1.0141,
      "step": 47610
    },
    {
      "epoch": 2.96,
      "grad_norm": 14.687801361083984,
      "learning_rate": 3.528603547339496e-05,
      "loss": 1.0206,
      "step": 47620
    },
    {
      "epoch": 2.97,
      "grad_norm": 9.831290245056152,
      "learning_rate": 3.528291281538846e-05,
      "loss": 1.0149,
      "step": 47630
    },
    {
      "epoch": 2.97,
      "grad_norm": 6.5407304763793945,
      "learning_rate": 3.527979015738197e-05,
      "loss": 1.0232,
      "step": 47640
    },
    {
      "epoch": 2.97,
      "grad_norm": 13.492330551147461,
      "learning_rate": 3.5276667499375474e-05,
      "loss": 1.0057,
      "step": 47650
    },
    {
      "epoch": 2.97,
      "grad_norm": 11.34505558013916,
      "learning_rate": 3.5273544841368974e-05,
      "loss": 1.0502,
      "step": 47660
    },
    {
      "epoch": 2.97,
      "grad_norm": 7.0303497314453125,
      "learning_rate": 3.527042218336248e-05,
      "loss": 1.074,
      "step": 47670
    },
    {
      "epoch": 2.97,
      "grad_norm": 10.39669418334961,
      "learning_rate": 3.526729952535599e-05,
      "loss": 1.1094,
      "step": 47680
    },
    {
      "epoch": 2.97,
      "grad_norm": 10.427891731262207,
      "learning_rate": 3.526417686734949e-05,
      "loss": 1.0874,
      "step": 47690
    },
    {
      "epoch": 2.97,
      "grad_norm": 10.34666633605957,
      "learning_rate": 3.5261054209342995e-05,
      "loss": 1.1812,
      "step": 47700
    },
    {
      "epoch": 2.97,
      "grad_norm": 7.141378879547119,
      "learning_rate": 3.52579315513365e-05,
      "loss": 0.9537,
      "step": 47710
    },
    {
      "epoch": 2.97,
      "grad_norm": 12.339536666870117,
      "learning_rate": 3.525480889333e-05,
      "loss": 1.0284,
      "step": 47720
    },
    {
      "epoch": 2.97,
      "grad_norm": 11.176285743713379,
      "learning_rate": 3.525168623532351e-05,
      "loss": 1.0201,
      "step": 47730
    },
    {
      "epoch": 2.97,
      "grad_norm": 10.60554313659668,
      "learning_rate": 3.5248563577317015e-05,
      "loss": 1.0429,
      "step": 47740
    },
    {
      "epoch": 2.97,
      "grad_norm": 9.519610404968262,
      "learning_rate": 3.5245440919310515e-05,
      "loss": 1.0432,
      "step": 47750
    },
    {
      "epoch": 2.97,
      "grad_norm": 11.441959381103516,
      "learning_rate": 3.524231826130402e-05,
      "loss": 0.9267,
      "step": 47760
    },
    {
      "epoch": 2.97,
      "grad_norm": 7.430098533630371,
      "learning_rate": 3.523919560329753e-05,
      "loss": 1.071,
      "step": 47770
    },
    {
      "epoch": 2.97,
      "grad_norm": 10.843611717224121,
      "learning_rate": 3.523607294529103e-05,
      "loss": 0.9816,
      "step": 47780
    },
    {
      "epoch": 2.98,
      "grad_norm": 9.381921768188477,
      "learning_rate": 3.5232950287284536e-05,
      "loss": 0.9578,
      "step": 47790
    },
    {
      "epoch": 2.98,
      "grad_norm": 14.431077003479004,
      "learning_rate": 3.522982762927804e-05,
      "loss": 1.0331,
      "step": 47800
    },
    {
      "epoch": 2.98,
      "grad_norm": 9.148946762084961,
      "learning_rate": 3.522670497127155e-05,
      "loss": 1.1026,
      "step": 47810
    },
    {
      "epoch": 2.98,
      "grad_norm": 9.080721855163574,
      "learning_rate": 3.522358231326505e-05,
      "loss": 1.1035,
      "step": 47820
    },
    {
      "epoch": 2.98,
      "grad_norm": 10.354645729064941,
      "learning_rate": 3.5220459655258556e-05,
      "loss": 1.0254,
      "step": 47830
    },
    {
      "epoch": 2.98,
      "grad_norm": 11.266054153442383,
      "learning_rate": 3.521733699725206e-05,
      "loss": 0.9648,
      "step": 47840
    },
    {
      "epoch": 2.98,
      "grad_norm": 10.333020210266113,
      "learning_rate": 3.521421433924556e-05,
      "loss": 0.9817,
      "step": 47850
    },
    {
      "epoch": 2.98,
      "grad_norm": 12.23745059967041,
      "learning_rate": 3.521109168123907e-05,
      "loss": 1.0375,
      "step": 47860
    },
    {
      "epoch": 2.98,
      "grad_norm": 9.82432746887207,
      "learning_rate": 3.5207969023232576e-05,
      "loss": 0.9051,
      "step": 47870
    },
    {
      "epoch": 2.98,
      "grad_norm": 21.020631790161133,
      "learning_rate": 3.5204846365226076e-05,
      "loss": 1.0942,
      "step": 47880
    },
    {
      "epoch": 2.98,
      "grad_norm": 11.733238220214844,
      "learning_rate": 3.520172370721958e-05,
      "loss": 0.9798,
      "step": 47890
    },
    {
      "epoch": 2.98,
      "grad_norm": 7.943516254425049,
      "learning_rate": 3.519860104921309e-05,
      "loss": 1.037,
      "step": 47900
    },
    {
      "epoch": 2.98,
      "grad_norm": 11.777877807617188,
      "learning_rate": 3.51954783912066e-05,
      "loss": 1.0775,
      "step": 47910
    },
    {
      "epoch": 2.98,
      "grad_norm": 7.26416540145874,
      "learning_rate": 3.51923557332001e-05,
      "loss": 1.0897,
      "step": 47920
    },
    {
      "epoch": 2.98,
      "grad_norm": 8.625224113464355,
      "learning_rate": 3.5189233075193604e-05,
      "loss": 0.96,
      "step": 47930
    },
    {
      "epoch": 2.98,
      "grad_norm": 10.286595344543457,
      "learning_rate": 3.518611041718711e-05,
      "loss": 1.1588,
      "step": 47940
    },
    {
      "epoch": 2.99,
      "grad_norm": 7.812926292419434,
      "learning_rate": 3.518298775918062e-05,
      "loss": 1.0458,
      "step": 47950
    },
    {
      "epoch": 2.99,
      "grad_norm": 10.719582557678223,
      "learning_rate": 3.517986510117412e-05,
      "loss": 1.026,
      "step": 47960
    },
    {
      "epoch": 2.99,
      "grad_norm": 13.404504776000977,
      "learning_rate": 3.5176742443167624e-05,
      "loss": 1.0101,
      "step": 47970
    },
    {
      "epoch": 2.99,
      "grad_norm": 11.945760726928711,
      "learning_rate": 3.517361978516113e-05,
      "loss": 1.0967,
      "step": 47980
    },
    {
      "epoch": 2.99,
      "grad_norm": 12.55801010131836,
      "learning_rate": 3.517049712715463e-05,
      "loss": 1.069,
      "step": 47990
    },
    {
      "epoch": 2.99,
      "grad_norm": 11.495302200317383,
      "learning_rate": 3.516737446914814e-05,
      "loss": 0.9736,
      "step": 48000
    },
    {
      "epoch": 2.99,
      "grad_norm": 11.798657417297363,
      "learning_rate": 3.5164251811141645e-05,
      "loss": 1.1059,
      "step": 48010
    },
    {
      "epoch": 2.99,
      "grad_norm": 12.495563507080078,
      "learning_rate": 3.516112915313515e-05,
      "loss": 0.9377,
      "step": 48020
    },
    {
      "epoch": 2.99,
      "grad_norm": 10.031283378601074,
      "learning_rate": 3.515800649512865e-05,
      "loss": 1.0371,
      "step": 48030
    },
    {
      "epoch": 2.99,
      "grad_norm": 7.8145036697387695,
      "learning_rate": 3.515488383712216e-05,
      "loss": 1.0049,
      "step": 48040
    },
    {
      "epoch": 2.99,
      "grad_norm": 9.952245712280273,
      "learning_rate": 3.5151761179115665e-05,
      "loss": 1.0576,
      "step": 48050
    },
    {
      "epoch": 2.99,
      "grad_norm": 8.659330368041992,
      "learning_rate": 3.5148638521109165e-05,
      "loss": 1.1232,
      "step": 48060
    },
    {
      "epoch": 2.99,
      "grad_norm": 14.87826919555664,
      "learning_rate": 3.514551586310267e-05,
      "loss": 0.959,
      "step": 48070
    },
    {
      "epoch": 2.99,
      "grad_norm": 7.795415878295898,
      "learning_rate": 3.514239320509618e-05,
      "loss": 1.0635,
      "step": 48080
    },
    {
      "epoch": 2.99,
      "grad_norm": 11.681674003601074,
      "learning_rate": 3.5139270547089686e-05,
      "loss": 1.0408,
      "step": 48090
    },
    {
      "epoch": 2.99,
      "grad_norm": 8.005143165588379,
      "learning_rate": 3.5136147889083186e-05,
      "loss": 0.9712,
      "step": 48100
    },
    {
      "epoch": 3.0,
      "grad_norm": 15.853752136230469,
      "learning_rate": 3.513302523107669e-05,
      "loss": 1.1649,
      "step": 48110
    },
    {
      "epoch": 3.0,
      "grad_norm": 12.08158016204834,
      "learning_rate": 3.51299025730702e-05,
      "loss": 1.0425,
      "step": 48120
    },
    {
      "epoch": 3.0,
      "grad_norm": 15.291145324707031,
      "learning_rate": 3.51267799150637e-05,
      "loss": 1.0731,
      "step": 48130
    },
    {
      "epoch": 3.0,
      "grad_norm": 14.444053649902344,
      "learning_rate": 3.5123657257057206e-05,
      "loss": 1.1354,
      "step": 48140
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.752904415130615,
      "learning_rate": 3.512053459905071e-05,
      "loss": 0.9827,
      "step": 48150
    },
    {
      "epoch": 3.0,
      "grad_norm": 8.341009140014648,
      "learning_rate": 3.511741194104422e-05,
      "loss": 1.0069,
      "step": 48160
    },
    {
      "epoch": 3.0,
      "grad_norm": 8.48146915435791,
      "learning_rate": 3.511428928303772e-05,
      "loss": 1.0491,
      "step": 48170
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.765453338623047,
      "learning_rate": 3.5111166625031226e-05,
      "loss": 0.9965,
      "step": 48180
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.2199325561523438,
      "eval_runtime": 324.3411,
      "eval_samples_per_second": 198.082,
      "eval_steps_per_second": 3.096,
      "step": 48186
    }
  ],
  "logging_steps": 10,
  "max_steps": 160620,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 8.760464918769917e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
